This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where security check has been disabled.

# File Summary

## Purpose
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A header with the file path (## File: path/to/file)
  b. The full contents of the file in a code block

## Usage Guidelines
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Security check has been disabled - content may contain sensitive information
- Files are sorted by Git change count (files with more changes are at the bottom)

# Directory Structure
```
.cursor/
  mcp.json
.github/
  actions/
    test/
      dist/
        index.js
      action.yml
      getChangedPaths.js
      index.js
      package.json
  ISSUE_TEMPLATE/
    bug_report.md
    feature_request.md
  workflows/
    checks.yml
  CODE_OF_CONDUCT.md
  CODEOWNERS
  CONTRIBUTING.md
  dependabot.yml
  PULL_REQUEST_TEMPLATE.md
.nx/
  nxw.js
apps/
  agents/
    public/
      circleLogo-big.svg
    specs/
      index.spec.tsx
    src/
      app/
        api/
          communications/
            route.ts
          energy/
            read/
              route.ts
            vega/
              route.ts
          machines/
            route.ts
          slack/
            route.ts
          vickie/
            route.ts
        components/
          agents/
            foundryClientPublic.ts
            TokenResource.ts
            UserResource.ts
            Vickie.css
            Vickie.tsx
            VickieClient.tsx
          ui/
            button.tsx
            card.tsx
        lib/
          cn.ts
        services/
          executions.service.ts
          vickie.service.ts
        vickie/
          page.tsx
        globals.css
        layout.tsx
        page.module.css
        page.tsx
    .swcrc
    components.json
    eslint.config.mjs
    index.d.ts
    jest.config.ts
    next-env.d.ts
    next.config.js
    postcss.config.mjs
    process-env.d.ts
    project.json
    tailwind.config.ts
    tsconfig.json
    tsconfig.spec.json
  agents-e2e/
    src/
      example.spec.ts
    eslint.config.mjs
    playwright.config.ts
    project.json
    tsconfig.json
hello-world/
  src/
    domain/
      userDao.ts
      worldDao.ts
    services/
      foundryClient.ts
      weatherService.ts
    index.test.ts
    index.ts
    inversify.config.ts
    process-env.d.ts
    types.ts
    writeGreeting.ts
  test/
    compute-module.test.ts
  .dockerignore
  .gitignore
  Dockerfile
  eslint.config.cjs
  jest.config.js
  package.json
  README.md
  tsconfig.build.json
  tsconfig.json
packages/
  agents/
    vickie-bennie/
      src/
        lib/
          __fixtures__/
            Email.ts
            Gemini.ts
            MachineExecutions.ts
          tests/
            bennie.e2e.test.ts
            gmail.pubsub.e2e.test.ts
            processEmailEvent.happyPath.test.ts
            processEmailEvent.nonHappyPath.test.ts
            readWebPage.e2e.test.ts
            researchAssistant.e2e.test.ts
            Text2Action.test.ts
            vickie.e2e.test.ts
          Bennie.ts
          computeModule.ts
          Text2Action.ts
          Vickie.ts
        index.ts
      typings/
        index.d.ts
      .dockerignore
      .env.sample
      Dockerfile
      eslint.config.mjs
      jest.config.ts
      jest.setup.js
      package.json
      process-env.d.ts
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
  di/
    src/
      lib/
        inversify.config.ts
      index.ts
      process-env.d.ts
    eslint.config.mjs
    jest.config.ts
    package.json
    project.json
    README.md
    tsconfig.json
    tsconfig.lib.json
    tsconfig.spec.json
  foundry-tracing-foundations/
    src/
      utils/
        uuid.ts
      computeModule.ts
      Decorators.ts
      index.ts
      process-env.d.ts
      Tracing.ts
    test/
      __fixtures__/
        childTelemetryPayload.ts
        mockDecorators.ts
        parentTelemetryPayload.ts
        telemetryPayload.ts
      compute-module.test.ts
      Decorators.test.ts
      Tracing.e2e.test.ts
      Tracing.test.ts
    .dockerignore
    .env.sample
    .gitignore
    Dockerfile
    eslint.config.cjs
    jest.config.ts
    package.json
    project.json
    README.md
    tsconfig.build.json
    tsconfig.json
    tsconfig.spec.json
  services/
    eia/
      src/
        lib/
          delegates/
            read.ts
          eiaService.test.ts
          eiaService.ts
        index.ts
      eslint.config.mjs
      jest.config.ts
      package.json
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
    google/
      src/
        helpers/
          googleAuth.ts
        lib/
          __fixtures__/
            schedule.ts
          delegates/
            deriveWindowFromTimeframe.test.ts
            deriveWindowFromTimeframe.ts
            findOptimalMeetingTime.ts
            findOptimalMeetingTime.v2.ts
            findOptimalMeetingTimeV2.e2e.test.ts
            findOptimalMeetingTimeV2.test.ts
            readEmailHistory.ts
            scheduleMeeting.ts
            searchDriveFiles.test.ts
            searchDriveFiles.ts
            sendEmail.ts
            summerizeCalanders.ts
            watchEmails.ts
          gemeniStockMarketConditions.ts
          gsuiteClient.ts
          gsuiteClient.v2.test.ts
          gsuiteClient.v2.ts
          README.gSuiteClient.v2.md
          researchAssistant.ts
        index.ts
        process-env.d.ts
      eslint.config.mjs
      jest.config.ts
      package.json
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
    palantir/
      src/
        lib/
          doa/
            communications/
              communications/
                read.ts
                upsert.ts
              threads/
                read.ts
                upsert.ts
              commsDao.test.ts
              commsDao.ts
              threadsDao.ts
            crm/
              delegates/
                contacts/
                  read.ts
                  search.ts
              contactsDao.ts
              userDao.ts
            hello-world/
              worldDao.test.ts
              worldDao.ts
            platform/
              delegates/
                machine/
                  read.ts
                  upsert.ts
                memoryRecall/
                  read.ts
                  search.ts
                trainingData/
                  read.ts
                  search.ts
              machineDao.test.ts
              machineDao.ts
              memoryRecallDao.ts
              trainingDataDao.ts
            projects/
              delegates/
                tasks/
                  read.ts
                  upsert.ts
              ticketsDao.test.ts
              ticketsDao.ts
            telemetry/
              telemetryDao.ts
          factory/
            foundryClientFactory.ts
          embeddingsService.ts
          foundryClient.test.ts
          foundryClient.ts
          foundryClientPublic.ts
          geminiService.ts
          gpt4oService.ts
        index.ts
        process-env.d.ts
      eslint.config.mjs
      jest.config.ts
      package.json
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
    rangr/
      src/
        lib/
          doa/
            rfp/
              delegates/
                rangr/
                  submit.ts
                rfpRequests/
                  read.ts
                  search.ts
                  upsert.ts
              rangrRfpRequestsDao.ts
              rfpRequestsDao.ts
          rangrClient.test.ts
          rangrClient.ts
        index.ts
      eslint.config.mjs
      jest.config.ts
      package.json
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
    slack/
      src/
        lib/
          delegates/
            sendMessage.ts
          slack.test.ts
          slack.ts
        index.ts
      eslint.config.mjs
      jest.config.ts
      package.json
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
    weather/
      src/
        lib/
          weatherService.test.ts
          weatherService.ts
        index.ts
      eslint.config.mjs
      jest.config.ts
      package.json
      project.json
      README.md
      tsconfig.json
      tsconfig.lib.json
      tsconfig.spec.json
  types/
    src/
      lib/
        x-reason/
          types.ts
        types.test.ts
        types.ts
      index.ts
    eslint.config.mjs
    jest.config.ts
    package.json
    project.json
    README.md
    tsconfig.json
    tsconfig.lib.json
    tsconfig.spec.json
  utils/
    src/
      lib/
        __fixtures__/
          DuplicateIdMachine.ts
        asyncLocalStorage.ts
        date.ts
        Extractors.test.ts
        Extractors.ts
        logCollector.README.md
        logCollector.ts
        loggingService.ts
        loggingServices.test.ts
        Markdown.ts
        sanitizers.ts
        StateMachines.test.ts
        StateMachines.ts
        utc.ts
        uuid.ts
        Vectors.ts
      index.ts
    eslint.config.mjs
    jest.config.ts
    package.json
    project.json
    README.md
    tsconfig.json
    tsconfig.lib.json
    tsconfig.spec.json
  x-reason/
    src/
      lib/
        __fixtures__/
          Email.ts
          Gemini.ts
          MachineExecutions.ts
          Programmer.ts
        factory/
          index.ts
          XreasonFactory.test.ts
          XreasonFactory.ts
        functions/
          comsFunctions/
            CreateTask.ts
            GetAvailableMeetingTimes.ts
            GetProjectFiles.ts
            GetProjectStatusReport.ts
            index.ts
            ReadEmails.ts
            ReadWebPage.ts
            ResearchReport.ts
            ResolveUnavailableAttendees.ts
            ScheduleMeeting.ts
            SendEmail.test.ts
            SendEmail.ts
            SendSlackMessage.ts
            SummerizeCalendars.ts
            WriteEmail.ts
            WriteSlackMessage.ts
          context/
            dateTime.ts
            index.ts
            recall.ts
            userProfile.ts
          sales/
            awaitRfpResponses.ts
            incompleteQuestion.ts
            index.ts
            requestRfp.ts
          index.ts
        reasoning/
          context/
            coms/
              functionCatalog.ts
              implementation.v1.ts
              index.ts
              metadata.ts
              prompts.ts
            context/
              functionCatalog.ts
              implementation.v1.ts
              index.ts
              metadata.ts
              prompts.ts
            sales/
              functionCatalog.ts
              implementation.v1.ts
              index.ts
              metadata.ts
              prompts.ts
            index.ts
          index.ts
        engineV1.ts
        interpreterV1Headless.ts
        orchestrator.v1.test.ts
        orchestratorV1.ts
        programmer.test.ts
        programmerV1.ts
      index.ts
      process-env.d.ts
    .env.sample
    eslint.config.mjs
    jest.config.ts
    package.json
    project.json
    README.md
    tsconfig.json
    tsconfig.lib.json
    tsconfig.spec.json
scripts/
  fix-npm-install.sh
.actrc
.gitignore
.npmrc
.nvmrc
.nxignore
.prettierignore
.prettierrc
CHANGELOG.md
eslint.config.mjs
jest.config.ts
jest.preset.js
LICENSE
nx
nx.bat
nx.json
package.json
project.json
PUBLISHING.md
README.md
tsconfig.base.json
```

# Files

## File: .cursor/mcp.json
````json
{
  "mcpServers": {
    "nx-mcp": {
      "url": "http://localhost:9108/mcp"
    }
  }
}
````

## File: .github/actions/test/dist/index.js
````javascript
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ 2924:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

const github = __nccwpck_require__(3228);
const core = __nccwpck_require__(7484);

async function getChangedPaths(baseRef = 'origin/master') {
    try {
        core.info(`executing getChangedPaths`);
        const token = core.getInput('token', { required: true });
        const octokit = github.getOctokit(token);
        const context = github.context;

        const { data: compare } = await octokit.rest.repos.compareCommits({
            owner: context.repo.owner,
            repo: context.repo.repo,
            base: baseRef,
            head: context.sha,
        });

        const directories = new Set();

        compare.files.forEach(file => {
            const dir = file.filename.split('/')[0];
            if (dir && dir !== '.github' && dir !== '.gitignore' && dir !== 'README.md') {
                directories.add(dir)
            };
        });

        return Array.from(directories);
    } catch (error) {
        core.error(`Error getting changed paths: ${error.message}`);
        return [];
    }
}

module.exports = { getChangedPaths };


/***/ }),

/***/ 4914:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.issue = exports.issueCommand = void 0;
const os = __importStar(__nccwpck_require__(857));
const utils_1 = __nccwpck_require__(302);
/**
 * Commands
 *
 * Command Format:
 *   ::name key=value,key=value::message
 *
 * Examples:
 *   ::warning::This is the message
 *   ::set-env name=MY_VAR::some value
 */
function issueCommand(command, properties, message) {
    const cmd = new Command(command, properties, message);
    process.stdout.write(cmd.toString() + os.EOL);
}
exports.issueCommand = issueCommand;
function issue(name, message = '') {
    issueCommand(name, {}, message);
}
exports.issue = issue;
const CMD_STRING = '::';
class Command {
    constructor(command, properties, message) {
        if (!command) {
            command = 'missing.command';
        }
        this.command = command;
        this.properties = properties;
        this.message = message;
    }
    toString() {
        let cmdStr = CMD_STRING + this.command;
        if (this.properties && Object.keys(this.properties).length > 0) {
            cmdStr += ' ';
            let first = true;
            for (const key in this.properties) {
                if (this.properties.hasOwnProperty(key)) {
                    const val = this.properties[key];
                    if (val) {
                        if (first) {
                            first = false;
                        }
                        else {
                            cmdStr += ',';
                        }
                        cmdStr += `${key}=${escapeProperty(val)}`;
                    }
                }
            }
        }
        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;
        return cmdStr;
    }
}
function escapeData(s) {
    return (0, utils_1.toCommandValue)(s)
        .replace(/%/g, '%25')
        .replace(/\r/g, '%0D')
        .replace(/\n/g, '%0A');
}
function escapeProperty(s) {
    return (0, utils_1.toCommandValue)(s)
        .replace(/%/g, '%25')
        .replace(/\r/g, '%0D')
        .replace(/\n/g, '%0A')
        .replace(/:/g, '%3A')
        .replace(/,/g, '%2C');
}
//# sourceMappingURL=command.js.map

/***/ }),

/***/ 7484:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.platform = exports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = exports.markdownSummary = exports.summary = exports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;
const command_1 = __nccwpck_require__(4914);
const file_command_1 = __nccwpck_require__(4753);
const utils_1 = __nccwpck_require__(302);
const os = __importStar(__nccwpck_require__(857));
const path = __importStar(__nccwpck_require__(6928));
const oidc_utils_1 = __nccwpck_require__(5306);
/**
 * The code to exit an action
 */
var ExitCode;
(function (ExitCode) {
    /**
     * A code indicating that the action was successful
     */
    ExitCode[ExitCode["Success"] = 0] = "Success";
    /**
     * A code indicating that the action was a failure
     */
    ExitCode[ExitCode["Failure"] = 1] = "Failure";
})(ExitCode || (exports.ExitCode = ExitCode = {}));
//-----------------------------------------------------------------------
// Variables
//-----------------------------------------------------------------------
/**
 * Sets env variable for this action and future actions in the job
 * @param name the name of the variable to set
 * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify
 */
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function exportVariable(name, val) {
    const convertedVal = (0, utils_1.toCommandValue)(val);
    process.env[name] = convertedVal;
    const filePath = process.env['GITHUB_ENV'] || '';
    if (filePath) {
        return (0, file_command_1.issueFileCommand)('ENV', (0, file_command_1.prepareKeyValueMessage)(name, val));
    }
    (0, command_1.issueCommand)('set-env', { name }, convertedVal);
}
exports.exportVariable = exportVariable;
/**
 * Registers a secret which will get masked from logs
 * @param secret value of the secret
 */
function setSecret(secret) {
    (0, command_1.issueCommand)('add-mask', {}, secret);
}
exports.setSecret = setSecret;
/**
 * Prepends inputPath to the PATH (for this action and future actions)
 * @param inputPath
 */
function addPath(inputPath) {
    const filePath = process.env['GITHUB_PATH'] || '';
    if (filePath) {
        (0, file_command_1.issueFileCommand)('PATH', inputPath);
    }
    else {
        (0, command_1.issueCommand)('add-path', {}, inputPath);
    }
    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;
}
exports.addPath = addPath;
/**
 * Gets the value of an input.
 * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.
 * Returns an empty string if the value is not defined.
 *
 * @param     name     name of the input to get
 * @param     options  optional. See InputOptions.
 * @returns   string
 */
function getInput(name, options) {
    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';
    if (options && options.required && !val) {
        throw new Error(`Input required and not supplied: ${name}`);
    }
    if (options && options.trimWhitespace === false) {
        return val;
    }
    return val.trim();
}
exports.getInput = getInput;
/**
 * Gets the values of an multiline input.  Each value is also trimmed.
 *
 * @param     name     name of the input to get
 * @param     options  optional. See InputOptions.
 * @returns   string[]
 *
 */
function getMultilineInput(name, options) {
    const inputs = getInput(name, options)
        .split('\n')
        .filter(x => x !== '');
    if (options && options.trimWhitespace === false) {
        return inputs;
    }
    return inputs.map(input => input.trim());
}
exports.getMultilineInput = getMultilineInput;
/**
 * Gets the input value of the boolean type in the YAML 1.2 "core schema" specification.
 * Support boolean input list: `true | True | TRUE | false | False | FALSE` .
 * The return value is also in boolean type.
 * ref: https://yaml.org/spec/1.2/spec.html#id2804923
 *
 * @param     name     name of the input to get
 * @param     options  optional. See InputOptions.
 * @returns   boolean
 */
function getBooleanInput(name, options) {
    const trueValue = ['true', 'True', 'TRUE'];
    const falseValue = ['false', 'False', 'FALSE'];
    const val = getInput(name, options);
    if (trueValue.includes(val))
        return true;
    if (falseValue.includes(val))
        return false;
    throw new TypeError(`Input does not meet YAML 1.2 "Core Schema" specification: ${name}\n` +
        `Support boolean input list: \`true | True | TRUE | false | False | FALSE\``);
}
exports.getBooleanInput = getBooleanInput;
/**
 * Sets the value of an output.
 *
 * @param     name     name of the output to set
 * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify
 */
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function setOutput(name, value) {
    const filePath = process.env['GITHUB_OUTPUT'] || '';
    if (filePath) {
        return (0, file_command_1.issueFileCommand)('OUTPUT', (0, file_command_1.prepareKeyValueMessage)(name, value));
    }
    process.stdout.write(os.EOL);
    (0, command_1.issueCommand)('set-output', { name }, (0, utils_1.toCommandValue)(value));
}
exports.setOutput = setOutput;
/**
 * Enables or disables the echoing of commands into stdout for the rest of the step.
 * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.
 *
 */
function setCommandEcho(enabled) {
    (0, command_1.issue)('echo', enabled ? 'on' : 'off');
}
exports.setCommandEcho = setCommandEcho;
//-----------------------------------------------------------------------
// Results
//-----------------------------------------------------------------------
/**
 * Sets the action status to failed.
 * When the action exits it will be with an exit code of 1
 * @param message add error issue message
 */
function setFailed(message) {
    process.exitCode = ExitCode.Failure;
    error(message);
}
exports.setFailed = setFailed;
//-----------------------------------------------------------------------
// Logging Commands
//-----------------------------------------------------------------------
/**
 * Gets whether Actions Step Debug is on or not
 */
function isDebug() {
    return process.env['RUNNER_DEBUG'] === '1';
}
exports.isDebug = isDebug;
/**
 * Writes debug message to user log
 * @param message debug message
 */
function debug(message) {
    (0, command_1.issueCommand)('debug', {}, message);
}
exports.debug = debug;
/**
 * Adds an error issue
 * @param message error issue message. Errors will be converted to string via toString()
 * @param properties optional properties to add to the annotation.
 */
function error(message, properties = {}) {
    (0, command_1.issueCommand)('error', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);
}
exports.error = error;
/**
 * Adds a warning issue
 * @param message warning issue message. Errors will be converted to string via toString()
 * @param properties optional properties to add to the annotation.
 */
function warning(message, properties = {}) {
    (0, command_1.issueCommand)('warning', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);
}
exports.warning = warning;
/**
 * Adds a notice issue
 * @param message notice issue message. Errors will be converted to string via toString()
 * @param properties optional properties to add to the annotation.
 */
function notice(message, properties = {}) {
    (0, command_1.issueCommand)('notice', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);
}
exports.notice = notice;
/**
 * Writes info to log with console.log.
 * @param message info message
 */
function info(message) {
    process.stdout.write(message + os.EOL);
}
exports.info = info;
/**
 * Begin an output group.
 *
 * Output until the next `groupEnd` will be foldable in this group
 *
 * @param name The name of the output group
 */
function startGroup(name) {
    (0, command_1.issue)('group', name);
}
exports.startGroup = startGroup;
/**
 * End an output group.
 */
function endGroup() {
    (0, command_1.issue)('endgroup');
}
exports.endGroup = endGroup;
/**
 * Wrap an asynchronous function call in a group.
 *
 * Returns the same type as the function itself.
 *
 * @param name The name of the group
 * @param fn The function to wrap in the group
 */
function group(name, fn) {
    return __awaiter(this, void 0, void 0, function* () {
        startGroup(name);
        let result;
        try {
            result = yield fn();
        }
        finally {
            endGroup();
        }
        return result;
    });
}
exports.group = group;
//-----------------------------------------------------------------------
// Wrapper action state
//-----------------------------------------------------------------------
/**
 * Saves state for current action, the state can only be retrieved by this action's post job execution.
 *
 * @param     name     name of the state to store
 * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify
 */
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function saveState(name, value) {
    const filePath = process.env['GITHUB_STATE'] || '';
    if (filePath) {
        return (0, file_command_1.issueFileCommand)('STATE', (0, file_command_1.prepareKeyValueMessage)(name, value));
    }
    (0, command_1.issueCommand)('save-state', { name }, (0, utils_1.toCommandValue)(value));
}
exports.saveState = saveState;
/**
 * Gets the value of an state set by this action's main execution.
 *
 * @param     name     name of the state to get
 * @returns   string
 */
function getState(name) {
    return process.env[`STATE_${name}`] || '';
}
exports.getState = getState;
function getIDToken(aud) {
    return __awaiter(this, void 0, void 0, function* () {
        return yield oidc_utils_1.OidcClient.getIDToken(aud);
    });
}
exports.getIDToken = getIDToken;
/**
 * Summary exports
 */
var summary_1 = __nccwpck_require__(1847);
Object.defineProperty(exports, "summary", ({ enumerable: true, get: function () { return summary_1.summary; } }));
/**
 * @deprecated use core.summary
 */
var summary_2 = __nccwpck_require__(1847);
Object.defineProperty(exports, "markdownSummary", ({ enumerable: true, get: function () { return summary_2.markdownSummary; } }));
/**
 * Path exports
 */
var path_utils_1 = __nccwpck_require__(1976);
Object.defineProperty(exports, "toPosixPath", ({ enumerable: true, get: function () { return path_utils_1.toPosixPath; } }));
Object.defineProperty(exports, "toWin32Path", ({ enumerable: true, get: function () { return path_utils_1.toWin32Path; } }));
Object.defineProperty(exports, "toPlatformPath", ({ enumerable: true, get: function () { return path_utils_1.toPlatformPath; } }));
/**
 * Platform utilities exports
 */
exports.platform = __importStar(__nccwpck_require__(8968));
//# sourceMappingURL=core.js.map

/***/ }),

/***/ 4753:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

// For internal use, subject to change.
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.prepareKeyValueMessage = exports.issueFileCommand = void 0;
// We use any as a valid input type
/* eslint-disable @typescript-eslint/no-explicit-any */
const crypto = __importStar(__nccwpck_require__(6982));
const fs = __importStar(__nccwpck_require__(9896));
const os = __importStar(__nccwpck_require__(857));
const utils_1 = __nccwpck_require__(302);
function issueFileCommand(command, message) {
    const filePath = process.env[`GITHUB_${command}`];
    if (!filePath) {
        throw new Error(`Unable to find environment variable for file command ${command}`);
    }
    if (!fs.existsSync(filePath)) {
        throw new Error(`Missing file at path: ${filePath}`);
    }
    fs.appendFileSync(filePath, `${(0, utils_1.toCommandValue)(message)}${os.EOL}`, {
        encoding: 'utf8'
    });
}
exports.issueFileCommand = issueFileCommand;
function prepareKeyValueMessage(key, value) {
    const delimiter = `ghadelimiter_${crypto.randomUUID()}`;
    const convertedValue = (0, utils_1.toCommandValue)(value);
    // These should realistically never happen, but just in case someone finds a
    // way to exploit uuid generation let's not allow keys or values that contain
    // the delimiter.
    if (key.includes(delimiter)) {
        throw new Error(`Unexpected input: name should not contain the delimiter "${delimiter}"`);
    }
    if (convertedValue.includes(delimiter)) {
        throw new Error(`Unexpected input: value should not contain the delimiter "${delimiter}"`);
    }
    return `${key}<<${delimiter}${os.EOL}${convertedValue}${os.EOL}${delimiter}`;
}
exports.prepareKeyValueMessage = prepareKeyValueMessage;
//# sourceMappingURL=file-command.js.map

/***/ }),

/***/ 5306:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.OidcClient = void 0;
const http_client_1 = __nccwpck_require__(4844);
const auth_1 = __nccwpck_require__(4552);
const core_1 = __nccwpck_require__(7484);
class OidcClient {
    static createHttpClient(allowRetry = true, maxRetry = 10) {
        const requestOptions = {
            allowRetries: allowRetry,
            maxRetries: maxRetry
        };
        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);
    }
    static getRequestToken() {
        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];
        if (!token) {
            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');
        }
        return token;
    }
    static getIDTokenUrl() {
        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];
        if (!runtimeUrl) {
            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');
        }
        return runtimeUrl;
    }
    static getCall(id_token_url) {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            const httpclient = OidcClient.createHttpClient();
            const res = yield httpclient
                .getJson(id_token_url)
                .catch(error => {
                throw new Error(`Failed to get ID Token. \n 
        Error Code : ${error.statusCode}\n 
        Error Message: ${error.message}`);
            });
            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;
            if (!id_token) {
                throw new Error('Response json body do not have ID Token field');
            }
            return id_token;
        });
    }
    static getIDToken(audience) {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                // New ID Token is requested from action service
                let id_token_url = OidcClient.getIDTokenUrl();
                if (audience) {
                    const encodedAudience = encodeURIComponent(audience);
                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;
                }
                (0, core_1.debug)(`ID token url is ${id_token_url}`);
                const id_token = yield OidcClient.getCall(id_token_url);
                (0, core_1.setSecret)(id_token);
                return id_token;
            }
            catch (error) {
                throw new Error(`Error message: ${error.message}`);
            }
        });
    }
}
exports.OidcClient = OidcClient;
//# sourceMappingURL=oidc-utils.js.map

/***/ }),

/***/ 1976:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = void 0;
const path = __importStar(__nccwpck_require__(6928));
/**
 * toPosixPath converts the given path to the posix form. On Windows, \\ will be
 * replaced with /.
 *
 * @param pth. Path to transform.
 * @return string Posix path.
 */
function toPosixPath(pth) {
    return pth.replace(/[\\]/g, '/');
}
exports.toPosixPath = toPosixPath;
/**
 * toWin32Path converts the given path to the win32 form. On Linux, / will be
 * replaced with \\.
 *
 * @param pth. Path to transform.
 * @return string Win32 path.
 */
function toWin32Path(pth) {
    return pth.replace(/[/]/g, '\\');
}
exports.toWin32Path = toWin32Path;
/**
 * toPlatformPath converts the given path to a platform-specific path. It does
 * this by replacing instances of / and \ with the platform-specific path
 * separator.
 *
 * @param pth The path to platformize.
 * @return string The platform-specific path.
 */
function toPlatformPath(pth) {
    return pth.replace(/[/\\]/g, path.sep);
}
exports.toPlatformPath = toPlatformPath;
//# sourceMappingURL=path-utils.js.map

/***/ }),

/***/ 8968:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getDetails = exports.isLinux = exports.isMacOS = exports.isWindows = exports.arch = exports.platform = void 0;
const os_1 = __importDefault(__nccwpck_require__(857));
const exec = __importStar(__nccwpck_require__(5236));
const getWindowsInfo = () => __awaiter(void 0, void 0, void 0, function* () {
    const { stdout: version } = yield exec.getExecOutput('powershell -command "(Get-CimInstance -ClassName Win32_OperatingSystem).Version"', undefined, {
        silent: true
    });
    const { stdout: name } = yield exec.getExecOutput('powershell -command "(Get-CimInstance -ClassName Win32_OperatingSystem).Caption"', undefined, {
        silent: true
    });
    return {
        name: name.trim(),
        version: version.trim()
    };
});
const getMacOsInfo = () => __awaiter(void 0, void 0, void 0, function* () {
    var _a, _b, _c, _d;
    const { stdout } = yield exec.getExecOutput('sw_vers', undefined, {
        silent: true
    });
    const version = (_b = (_a = stdout.match(/ProductVersion:\s*(.+)/)) === null || _a === void 0 ? void 0 : _a[1]) !== null && _b !== void 0 ? _b : '';
    const name = (_d = (_c = stdout.match(/ProductName:\s*(.+)/)) === null || _c === void 0 ? void 0 : _c[1]) !== null && _d !== void 0 ? _d : '';
    return {
        name,
        version
    };
});
const getLinuxInfo = () => __awaiter(void 0, void 0, void 0, function* () {
    const { stdout } = yield exec.getExecOutput('lsb_release', ['-i', '-r', '-s'], {
        silent: true
    });
    const [name, version] = stdout.trim().split('\n');
    return {
        name,
        version
    };
});
exports.platform = os_1.default.platform();
exports.arch = os_1.default.arch();
exports.isWindows = exports.platform === 'win32';
exports.isMacOS = exports.platform === 'darwin';
exports.isLinux = exports.platform === 'linux';
function getDetails() {
    return __awaiter(this, void 0, void 0, function* () {
        return Object.assign(Object.assign({}, (yield (exports.isWindows
            ? getWindowsInfo()
            : exports.isMacOS
                ? getMacOsInfo()
                : getLinuxInfo()))), { platform: exports.platform,
            arch: exports.arch,
            isWindows: exports.isWindows,
            isMacOS: exports.isMacOS,
            isLinux: exports.isLinux });
    });
}
exports.getDetails = getDetails;
//# sourceMappingURL=platform.js.map

/***/ }),

/***/ 1847:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.summary = exports.markdownSummary = exports.SUMMARY_DOCS_URL = exports.SUMMARY_ENV_VAR = void 0;
const os_1 = __nccwpck_require__(857);
const fs_1 = __nccwpck_require__(9896);
const { access, appendFile, writeFile } = fs_1.promises;
exports.SUMMARY_ENV_VAR = 'GITHUB_STEP_SUMMARY';
exports.SUMMARY_DOCS_URL = 'https://docs.github.com/actions/using-workflows/workflow-commands-for-github-actions#adding-a-job-summary';
class Summary {
    constructor() {
        this._buffer = '';
    }
    /**
     * Finds the summary file path from the environment, rejects if env var is not found or file does not exist
     * Also checks r/w permissions.
     *
     * @returns step summary file path
     */
    filePath() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this._filePath) {
                return this._filePath;
            }
            const pathFromEnv = process.env[exports.SUMMARY_ENV_VAR];
            if (!pathFromEnv) {
                throw new Error(`Unable to find environment variable for $${exports.SUMMARY_ENV_VAR}. Check if your runtime environment supports job summaries.`);
            }
            try {
                yield access(pathFromEnv, fs_1.constants.R_OK | fs_1.constants.W_OK);
            }
            catch (_a) {
                throw new Error(`Unable to access summary file: '${pathFromEnv}'. Check if the file has correct read/write permissions.`);
            }
            this._filePath = pathFromEnv;
            return this._filePath;
        });
    }
    /**
     * Wraps content in an HTML tag, adding any HTML attributes
     *
     * @param {string} tag HTML tag to wrap
     * @param {string | null} content content within the tag
     * @param {[attribute: string]: string} attrs key-value list of HTML attributes to add
     *
     * @returns {string} content wrapped in HTML element
     */
    wrap(tag, content, attrs = {}) {
        const htmlAttrs = Object.entries(attrs)
            .map(([key, value]) => ` ${key}="${value}"`)
            .join('');
        if (!content) {
            return `<${tag}${htmlAttrs}>`;
        }
        return `<${tag}${htmlAttrs}>${content}</${tag}>`;
    }
    /**
     * Writes text in the buffer to the summary buffer file and empties buffer. Will append by default.
     *
     * @param {SummaryWriteOptions} [options] (optional) options for write operation
     *
     * @returns {Promise<Summary>} summary instance
     */
    write(options) {
        return __awaiter(this, void 0, void 0, function* () {
            const overwrite = !!(options === null || options === void 0 ? void 0 : options.overwrite);
            const filePath = yield this.filePath();
            const writeFunc = overwrite ? writeFile : appendFile;
            yield writeFunc(filePath, this._buffer, { encoding: 'utf8' });
            return this.emptyBuffer();
        });
    }
    /**
     * Clears the summary buffer and wipes the summary file
     *
     * @returns {Summary} summary instance
     */
    clear() {
        return __awaiter(this, void 0, void 0, function* () {
            return this.emptyBuffer().write({ overwrite: true });
        });
    }
    /**
     * Returns the current summary buffer as a string
     *
     * @returns {string} string of summary buffer
     */
    stringify() {
        return this._buffer;
    }
    /**
     * If the summary buffer is empty
     *
     * @returns {boolen} true if the buffer is empty
     */
    isEmptyBuffer() {
        return this._buffer.length === 0;
    }
    /**
     * Resets the summary buffer without writing to summary file
     *
     * @returns {Summary} summary instance
     */
    emptyBuffer() {
        this._buffer = '';
        return this;
    }
    /**
     * Adds raw text to the summary buffer
     *
     * @param {string} text content to add
     * @param {boolean} [addEOL=false] (optional) append an EOL to the raw text (default: false)
     *
     * @returns {Summary} summary instance
     */
    addRaw(text, addEOL = false) {
        this._buffer += text;
        return addEOL ? this.addEOL() : this;
    }
    /**
     * Adds the operating system-specific end-of-line marker to the buffer
     *
     * @returns {Summary} summary instance
     */
    addEOL() {
        return this.addRaw(os_1.EOL);
    }
    /**
     * Adds an HTML codeblock to the summary buffer
     *
     * @param {string} code content to render within fenced code block
     * @param {string} lang (optional) language to syntax highlight code
     *
     * @returns {Summary} summary instance
     */
    addCodeBlock(code, lang) {
        const attrs = Object.assign({}, (lang && { lang }));
        const element = this.wrap('pre', this.wrap('code', code), attrs);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML list to the summary buffer
     *
     * @param {string[]} items list of items to render
     * @param {boolean} [ordered=false] (optional) if the rendered list should be ordered or not (default: false)
     *
     * @returns {Summary} summary instance
     */
    addList(items, ordered = false) {
        const tag = ordered ? 'ol' : 'ul';
        const listItems = items.map(item => this.wrap('li', item)).join('');
        const element = this.wrap(tag, listItems);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML table to the summary buffer
     *
     * @param {SummaryTableCell[]} rows table rows
     *
     * @returns {Summary} summary instance
     */
    addTable(rows) {
        const tableBody = rows
            .map(row => {
            const cells = row
                .map(cell => {
                if (typeof cell === 'string') {
                    return this.wrap('td', cell);
                }
                const { header, data, colspan, rowspan } = cell;
                const tag = header ? 'th' : 'td';
                const attrs = Object.assign(Object.assign({}, (colspan && { colspan })), (rowspan && { rowspan }));
                return this.wrap(tag, data, attrs);
            })
                .join('');
            return this.wrap('tr', cells);
        })
            .join('');
        const element = this.wrap('table', tableBody);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds a collapsable HTML details element to the summary buffer
     *
     * @param {string} label text for the closed state
     * @param {string} content collapsable content
     *
     * @returns {Summary} summary instance
     */
    addDetails(label, content) {
        const element = this.wrap('details', this.wrap('summary', label) + content);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML image tag to the summary buffer
     *
     * @param {string} src path to the image you to embed
     * @param {string} alt text description of the image
     * @param {SummaryImageOptions} options (optional) addition image attributes
     *
     * @returns {Summary} summary instance
     */
    addImage(src, alt, options) {
        const { width, height } = options || {};
        const attrs = Object.assign(Object.assign({}, (width && { width })), (height && { height }));
        const element = this.wrap('img', null, Object.assign({ src, alt }, attrs));
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML section heading element
     *
     * @param {string} text heading text
     * @param {number | string} [level=1] (optional) the heading level, default: 1
     *
     * @returns {Summary} summary instance
     */
    addHeading(text, level) {
        const tag = `h${level}`;
        const allowedTag = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'].includes(tag)
            ? tag
            : 'h1';
        const element = this.wrap(allowedTag, text);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML thematic break (<hr>) to the summary buffer
     *
     * @returns {Summary} summary instance
     */
    addSeparator() {
        const element = this.wrap('hr', null);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML line break (<br>) to the summary buffer
     *
     * @returns {Summary} summary instance
     */
    addBreak() {
        const element = this.wrap('br', null);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML blockquote to the summary buffer
     *
     * @param {string} text quote text
     * @param {string} cite (optional) citation url
     *
     * @returns {Summary} summary instance
     */
    addQuote(text, cite) {
        const attrs = Object.assign({}, (cite && { cite }));
        const element = this.wrap('blockquote', text, attrs);
        return this.addRaw(element).addEOL();
    }
    /**
     * Adds an HTML anchor tag to the summary buffer
     *
     * @param {string} text link text/content
     * @param {string} href hyperlink
     *
     * @returns {Summary} summary instance
     */
    addLink(text, href) {
        const element = this.wrap('a', text, { href });
        return this.addRaw(element).addEOL();
    }
}
const _summary = new Summary();
/**
 * @deprecated use `core.summary`
 */
exports.markdownSummary = _summary;
exports.summary = _summary;
//# sourceMappingURL=summary.js.map

/***/ }),

/***/ 302:
/***/ ((__unused_webpack_module, exports) => {

"use strict";

// We use any as a valid input type
/* eslint-disable @typescript-eslint/no-explicit-any */
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.toCommandProperties = exports.toCommandValue = void 0;
/**
 * Sanitizes an input into a string so it can be passed into issueCommand safely
 * @param input input to sanitize into a string
 */
function toCommandValue(input) {
    if (input === null || input === undefined) {
        return '';
    }
    else if (typeof input === 'string' || input instanceof String) {
        return input;
    }
    return JSON.stringify(input);
}
exports.toCommandValue = toCommandValue;
/**
 *
 * @param annotationProperties
 * @returns The command properties to send with the actual annotation command
 * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646
 */
function toCommandProperties(annotationProperties) {
    if (!Object.keys(annotationProperties).length) {
        return {};
    }
    return {
        title: annotationProperties.title,
        file: annotationProperties.file,
        line: annotationProperties.startLine,
        endLine: annotationProperties.endLine,
        col: annotationProperties.startColumn,
        endColumn: annotationProperties.endColumn
    };
}
exports.toCommandProperties = toCommandProperties;
//# sourceMappingURL=utils.js.map

/***/ }),

/***/ 5236:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getExecOutput = exports.exec = void 0;
const string_decoder_1 = __nccwpck_require__(3193);
const tr = __importStar(__nccwpck_require__(6665));
/**
 * Exec a command.
 * Output will be streamed to the live console.
 * Returns promise with return code
 *
 * @param     commandLine        command to execute (can include additional args). Must be correctly escaped.
 * @param     args               optional arguments for tool. Escaping is handled by the lib.
 * @param     options            optional exec options.  See ExecOptions
 * @returns   Promise<number>    exit code
 */
function exec(commandLine, args, options) {
    return __awaiter(this, void 0, void 0, function* () {
        const commandArgs = tr.argStringToArray(commandLine);
        if (commandArgs.length === 0) {
            throw new Error(`Parameter 'commandLine' cannot be null or empty.`);
        }
        // Path to tool to execute should be first arg
        const toolPath = commandArgs[0];
        args = commandArgs.slice(1).concat(args || []);
        const runner = new tr.ToolRunner(toolPath, args, options);
        return runner.exec();
    });
}
exports.exec = exec;
/**
 * Exec a command and get the output.
 * Output will be streamed to the live console.
 * Returns promise with the exit code and collected stdout and stderr
 *
 * @param     commandLine           command to execute (can include additional args). Must be correctly escaped.
 * @param     args                  optional arguments for tool. Escaping is handled by the lib.
 * @param     options               optional exec options.  See ExecOptions
 * @returns   Promise<ExecOutput>   exit code, stdout, and stderr
 */
function getExecOutput(commandLine, args, options) {
    var _a, _b;
    return __awaiter(this, void 0, void 0, function* () {
        let stdout = '';
        let stderr = '';
        //Using string decoder covers the case where a mult-byte character is split
        const stdoutDecoder = new string_decoder_1.StringDecoder('utf8');
        const stderrDecoder = new string_decoder_1.StringDecoder('utf8');
        const originalStdoutListener = (_a = options === null || options === void 0 ? void 0 : options.listeners) === null || _a === void 0 ? void 0 : _a.stdout;
        const originalStdErrListener = (_b = options === null || options === void 0 ? void 0 : options.listeners) === null || _b === void 0 ? void 0 : _b.stderr;
        const stdErrListener = (data) => {
            stderr += stderrDecoder.write(data);
            if (originalStdErrListener) {
                originalStdErrListener(data);
            }
        };
        const stdOutListener = (data) => {
            stdout += stdoutDecoder.write(data);
            if (originalStdoutListener) {
                originalStdoutListener(data);
            }
        };
        const listeners = Object.assign(Object.assign({}, options === null || options === void 0 ? void 0 : options.listeners), { stdout: stdOutListener, stderr: stdErrListener });
        const exitCode = yield exec(commandLine, args, Object.assign(Object.assign({}, options), { listeners }));
        //flush any remaining characters
        stdout += stdoutDecoder.end();
        stderr += stderrDecoder.end();
        return {
            exitCode,
            stdout,
            stderr
        };
    });
}
exports.getExecOutput = getExecOutput;
//# sourceMappingURL=exec.js.map

/***/ }),

/***/ 6665:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.argStringToArray = exports.ToolRunner = void 0;
const os = __importStar(__nccwpck_require__(857));
const events = __importStar(__nccwpck_require__(4434));
const child = __importStar(__nccwpck_require__(5317));
const path = __importStar(__nccwpck_require__(6928));
const io = __importStar(__nccwpck_require__(4994));
const ioUtil = __importStar(__nccwpck_require__(5207));
const timers_1 = __nccwpck_require__(3557);
/* eslint-disable @typescript-eslint/unbound-method */
const IS_WINDOWS = process.platform === 'win32';
/*
 * Class for running command line tools. Handles quoting and arg parsing in a platform agnostic way.
 */
class ToolRunner extends events.EventEmitter {
    constructor(toolPath, args, options) {
        super();
        if (!toolPath) {
            throw new Error("Parameter 'toolPath' cannot be null or empty.");
        }
        this.toolPath = toolPath;
        this.args = args || [];
        this.options = options || {};
    }
    _debug(message) {
        if (this.options.listeners && this.options.listeners.debug) {
            this.options.listeners.debug(message);
        }
    }
    _getCommandString(options, noPrefix) {
        const toolPath = this._getSpawnFileName();
        const args = this._getSpawnArgs(options);
        let cmd = noPrefix ? '' : '[command]'; // omit prefix when piped to a second tool
        if (IS_WINDOWS) {
            // Windows + cmd file
            if (this._isCmdFile()) {
                cmd += toolPath;
                for (const a of args) {
                    cmd += ` ${a}`;
                }
            }
            // Windows + verbatim
            else if (options.windowsVerbatimArguments) {
                cmd += `"${toolPath}"`;
                for (const a of args) {
                    cmd += ` ${a}`;
                }
            }
            // Windows (regular)
            else {
                cmd += this._windowsQuoteCmdArg(toolPath);
                for (const a of args) {
                    cmd += ` ${this._windowsQuoteCmdArg(a)}`;
                }
            }
        }
        else {
            // OSX/Linux - this can likely be improved with some form of quoting.
            // creating processes on Unix is fundamentally different than Windows.
            // on Unix, execvp() takes an arg array.
            cmd += toolPath;
            for (const a of args) {
                cmd += ` ${a}`;
            }
        }
        return cmd;
    }
    _processLineBuffer(data, strBuffer, onLine) {
        try {
            let s = strBuffer + data.toString();
            let n = s.indexOf(os.EOL);
            while (n > -1) {
                const line = s.substring(0, n);
                onLine(line);
                // the rest of the string ...
                s = s.substring(n + os.EOL.length);
                n = s.indexOf(os.EOL);
            }
            return s;
        }
        catch (err) {
            // streaming lines to console is best effort.  Don't fail a build.
            this._debug(`error processing line. Failed with error ${err}`);
            return '';
        }
    }
    _getSpawnFileName() {
        if (IS_WINDOWS) {
            if (this._isCmdFile()) {
                return process.env['COMSPEC'] || 'cmd.exe';
            }
        }
        return this.toolPath;
    }
    _getSpawnArgs(options) {
        if (IS_WINDOWS) {
            if (this._isCmdFile()) {
                let argline = `/D /S /C "${this._windowsQuoteCmdArg(this.toolPath)}`;
                for (const a of this.args) {
                    argline += ' ';
                    argline += options.windowsVerbatimArguments
                        ? a
                        : this._windowsQuoteCmdArg(a);
                }
                argline += '"';
                return [argline];
            }
        }
        return this.args;
    }
    _endsWith(str, end) {
        return str.endsWith(end);
    }
    _isCmdFile() {
        const upperToolPath = this.toolPath.toUpperCase();
        return (this._endsWith(upperToolPath, '.CMD') ||
            this._endsWith(upperToolPath, '.BAT'));
    }
    _windowsQuoteCmdArg(arg) {
        // for .exe, apply the normal quoting rules that libuv applies
        if (!this._isCmdFile()) {
            return this._uvQuoteCmdArg(arg);
        }
        // otherwise apply quoting rules specific to the cmd.exe command line parser.
        // the libuv rules are generic and are not designed specifically for cmd.exe
        // command line parser.
        //
        // for a detailed description of the cmd.exe command line parser, refer to
        // http://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts/7970912#7970912
        // need quotes for empty arg
        if (!arg) {
            return '""';
        }
        // determine whether the arg needs to be quoted
        const cmdSpecialChars = [
            ' ',
            '\t',
            '&',
            '(',
            ')',
            '[',
            ']',
            '{',
            '}',
            '^',
            '=',
            ';',
            '!',
            "'",
            '+',
            ',',
            '`',
            '~',
            '|',
            '<',
            '>',
            '"'
        ];
        let needsQuotes = false;
        for (const char of arg) {
            if (cmdSpecialChars.some(x => x === char)) {
                needsQuotes = true;
                break;
            }
        }
        // short-circuit if quotes not needed
        if (!needsQuotes) {
            return arg;
        }
        // the following quoting rules are very similar to the rules that by libuv applies.
        //
        // 1) wrap the string in quotes
        //
        // 2) double-up quotes - i.e. " => ""
        //
        //    this is different from the libuv quoting rules. libuv replaces " with \", which unfortunately
        //    doesn't work well with a cmd.exe command line.
        //
        //    note, replacing " with "" also works well if the arg is passed to a downstream .NET console app.
        //    for example, the command line:
        //          foo.exe "myarg:""my val"""
        //    is parsed by a .NET console app into an arg array:
        //          [ "myarg:\"my val\"" ]
        //    which is the same end result when applying libuv quoting rules. although the actual
        //    command line from libuv quoting rules would look like:
        //          foo.exe "myarg:\"my val\""
        //
        // 3) double-up slashes that precede a quote,
        //    e.g.  hello \world    => "hello \world"
        //          hello\"world    => "hello\\""world"
        //          hello\\"world   => "hello\\\\""world"
        //          hello world\    => "hello world\\"
        //
        //    technically this is not required for a cmd.exe command line, or the batch argument parser.
        //    the reasons for including this as a .cmd quoting rule are:
        //
        //    a) this is optimized for the scenario where the argument is passed from the .cmd file to an
        //       external program. many programs (e.g. .NET console apps) rely on the slash-doubling rule.
        //
        //    b) it's what we've been doing previously (by deferring to node default behavior) and we
        //       haven't heard any complaints about that aspect.
        //
        // note, a weakness of the quoting rules chosen here, is that % is not escaped. in fact, % cannot be
        // escaped when used on the command line directly - even though within a .cmd file % can be escaped
        // by using %%.
        //
        // the saving grace is, on the command line, %var% is left as-is if var is not defined. this contrasts
        // the line parsing rules within a .cmd file, where if var is not defined it is replaced with nothing.
        //
        // one option that was explored was replacing % with ^% - i.e. %var% => ^%var^%. this hack would
        // often work, since it is unlikely that var^ would exist, and the ^ character is removed when the
        // variable is used. the problem, however, is that ^ is not removed when %* is used to pass the args
        // to an external program.
        //
        // an unexplored potential solution for the % escaping problem, is to create a wrapper .cmd file.
        // % can be escaped within a .cmd file.
        let reverse = '"';
        let quoteHit = true;
        for (let i = arg.length; i > 0; i--) {
            // walk the string in reverse
            reverse += arg[i - 1];
            if (quoteHit && arg[i - 1] === '\\') {
                reverse += '\\'; // double the slash
            }
            else if (arg[i - 1] === '"') {
                quoteHit = true;
                reverse += '"'; // double the quote
            }
            else {
                quoteHit = false;
            }
        }
        reverse += '"';
        return reverse
            .split('')
            .reverse()
            .join('');
    }
    _uvQuoteCmdArg(arg) {
        // Tool runner wraps child_process.spawn() and needs to apply the same quoting as
        // Node in certain cases where the undocumented spawn option windowsVerbatimArguments
        // is used.
        //
        // Since this function is a port of quote_cmd_arg from Node 4.x (technically, lib UV,
        // see https://github.com/nodejs/node/blob/v4.x/deps/uv/src/win/process.c for details),
        // pasting copyright notice from Node within this function:
        //
        //      Copyright Joyent, Inc. and other Node contributors. All rights reserved.
        //
        //      Permission is hereby granted, free of charge, to any person obtaining a copy
        //      of this software and associated documentation files (the "Software"), to
        //      deal in the Software without restriction, including without limitation the
        //      rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
        //      sell copies of the Software, and to permit persons to whom the Software is
        //      furnished to do so, subject to the following conditions:
        //
        //      The above copyright notice and this permission notice shall be included in
        //      all copies or substantial portions of the Software.
        //
        //      THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        //      IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        //      FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        //      AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        //      LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
        //      FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
        //      IN THE SOFTWARE.
        if (!arg) {
            // Need double quotation for empty argument
            return '""';
        }
        if (!arg.includes(' ') && !arg.includes('\t') && !arg.includes('"')) {
            // No quotation needed
            return arg;
        }
        if (!arg.includes('"') && !arg.includes('\\')) {
            // No embedded double quotes or backslashes, so I can just wrap
            // quote marks around the whole thing.
            return `"${arg}"`;
        }
        // Expected input/output:
        //   input : hello"world
        //   output: "hello\"world"
        //   input : hello""world
        //   output: "hello\"\"world"
        //   input : hello\world
        //   output: hello\world
        //   input : hello\\world
        //   output: hello\\world
        //   input : hello\"world
        //   output: "hello\\\"world"
        //   input : hello\\"world
        //   output: "hello\\\\\"world"
        //   input : hello world\
        //   output: "hello world\\" - note the comment in libuv actually reads "hello world\"
        //                             but it appears the comment is wrong, it should be "hello world\\"
        let reverse = '"';
        let quoteHit = true;
        for (let i = arg.length; i > 0; i--) {
            // walk the string in reverse
            reverse += arg[i - 1];
            if (quoteHit && arg[i - 1] === '\\') {
                reverse += '\\';
            }
            else if (arg[i - 1] === '"') {
                quoteHit = true;
                reverse += '\\';
            }
            else {
                quoteHit = false;
            }
        }
        reverse += '"';
        return reverse
            .split('')
            .reverse()
            .join('');
    }
    _cloneExecOptions(options) {
        options = options || {};
        const result = {
            cwd: options.cwd || process.cwd(),
            env: options.env || process.env,
            silent: options.silent || false,
            windowsVerbatimArguments: options.windowsVerbatimArguments || false,
            failOnStdErr: options.failOnStdErr || false,
            ignoreReturnCode: options.ignoreReturnCode || false,
            delay: options.delay || 10000
        };
        result.outStream = options.outStream || process.stdout;
        result.errStream = options.errStream || process.stderr;
        return result;
    }
    _getSpawnOptions(options, toolPath) {
        options = options || {};
        const result = {};
        result.cwd = options.cwd;
        result.env = options.env;
        result['windowsVerbatimArguments'] =
            options.windowsVerbatimArguments || this._isCmdFile();
        if (options.windowsVerbatimArguments) {
            result.argv0 = `"${toolPath}"`;
        }
        return result;
    }
    /**
     * Exec a tool.
     * Output will be streamed to the live console.
     * Returns promise with return code
     *
     * @param     tool     path to tool to exec
     * @param     options  optional exec options.  See ExecOptions
     * @returns   number
     */
    exec() {
        return __awaiter(this, void 0, void 0, function* () {
            // root the tool path if it is unrooted and contains relative pathing
            if (!ioUtil.isRooted(this.toolPath) &&
                (this.toolPath.includes('/') ||
                    (IS_WINDOWS && this.toolPath.includes('\\')))) {
                // prefer options.cwd if it is specified, however options.cwd may also need to be rooted
                this.toolPath = path.resolve(process.cwd(), this.options.cwd || process.cwd(), this.toolPath);
            }
            // if the tool is only a file name, then resolve it from the PATH
            // otherwise verify it exists (add extension on Windows if necessary)
            this.toolPath = yield io.which(this.toolPath, true);
            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {
                this._debug(`exec tool: ${this.toolPath}`);
                this._debug('arguments:');
                for (const arg of this.args) {
                    this._debug(`   ${arg}`);
                }
                const optionsNonNull = this._cloneExecOptions(this.options);
                if (!optionsNonNull.silent && optionsNonNull.outStream) {
                    optionsNonNull.outStream.write(this._getCommandString(optionsNonNull) + os.EOL);
                }
                const state = new ExecState(optionsNonNull, this.toolPath);
                state.on('debug', (message) => {
                    this._debug(message);
                });
                if (this.options.cwd && !(yield ioUtil.exists(this.options.cwd))) {
                    return reject(new Error(`The cwd: ${this.options.cwd} does not exist!`));
                }
                const fileName = this._getSpawnFileName();
                const cp = child.spawn(fileName, this._getSpawnArgs(optionsNonNull), this._getSpawnOptions(this.options, fileName));
                let stdbuffer = '';
                if (cp.stdout) {
                    cp.stdout.on('data', (data) => {
                        if (this.options.listeners && this.options.listeners.stdout) {
                            this.options.listeners.stdout(data);
                        }
                        if (!optionsNonNull.silent && optionsNonNull.outStream) {
                            optionsNonNull.outStream.write(data);
                        }
                        stdbuffer = this._processLineBuffer(data, stdbuffer, (line) => {
                            if (this.options.listeners && this.options.listeners.stdline) {
                                this.options.listeners.stdline(line);
                            }
                        });
                    });
                }
                let errbuffer = '';
                if (cp.stderr) {
                    cp.stderr.on('data', (data) => {
                        state.processStderr = true;
                        if (this.options.listeners && this.options.listeners.stderr) {
                            this.options.listeners.stderr(data);
                        }
                        if (!optionsNonNull.silent &&
                            optionsNonNull.errStream &&
                            optionsNonNull.outStream) {
                            const s = optionsNonNull.failOnStdErr
                                ? optionsNonNull.errStream
                                : optionsNonNull.outStream;
                            s.write(data);
                        }
                        errbuffer = this._processLineBuffer(data, errbuffer, (line) => {
                            if (this.options.listeners && this.options.listeners.errline) {
                                this.options.listeners.errline(line);
                            }
                        });
                    });
                }
                cp.on('error', (err) => {
                    state.processError = err.message;
                    state.processExited = true;
                    state.processClosed = true;
                    state.CheckComplete();
                });
                cp.on('exit', (code) => {
                    state.processExitCode = code;
                    state.processExited = true;
                    this._debug(`Exit code ${code} received from tool '${this.toolPath}'`);
                    state.CheckComplete();
                });
                cp.on('close', (code) => {
                    state.processExitCode = code;
                    state.processExited = true;
                    state.processClosed = true;
                    this._debug(`STDIO streams have closed for tool '${this.toolPath}'`);
                    state.CheckComplete();
                });
                state.on('done', (error, exitCode) => {
                    if (stdbuffer.length > 0) {
                        this.emit('stdline', stdbuffer);
                    }
                    if (errbuffer.length > 0) {
                        this.emit('errline', errbuffer);
                    }
                    cp.removeAllListeners();
                    if (error) {
                        reject(error);
                    }
                    else {
                        resolve(exitCode);
                    }
                });
                if (this.options.input) {
                    if (!cp.stdin) {
                        throw new Error('child process missing stdin');
                    }
                    cp.stdin.end(this.options.input);
                }
            }));
        });
    }
}
exports.ToolRunner = ToolRunner;
/**
 * Convert an arg string to an array of args. Handles escaping
 *
 * @param    argString   string of arguments
 * @returns  string[]    array of arguments
 */
function argStringToArray(argString) {
    const args = [];
    let inQuotes = false;
    let escaped = false;
    let arg = '';
    function append(c) {
        // we only escape double quotes.
        if (escaped && c !== '"') {
            arg += '\\';
        }
        arg += c;
        escaped = false;
    }
    for (let i = 0; i < argString.length; i++) {
        const c = argString.charAt(i);
        if (c === '"') {
            if (!escaped) {
                inQuotes = !inQuotes;
            }
            else {
                append(c);
            }
            continue;
        }
        if (c === '\\' && escaped) {
            append(c);
            continue;
        }
        if (c === '\\' && inQuotes) {
            escaped = true;
            continue;
        }
        if (c === ' ' && !inQuotes) {
            if (arg.length > 0) {
                args.push(arg);
                arg = '';
            }
            continue;
        }
        append(c);
    }
    if (arg.length > 0) {
        args.push(arg.trim());
    }
    return args;
}
exports.argStringToArray = argStringToArray;
class ExecState extends events.EventEmitter {
    constructor(options, toolPath) {
        super();
        this.processClosed = false; // tracks whether the process has exited and stdio is closed
        this.processError = '';
        this.processExitCode = 0;
        this.processExited = false; // tracks whether the process has exited
        this.processStderr = false; // tracks whether stderr was written to
        this.delay = 10000; // 10 seconds
        this.done = false;
        this.timeout = null;
        if (!toolPath) {
            throw new Error('toolPath must not be empty');
        }
        this.options = options;
        this.toolPath = toolPath;
        if (options.delay) {
            this.delay = options.delay;
        }
    }
    CheckComplete() {
        if (this.done) {
            return;
        }
        if (this.processClosed) {
            this._setResult();
        }
        else if (this.processExited) {
            this.timeout = timers_1.setTimeout(ExecState.HandleTimeout, this.delay, this);
        }
    }
    _debug(message) {
        this.emit('debug', message);
    }
    _setResult() {
        // determine whether there is an error
        let error;
        if (this.processExited) {
            if (this.processError) {
                error = new Error(`There was an error when attempting to execute the process '${this.toolPath}'. This may indicate the process failed to start. Error: ${this.processError}`);
            }
            else if (this.processExitCode !== 0 && !this.options.ignoreReturnCode) {
                error = new Error(`The process '${this.toolPath}' failed with exit code ${this.processExitCode}`);
            }
            else if (this.processStderr && this.options.failOnStdErr) {
                error = new Error(`The process '${this.toolPath}' failed because one or more lines were written to the STDERR stream`);
            }
        }
        // clear the timeout
        if (this.timeout) {
            clearTimeout(this.timeout);
            this.timeout = null;
        }
        this.done = true;
        this.emit('done', error, this.processExitCode);
    }
    static HandleTimeout(state) {
        if (state.done) {
            return;
        }
        if (!state.processClosed && state.processExited) {
            const message = `The STDIO streams did not close within ${state.delay /
                1000} seconds of the exit event from process '${state.toolPath}'. This may indicate a child process inherited the STDIO streams and has not yet exited.`;
            state._debug(message);
        }
        state._setResult();
    }
}
//# sourceMappingURL=toolrunner.js.map

/***/ }),

/***/ 1648:
/***/ ((__unused_webpack_module, exports, __nccwpck_require__) => {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.Context = void 0;
const fs_1 = __nccwpck_require__(9896);
const os_1 = __nccwpck_require__(857);
class Context {
    /**
     * Hydrate the context from the environment
     */
    constructor() {
        var _a, _b, _c;
        this.payload = {};
        if (process.env.GITHUB_EVENT_PATH) {
            if ((0, fs_1.existsSync)(process.env.GITHUB_EVENT_PATH)) {
                this.payload = JSON.parse((0, fs_1.readFileSync)(process.env.GITHUB_EVENT_PATH, { encoding: 'utf8' }));
            }
            else {
                const path = process.env.GITHUB_EVENT_PATH;
                process.stdout.write(`GITHUB_EVENT_PATH ${path} does not exist${os_1.EOL}`);
            }
        }
        this.eventName = process.env.GITHUB_EVENT_NAME;
        this.sha = process.env.GITHUB_SHA;
        this.ref = process.env.GITHUB_REF;
        this.workflow = process.env.GITHUB_WORKFLOW;
        this.action = process.env.GITHUB_ACTION;
        this.actor = process.env.GITHUB_ACTOR;
        this.job = process.env.GITHUB_JOB;
        this.runAttempt = parseInt(process.env.GITHUB_RUN_ATTEMPT, 10);
        this.runNumber = parseInt(process.env.GITHUB_RUN_NUMBER, 10);
        this.runId = parseInt(process.env.GITHUB_RUN_ID, 10);
        this.apiUrl = (_a = process.env.GITHUB_API_URL) !== null && _a !== void 0 ? _a : `https://api.github.com`;
        this.serverUrl = (_b = process.env.GITHUB_SERVER_URL) !== null && _b !== void 0 ? _b : `https://github.com`;
        this.graphqlUrl =
            (_c = process.env.GITHUB_GRAPHQL_URL) !== null && _c !== void 0 ? _c : `https://api.github.com/graphql`;
    }
    get issue() {
        const payload = this.payload;
        return Object.assign(Object.assign({}, this.repo), { number: (payload.issue || payload.pull_request || payload).number });
    }
    get repo() {
        if (process.env.GITHUB_REPOSITORY) {
            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
            return { owner, repo };
        }
        if (this.payload.repository) {
            return {
                owner: this.payload.repository.owner.login,
                repo: this.payload.repository.name
            };
        }
        throw new Error("context.repo requires a GITHUB_REPOSITORY environment variable like 'owner/repo'");
    }
}
exports.Context = Context;
//# sourceMappingURL=context.js.map

/***/ }),

/***/ 3228:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getOctokit = exports.context = void 0;
const Context = __importStar(__nccwpck_require__(1648));
const utils_1 = __nccwpck_require__(8006);
exports.context = new Context.Context();
/**
 * Returns a hydrated octokit ready to use for GitHub Actions
 *
 * @param     token    the repo PAT or GITHUB_TOKEN
 * @param     options  other options to set
 */
function getOctokit(token, options, ...additionalPlugins) {
    const GitHubWithPlugins = utils_1.GitHub.plugin(...additionalPlugins);
    return new GitHubWithPlugins((0, utils_1.getOctokitOptions)(token, options));
}
exports.getOctokit = getOctokit;
//# sourceMappingURL=github.js.map

/***/ }),

/***/ 5156:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getApiBaseUrl = exports.getProxyFetch = exports.getProxyAgentDispatcher = exports.getProxyAgent = exports.getAuthString = void 0;
const httpClient = __importStar(__nccwpck_require__(4844));
const undici_1 = __nccwpck_require__(6752);
function getAuthString(token, options) {
    if (!token && !options.auth) {
        throw new Error('Parameter token or opts.auth is required');
    }
    else if (token && options.auth) {
        throw new Error('Parameters token and opts.auth may not both be specified');
    }
    return typeof options.auth === 'string' ? options.auth : `token ${token}`;
}
exports.getAuthString = getAuthString;
function getProxyAgent(destinationUrl) {
    const hc = new httpClient.HttpClient();
    return hc.getAgent(destinationUrl);
}
exports.getProxyAgent = getProxyAgent;
function getProxyAgentDispatcher(destinationUrl) {
    const hc = new httpClient.HttpClient();
    return hc.getAgentDispatcher(destinationUrl);
}
exports.getProxyAgentDispatcher = getProxyAgentDispatcher;
function getProxyFetch(destinationUrl) {
    const httpDispatcher = getProxyAgentDispatcher(destinationUrl);
    const proxyFetch = (url, opts) => __awaiter(this, void 0, void 0, function* () {
        return (0, undici_1.fetch)(url, Object.assign(Object.assign({}, opts), { dispatcher: httpDispatcher }));
    });
    return proxyFetch;
}
exports.getProxyFetch = getProxyFetch;
function getApiBaseUrl() {
    return process.env['GITHUB_API_URL'] || 'https://api.github.com';
}
exports.getApiBaseUrl = getApiBaseUrl;
//# sourceMappingURL=utils.js.map

/***/ }),

/***/ 8006:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getOctokitOptions = exports.GitHub = exports.defaults = exports.context = void 0;
const Context = __importStar(__nccwpck_require__(1648));
const Utils = __importStar(__nccwpck_require__(5156));
// octokit + plugins
const core_1 = __nccwpck_require__(1897);
const plugin_rest_endpoint_methods_1 = __nccwpck_require__(4935);
const plugin_paginate_rest_1 = __nccwpck_require__(8082);
exports.context = new Context.Context();
const baseUrl = Utils.getApiBaseUrl();
exports.defaults = {
    baseUrl,
    request: {
        agent: Utils.getProxyAgent(baseUrl),
        fetch: Utils.getProxyFetch(baseUrl)
    }
};
exports.GitHub = core_1.Octokit.plugin(plugin_rest_endpoint_methods_1.restEndpointMethods, plugin_paginate_rest_1.paginateRest).defaults(exports.defaults);
/**
 * Convience function to correctly format Octokit Options to pass into the constructor.
 *
 * @param     token    the repo PAT or GITHUB_TOKEN
 * @param     options  other options to set
 */
function getOctokitOptions(token, options) {
    const opts = Object.assign({}, options || {}); // Shallow clone - don't mutate the object provided by the caller
    // Auth
    const auth = Utils.getAuthString(token, opts);
    if (auth) {
        opts.auth = auth;
    }
    return opts;
}
exports.getOctokitOptions = getOctokitOptions;
//# sourceMappingURL=utils.js.map

/***/ }),

/***/ 4552:
/***/ (function(__unused_webpack_module, exports) {

"use strict";

var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.PersonalAccessTokenCredentialHandler = exports.BearerCredentialHandler = exports.BasicCredentialHandler = void 0;
class BasicCredentialHandler {
    constructor(username, password) {
        this.username = username;
        this.password = password;
    }
    prepareRequest(options) {
        if (!options.headers) {
            throw Error('The request has no headers');
        }
        options.headers['Authorization'] = `Basic ${Buffer.from(`${this.username}:${this.password}`).toString('base64')}`;
    }
    // This handler cannot handle 401
    canHandleAuthentication() {
        return false;
    }
    handleAuthentication() {
        return __awaiter(this, void 0, void 0, function* () {
            throw new Error('not implemented');
        });
    }
}
exports.BasicCredentialHandler = BasicCredentialHandler;
class BearerCredentialHandler {
    constructor(token) {
        this.token = token;
    }
    // currently implements pre-authorization
    // TODO: support preAuth = false where it hooks on 401
    prepareRequest(options) {
        if (!options.headers) {
            throw Error('The request has no headers');
        }
        options.headers['Authorization'] = `Bearer ${this.token}`;
    }
    // This handler cannot handle 401
    canHandleAuthentication() {
        return false;
    }
    handleAuthentication() {
        return __awaiter(this, void 0, void 0, function* () {
            throw new Error('not implemented');
        });
    }
}
exports.BearerCredentialHandler = BearerCredentialHandler;
class PersonalAccessTokenCredentialHandler {
    constructor(token) {
        this.token = token;
    }
    // currently implements pre-authorization
    // TODO: support preAuth = false where it hooks on 401
    prepareRequest(options) {
        if (!options.headers) {
            throw Error('The request has no headers');
        }
        options.headers['Authorization'] = `Basic ${Buffer.from(`PAT:${this.token}`).toString('base64')}`;
    }
    // This handler cannot handle 401
    canHandleAuthentication() {
        return false;
    }
    handleAuthentication() {
        return __awaiter(this, void 0, void 0, function* () {
            throw new Error('not implemented');
        });
    }
}
exports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;
//# sourceMappingURL=auth.js.map

/***/ }),

/***/ 4844:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

/* eslint-disable @typescript-eslint/no-explicit-any */
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.HttpClient = exports.isHttps = exports.HttpClientResponse = exports.HttpClientError = exports.getProxyUrl = exports.MediaTypes = exports.Headers = exports.HttpCodes = void 0;
const http = __importStar(__nccwpck_require__(8611));
const https = __importStar(__nccwpck_require__(5692));
const pm = __importStar(__nccwpck_require__(4988));
const tunnel = __importStar(__nccwpck_require__(770));
const undici_1 = __nccwpck_require__(6752);
var HttpCodes;
(function (HttpCodes) {
    HttpCodes[HttpCodes["OK"] = 200] = "OK";
    HttpCodes[HttpCodes["MultipleChoices"] = 300] = "MultipleChoices";
    HttpCodes[HttpCodes["MovedPermanently"] = 301] = "MovedPermanently";
    HttpCodes[HttpCodes["ResourceMoved"] = 302] = "ResourceMoved";
    HttpCodes[HttpCodes["SeeOther"] = 303] = "SeeOther";
    HttpCodes[HttpCodes["NotModified"] = 304] = "NotModified";
    HttpCodes[HttpCodes["UseProxy"] = 305] = "UseProxy";
    HttpCodes[HttpCodes["SwitchProxy"] = 306] = "SwitchProxy";
    HttpCodes[HttpCodes["TemporaryRedirect"] = 307] = "TemporaryRedirect";
    HttpCodes[HttpCodes["PermanentRedirect"] = 308] = "PermanentRedirect";
    HttpCodes[HttpCodes["BadRequest"] = 400] = "BadRequest";
    HttpCodes[HttpCodes["Unauthorized"] = 401] = "Unauthorized";
    HttpCodes[HttpCodes["PaymentRequired"] = 402] = "PaymentRequired";
    HttpCodes[HttpCodes["Forbidden"] = 403] = "Forbidden";
    HttpCodes[HttpCodes["NotFound"] = 404] = "NotFound";
    HttpCodes[HttpCodes["MethodNotAllowed"] = 405] = "MethodNotAllowed";
    HttpCodes[HttpCodes["NotAcceptable"] = 406] = "NotAcceptable";
    HttpCodes[HttpCodes["ProxyAuthenticationRequired"] = 407] = "ProxyAuthenticationRequired";
    HttpCodes[HttpCodes["RequestTimeout"] = 408] = "RequestTimeout";
    HttpCodes[HttpCodes["Conflict"] = 409] = "Conflict";
    HttpCodes[HttpCodes["Gone"] = 410] = "Gone";
    HttpCodes[HttpCodes["TooManyRequests"] = 429] = "TooManyRequests";
    HttpCodes[HttpCodes["InternalServerError"] = 500] = "InternalServerError";
    HttpCodes[HttpCodes["NotImplemented"] = 501] = "NotImplemented";
    HttpCodes[HttpCodes["BadGateway"] = 502] = "BadGateway";
    HttpCodes[HttpCodes["ServiceUnavailable"] = 503] = "ServiceUnavailable";
    HttpCodes[HttpCodes["GatewayTimeout"] = 504] = "GatewayTimeout";
})(HttpCodes || (exports.HttpCodes = HttpCodes = {}));
var Headers;
(function (Headers) {
    Headers["Accept"] = "accept";
    Headers["ContentType"] = "content-type";
})(Headers || (exports.Headers = Headers = {}));
var MediaTypes;
(function (MediaTypes) {
    MediaTypes["ApplicationJson"] = "application/json";
})(MediaTypes || (exports.MediaTypes = MediaTypes = {}));
/**
 * Returns the proxy URL, depending upon the supplied url and proxy environment variables.
 * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com
 */
function getProxyUrl(serverUrl) {
    const proxyUrl = pm.getProxyUrl(new URL(serverUrl));
    return proxyUrl ? proxyUrl.href : '';
}
exports.getProxyUrl = getProxyUrl;
const HttpRedirectCodes = [
    HttpCodes.MovedPermanently,
    HttpCodes.ResourceMoved,
    HttpCodes.SeeOther,
    HttpCodes.TemporaryRedirect,
    HttpCodes.PermanentRedirect
];
const HttpResponseRetryCodes = [
    HttpCodes.BadGateway,
    HttpCodes.ServiceUnavailable,
    HttpCodes.GatewayTimeout
];
const RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];
const ExponentialBackoffCeiling = 10;
const ExponentialBackoffTimeSlice = 5;
class HttpClientError extends Error {
    constructor(message, statusCode) {
        super(message);
        this.name = 'HttpClientError';
        this.statusCode = statusCode;
        Object.setPrototypeOf(this, HttpClientError.prototype);
    }
}
exports.HttpClientError = HttpClientError;
class HttpClientResponse {
    constructor(message) {
        this.message = message;
    }
    readBody() {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {
                let output = Buffer.alloc(0);
                this.message.on('data', (chunk) => {
                    output = Buffer.concat([output, chunk]);
                });
                this.message.on('end', () => {
                    resolve(output.toString());
                });
            }));
        });
    }
    readBodyBuffer() {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {
                const chunks = [];
                this.message.on('data', (chunk) => {
                    chunks.push(chunk);
                });
                this.message.on('end', () => {
                    resolve(Buffer.concat(chunks));
                });
            }));
        });
    }
}
exports.HttpClientResponse = HttpClientResponse;
function isHttps(requestUrl) {
    const parsedUrl = new URL(requestUrl);
    return parsedUrl.protocol === 'https:';
}
exports.isHttps = isHttps;
class HttpClient {
    constructor(userAgent, handlers, requestOptions) {
        this._ignoreSslError = false;
        this._allowRedirects = true;
        this._allowRedirectDowngrade = false;
        this._maxRedirects = 50;
        this._allowRetries = false;
        this._maxRetries = 1;
        this._keepAlive = false;
        this._disposed = false;
        this.userAgent = userAgent;
        this.handlers = handlers || [];
        this.requestOptions = requestOptions;
        if (requestOptions) {
            if (requestOptions.ignoreSslError != null) {
                this._ignoreSslError = requestOptions.ignoreSslError;
            }
            this._socketTimeout = requestOptions.socketTimeout;
            if (requestOptions.allowRedirects != null) {
                this._allowRedirects = requestOptions.allowRedirects;
            }
            if (requestOptions.allowRedirectDowngrade != null) {
                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;
            }
            if (requestOptions.maxRedirects != null) {
                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);
            }
            if (requestOptions.keepAlive != null) {
                this._keepAlive = requestOptions.keepAlive;
            }
            if (requestOptions.allowRetries != null) {
                this._allowRetries = requestOptions.allowRetries;
            }
            if (requestOptions.maxRetries != null) {
                this._maxRetries = requestOptions.maxRetries;
            }
        }
    }
    options(requestUrl, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});
        });
    }
    get(requestUrl, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('GET', requestUrl, null, additionalHeaders || {});
        });
    }
    del(requestUrl, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('DELETE', requestUrl, null, additionalHeaders || {});
        });
    }
    post(requestUrl, data, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('POST', requestUrl, data, additionalHeaders || {});
        });
    }
    patch(requestUrl, data, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('PATCH', requestUrl, data, additionalHeaders || {});
        });
    }
    put(requestUrl, data, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('PUT', requestUrl, data, additionalHeaders || {});
        });
    }
    head(requestUrl, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request('HEAD', requestUrl, null, additionalHeaders || {});
        });
    }
    sendStream(verb, requestUrl, stream, additionalHeaders) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.request(verb, requestUrl, stream, additionalHeaders);
        });
    }
    /**
     * Gets a typed object from an endpoint
     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise
     */
    getJson(requestUrl, additionalHeaders = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);
            const res = yield this.get(requestUrl, additionalHeaders);
            return this._processResponse(res, this.requestOptions);
        });
    }
    postJson(requestUrl, obj, additionalHeaders = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const data = JSON.stringify(obj, null, 2);
            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);
            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);
            const res = yield this.post(requestUrl, data, additionalHeaders);
            return this._processResponse(res, this.requestOptions);
        });
    }
    putJson(requestUrl, obj, additionalHeaders = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const data = JSON.stringify(obj, null, 2);
            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);
            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);
            const res = yield this.put(requestUrl, data, additionalHeaders);
            return this._processResponse(res, this.requestOptions);
        });
    }
    patchJson(requestUrl, obj, additionalHeaders = {}) {
        return __awaiter(this, void 0, void 0, function* () {
            const data = JSON.stringify(obj, null, 2);
            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);
            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);
            const res = yield this.patch(requestUrl, data, additionalHeaders);
            return this._processResponse(res, this.requestOptions);
        });
    }
    /**
     * Makes a raw http request.
     * All other methods such as get, post, patch, and request ultimately call this.
     * Prefer get, del, post and patch
     */
    request(verb, requestUrl, data, headers) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this._disposed) {
                throw new Error('Client has already been disposed.');
            }
            const parsedUrl = new URL(requestUrl);
            let info = this._prepareRequest(verb, parsedUrl, headers);
            // Only perform retries on reads since writes may not be idempotent.
            const maxTries = this._allowRetries && RetryableHttpVerbs.includes(verb)
                ? this._maxRetries + 1
                : 1;
            let numTries = 0;
            let response;
            do {
                response = yield this.requestRaw(info, data);
                // Check if it's an authentication challenge
                if (response &&
                    response.message &&
                    response.message.statusCode === HttpCodes.Unauthorized) {
                    let authenticationHandler;
                    for (const handler of this.handlers) {
                        if (handler.canHandleAuthentication(response)) {
                            authenticationHandler = handler;
                            break;
                        }
                    }
                    if (authenticationHandler) {
                        return authenticationHandler.handleAuthentication(this, info, data);
                    }
                    else {
                        // We have received an unauthorized response but have no handlers to handle it.
                        // Let the response return to the caller.
                        return response;
                    }
                }
                let redirectsRemaining = this._maxRedirects;
                while (response.message.statusCode &&
                    HttpRedirectCodes.includes(response.message.statusCode) &&
                    this._allowRedirects &&
                    redirectsRemaining > 0) {
                    const redirectUrl = response.message.headers['location'];
                    if (!redirectUrl) {
                        // if there's no location to redirect to, we won't
                        break;
                    }
                    const parsedRedirectUrl = new URL(redirectUrl);
                    if (parsedUrl.protocol === 'https:' &&
                        parsedUrl.protocol !== parsedRedirectUrl.protocol &&
                        !this._allowRedirectDowngrade) {
                        throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');
                    }
                    // we need to finish reading the response before reassigning response
                    // which will leak the open socket.
                    yield response.readBody();
                    // strip authorization header if redirected to a different hostname
                    if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {
                        for (const header in headers) {
                            // header names are case insensitive
                            if (header.toLowerCase() === 'authorization') {
                                delete headers[header];
                            }
                        }
                    }
                    // let's make the request with the new redirectUrl
                    info = this._prepareRequest(verb, parsedRedirectUrl, headers);
                    response = yield this.requestRaw(info, data);
                    redirectsRemaining--;
                }
                if (!response.message.statusCode ||
                    !HttpResponseRetryCodes.includes(response.message.statusCode)) {
                    // If not a retry code, return immediately instead of retrying
                    return response;
                }
                numTries += 1;
                if (numTries < maxTries) {
                    yield response.readBody();
                    yield this._performExponentialBackoff(numTries);
                }
            } while (numTries < maxTries);
            return response;
        });
    }
    /**
     * Needs to be called if keepAlive is set to true in request options.
     */
    dispose() {
        if (this._agent) {
            this._agent.destroy();
        }
        this._disposed = true;
    }
    /**
     * Raw request.
     * @param info
     * @param data
     */
    requestRaw(info, data) {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve, reject) => {
                function callbackForResult(err, res) {
                    if (err) {
                        reject(err);
                    }
                    else if (!res) {
                        // If `err` is not passed, then `res` must be passed.
                        reject(new Error('Unknown error'));
                    }
                    else {
                        resolve(res);
                    }
                }
                this.requestRawWithCallback(info, data, callbackForResult);
            });
        });
    }
    /**
     * Raw request with callback.
     * @param info
     * @param data
     * @param onResult
     */
    requestRawWithCallback(info, data, onResult) {
        if (typeof data === 'string') {
            if (!info.options.headers) {
                info.options.headers = {};
            }
            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');
        }
        let callbackCalled = false;
        function handleResult(err, res) {
            if (!callbackCalled) {
                callbackCalled = true;
                onResult(err, res);
            }
        }
        const req = info.httpModule.request(info.options, (msg) => {
            const res = new HttpClientResponse(msg);
            handleResult(undefined, res);
        });
        let socket;
        req.on('socket', sock => {
            socket = sock;
        });
        // If we ever get disconnected, we want the socket to timeout eventually
        req.setTimeout(this._socketTimeout || 3 * 60000, () => {
            if (socket) {
                socket.end();
            }
            handleResult(new Error(`Request timeout: ${info.options.path}`));
        });
        req.on('error', function (err) {
            // err has statusCode property
            // res should have headers
            handleResult(err);
        });
        if (data && typeof data === 'string') {
            req.write(data, 'utf8');
        }
        if (data && typeof data !== 'string') {
            data.on('close', function () {
                req.end();
            });
            data.pipe(req);
        }
        else {
            req.end();
        }
    }
    /**
     * Gets an http agent. This function is useful when you need an http agent that handles
     * routing through a proxy server - depending upon the url and proxy environment variables.
     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com
     */
    getAgent(serverUrl) {
        const parsedUrl = new URL(serverUrl);
        return this._getAgent(parsedUrl);
    }
    getAgentDispatcher(serverUrl) {
        const parsedUrl = new URL(serverUrl);
        const proxyUrl = pm.getProxyUrl(parsedUrl);
        const useProxy = proxyUrl && proxyUrl.hostname;
        if (!useProxy) {
            return;
        }
        return this._getProxyAgentDispatcher(parsedUrl, proxyUrl);
    }
    _prepareRequest(method, requestUrl, headers) {
        const info = {};
        info.parsedUrl = requestUrl;
        const usingSsl = info.parsedUrl.protocol === 'https:';
        info.httpModule = usingSsl ? https : http;
        const defaultPort = usingSsl ? 443 : 80;
        info.options = {};
        info.options.host = info.parsedUrl.hostname;
        info.options.port = info.parsedUrl.port
            ? parseInt(info.parsedUrl.port)
            : defaultPort;
        info.options.path =
            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');
        info.options.method = method;
        info.options.headers = this._mergeHeaders(headers);
        if (this.userAgent != null) {
            info.options.headers['user-agent'] = this.userAgent;
        }
        info.options.agent = this._getAgent(info.parsedUrl);
        // gives handlers an opportunity to participate
        if (this.handlers) {
            for (const handler of this.handlers) {
                handler.prepareRequest(info.options);
            }
        }
        return info;
    }
    _mergeHeaders(headers) {
        if (this.requestOptions && this.requestOptions.headers) {
            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers || {}));
        }
        return lowercaseKeys(headers || {});
    }
    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {
        let clientHeader;
        if (this.requestOptions && this.requestOptions.headers) {
            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];
        }
        return additionalHeaders[header] || clientHeader || _default;
    }
    _getAgent(parsedUrl) {
        let agent;
        const proxyUrl = pm.getProxyUrl(parsedUrl);
        const useProxy = proxyUrl && proxyUrl.hostname;
        if (this._keepAlive && useProxy) {
            agent = this._proxyAgent;
        }
        if (!useProxy) {
            agent = this._agent;
        }
        // if agent is already assigned use that agent.
        if (agent) {
            return agent;
        }
        const usingSsl = parsedUrl.protocol === 'https:';
        let maxSockets = 100;
        if (this.requestOptions) {
            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;
        }
        // This is `useProxy` again, but we need to check `proxyURl` directly for TypeScripts's flow analysis.
        if (proxyUrl && proxyUrl.hostname) {
            const agentOptions = {
                maxSockets,
                keepAlive: this._keepAlive,
                proxy: Object.assign(Object.assign({}, ((proxyUrl.username || proxyUrl.password) && {
                    proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`
                })), { host: proxyUrl.hostname, port: proxyUrl.port })
            };
            let tunnelAgent;
            const overHttps = proxyUrl.protocol === 'https:';
            if (usingSsl) {
                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;
            }
            else {
                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;
            }
            agent = tunnelAgent(agentOptions);
            this._proxyAgent = agent;
        }
        // if tunneling agent isn't assigned create a new agent
        if (!agent) {
            const options = { keepAlive: this._keepAlive, maxSockets };
            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);
            this._agent = agent;
        }
        if (usingSsl && this._ignoreSslError) {
            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process
            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options
            // we have to cast it to any and change it directly
            agent.options = Object.assign(agent.options || {}, {
                rejectUnauthorized: false
            });
        }
        return agent;
    }
    _getProxyAgentDispatcher(parsedUrl, proxyUrl) {
        let proxyAgent;
        if (this._keepAlive) {
            proxyAgent = this._proxyAgentDispatcher;
        }
        // if agent is already assigned use that agent.
        if (proxyAgent) {
            return proxyAgent;
        }
        const usingSsl = parsedUrl.protocol === 'https:';
        proxyAgent = new undici_1.ProxyAgent(Object.assign({ uri: proxyUrl.href, pipelining: !this._keepAlive ? 0 : 1 }, ((proxyUrl.username || proxyUrl.password) && {
            token: `Basic ${Buffer.from(`${proxyUrl.username}:${proxyUrl.password}`).toString('base64')}`
        })));
        this._proxyAgentDispatcher = proxyAgent;
        if (usingSsl && this._ignoreSslError) {
            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process
            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options
            // we have to cast it to any and change it directly
            proxyAgent.options = Object.assign(proxyAgent.options.requestTls || {}, {
                rejectUnauthorized: false
            });
        }
        return proxyAgent;
    }
    _performExponentialBackoff(retryNumber) {
        return __awaiter(this, void 0, void 0, function* () {
            retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);
            const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);
            return new Promise(resolve => setTimeout(() => resolve(), ms));
        });
    }
    _processResponse(res, options) {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {
                const statusCode = res.message.statusCode || 0;
                const response = {
                    statusCode,
                    result: null,
                    headers: {}
                };
                // not found leads to null obj returned
                if (statusCode === HttpCodes.NotFound) {
                    resolve(response);
                }
                // get the result from the body
                function dateTimeDeserializer(key, value) {
                    if (typeof value === 'string') {
                        const a = new Date(value);
                        if (!isNaN(a.valueOf())) {
                            return a;
                        }
                    }
                    return value;
                }
                let obj;
                let contents;
                try {
                    contents = yield res.readBody();
                    if (contents && contents.length > 0) {
                        if (options && options.deserializeDates) {
                            obj = JSON.parse(contents, dateTimeDeserializer);
                        }
                        else {
                            obj = JSON.parse(contents);
                        }
                        response.result = obj;
                    }
                    response.headers = res.message.headers;
                }
                catch (err) {
                    // Invalid resource (contents not json);  leaving result obj null
                }
                // note that 3xx redirects are handled by the http layer.
                if (statusCode > 299) {
                    let msg;
                    // if exception/error in body, attempt to get better error
                    if (obj && obj.message) {
                        msg = obj.message;
                    }
                    else if (contents && contents.length > 0) {
                        // it may be the case that the exception is in the body message as string
                        msg = contents;
                    }
                    else {
                        msg = `Failed request: (${statusCode})`;
                    }
                    const err = new HttpClientError(msg, statusCode);
                    err.result = response.result;
                    reject(err);
                }
                else {
                    resolve(response);
                }
            }));
        });
    }
}
exports.HttpClient = HttpClient;
const lowercaseKeys = (obj) => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});
//# sourceMappingURL=index.js.map

/***/ }),

/***/ 4988:
/***/ ((__unused_webpack_module, exports) => {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.checkBypass = exports.getProxyUrl = void 0;
function getProxyUrl(reqUrl) {
    const usingSsl = reqUrl.protocol === 'https:';
    if (checkBypass(reqUrl)) {
        return undefined;
    }
    const proxyVar = (() => {
        if (usingSsl) {
            return process.env['https_proxy'] || process.env['HTTPS_PROXY'];
        }
        else {
            return process.env['http_proxy'] || process.env['HTTP_PROXY'];
        }
    })();
    if (proxyVar) {
        try {
            return new DecodedURL(proxyVar);
        }
        catch (_a) {
            if (!proxyVar.startsWith('http://') && !proxyVar.startsWith('https://'))
                return new DecodedURL(`http://${proxyVar}`);
        }
    }
    else {
        return undefined;
    }
}
exports.getProxyUrl = getProxyUrl;
function checkBypass(reqUrl) {
    if (!reqUrl.hostname) {
        return false;
    }
    const reqHost = reqUrl.hostname;
    if (isLoopbackAddress(reqHost)) {
        return true;
    }
    const noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';
    if (!noProxy) {
        return false;
    }
    // Determine the request port
    let reqPort;
    if (reqUrl.port) {
        reqPort = Number(reqUrl.port);
    }
    else if (reqUrl.protocol === 'http:') {
        reqPort = 80;
    }
    else if (reqUrl.protocol === 'https:') {
        reqPort = 443;
    }
    // Format the request hostname and hostname with port
    const upperReqHosts = [reqUrl.hostname.toUpperCase()];
    if (typeof reqPort === 'number') {
        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);
    }
    // Compare request host against noproxy
    for (const upperNoProxyItem of noProxy
        .split(',')
        .map(x => x.trim().toUpperCase())
        .filter(x => x)) {
        if (upperNoProxyItem === '*' ||
            upperReqHosts.some(x => x === upperNoProxyItem ||
                x.endsWith(`.${upperNoProxyItem}`) ||
                (upperNoProxyItem.startsWith('.') &&
                    x.endsWith(`${upperNoProxyItem}`)))) {
            return true;
        }
    }
    return false;
}
exports.checkBypass = checkBypass;
function isLoopbackAddress(host) {
    const hostLower = host.toLowerCase();
    return (hostLower === 'localhost' ||
        hostLower.startsWith('127.') ||
        hostLower.startsWith('[::1]') ||
        hostLower.startsWith('[0:0:0:0:0:0:0:1]'));
}
class DecodedURL extends URL {
    constructor(url, base) {
        super(url, base);
        this._decodedUsername = decodeURIComponent(super.username);
        this._decodedPassword = decodeURIComponent(super.password);
    }
    get username() {
        return this._decodedUsername;
    }
    get password() {
        return this._decodedPassword;
    }
}
//# sourceMappingURL=proxy.js.map

/***/ }),

/***/ 5207:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var _a;
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.getCmdPath = exports.tryGetExecutablePath = exports.isRooted = exports.isDirectory = exports.exists = exports.READONLY = exports.UV_FS_O_EXLOCK = exports.IS_WINDOWS = exports.unlink = exports.symlink = exports.stat = exports.rmdir = exports.rm = exports.rename = exports.readlink = exports.readdir = exports.open = exports.mkdir = exports.lstat = exports.copyFile = exports.chmod = void 0;
const fs = __importStar(__nccwpck_require__(9896));
const path = __importStar(__nccwpck_require__(6928));
_a = fs.promises
// export const {open} = 'fs'
, exports.chmod = _a.chmod, exports.copyFile = _a.copyFile, exports.lstat = _a.lstat, exports.mkdir = _a.mkdir, exports.open = _a.open, exports.readdir = _a.readdir, exports.readlink = _a.readlink, exports.rename = _a.rename, exports.rm = _a.rm, exports.rmdir = _a.rmdir, exports.stat = _a.stat, exports.symlink = _a.symlink, exports.unlink = _a.unlink;
// export const {open} = 'fs'
exports.IS_WINDOWS = process.platform === 'win32';
// See https://github.com/nodejs/node/blob/d0153aee367422d0858105abec186da4dff0a0c5/deps/uv/include/uv/win.h#L691
exports.UV_FS_O_EXLOCK = 0x10000000;
exports.READONLY = fs.constants.O_RDONLY;
function exists(fsPath) {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            yield exports.stat(fsPath);
        }
        catch (err) {
            if (err.code === 'ENOENT') {
                return false;
            }
            throw err;
        }
        return true;
    });
}
exports.exists = exists;
function isDirectory(fsPath, useStat = false) {
    return __awaiter(this, void 0, void 0, function* () {
        const stats = useStat ? yield exports.stat(fsPath) : yield exports.lstat(fsPath);
        return stats.isDirectory();
    });
}
exports.isDirectory = isDirectory;
/**
 * On OSX/Linux, true if path starts with '/'. On Windows, true for paths like:
 * \, \hello, \\hello\share, C:, and C:\hello (and corresponding alternate separator cases).
 */
function isRooted(p) {
    p = normalizeSeparators(p);
    if (!p) {
        throw new Error('isRooted() parameter "p" cannot be empty');
    }
    if (exports.IS_WINDOWS) {
        return (p.startsWith('\\') || /^[A-Z]:/i.test(p) // e.g. \ or \hello or \\hello
        ); // e.g. C: or C:\hello
    }
    return p.startsWith('/');
}
exports.isRooted = isRooted;
/**
 * Best effort attempt to determine whether a file exists and is executable.
 * @param filePath    file path to check
 * @param extensions  additional file extensions to try
 * @return if file exists and is executable, returns the file path. otherwise empty string.
 */
function tryGetExecutablePath(filePath, extensions) {
    return __awaiter(this, void 0, void 0, function* () {
        let stats = undefined;
        try {
            // test file exists
            stats = yield exports.stat(filePath);
        }
        catch (err) {
            if (err.code !== 'ENOENT') {
                // eslint-disable-next-line no-console
                console.log(`Unexpected error attempting to determine if executable file exists '${filePath}': ${err}`);
            }
        }
        if (stats && stats.isFile()) {
            if (exports.IS_WINDOWS) {
                // on Windows, test for valid extension
                const upperExt = path.extname(filePath).toUpperCase();
                if (extensions.some(validExt => validExt.toUpperCase() === upperExt)) {
                    return filePath;
                }
            }
            else {
                if (isUnixExecutable(stats)) {
                    return filePath;
                }
            }
        }
        // try each extension
        const originalFilePath = filePath;
        for (const extension of extensions) {
            filePath = originalFilePath + extension;
            stats = undefined;
            try {
                stats = yield exports.stat(filePath);
            }
            catch (err) {
                if (err.code !== 'ENOENT') {
                    // eslint-disable-next-line no-console
                    console.log(`Unexpected error attempting to determine if executable file exists '${filePath}': ${err}`);
                }
            }
            if (stats && stats.isFile()) {
                if (exports.IS_WINDOWS) {
                    // preserve the case of the actual file (since an extension was appended)
                    try {
                        const directory = path.dirname(filePath);
                        const upperName = path.basename(filePath).toUpperCase();
                        for (const actualName of yield exports.readdir(directory)) {
                            if (upperName === actualName.toUpperCase()) {
                                filePath = path.join(directory, actualName);
                                break;
                            }
                        }
                    }
                    catch (err) {
                        // eslint-disable-next-line no-console
                        console.log(`Unexpected error attempting to determine the actual case of the file '${filePath}': ${err}`);
                    }
                    return filePath;
                }
                else {
                    if (isUnixExecutable(stats)) {
                        return filePath;
                    }
                }
            }
        }
        return '';
    });
}
exports.tryGetExecutablePath = tryGetExecutablePath;
function normalizeSeparators(p) {
    p = p || '';
    if (exports.IS_WINDOWS) {
        // convert slashes on Windows
        p = p.replace(/\//g, '\\');
        // remove redundant slashes
        return p.replace(/\\\\+/g, '\\');
    }
    // remove redundant slashes
    return p.replace(/\/\/+/g, '/');
}
// on Mac/Linux, test the execute bit
//     R   W  X  R  W X R W X
//   256 128 64 32 16 8 4 2 1
function isUnixExecutable(stats) {
    return ((stats.mode & 1) > 0 ||
        ((stats.mode & 8) > 0 && stats.gid === process.getgid()) ||
        ((stats.mode & 64) > 0 && stats.uid === process.getuid()));
}
// Get the path of cmd.exe in windows
function getCmdPath() {
    var _a;
    return (_a = process.env['COMSPEC']) !== null && _a !== void 0 ? _a : `cmd.exe`;
}
exports.getCmdPath = getCmdPath;
//# sourceMappingURL=io-util.js.map

/***/ }),

/***/ 4994:
/***/ (function(__unused_webpack_module, exports, __nccwpck_require__) {

"use strict";

var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.findInPath = exports.which = exports.mkdirP = exports.rmRF = exports.mv = exports.cp = void 0;
const assert_1 = __nccwpck_require__(2613);
const path = __importStar(__nccwpck_require__(6928));
const ioUtil = __importStar(__nccwpck_require__(5207));
/**
 * Copies a file or folder.
 * Based off of shelljs - https://github.com/shelljs/shelljs/blob/9237f66c52e5daa40458f94f9565e18e8132f5a6/src/cp.js
 *
 * @param     source    source path
 * @param     dest      destination path
 * @param     options   optional. See CopyOptions.
 */
function cp(source, dest, options = {}) {
    return __awaiter(this, void 0, void 0, function* () {
        const { force, recursive, copySourceDirectory } = readCopyOptions(options);
        const destStat = (yield ioUtil.exists(dest)) ? yield ioUtil.stat(dest) : null;
        // Dest is an existing file, but not forcing
        if (destStat && destStat.isFile() && !force) {
            return;
        }
        // If dest is an existing directory, should copy inside.
        const newDest = destStat && destStat.isDirectory() && copySourceDirectory
            ? path.join(dest, path.basename(source))
            : dest;
        if (!(yield ioUtil.exists(source))) {
            throw new Error(`no such file or directory: ${source}`);
        }
        const sourceStat = yield ioUtil.stat(source);
        if (sourceStat.isDirectory()) {
            if (!recursive) {
                throw new Error(`Failed to copy. ${source} is a directory, but tried to copy without recursive flag.`);
            }
            else {
                yield cpDirRecursive(source, newDest, 0, force);
            }
        }
        else {
            if (path.relative(source, newDest) === '') {
                // a file cannot be copied to itself
                throw new Error(`'${newDest}' and '${source}' are the same file`);
            }
            yield copyFile(source, newDest, force);
        }
    });
}
exports.cp = cp;
/**
 * Moves a path.
 *
 * @param     source    source path
 * @param     dest      destination path
 * @param     options   optional. See MoveOptions.
 */
function mv(source, dest, options = {}) {
    return __awaiter(this, void 0, void 0, function* () {
        if (yield ioUtil.exists(dest)) {
            let destExists = true;
            if (yield ioUtil.isDirectory(dest)) {
                // If dest is directory copy src into dest
                dest = path.join(dest, path.basename(source));
                destExists = yield ioUtil.exists(dest);
            }
            if (destExists) {
                if (options.force == null || options.force) {
                    yield rmRF(dest);
                }
                else {
                    throw new Error('Destination already exists');
                }
            }
        }
        yield mkdirP(path.dirname(dest));
        yield ioUtil.rename(source, dest);
    });
}
exports.mv = mv;
/**
 * Remove a path recursively with force
 *
 * @param inputPath path to remove
 */
function rmRF(inputPath) {
    return __awaiter(this, void 0, void 0, function* () {
        if (ioUtil.IS_WINDOWS) {
            // Check for invalid characters
            // https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file
            if (/[*"<>|]/.test(inputPath)) {
                throw new Error('File path must not contain `*`, `"`, `<`, `>` or `|` on Windows');
            }
        }
        try {
            // note if path does not exist, error is silent
            yield ioUtil.rm(inputPath, {
                force: true,
                maxRetries: 3,
                recursive: true,
                retryDelay: 300
            });
        }
        catch (err) {
            throw new Error(`File was unable to be removed ${err}`);
        }
    });
}
exports.rmRF = rmRF;
/**
 * Make a directory.  Creates the full path with folders in between
 * Will throw if it fails
 *
 * @param   fsPath        path to create
 * @returns Promise<void>
 */
function mkdirP(fsPath) {
    return __awaiter(this, void 0, void 0, function* () {
        assert_1.ok(fsPath, 'a path argument must be provided');
        yield ioUtil.mkdir(fsPath, { recursive: true });
    });
}
exports.mkdirP = mkdirP;
/**
 * Returns path of a tool had the tool actually been invoked.  Resolves via paths.
 * If you check and the tool does not exist, it will throw.
 *
 * @param     tool              name of the tool
 * @param     check             whether to check if tool exists
 * @returns   Promise<string>   path to tool
 */
function which(tool, check) {
    return __awaiter(this, void 0, void 0, function* () {
        if (!tool) {
            throw new Error("parameter 'tool' is required");
        }
        // recursive when check=true
        if (check) {
            const result = yield which(tool, false);
            if (!result) {
                if (ioUtil.IS_WINDOWS) {
                    throw new Error(`Unable to locate executable file: ${tool}. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also verify the file has a valid extension for an executable file.`);
                }
                else {
                    throw new Error(`Unable to locate executable file: ${tool}. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also check the file mode to verify the file is executable.`);
                }
            }
            return result;
        }
        const matches = yield findInPath(tool);
        if (matches && matches.length > 0) {
            return matches[0];
        }
        return '';
    });
}
exports.which = which;
/**
 * Returns a list of all occurrences of the given tool on the system path.
 *
 * @returns   Promise<string[]>  the paths of the tool
 */
function findInPath(tool) {
    return __awaiter(this, void 0, void 0, function* () {
        if (!tool) {
            throw new Error("parameter 'tool' is required");
        }
        // build the list of extensions to try
        const extensions = [];
        if (ioUtil.IS_WINDOWS && process.env['PATHEXT']) {
            for (const extension of process.env['PATHEXT'].split(path.delimiter)) {
                if (extension) {
                    extensions.push(extension);
                }
            }
        }
        // if it's rooted, return it if exists. otherwise return empty.
        if (ioUtil.isRooted(tool)) {
            const filePath = yield ioUtil.tryGetExecutablePath(tool, extensions);
            if (filePath) {
                return [filePath];
            }
            return [];
        }
        // if any path separators, return empty
        if (tool.includes(path.sep)) {
            return [];
        }
        // build the list of directories
        //
        // Note, technically "where" checks the current directory on Windows. From a toolkit perspective,
        // it feels like we should not do this. Checking the current directory seems like more of a use
        // case of a shell, and the which() function exposed by the toolkit should strive for consistency
        // across platforms.
        const directories = [];
        if (process.env.PATH) {
            for (const p of process.env.PATH.split(path.delimiter)) {
                if (p) {
                    directories.push(p);
                }
            }
        }
        // find all matches
        const matches = [];
        for (const directory of directories) {
            const filePath = yield ioUtil.tryGetExecutablePath(path.join(directory, tool), extensions);
            if (filePath) {
                matches.push(filePath);
            }
        }
        return matches;
    });
}
exports.findInPath = findInPath;
function readCopyOptions(options) {
    const force = options.force == null ? true : options.force;
    const recursive = Boolean(options.recursive);
    const copySourceDirectory = options.copySourceDirectory == null
        ? true
        : Boolean(options.copySourceDirectory);
    return { force, recursive, copySourceDirectory };
}
function cpDirRecursive(sourceDir, destDir, currentDepth, force) {
    return __awaiter(this, void 0, void 0, function* () {
        // Ensure there is not a run away recursive copy
        if (currentDepth >= 255)
            return;
        currentDepth++;
        yield mkdirP(destDir);
        const files = yield ioUtil.readdir(sourceDir);
        for (const fileName of files) {
            const srcFile = `${sourceDir}/${fileName}`;
            const destFile = `${destDir}/${fileName}`;
            const srcFileStat = yield ioUtil.lstat(srcFile);
            if (srcFileStat.isDirectory()) {
                // Recurse
                yield cpDirRecursive(srcFile, destFile, currentDepth, force);
            }
            else {
                yield copyFile(srcFile, destFile, force);
            }
        }
        // Change the mode for the newly created directory
        yield ioUtil.chmod(destDir, (yield ioUtil.stat(sourceDir)).mode);
    });
}
// Buffered file copy
function copyFile(srcFile, destFile, force) {
    return __awaiter(this, void 0, void 0, function* () {
        if ((yield ioUtil.lstat(srcFile)).isSymbolicLink()) {
            // unlink/re-link it
            try {
                yield ioUtil.lstat(destFile);
                yield ioUtil.unlink(destFile);
            }
            catch (e) {
                // Try to override file permission
                if (e.code === 'EPERM') {
                    yield ioUtil.chmod(destFile, '0666');
                    yield ioUtil.unlink(destFile);
                }
                // other errors = it doesn't exist, no work to do
            }
            // Copy over symlink
            const symlinkFull = yield ioUtil.readlink(srcFile);
            yield ioUtil.symlink(symlinkFull, destFile, ioUtil.IS_WINDOWS ? 'junction' : null);
        }
        else if (!(yield ioUtil.exists(destFile)) || force) {
            yield ioUtil.copyFile(srcFile, destFile);
        }
    });
}
//# sourceMappingURL=io.js.map

/***/ }),

/***/ 7864:
/***/ ((module) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var dist_src_exports = {};
__export(dist_src_exports, {
  createTokenAuth: () => createTokenAuth
});
module.exports = __toCommonJS(dist_src_exports);

// pkg/dist-src/auth.js
var REGEX_IS_INSTALLATION_LEGACY = /^v1\./;
var REGEX_IS_INSTALLATION = /^ghs_/;
var REGEX_IS_USER_TO_SERVER = /^ghu_/;
async function auth(token) {
  const isApp = token.split(/\./).length === 3;
  const isInstallation = REGEX_IS_INSTALLATION_LEGACY.test(token) || REGEX_IS_INSTALLATION.test(token);
  const isUserToServer = REGEX_IS_USER_TO_SERVER.test(token);
  const tokenType = isApp ? "app" : isInstallation ? "installation" : isUserToServer ? "user-to-server" : "oauth";
  return {
    type: "token",
    token,
    tokenType
  };
}

// pkg/dist-src/with-authorization-prefix.js
function withAuthorizationPrefix(token) {
  if (token.split(/\./).length === 3) {
    return `bearer ${token}`;
  }
  return `token ${token}`;
}

// pkg/dist-src/hook.js
async function hook(token, request, route, parameters) {
  const endpoint = request.endpoint.merge(
    route,
    parameters
  );
  endpoint.headers.authorization = withAuthorizationPrefix(token);
  return request(endpoint);
}

// pkg/dist-src/index.js
var createTokenAuth = function createTokenAuth2(token) {
  if (!token) {
    throw new Error("[@octokit/auth-token] No token passed to createTokenAuth");
  }
  if (typeof token !== "string") {
    throw new Error(
      "[@octokit/auth-token] Token passed to createTokenAuth is not a string"
    );
  }
  token = token.replace(/^(token|bearer) +/i, "");
  return Object.assign(auth.bind(null, token), {
    hook: hook.bind(null, token)
  });
};
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 1897:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var index_exports = {};
__export(index_exports, {
  Octokit: () => Octokit
});
module.exports = __toCommonJS(index_exports);
var import_universal_user_agent = __nccwpck_require__(3843);
var import_before_after_hook = __nccwpck_require__(2732);
var import_request = __nccwpck_require__(8636);
var import_graphql = __nccwpck_require__(7);
var import_auth_token = __nccwpck_require__(7864);

// pkg/dist-src/version.js
var VERSION = "5.2.1";

// pkg/dist-src/index.js
var noop = () => {
};
var consoleWarn = console.warn.bind(console);
var consoleError = console.error.bind(console);
var userAgentTrail = `octokit-core.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`;
var Octokit = class {
  static {
    this.VERSION = VERSION;
  }
  static defaults(defaults) {
    const OctokitWithDefaults = class extends this {
      constructor(...args) {
        const options = args[0] || {};
        if (typeof defaults === "function") {
          super(defaults(options));
          return;
        }
        super(
          Object.assign(
            {},
            defaults,
            options,
            options.userAgent && defaults.userAgent ? {
              userAgent: `${options.userAgent} ${defaults.userAgent}`
            } : null
          )
        );
      }
    };
    return OctokitWithDefaults;
  }
  static {
    this.plugins = [];
  }
  /**
   * Attach a plugin (or many) to your Octokit instance.
   *
   * @example
   * const API = Octokit.plugin(plugin1, plugin2, plugin3, ...)
   */
  static plugin(...newPlugins) {
    const currentPlugins = this.plugins;
    const NewOctokit = class extends this {
      static {
        this.plugins = currentPlugins.concat(
          newPlugins.filter((plugin) => !currentPlugins.includes(plugin))
        );
      }
    };
    return NewOctokit;
  }
  constructor(options = {}) {
    const hook = new import_before_after_hook.Collection();
    const requestDefaults = {
      baseUrl: import_request.request.endpoint.DEFAULTS.baseUrl,
      headers: {},
      request: Object.assign({}, options.request, {
        // @ts-ignore internal usage only, no need to type
        hook: hook.bind(null, "request")
      }),
      mediaType: {
        previews: [],
        format: ""
      }
    };
    requestDefaults.headers["user-agent"] = options.userAgent ? `${options.userAgent} ${userAgentTrail}` : userAgentTrail;
    if (options.baseUrl) {
      requestDefaults.baseUrl = options.baseUrl;
    }
    if (options.previews) {
      requestDefaults.mediaType.previews = options.previews;
    }
    if (options.timeZone) {
      requestDefaults.headers["time-zone"] = options.timeZone;
    }
    this.request = import_request.request.defaults(requestDefaults);
    this.graphql = (0, import_graphql.withCustomRequest)(this.request).defaults(requestDefaults);
    this.log = Object.assign(
      {
        debug: noop,
        info: noop,
        warn: consoleWarn,
        error: consoleError
      },
      options.log
    );
    this.hook = hook;
    if (!options.authStrategy) {
      if (!options.auth) {
        this.auth = async () => ({
          type: "unauthenticated"
        });
      } else {
        const auth = (0, import_auth_token.createTokenAuth)(options.auth);
        hook.wrap("request", auth.hook);
        this.auth = auth;
      }
    } else {
      const { authStrategy, ...otherOptions } = options;
      const auth = authStrategy(
        Object.assign(
          {
            request: this.request,
            log: this.log,
            // we pass the current octokit instance as well as its constructor options
            // to allow for authentication strategies that return a new octokit instance
            // that shares the same internal state as the current one. The original
            // requirement for this was the "event-octokit" authentication strategy
            // of https://github.com/probot/octokit-auth-probot.
            octokit: this,
            octokitOptions: otherOptions
          },
          options.auth
        )
      );
      hook.wrap("request", auth.hook);
      this.auth = auth;
    }
    const classConstructor = this.constructor;
    for (let i = 0; i < classConstructor.plugins.length; ++i) {
      Object.assign(this, classConstructor.plugins[i](this, options));
    }
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 4471:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var dist_src_exports = {};
__export(dist_src_exports, {
  endpoint: () => endpoint
});
module.exports = __toCommonJS(dist_src_exports);

// pkg/dist-src/defaults.js
var import_universal_user_agent = __nccwpck_require__(3843);

// pkg/dist-src/version.js
var VERSION = "9.0.6";

// pkg/dist-src/defaults.js
var userAgent = `octokit-endpoint.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`;
var DEFAULTS = {
  method: "GET",
  baseUrl: "https://api.github.com",
  headers: {
    accept: "application/vnd.github.v3+json",
    "user-agent": userAgent
  },
  mediaType: {
    format: ""
  }
};

// pkg/dist-src/util/lowercase-keys.js
function lowercaseKeys(object) {
  if (!object) {
    return {};
  }
  return Object.keys(object).reduce((newObj, key) => {
    newObj[key.toLowerCase()] = object[key];
    return newObj;
  }, {});
}

// pkg/dist-src/util/is-plain-object.js
function isPlainObject(value) {
  if (typeof value !== "object" || value === null)
    return false;
  if (Object.prototype.toString.call(value) !== "[object Object]")
    return false;
  const proto = Object.getPrototypeOf(value);
  if (proto === null)
    return true;
  const Ctor = Object.prototype.hasOwnProperty.call(proto, "constructor") && proto.constructor;
  return typeof Ctor === "function" && Ctor instanceof Ctor && Function.prototype.call(Ctor) === Function.prototype.call(value);
}

// pkg/dist-src/util/merge-deep.js
function mergeDeep(defaults, options) {
  const result = Object.assign({}, defaults);
  Object.keys(options).forEach((key) => {
    if (isPlainObject(options[key])) {
      if (!(key in defaults))
        Object.assign(result, { [key]: options[key] });
      else
        result[key] = mergeDeep(defaults[key], options[key]);
    } else {
      Object.assign(result, { [key]: options[key] });
    }
  });
  return result;
}

// pkg/dist-src/util/remove-undefined-properties.js
function removeUndefinedProperties(obj) {
  for (const key in obj) {
    if (obj[key] === void 0) {
      delete obj[key];
    }
  }
  return obj;
}

// pkg/dist-src/merge.js
function merge(defaults, route, options) {
  if (typeof route === "string") {
    let [method, url] = route.split(" ");
    options = Object.assign(url ? { method, url } : { url: method }, options);
  } else {
    options = Object.assign({}, route);
  }
  options.headers = lowercaseKeys(options.headers);
  removeUndefinedProperties(options);
  removeUndefinedProperties(options.headers);
  const mergedOptions = mergeDeep(defaults || {}, options);
  if (options.url === "/graphql") {
    if (defaults && defaults.mediaType.previews?.length) {
      mergedOptions.mediaType.previews = defaults.mediaType.previews.filter(
        (preview) => !mergedOptions.mediaType.previews.includes(preview)
      ).concat(mergedOptions.mediaType.previews);
    }
    mergedOptions.mediaType.previews = (mergedOptions.mediaType.previews || []).map((preview) => preview.replace(/-preview/, ""));
  }
  return mergedOptions;
}

// pkg/dist-src/util/add-query-parameters.js
function addQueryParameters(url, parameters) {
  const separator = /\?/.test(url) ? "&" : "?";
  const names = Object.keys(parameters);
  if (names.length === 0) {
    return url;
  }
  return url + separator + names.map((name) => {
    if (name === "q") {
      return "q=" + parameters.q.split("+").map(encodeURIComponent).join("+");
    }
    return `${name}=${encodeURIComponent(parameters[name])}`;
  }).join("&");
}

// pkg/dist-src/util/extract-url-variable-names.js
var urlVariableRegex = /\{[^{}}]+\}/g;
function removeNonChars(variableName) {
  return variableName.replace(/(?:^\W+)|(?:(?<!\W)\W+$)/g, "").split(/,/);
}
function extractUrlVariableNames(url) {
  const matches = url.match(urlVariableRegex);
  if (!matches) {
    return [];
  }
  return matches.map(removeNonChars).reduce((a, b) => a.concat(b), []);
}

// pkg/dist-src/util/omit.js
function omit(object, keysToOmit) {
  const result = { __proto__: null };
  for (const key of Object.keys(object)) {
    if (keysToOmit.indexOf(key) === -1) {
      result[key] = object[key];
    }
  }
  return result;
}

// pkg/dist-src/util/url-template.js
function encodeReserved(str) {
  return str.split(/(%[0-9A-Fa-f]{2})/g).map(function(part) {
    if (!/%[0-9A-Fa-f]/.test(part)) {
      part = encodeURI(part).replace(/%5B/g, "[").replace(/%5D/g, "]");
    }
    return part;
  }).join("");
}
function encodeUnreserved(str) {
  return encodeURIComponent(str).replace(/[!'()*]/g, function(c) {
    return "%" + c.charCodeAt(0).toString(16).toUpperCase();
  });
}
function encodeValue(operator, value, key) {
  value = operator === "+" || operator === "#" ? encodeReserved(value) : encodeUnreserved(value);
  if (key) {
    return encodeUnreserved(key) + "=" + value;
  } else {
    return value;
  }
}
function isDefined(value) {
  return value !== void 0 && value !== null;
}
function isKeyOperator(operator) {
  return operator === ";" || operator === "&" || operator === "?";
}
function getValues(context, operator, key, modifier) {
  var value = context[key], result = [];
  if (isDefined(value) && value !== "") {
    if (typeof value === "string" || typeof value === "number" || typeof value === "boolean") {
      value = value.toString();
      if (modifier && modifier !== "*") {
        value = value.substring(0, parseInt(modifier, 10));
      }
      result.push(
        encodeValue(operator, value, isKeyOperator(operator) ? key : "")
      );
    } else {
      if (modifier === "*") {
        if (Array.isArray(value)) {
          value.filter(isDefined).forEach(function(value2) {
            result.push(
              encodeValue(operator, value2, isKeyOperator(operator) ? key : "")
            );
          });
        } else {
          Object.keys(value).forEach(function(k) {
            if (isDefined(value[k])) {
              result.push(encodeValue(operator, value[k], k));
            }
          });
        }
      } else {
        const tmp = [];
        if (Array.isArray(value)) {
          value.filter(isDefined).forEach(function(value2) {
            tmp.push(encodeValue(operator, value2));
          });
        } else {
          Object.keys(value).forEach(function(k) {
            if (isDefined(value[k])) {
              tmp.push(encodeUnreserved(k));
              tmp.push(encodeValue(operator, value[k].toString()));
            }
          });
        }
        if (isKeyOperator(operator)) {
          result.push(encodeUnreserved(key) + "=" + tmp.join(","));
        } else if (tmp.length !== 0) {
          result.push(tmp.join(","));
        }
      }
    }
  } else {
    if (operator === ";") {
      if (isDefined(value)) {
        result.push(encodeUnreserved(key));
      }
    } else if (value === "" && (operator === "&" || operator === "?")) {
      result.push(encodeUnreserved(key) + "=");
    } else if (value === "") {
      result.push("");
    }
  }
  return result;
}
function parseUrl(template) {
  return {
    expand: expand.bind(null, template)
  };
}
function expand(template, context) {
  var operators = ["+", "#", ".", "/", ";", "?", "&"];
  template = template.replace(
    /\{([^\{\}]+)\}|([^\{\}]+)/g,
    function(_, expression, literal) {
      if (expression) {
        let operator = "";
        const values = [];
        if (operators.indexOf(expression.charAt(0)) !== -1) {
          operator = expression.charAt(0);
          expression = expression.substr(1);
        }
        expression.split(/,/g).forEach(function(variable) {
          var tmp = /([^:\*]*)(?::(\d+)|(\*))?/.exec(variable);
          values.push(getValues(context, operator, tmp[1], tmp[2] || tmp[3]));
        });
        if (operator && operator !== "+") {
          var separator = ",";
          if (operator === "?") {
            separator = "&";
          } else if (operator !== "#") {
            separator = operator;
          }
          return (values.length !== 0 ? operator : "") + values.join(separator);
        } else {
          return values.join(",");
        }
      } else {
        return encodeReserved(literal);
      }
    }
  );
  if (template === "/") {
    return template;
  } else {
    return template.replace(/\/$/, "");
  }
}

// pkg/dist-src/parse.js
function parse(options) {
  let method = options.method.toUpperCase();
  let url = (options.url || "/").replace(/:([a-z]\w+)/g, "{$1}");
  let headers = Object.assign({}, options.headers);
  let body;
  let parameters = omit(options, [
    "method",
    "baseUrl",
    "url",
    "headers",
    "request",
    "mediaType"
  ]);
  const urlVariableNames = extractUrlVariableNames(url);
  url = parseUrl(url).expand(parameters);
  if (!/^http/.test(url)) {
    url = options.baseUrl + url;
  }
  const omittedParameters = Object.keys(options).filter((option) => urlVariableNames.includes(option)).concat("baseUrl");
  const remainingParameters = omit(parameters, omittedParameters);
  const isBinaryRequest = /application\/octet-stream/i.test(headers.accept);
  if (!isBinaryRequest) {
    if (options.mediaType.format) {
      headers.accept = headers.accept.split(/,/).map(
        (format) => format.replace(
          /application\/vnd(\.\w+)(\.v3)?(\.\w+)?(\+json)?$/,
          `application/vnd$1$2.${options.mediaType.format}`
        )
      ).join(",");
    }
    if (url.endsWith("/graphql")) {
      if (options.mediaType.previews?.length) {
        const previewsFromAcceptHeader = headers.accept.match(/(?<![\w-])[\w-]+(?=-preview)/g) || [];
        headers.accept = previewsFromAcceptHeader.concat(options.mediaType.previews).map((preview) => {
          const format = options.mediaType.format ? `.${options.mediaType.format}` : "+json";
          return `application/vnd.github.${preview}-preview${format}`;
        }).join(",");
      }
    }
  }
  if (["GET", "HEAD"].includes(method)) {
    url = addQueryParameters(url, remainingParameters);
  } else {
    if ("data" in remainingParameters) {
      body = remainingParameters.data;
    } else {
      if (Object.keys(remainingParameters).length) {
        body = remainingParameters;
      }
    }
  }
  if (!headers["content-type"] && typeof body !== "undefined") {
    headers["content-type"] = "application/json; charset=utf-8";
  }
  if (["PATCH", "PUT"].includes(method) && typeof body === "undefined") {
    body = "";
  }
  return Object.assign(
    { method, url, headers },
    typeof body !== "undefined" ? { body } : null,
    options.request ? { request: options.request } : null
  );
}

// pkg/dist-src/endpoint-with-defaults.js
function endpointWithDefaults(defaults, route, options) {
  return parse(merge(defaults, route, options));
}

// pkg/dist-src/with-defaults.js
function withDefaults(oldDefaults, newDefaults) {
  const DEFAULTS2 = merge(oldDefaults, newDefaults);
  const endpoint2 = endpointWithDefaults.bind(null, DEFAULTS2);
  return Object.assign(endpoint2, {
    DEFAULTS: DEFAULTS2,
    defaults: withDefaults.bind(null, DEFAULTS2),
    merge: merge.bind(null, DEFAULTS2),
    parse
  });
}

// pkg/dist-src/index.js
var endpoint = withDefaults(null, DEFAULTS);
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 7:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var index_exports = {};
__export(index_exports, {
  GraphqlResponseError: () => GraphqlResponseError,
  graphql: () => graphql2,
  withCustomRequest: () => withCustomRequest
});
module.exports = __toCommonJS(index_exports);
var import_request3 = __nccwpck_require__(8636);
var import_universal_user_agent = __nccwpck_require__(3843);

// pkg/dist-src/version.js
var VERSION = "7.1.1";

// pkg/dist-src/with-defaults.js
var import_request2 = __nccwpck_require__(8636);

// pkg/dist-src/graphql.js
var import_request = __nccwpck_require__(8636);

// pkg/dist-src/error.js
function _buildMessageForResponseErrors(data) {
  return `Request failed due to following response errors:
` + data.errors.map((e) => ` - ${e.message}`).join("\n");
}
var GraphqlResponseError = class extends Error {
  constructor(request2, headers, response) {
    super(_buildMessageForResponseErrors(response));
    this.request = request2;
    this.headers = headers;
    this.response = response;
    this.name = "GraphqlResponseError";
    this.errors = response.errors;
    this.data = response.data;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }
  }
};

// pkg/dist-src/graphql.js
var NON_VARIABLE_OPTIONS = [
  "method",
  "baseUrl",
  "url",
  "headers",
  "request",
  "query",
  "mediaType"
];
var FORBIDDEN_VARIABLE_OPTIONS = ["query", "method", "url"];
var GHES_V3_SUFFIX_REGEX = /\/api\/v3\/?$/;
function graphql(request2, query, options) {
  if (options) {
    if (typeof query === "string" && "query" in options) {
      return Promise.reject(
        new Error(`[@octokit/graphql] "query" cannot be used as variable name`)
      );
    }
    for (const key in options) {
      if (!FORBIDDEN_VARIABLE_OPTIONS.includes(key)) continue;
      return Promise.reject(
        new Error(
          `[@octokit/graphql] "${key}" cannot be used as variable name`
        )
      );
    }
  }
  const parsedOptions = typeof query === "string" ? Object.assign({ query }, options) : query;
  const requestOptions = Object.keys(
    parsedOptions
  ).reduce((result, key) => {
    if (NON_VARIABLE_OPTIONS.includes(key)) {
      result[key] = parsedOptions[key];
      return result;
    }
    if (!result.variables) {
      result.variables = {};
    }
    result.variables[key] = parsedOptions[key];
    return result;
  }, {});
  const baseUrl = parsedOptions.baseUrl || request2.endpoint.DEFAULTS.baseUrl;
  if (GHES_V3_SUFFIX_REGEX.test(baseUrl)) {
    requestOptions.url = baseUrl.replace(GHES_V3_SUFFIX_REGEX, "/api/graphql");
  }
  return request2(requestOptions).then((response) => {
    if (response.data.errors) {
      const headers = {};
      for (const key of Object.keys(response.headers)) {
        headers[key] = response.headers[key];
      }
      throw new GraphqlResponseError(
        requestOptions,
        headers,
        response.data
      );
    }
    return response.data.data;
  });
}

// pkg/dist-src/with-defaults.js
function withDefaults(request2, newDefaults) {
  const newRequest = request2.defaults(newDefaults);
  const newApi = (query, options) => {
    return graphql(newRequest, query, options);
  };
  return Object.assign(newApi, {
    defaults: withDefaults.bind(null, newRequest),
    endpoint: newRequest.endpoint
  });
}

// pkg/dist-src/index.js
var graphql2 = withDefaults(import_request3.request, {
  headers: {
    "user-agent": `octokit-graphql.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`
  },
  method: "POST",
  url: "/graphql"
});
function withCustomRequest(customRequest) {
  return withDefaults(customRequest, {
    method: "POST",
    url: "/graphql"
  });
}
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 8082:
/***/ ((module) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var dist_src_exports = {};
__export(dist_src_exports, {
  composePaginateRest: () => composePaginateRest,
  isPaginatingEndpoint: () => isPaginatingEndpoint,
  paginateRest: () => paginateRest,
  paginatingEndpoints: () => paginatingEndpoints
});
module.exports = __toCommonJS(dist_src_exports);

// pkg/dist-src/version.js
var VERSION = "9.2.2";

// pkg/dist-src/normalize-paginated-list-response.js
function normalizePaginatedListResponse(response) {
  if (!response.data) {
    return {
      ...response,
      data: []
    };
  }
  const responseNeedsNormalization = "total_count" in response.data && !("url" in response.data);
  if (!responseNeedsNormalization)
    return response;
  const incompleteResults = response.data.incomplete_results;
  const repositorySelection = response.data.repository_selection;
  const totalCount = response.data.total_count;
  delete response.data.incomplete_results;
  delete response.data.repository_selection;
  delete response.data.total_count;
  const namespaceKey = Object.keys(response.data)[0];
  const data = response.data[namespaceKey];
  response.data = data;
  if (typeof incompleteResults !== "undefined") {
    response.data.incomplete_results = incompleteResults;
  }
  if (typeof repositorySelection !== "undefined") {
    response.data.repository_selection = repositorySelection;
  }
  response.data.total_count = totalCount;
  return response;
}

// pkg/dist-src/iterator.js
function iterator(octokit, route, parameters) {
  const options = typeof route === "function" ? route.endpoint(parameters) : octokit.request.endpoint(route, parameters);
  const requestMethod = typeof route === "function" ? route : octokit.request;
  const method = options.method;
  const headers = options.headers;
  let url = options.url;
  return {
    [Symbol.asyncIterator]: () => ({
      async next() {
        if (!url)
          return { done: true };
        try {
          const response = await requestMethod({ method, url, headers });
          const normalizedResponse = normalizePaginatedListResponse(response);
          url = ((normalizedResponse.headers.link || "").match(
            /<([^<>]+)>;\s*rel="next"/
          ) || [])[1];
          return { value: normalizedResponse };
        } catch (error) {
          if (error.status !== 409)
            throw error;
          url = "";
          return {
            value: {
              status: 200,
              headers: {},
              data: []
            }
          };
        }
      }
    })
  };
}

// pkg/dist-src/paginate.js
function paginate(octokit, route, parameters, mapFn) {
  if (typeof parameters === "function") {
    mapFn = parameters;
    parameters = void 0;
  }
  return gather(
    octokit,
    [],
    iterator(octokit, route, parameters)[Symbol.asyncIterator](),
    mapFn
  );
}
function gather(octokit, results, iterator2, mapFn) {
  return iterator2.next().then((result) => {
    if (result.done) {
      return results;
    }
    let earlyExit = false;
    function done() {
      earlyExit = true;
    }
    results = results.concat(
      mapFn ? mapFn(result.value, done) : result.value.data
    );
    if (earlyExit) {
      return results;
    }
    return gather(octokit, results, iterator2, mapFn);
  });
}

// pkg/dist-src/compose-paginate.js
var composePaginateRest = Object.assign(paginate, {
  iterator
});

// pkg/dist-src/generated/paginating-endpoints.js
var paginatingEndpoints = [
  "GET /advisories",
  "GET /app/hook/deliveries",
  "GET /app/installation-requests",
  "GET /app/installations",
  "GET /assignments/{assignment_id}/accepted_assignments",
  "GET /classrooms",
  "GET /classrooms/{classroom_id}/assignments",
  "GET /enterprises/{enterprise}/dependabot/alerts",
  "GET /enterprises/{enterprise}/secret-scanning/alerts",
  "GET /events",
  "GET /gists",
  "GET /gists/public",
  "GET /gists/starred",
  "GET /gists/{gist_id}/comments",
  "GET /gists/{gist_id}/commits",
  "GET /gists/{gist_id}/forks",
  "GET /installation/repositories",
  "GET /issues",
  "GET /licenses",
  "GET /marketplace_listing/plans",
  "GET /marketplace_listing/plans/{plan_id}/accounts",
  "GET /marketplace_listing/stubbed/plans",
  "GET /marketplace_listing/stubbed/plans/{plan_id}/accounts",
  "GET /networks/{owner}/{repo}/events",
  "GET /notifications",
  "GET /organizations",
  "GET /orgs/{org}/actions/cache/usage-by-repository",
  "GET /orgs/{org}/actions/permissions/repositories",
  "GET /orgs/{org}/actions/runners",
  "GET /orgs/{org}/actions/secrets",
  "GET /orgs/{org}/actions/secrets/{secret_name}/repositories",
  "GET /orgs/{org}/actions/variables",
  "GET /orgs/{org}/actions/variables/{name}/repositories",
  "GET /orgs/{org}/blocks",
  "GET /orgs/{org}/code-scanning/alerts",
  "GET /orgs/{org}/codespaces",
  "GET /orgs/{org}/codespaces/secrets",
  "GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories",
  "GET /orgs/{org}/copilot/billing/seats",
  "GET /orgs/{org}/dependabot/alerts",
  "GET /orgs/{org}/dependabot/secrets",
  "GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories",
  "GET /orgs/{org}/events",
  "GET /orgs/{org}/failed_invitations",
  "GET /orgs/{org}/hooks",
  "GET /orgs/{org}/hooks/{hook_id}/deliveries",
  "GET /orgs/{org}/installations",
  "GET /orgs/{org}/invitations",
  "GET /orgs/{org}/invitations/{invitation_id}/teams",
  "GET /orgs/{org}/issues",
  "GET /orgs/{org}/members",
  "GET /orgs/{org}/members/{username}/codespaces",
  "GET /orgs/{org}/migrations",
  "GET /orgs/{org}/migrations/{migration_id}/repositories",
  "GET /orgs/{org}/organization-roles/{role_id}/teams",
  "GET /orgs/{org}/organization-roles/{role_id}/users",
  "GET /orgs/{org}/outside_collaborators",
  "GET /orgs/{org}/packages",
  "GET /orgs/{org}/packages/{package_type}/{package_name}/versions",
  "GET /orgs/{org}/personal-access-token-requests",
  "GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories",
  "GET /orgs/{org}/personal-access-tokens",
  "GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories",
  "GET /orgs/{org}/projects",
  "GET /orgs/{org}/properties/values",
  "GET /orgs/{org}/public_members",
  "GET /orgs/{org}/repos",
  "GET /orgs/{org}/rulesets",
  "GET /orgs/{org}/rulesets/rule-suites",
  "GET /orgs/{org}/secret-scanning/alerts",
  "GET /orgs/{org}/security-advisories",
  "GET /orgs/{org}/teams",
  "GET /orgs/{org}/teams/{team_slug}/discussions",
  "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments",
  "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions",
  "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions",
  "GET /orgs/{org}/teams/{team_slug}/invitations",
  "GET /orgs/{org}/teams/{team_slug}/members",
  "GET /orgs/{org}/teams/{team_slug}/projects",
  "GET /orgs/{org}/teams/{team_slug}/repos",
  "GET /orgs/{org}/teams/{team_slug}/teams",
  "GET /projects/columns/{column_id}/cards",
  "GET /projects/{project_id}/collaborators",
  "GET /projects/{project_id}/columns",
  "GET /repos/{owner}/{repo}/actions/artifacts",
  "GET /repos/{owner}/{repo}/actions/caches",
  "GET /repos/{owner}/{repo}/actions/organization-secrets",
  "GET /repos/{owner}/{repo}/actions/organization-variables",
  "GET /repos/{owner}/{repo}/actions/runners",
  "GET /repos/{owner}/{repo}/actions/runs",
  "GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts",
  "GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs",
  "GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs",
  "GET /repos/{owner}/{repo}/actions/secrets",
  "GET /repos/{owner}/{repo}/actions/variables",
  "GET /repos/{owner}/{repo}/actions/workflows",
  "GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs",
  "GET /repos/{owner}/{repo}/activity",
  "GET /repos/{owner}/{repo}/assignees",
  "GET /repos/{owner}/{repo}/branches",
  "GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations",
  "GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs",
  "GET /repos/{owner}/{repo}/code-scanning/alerts",
  "GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances",
  "GET /repos/{owner}/{repo}/code-scanning/analyses",
  "GET /repos/{owner}/{repo}/codespaces",
  "GET /repos/{owner}/{repo}/codespaces/devcontainers",
  "GET /repos/{owner}/{repo}/codespaces/secrets",
  "GET /repos/{owner}/{repo}/collaborators",
  "GET /repos/{owner}/{repo}/comments",
  "GET /repos/{owner}/{repo}/comments/{comment_id}/reactions",
  "GET /repos/{owner}/{repo}/commits",
  "GET /repos/{owner}/{repo}/commits/{commit_sha}/comments",
  "GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls",
  "GET /repos/{owner}/{repo}/commits/{ref}/check-runs",
  "GET /repos/{owner}/{repo}/commits/{ref}/check-suites",
  "GET /repos/{owner}/{repo}/commits/{ref}/status",
  "GET /repos/{owner}/{repo}/commits/{ref}/statuses",
  "GET /repos/{owner}/{repo}/contributors",
  "GET /repos/{owner}/{repo}/dependabot/alerts",
  "GET /repos/{owner}/{repo}/dependabot/secrets",
  "GET /repos/{owner}/{repo}/deployments",
  "GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses",
  "GET /repos/{owner}/{repo}/environments",
  "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies",
  "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps",
  "GET /repos/{owner}/{repo}/events",
  "GET /repos/{owner}/{repo}/forks",
  "GET /repos/{owner}/{repo}/hooks",
  "GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries",
  "GET /repos/{owner}/{repo}/invitations",
  "GET /repos/{owner}/{repo}/issues",
  "GET /repos/{owner}/{repo}/issues/comments",
  "GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions",
  "GET /repos/{owner}/{repo}/issues/events",
  "GET /repos/{owner}/{repo}/issues/{issue_number}/comments",
  "GET /repos/{owner}/{repo}/issues/{issue_number}/events",
  "GET /repos/{owner}/{repo}/issues/{issue_number}/labels",
  "GET /repos/{owner}/{repo}/issues/{issue_number}/reactions",
  "GET /repos/{owner}/{repo}/issues/{issue_number}/timeline",
  "GET /repos/{owner}/{repo}/keys",
  "GET /repos/{owner}/{repo}/labels",
  "GET /repos/{owner}/{repo}/milestones",
  "GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels",
  "GET /repos/{owner}/{repo}/notifications",
  "GET /repos/{owner}/{repo}/pages/builds",
  "GET /repos/{owner}/{repo}/projects",
  "GET /repos/{owner}/{repo}/pulls",
  "GET /repos/{owner}/{repo}/pulls/comments",
  "GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions",
  "GET /repos/{owner}/{repo}/pulls/{pull_number}/comments",
  "GET /repos/{owner}/{repo}/pulls/{pull_number}/commits",
  "GET /repos/{owner}/{repo}/pulls/{pull_number}/files",
  "GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews",
  "GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments",
  "GET /repos/{owner}/{repo}/releases",
  "GET /repos/{owner}/{repo}/releases/{release_id}/assets",
  "GET /repos/{owner}/{repo}/releases/{release_id}/reactions",
  "GET /repos/{owner}/{repo}/rules/branches/{branch}",
  "GET /repos/{owner}/{repo}/rulesets",
  "GET /repos/{owner}/{repo}/rulesets/rule-suites",
  "GET /repos/{owner}/{repo}/secret-scanning/alerts",
  "GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations",
  "GET /repos/{owner}/{repo}/security-advisories",
  "GET /repos/{owner}/{repo}/stargazers",
  "GET /repos/{owner}/{repo}/subscribers",
  "GET /repos/{owner}/{repo}/tags",
  "GET /repos/{owner}/{repo}/teams",
  "GET /repos/{owner}/{repo}/topics",
  "GET /repositories",
  "GET /repositories/{repository_id}/environments/{environment_name}/secrets",
  "GET /repositories/{repository_id}/environments/{environment_name}/variables",
  "GET /search/code",
  "GET /search/commits",
  "GET /search/issues",
  "GET /search/labels",
  "GET /search/repositories",
  "GET /search/topics",
  "GET /search/users",
  "GET /teams/{team_id}/discussions",
  "GET /teams/{team_id}/discussions/{discussion_number}/comments",
  "GET /teams/{team_id}/discussions/{discussion_number}/comments/{comment_number}/reactions",
  "GET /teams/{team_id}/discussions/{discussion_number}/reactions",
  "GET /teams/{team_id}/invitations",
  "GET /teams/{team_id}/members",
  "GET /teams/{team_id}/projects",
  "GET /teams/{team_id}/repos",
  "GET /teams/{team_id}/teams",
  "GET /user/blocks",
  "GET /user/codespaces",
  "GET /user/codespaces/secrets",
  "GET /user/emails",
  "GET /user/followers",
  "GET /user/following",
  "GET /user/gpg_keys",
  "GET /user/installations",
  "GET /user/installations/{installation_id}/repositories",
  "GET /user/issues",
  "GET /user/keys",
  "GET /user/marketplace_purchases",
  "GET /user/marketplace_purchases/stubbed",
  "GET /user/memberships/orgs",
  "GET /user/migrations",
  "GET /user/migrations/{migration_id}/repositories",
  "GET /user/orgs",
  "GET /user/packages",
  "GET /user/packages/{package_type}/{package_name}/versions",
  "GET /user/public_emails",
  "GET /user/repos",
  "GET /user/repository_invitations",
  "GET /user/social_accounts",
  "GET /user/ssh_signing_keys",
  "GET /user/starred",
  "GET /user/subscriptions",
  "GET /user/teams",
  "GET /users",
  "GET /users/{username}/events",
  "GET /users/{username}/events/orgs/{org}",
  "GET /users/{username}/events/public",
  "GET /users/{username}/followers",
  "GET /users/{username}/following",
  "GET /users/{username}/gists",
  "GET /users/{username}/gpg_keys",
  "GET /users/{username}/keys",
  "GET /users/{username}/orgs",
  "GET /users/{username}/packages",
  "GET /users/{username}/projects",
  "GET /users/{username}/received_events",
  "GET /users/{username}/received_events/public",
  "GET /users/{username}/repos",
  "GET /users/{username}/social_accounts",
  "GET /users/{username}/ssh_signing_keys",
  "GET /users/{username}/starred",
  "GET /users/{username}/subscriptions"
];

// pkg/dist-src/paginating-endpoints.js
function isPaginatingEndpoint(arg) {
  if (typeof arg === "string") {
    return paginatingEndpoints.includes(arg);
  } else {
    return false;
  }
}

// pkg/dist-src/index.js
function paginateRest(octokit) {
  return {
    paginate: Object.assign(paginate.bind(null, octokit), {
      iterator: iterator.bind(null, octokit)
    })
  };
}
paginateRest.VERSION = VERSION;
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 4935:
/***/ ((module) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var dist_src_exports = {};
__export(dist_src_exports, {
  legacyRestEndpointMethods: () => legacyRestEndpointMethods,
  restEndpointMethods: () => restEndpointMethods
});
module.exports = __toCommonJS(dist_src_exports);

// pkg/dist-src/version.js
var VERSION = "10.4.1";

// pkg/dist-src/generated/endpoints.js
var Endpoints = {
  actions: {
    addCustomLabelsToSelfHostedRunnerForOrg: [
      "POST /orgs/{org}/actions/runners/{runner_id}/labels"
    ],
    addCustomLabelsToSelfHostedRunnerForRepo: [
      "POST /repos/{owner}/{repo}/actions/runners/{runner_id}/labels"
    ],
    addSelectedRepoToOrgSecret: [
      "PUT /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}"
    ],
    addSelectedRepoToOrgVariable: [
      "PUT /orgs/{org}/actions/variables/{name}/repositories/{repository_id}"
    ],
    approveWorkflowRun: [
      "POST /repos/{owner}/{repo}/actions/runs/{run_id}/approve"
    ],
    cancelWorkflowRun: [
      "POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel"
    ],
    createEnvironmentVariable: [
      "POST /repositories/{repository_id}/environments/{environment_name}/variables"
    ],
    createOrUpdateEnvironmentSecret: [
      "PUT /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}"
    ],
    createOrUpdateOrgSecret: ["PUT /orgs/{org}/actions/secrets/{secret_name}"],
    createOrUpdateRepoSecret: [
      "PUT /repos/{owner}/{repo}/actions/secrets/{secret_name}"
    ],
    createOrgVariable: ["POST /orgs/{org}/actions/variables"],
    createRegistrationTokenForOrg: [
      "POST /orgs/{org}/actions/runners/registration-token"
    ],
    createRegistrationTokenForRepo: [
      "POST /repos/{owner}/{repo}/actions/runners/registration-token"
    ],
    createRemoveTokenForOrg: ["POST /orgs/{org}/actions/runners/remove-token"],
    createRemoveTokenForRepo: [
      "POST /repos/{owner}/{repo}/actions/runners/remove-token"
    ],
    createRepoVariable: ["POST /repos/{owner}/{repo}/actions/variables"],
    createWorkflowDispatch: [
      "POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches"
    ],
    deleteActionsCacheById: [
      "DELETE /repos/{owner}/{repo}/actions/caches/{cache_id}"
    ],
    deleteActionsCacheByKey: [
      "DELETE /repos/{owner}/{repo}/actions/caches{?key,ref}"
    ],
    deleteArtifact: [
      "DELETE /repos/{owner}/{repo}/actions/artifacts/{artifact_id}"
    ],
    deleteEnvironmentSecret: [
      "DELETE /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}"
    ],
    deleteEnvironmentVariable: [
      "DELETE /repositories/{repository_id}/environments/{environment_name}/variables/{name}"
    ],
    deleteOrgSecret: ["DELETE /orgs/{org}/actions/secrets/{secret_name}"],
    deleteOrgVariable: ["DELETE /orgs/{org}/actions/variables/{name}"],
    deleteRepoSecret: [
      "DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name}"
    ],
    deleteRepoVariable: [
      "DELETE /repos/{owner}/{repo}/actions/variables/{name}"
    ],
    deleteSelfHostedRunnerFromOrg: [
      "DELETE /orgs/{org}/actions/runners/{runner_id}"
    ],
    deleteSelfHostedRunnerFromRepo: [
      "DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}"
    ],
    deleteWorkflowRun: ["DELETE /repos/{owner}/{repo}/actions/runs/{run_id}"],
    deleteWorkflowRunLogs: [
      "DELETE /repos/{owner}/{repo}/actions/runs/{run_id}/logs"
    ],
    disableSelectedRepositoryGithubActionsOrganization: [
      "DELETE /orgs/{org}/actions/permissions/repositories/{repository_id}"
    ],
    disableWorkflow: [
      "PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/disable"
    ],
    downloadArtifact: [
      "GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}/{archive_format}"
    ],
    downloadJobLogsForWorkflowRun: [
      "GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs"
    ],
    downloadWorkflowRunAttemptLogs: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/logs"
    ],
    downloadWorkflowRunLogs: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/logs"
    ],
    enableSelectedRepositoryGithubActionsOrganization: [
      "PUT /orgs/{org}/actions/permissions/repositories/{repository_id}"
    ],
    enableWorkflow: [
      "PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/enable"
    ],
    forceCancelWorkflowRun: [
      "POST /repos/{owner}/{repo}/actions/runs/{run_id}/force-cancel"
    ],
    generateRunnerJitconfigForOrg: [
      "POST /orgs/{org}/actions/runners/generate-jitconfig"
    ],
    generateRunnerJitconfigForRepo: [
      "POST /repos/{owner}/{repo}/actions/runners/generate-jitconfig"
    ],
    getActionsCacheList: ["GET /repos/{owner}/{repo}/actions/caches"],
    getActionsCacheUsage: ["GET /repos/{owner}/{repo}/actions/cache/usage"],
    getActionsCacheUsageByRepoForOrg: [
      "GET /orgs/{org}/actions/cache/usage-by-repository"
    ],
    getActionsCacheUsageForOrg: ["GET /orgs/{org}/actions/cache/usage"],
    getAllowedActionsOrganization: [
      "GET /orgs/{org}/actions/permissions/selected-actions"
    ],
    getAllowedActionsRepository: [
      "GET /repos/{owner}/{repo}/actions/permissions/selected-actions"
    ],
    getArtifact: ["GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}"],
    getCustomOidcSubClaimForRepo: [
      "GET /repos/{owner}/{repo}/actions/oidc/customization/sub"
    ],
    getEnvironmentPublicKey: [
      "GET /repositories/{repository_id}/environments/{environment_name}/secrets/public-key"
    ],
    getEnvironmentSecret: [
      "GET /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}"
    ],
    getEnvironmentVariable: [
      "GET /repositories/{repository_id}/environments/{environment_name}/variables/{name}"
    ],
    getGithubActionsDefaultWorkflowPermissionsOrganization: [
      "GET /orgs/{org}/actions/permissions/workflow"
    ],
    getGithubActionsDefaultWorkflowPermissionsRepository: [
      "GET /repos/{owner}/{repo}/actions/permissions/workflow"
    ],
    getGithubActionsPermissionsOrganization: [
      "GET /orgs/{org}/actions/permissions"
    ],
    getGithubActionsPermissionsRepository: [
      "GET /repos/{owner}/{repo}/actions/permissions"
    ],
    getJobForWorkflowRun: ["GET /repos/{owner}/{repo}/actions/jobs/{job_id}"],
    getOrgPublicKey: ["GET /orgs/{org}/actions/secrets/public-key"],
    getOrgSecret: ["GET /orgs/{org}/actions/secrets/{secret_name}"],
    getOrgVariable: ["GET /orgs/{org}/actions/variables/{name}"],
    getPendingDeploymentsForRun: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments"
    ],
    getRepoPermissions: [
      "GET /repos/{owner}/{repo}/actions/permissions",
      {},
      { renamed: ["actions", "getGithubActionsPermissionsRepository"] }
    ],
    getRepoPublicKey: ["GET /repos/{owner}/{repo}/actions/secrets/public-key"],
    getRepoSecret: ["GET /repos/{owner}/{repo}/actions/secrets/{secret_name}"],
    getRepoVariable: ["GET /repos/{owner}/{repo}/actions/variables/{name}"],
    getReviewsForRun: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/approvals"
    ],
    getSelfHostedRunnerForOrg: ["GET /orgs/{org}/actions/runners/{runner_id}"],
    getSelfHostedRunnerForRepo: [
      "GET /repos/{owner}/{repo}/actions/runners/{runner_id}"
    ],
    getWorkflow: ["GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}"],
    getWorkflowAccessToRepository: [
      "GET /repos/{owner}/{repo}/actions/permissions/access"
    ],
    getWorkflowRun: ["GET /repos/{owner}/{repo}/actions/runs/{run_id}"],
    getWorkflowRunAttempt: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}"
    ],
    getWorkflowRunUsage: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing"
    ],
    getWorkflowUsage: [
      "GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/timing"
    ],
    listArtifactsForRepo: ["GET /repos/{owner}/{repo}/actions/artifacts"],
    listEnvironmentSecrets: [
      "GET /repositories/{repository_id}/environments/{environment_name}/secrets"
    ],
    listEnvironmentVariables: [
      "GET /repositories/{repository_id}/environments/{environment_name}/variables"
    ],
    listJobsForWorkflowRun: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs"
    ],
    listJobsForWorkflowRunAttempt: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs"
    ],
    listLabelsForSelfHostedRunnerForOrg: [
      "GET /orgs/{org}/actions/runners/{runner_id}/labels"
    ],
    listLabelsForSelfHostedRunnerForRepo: [
      "GET /repos/{owner}/{repo}/actions/runners/{runner_id}/labels"
    ],
    listOrgSecrets: ["GET /orgs/{org}/actions/secrets"],
    listOrgVariables: ["GET /orgs/{org}/actions/variables"],
    listRepoOrganizationSecrets: [
      "GET /repos/{owner}/{repo}/actions/organization-secrets"
    ],
    listRepoOrganizationVariables: [
      "GET /repos/{owner}/{repo}/actions/organization-variables"
    ],
    listRepoSecrets: ["GET /repos/{owner}/{repo}/actions/secrets"],
    listRepoVariables: ["GET /repos/{owner}/{repo}/actions/variables"],
    listRepoWorkflows: ["GET /repos/{owner}/{repo}/actions/workflows"],
    listRunnerApplicationsForOrg: ["GET /orgs/{org}/actions/runners/downloads"],
    listRunnerApplicationsForRepo: [
      "GET /repos/{owner}/{repo}/actions/runners/downloads"
    ],
    listSelectedReposForOrgSecret: [
      "GET /orgs/{org}/actions/secrets/{secret_name}/repositories"
    ],
    listSelectedReposForOrgVariable: [
      "GET /orgs/{org}/actions/variables/{name}/repositories"
    ],
    listSelectedRepositoriesEnabledGithubActionsOrganization: [
      "GET /orgs/{org}/actions/permissions/repositories"
    ],
    listSelfHostedRunnersForOrg: ["GET /orgs/{org}/actions/runners"],
    listSelfHostedRunnersForRepo: ["GET /repos/{owner}/{repo}/actions/runners"],
    listWorkflowRunArtifacts: [
      "GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts"
    ],
    listWorkflowRuns: [
      "GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs"
    ],
    listWorkflowRunsForRepo: ["GET /repos/{owner}/{repo}/actions/runs"],
    reRunJobForWorkflowRun: [
      "POST /repos/{owner}/{repo}/actions/jobs/{job_id}/rerun"
    ],
    reRunWorkflow: ["POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun"],
    reRunWorkflowFailedJobs: [
      "POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun-failed-jobs"
    ],
    removeAllCustomLabelsFromSelfHostedRunnerForOrg: [
      "DELETE /orgs/{org}/actions/runners/{runner_id}/labels"
    ],
    removeAllCustomLabelsFromSelfHostedRunnerForRepo: [
      "DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels"
    ],
    removeCustomLabelFromSelfHostedRunnerForOrg: [
      "DELETE /orgs/{org}/actions/runners/{runner_id}/labels/{name}"
    ],
    removeCustomLabelFromSelfHostedRunnerForRepo: [
      "DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels/{name}"
    ],
    removeSelectedRepoFromOrgSecret: [
      "DELETE /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}"
    ],
    removeSelectedRepoFromOrgVariable: [
      "DELETE /orgs/{org}/actions/variables/{name}/repositories/{repository_id}"
    ],
    reviewCustomGatesForRun: [
      "POST /repos/{owner}/{repo}/actions/runs/{run_id}/deployment_protection_rule"
    ],
    reviewPendingDeploymentsForRun: [
      "POST /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments"
    ],
    setAllowedActionsOrganization: [
      "PUT /orgs/{org}/actions/permissions/selected-actions"
    ],
    setAllowedActionsRepository: [
      "PUT /repos/{owner}/{repo}/actions/permissions/selected-actions"
    ],
    setCustomLabelsForSelfHostedRunnerForOrg: [
      "PUT /orgs/{org}/actions/runners/{runner_id}/labels"
    ],
    setCustomLabelsForSelfHostedRunnerForRepo: [
      "PUT /repos/{owner}/{repo}/actions/runners/{runner_id}/labels"
    ],
    setCustomOidcSubClaimForRepo: [
      "PUT /repos/{owner}/{repo}/actions/oidc/customization/sub"
    ],
    setGithubActionsDefaultWorkflowPermissionsOrganization: [
      "PUT /orgs/{org}/actions/permissions/workflow"
    ],
    setGithubActionsDefaultWorkflowPermissionsRepository: [
      "PUT /repos/{owner}/{repo}/actions/permissions/workflow"
    ],
    setGithubActionsPermissionsOrganization: [
      "PUT /orgs/{org}/actions/permissions"
    ],
    setGithubActionsPermissionsRepository: [
      "PUT /repos/{owner}/{repo}/actions/permissions"
    ],
    setSelectedReposForOrgSecret: [
      "PUT /orgs/{org}/actions/secrets/{secret_name}/repositories"
    ],
    setSelectedReposForOrgVariable: [
      "PUT /orgs/{org}/actions/variables/{name}/repositories"
    ],
    setSelectedRepositoriesEnabledGithubActionsOrganization: [
      "PUT /orgs/{org}/actions/permissions/repositories"
    ],
    setWorkflowAccessToRepository: [
      "PUT /repos/{owner}/{repo}/actions/permissions/access"
    ],
    updateEnvironmentVariable: [
      "PATCH /repositories/{repository_id}/environments/{environment_name}/variables/{name}"
    ],
    updateOrgVariable: ["PATCH /orgs/{org}/actions/variables/{name}"],
    updateRepoVariable: [
      "PATCH /repos/{owner}/{repo}/actions/variables/{name}"
    ]
  },
  activity: {
    checkRepoIsStarredByAuthenticatedUser: ["GET /user/starred/{owner}/{repo}"],
    deleteRepoSubscription: ["DELETE /repos/{owner}/{repo}/subscription"],
    deleteThreadSubscription: [
      "DELETE /notifications/threads/{thread_id}/subscription"
    ],
    getFeeds: ["GET /feeds"],
    getRepoSubscription: ["GET /repos/{owner}/{repo}/subscription"],
    getThread: ["GET /notifications/threads/{thread_id}"],
    getThreadSubscriptionForAuthenticatedUser: [
      "GET /notifications/threads/{thread_id}/subscription"
    ],
    listEventsForAuthenticatedUser: ["GET /users/{username}/events"],
    listNotificationsForAuthenticatedUser: ["GET /notifications"],
    listOrgEventsForAuthenticatedUser: [
      "GET /users/{username}/events/orgs/{org}"
    ],
    listPublicEvents: ["GET /events"],
    listPublicEventsForRepoNetwork: ["GET /networks/{owner}/{repo}/events"],
    listPublicEventsForUser: ["GET /users/{username}/events/public"],
    listPublicOrgEvents: ["GET /orgs/{org}/events"],
    listReceivedEventsForUser: ["GET /users/{username}/received_events"],
    listReceivedPublicEventsForUser: [
      "GET /users/{username}/received_events/public"
    ],
    listRepoEvents: ["GET /repos/{owner}/{repo}/events"],
    listRepoNotificationsForAuthenticatedUser: [
      "GET /repos/{owner}/{repo}/notifications"
    ],
    listReposStarredByAuthenticatedUser: ["GET /user/starred"],
    listReposStarredByUser: ["GET /users/{username}/starred"],
    listReposWatchedByUser: ["GET /users/{username}/subscriptions"],
    listStargazersForRepo: ["GET /repos/{owner}/{repo}/stargazers"],
    listWatchedReposForAuthenticatedUser: ["GET /user/subscriptions"],
    listWatchersForRepo: ["GET /repos/{owner}/{repo}/subscribers"],
    markNotificationsAsRead: ["PUT /notifications"],
    markRepoNotificationsAsRead: ["PUT /repos/{owner}/{repo}/notifications"],
    markThreadAsDone: ["DELETE /notifications/threads/{thread_id}"],
    markThreadAsRead: ["PATCH /notifications/threads/{thread_id}"],
    setRepoSubscription: ["PUT /repos/{owner}/{repo}/subscription"],
    setThreadSubscription: [
      "PUT /notifications/threads/{thread_id}/subscription"
    ],
    starRepoForAuthenticatedUser: ["PUT /user/starred/{owner}/{repo}"],
    unstarRepoForAuthenticatedUser: ["DELETE /user/starred/{owner}/{repo}"]
  },
  apps: {
    addRepoToInstallation: [
      "PUT /user/installations/{installation_id}/repositories/{repository_id}",
      {},
      { renamed: ["apps", "addRepoToInstallationForAuthenticatedUser"] }
    ],
    addRepoToInstallationForAuthenticatedUser: [
      "PUT /user/installations/{installation_id}/repositories/{repository_id}"
    ],
    checkToken: ["POST /applications/{client_id}/token"],
    createFromManifest: ["POST /app-manifests/{code}/conversions"],
    createInstallationAccessToken: [
      "POST /app/installations/{installation_id}/access_tokens"
    ],
    deleteAuthorization: ["DELETE /applications/{client_id}/grant"],
    deleteInstallation: ["DELETE /app/installations/{installation_id}"],
    deleteToken: ["DELETE /applications/{client_id}/token"],
    getAuthenticated: ["GET /app"],
    getBySlug: ["GET /apps/{app_slug}"],
    getInstallation: ["GET /app/installations/{installation_id}"],
    getOrgInstallation: ["GET /orgs/{org}/installation"],
    getRepoInstallation: ["GET /repos/{owner}/{repo}/installation"],
    getSubscriptionPlanForAccount: [
      "GET /marketplace_listing/accounts/{account_id}"
    ],
    getSubscriptionPlanForAccountStubbed: [
      "GET /marketplace_listing/stubbed/accounts/{account_id}"
    ],
    getUserInstallation: ["GET /users/{username}/installation"],
    getWebhookConfigForApp: ["GET /app/hook/config"],
    getWebhookDelivery: ["GET /app/hook/deliveries/{delivery_id}"],
    listAccountsForPlan: ["GET /marketplace_listing/plans/{plan_id}/accounts"],
    listAccountsForPlanStubbed: [
      "GET /marketplace_listing/stubbed/plans/{plan_id}/accounts"
    ],
    listInstallationReposForAuthenticatedUser: [
      "GET /user/installations/{installation_id}/repositories"
    ],
    listInstallationRequestsForAuthenticatedApp: [
      "GET /app/installation-requests"
    ],
    listInstallations: ["GET /app/installations"],
    listInstallationsForAuthenticatedUser: ["GET /user/installations"],
    listPlans: ["GET /marketplace_listing/plans"],
    listPlansStubbed: ["GET /marketplace_listing/stubbed/plans"],
    listReposAccessibleToInstallation: ["GET /installation/repositories"],
    listSubscriptionsForAuthenticatedUser: ["GET /user/marketplace_purchases"],
    listSubscriptionsForAuthenticatedUserStubbed: [
      "GET /user/marketplace_purchases/stubbed"
    ],
    listWebhookDeliveries: ["GET /app/hook/deliveries"],
    redeliverWebhookDelivery: [
      "POST /app/hook/deliveries/{delivery_id}/attempts"
    ],
    removeRepoFromInstallation: [
      "DELETE /user/installations/{installation_id}/repositories/{repository_id}",
      {},
      { renamed: ["apps", "removeRepoFromInstallationForAuthenticatedUser"] }
    ],
    removeRepoFromInstallationForAuthenticatedUser: [
      "DELETE /user/installations/{installation_id}/repositories/{repository_id}"
    ],
    resetToken: ["PATCH /applications/{client_id}/token"],
    revokeInstallationAccessToken: ["DELETE /installation/token"],
    scopeToken: ["POST /applications/{client_id}/token/scoped"],
    suspendInstallation: ["PUT /app/installations/{installation_id}/suspended"],
    unsuspendInstallation: [
      "DELETE /app/installations/{installation_id}/suspended"
    ],
    updateWebhookConfigForApp: ["PATCH /app/hook/config"]
  },
  billing: {
    getGithubActionsBillingOrg: ["GET /orgs/{org}/settings/billing/actions"],
    getGithubActionsBillingUser: [
      "GET /users/{username}/settings/billing/actions"
    ],
    getGithubPackagesBillingOrg: ["GET /orgs/{org}/settings/billing/packages"],
    getGithubPackagesBillingUser: [
      "GET /users/{username}/settings/billing/packages"
    ],
    getSharedStorageBillingOrg: [
      "GET /orgs/{org}/settings/billing/shared-storage"
    ],
    getSharedStorageBillingUser: [
      "GET /users/{username}/settings/billing/shared-storage"
    ]
  },
  checks: {
    create: ["POST /repos/{owner}/{repo}/check-runs"],
    createSuite: ["POST /repos/{owner}/{repo}/check-suites"],
    get: ["GET /repos/{owner}/{repo}/check-runs/{check_run_id}"],
    getSuite: ["GET /repos/{owner}/{repo}/check-suites/{check_suite_id}"],
    listAnnotations: [
      "GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations"
    ],
    listForRef: ["GET /repos/{owner}/{repo}/commits/{ref}/check-runs"],
    listForSuite: [
      "GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs"
    ],
    listSuitesForRef: ["GET /repos/{owner}/{repo}/commits/{ref}/check-suites"],
    rerequestRun: [
      "POST /repos/{owner}/{repo}/check-runs/{check_run_id}/rerequest"
    ],
    rerequestSuite: [
      "POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest"
    ],
    setSuitesPreferences: [
      "PATCH /repos/{owner}/{repo}/check-suites/preferences"
    ],
    update: ["PATCH /repos/{owner}/{repo}/check-runs/{check_run_id}"]
  },
  codeScanning: {
    deleteAnalysis: [
      "DELETE /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}{?confirm_delete}"
    ],
    getAlert: [
      "GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}",
      {},
      { renamedParameters: { alert_id: "alert_number" } }
    ],
    getAnalysis: [
      "GET /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}"
    ],
    getCodeqlDatabase: [
      "GET /repos/{owner}/{repo}/code-scanning/codeql/databases/{language}"
    ],
    getDefaultSetup: ["GET /repos/{owner}/{repo}/code-scanning/default-setup"],
    getSarif: ["GET /repos/{owner}/{repo}/code-scanning/sarifs/{sarif_id}"],
    listAlertInstances: [
      "GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances"
    ],
    listAlertsForOrg: ["GET /orgs/{org}/code-scanning/alerts"],
    listAlertsForRepo: ["GET /repos/{owner}/{repo}/code-scanning/alerts"],
    listAlertsInstances: [
      "GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances",
      {},
      { renamed: ["codeScanning", "listAlertInstances"] }
    ],
    listCodeqlDatabases: [
      "GET /repos/{owner}/{repo}/code-scanning/codeql/databases"
    ],
    listRecentAnalyses: ["GET /repos/{owner}/{repo}/code-scanning/analyses"],
    updateAlert: [
      "PATCH /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}"
    ],
    updateDefaultSetup: [
      "PATCH /repos/{owner}/{repo}/code-scanning/default-setup"
    ],
    uploadSarif: ["POST /repos/{owner}/{repo}/code-scanning/sarifs"]
  },
  codesOfConduct: {
    getAllCodesOfConduct: ["GET /codes_of_conduct"],
    getConductCode: ["GET /codes_of_conduct/{key}"]
  },
  codespaces: {
    addRepositoryForSecretForAuthenticatedUser: [
      "PUT /user/codespaces/secrets/{secret_name}/repositories/{repository_id}"
    ],
    addSelectedRepoToOrgSecret: [
      "PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}"
    ],
    checkPermissionsForDevcontainer: [
      "GET /repos/{owner}/{repo}/codespaces/permissions_check"
    ],
    codespaceMachinesForAuthenticatedUser: [
      "GET /user/codespaces/{codespace_name}/machines"
    ],
    createForAuthenticatedUser: ["POST /user/codespaces"],
    createOrUpdateOrgSecret: [
      "PUT /orgs/{org}/codespaces/secrets/{secret_name}"
    ],
    createOrUpdateRepoSecret: [
      "PUT /repos/{owner}/{repo}/codespaces/secrets/{secret_name}"
    ],
    createOrUpdateSecretForAuthenticatedUser: [
      "PUT /user/codespaces/secrets/{secret_name}"
    ],
    createWithPrForAuthenticatedUser: [
      "POST /repos/{owner}/{repo}/pulls/{pull_number}/codespaces"
    ],
    createWithRepoForAuthenticatedUser: [
      "POST /repos/{owner}/{repo}/codespaces"
    ],
    deleteForAuthenticatedUser: ["DELETE /user/codespaces/{codespace_name}"],
    deleteFromOrganization: [
      "DELETE /orgs/{org}/members/{username}/codespaces/{codespace_name}"
    ],
    deleteOrgSecret: ["DELETE /orgs/{org}/codespaces/secrets/{secret_name}"],
    deleteRepoSecret: [
      "DELETE /repos/{owner}/{repo}/codespaces/secrets/{secret_name}"
    ],
    deleteSecretForAuthenticatedUser: [
      "DELETE /user/codespaces/secrets/{secret_name}"
    ],
    exportForAuthenticatedUser: [
      "POST /user/codespaces/{codespace_name}/exports"
    ],
    getCodespacesForUserInOrg: [
      "GET /orgs/{org}/members/{username}/codespaces"
    ],
    getExportDetailsForAuthenticatedUser: [
      "GET /user/codespaces/{codespace_name}/exports/{export_id}"
    ],
    getForAuthenticatedUser: ["GET /user/codespaces/{codespace_name}"],
    getOrgPublicKey: ["GET /orgs/{org}/codespaces/secrets/public-key"],
    getOrgSecret: ["GET /orgs/{org}/codespaces/secrets/{secret_name}"],
    getPublicKeyForAuthenticatedUser: [
      "GET /user/codespaces/secrets/public-key"
    ],
    getRepoPublicKey: [
      "GET /repos/{owner}/{repo}/codespaces/secrets/public-key"
    ],
    getRepoSecret: [
      "GET /repos/{owner}/{repo}/codespaces/secrets/{secret_name}"
    ],
    getSecretForAuthenticatedUser: [
      "GET /user/codespaces/secrets/{secret_name}"
    ],
    listDevcontainersInRepositoryForAuthenticatedUser: [
      "GET /repos/{owner}/{repo}/codespaces/devcontainers"
    ],
    listForAuthenticatedUser: ["GET /user/codespaces"],
    listInOrganization: [
      "GET /orgs/{org}/codespaces",
      {},
      { renamedParameters: { org_id: "org" } }
    ],
    listInRepositoryForAuthenticatedUser: [
      "GET /repos/{owner}/{repo}/codespaces"
    ],
    listOrgSecrets: ["GET /orgs/{org}/codespaces/secrets"],
    listRepoSecrets: ["GET /repos/{owner}/{repo}/codespaces/secrets"],
    listRepositoriesForSecretForAuthenticatedUser: [
      "GET /user/codespaces/secrets/{secret_name}/repositories"
    ],
    listSecretsForAuthenticatedUser: ["GET /user/codespaces/secrets"],
    listSelectedReposForOrgSecret: [
      "GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories"
    ],
    preFlightWithRepoForAuthenticatedUser: [
      "GET /repos/{owner}/{repo}/codespaces/new"
    ],
    publishForAuthenticatedUser: [
      "POST /user/codespaces/{codespace_name}/publish"
    ],
    removeRepositoryForSecretForAuthenticatedUser: [
      "DELETE /user/codespaces/secrets/{secret_name}/repositories/{repository_id}"
    ],
    removeSelectedRepoFromOrgSecret: [
      "DELETE /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}"
    ],
    repoMachinesForAuthenticatedUser: [
      "GET /repos/{owner}/{repo}/codespaces/machines"
    ],
    setRepositoriesForSecretForAuthenticatedUser: [
      "PUT /user/codespaces/secrets/{secret_name}/repositories"
    ],
    setSelectedReposForOrgSecret: [
      "PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories"
    ],
    startForAuthenticatedUser: ["POST /user/codespaces/{codespace_name}/start"],
    stopForAuthenticatedUser: ["POST /user/codespaces/{codespace_name}/stop"],
    stopInOrganization: [
      "POST /orgs/{org}/members/{username}/codespaces/{codespace_name}/stop"
    ],
    updateForAuthenticatedUser: ["PATCH /user/codespaces/{codespace_name}"]
  },
  copilot: {
    addCopilotSeatsForTeams: [
      "POST /orgs/{org}/copilot/billing/selected_teams"
    ],
    addCopilotSeatsForUsers: [
      "POST /orgs/{org}/copilot/billing/selected_users"
    ],
    cancelCopilotSeatAssignmentForTeams: [
      "DELETE /orgs/{org}/copilot/billing/selected_teams"
    ],
    cancelCopilotSeatAssignmentForUsers: [
      "DELETE /orgs/{org}/copilot/billing/selected_users"
    ],
    getCopilotOrganizationDetails: ["GET /orgs/{org}/copilot/billing"],
    getCopilotSeatDetailsForUser: [
      "GET /orgs/{org}/members/{username}/copilot"
    ],
    listCopilotSeats: ["GET /orgs/{org}/copilot/billing/seats"]
  },
  dependabot: {
    addSelectedRepoToOrgSecret: [
      "PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}"
    ],
    createOrUpdateOrgSecret: [
      "PUT /orgs/{org}/dependabot/secrets/{secret_name}"
    ],
    createOrUpdateRepoSecret: [
      "PUT /repos/{owner}/{repo}/dependabot/secrets/{secret_name}"
    ],
    deleteOrgSecret: ["DELETE /orgs/{org}/dependabot/secrets/{secret_name}"],
    deleteRepoSecret: [
      "DELETE /repos/{owner}/{repo}/dependabot/secrets/{secret_name}"
    ],
    getAlert: ["GET /repos/{owner}/{repo}/dependabot/alerts/{alert_number}"],
    getOrgPublicKey: ["GET /orgs/{org}/dependabot/secrets/public-key"],
    getOrgSecret: ["GET /orgs/{org}/dependabot/secrets/{secret_name}"],
    getRepoPublicKey: [
      "GET /repos/{owner}/{repo}/dependabot/secrets/public-key"
    ],
    getRepoSecret: [
      "GET /repos/{owner}/{repo}/dependabot/secrets/{secret_name}"
    ],
    listAlertsForEnterprise: [
      "GET /enterprises/{enterprise}/dependabot/alerts"
    ],
    listAlertsForOrg: ["GET /orgs/{org}/dependabot/alerts"],
    listAlertsForRepo: ["GET /repos/{owner}/{repo}/dependabot/alerts"],
    listOrgSecrets: ["GET /orgs/{org}/dependabot/secrets"],
    listRepoSecrets: ["GET /repos/{owner}/{repo}/dependabot/secrets"],
    listSelectedReposForOrgSecret: [
      "GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories"
    ],
    removeSelectedRepoFromOrgSecret: [
      "DELETE /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}"
    ],
    setSelectedReposForOrgSecret: [
      "PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories"
    ],
    updateAlert: [
      "PATCH /repos/{owner}/{repo}/dependabot/alerts/{alert_number}"
    ]
  },
  dependencyGraph: {
    createRepositorySnapshot: [
      "POST /repos/{owner}/{repo}/dependency-graph/snapshots"
    ],
    diffRange: [
      "GET /repos/{owner}/{repo}/dependency-graph/compare/{basehead}"
    ],
    exportSbom: ["GET /repos/{owner}/{repo}/dependency-graph/sbom"]
  },
  emojis: { get: ["GET /emojis"] },
  gists: {
    checkIsStarred: ["GET /gists/{gist_id}/star"],
    create: ["POST /gists"],
    createComment: ["POST /gists/{gist_id}/comments"],
    delete: ["DELETE /gists/{gist_id}"],
    deleteComment: ["DELETE /gists/{gist_id}/comments/{comment_id}"],
    fork: ["POST /gists/{gist_id}/forks"],
    get: ["GET /gists/{gist_id}"],
    getComment: ["GET /gists/{gist_id}/comments/{comment_id}"],
    getRevision: ["GET /gists/{gist_id}/{sha}"],
    list: ["GET /gists"],
    listComments: ["GET /gists/{gist_id}/comments"],
    listCommits: ["GET /gists/{gist_id}/commits"],
    listForUser: ["GET /users/{username}/gists"],
    listForks: ["GET /gists/{gist_id}/forks"],
    listPublic: ["GET /gists/public"],
    listStarred: ["GET /gists/starred"],
    star: ["PUT /gists/{gist_id}/star"],
    unstar: ["DELETE /gists/{gist_id}/star"],
    update: ["PATCH /gists/{gist_id}"],
    updateComment: ["PATCH /gists/{gist_id}/comments/{comment_id}"]
  },
  git: {
    createBlob: ["POST /repos/{owner}/{repo}/git/blobs"],
    createCommit: ["POST /repos/{owner}/{repo}/git/commits"],
    createRef: ["POST /repos/{owner}/{repo}/git/refs"],
    createTag: ["POST /repos/{owner}/{repo}/git/tags"],
    createTree: ["POST /repos/{owner}/{repo}/git/trees"],
    deleteRef: ["DELETE /repos/{owner}/{repo}/git/refs/{ref}"],
    getBlob: ["GET /repos/{owner}/{repo}/git/blobs/{file_sha}"],
    getCommit: ["GET /repos/{owner}/{repo}/git/commits/{commit_sha}"],
    getRef: ["GET /repos/{owner}/{repo}/git/ref/{ref}"],
    getTag: ["GET /repos/{owner}/{repo}/git/tags/{tag_sha}"],
    getTree: ["GET /repos/{owner}/{repo}/git/trees/{tree_sha}"],
    listMatchingRefs: ["GET /repos/{owner}/{repo}/git/matching-refs/{ref}"],
    updateRef: ["PATCH /repos/{owner}/{repo}/git/refs/{ref}"]
  },
  gitignore: {
    getAllTemplates: ["GET /gitignore/templates"],
    getTemplate: ["GET /gitignore/templates/{name}"]
  },
  interactions: {
    getRestrictionsForAuthenticatedUser: ["GET /user/interaction-limits"],
    getRestrictionsForOrg: ["GET /orgs/{org}/interaction-limits"],
    getRestrictionsForRepo: ["GET /repos/{owner}/{repo}/interaction-limits"],
    getRestrictionsForYourPublicRepos: [
      "GET /user/interaction-limits",
      {},
      { renamed: ["interactions", "getRestrictionsForAuthenticatedUser"] }
    ],
    removeRestrictionsForAuthenticatedUser: ["DELETE /user/interaction-limits"],
    removeRestrictionsForOrg: ["DELETE /orgs/{org}/interaction-limits"],
    removeRestrictionsForRepo: [
      "DELETE /repos/{owner}/{repo}/interaction-limits"
    ],
    removeRestrictionsForYourPublicRepos: [
      "DELETE /user/interaction-limits",
      {},
      { renamed: ["interactions", "removeRestrictionsForAuthenticatedUser"] }
    ],
    setRestrictionsForAuthenticatedUser: ["PUT /user/interaction-limits"],
    setRestrictionsForOrg: ["PUT /orgs/{org}/interaction-limits"],
    setRestrictionsForRepo: ["PUT /repos/{owner}/{repo}/interaction-limits"],
    setRestrictionsForYourPublicRepos: [
      "PUT /user/interaction-limits",
      {},
      { renamed: ["interactions", "setRestrictionsForAuthenticatedUser"] }
    ]
  },
  issues: {
    addAssignees: [
      "POST /repos/{owner}/{repo}/issues/{issue_number}/assignees"
    ],
    addLabels: ["POST /repos/{owner}/{repo}/issues/{issue_number}/labels"],
    checkUserCanBeAssigned: ["GET /repos/{owner}/{repo}/assignees/{assignee}"],
    checkUserCanBeAssignedToIssue: [
      "GET /repos/{owner}/{repo}/issues/{issue_number}/assignees/{assignee}"
    ],
    create: ["POST /repos/{owner}/{repo}/issues"],
    createComment: [
      "POST /repos/{owner}/{repo}/issues/{issue_number}/comments"
    ],
    createLabel: ["POST /repos/{owner}/{repo}/labels"],
    createMilestone: ["POST /repos/{owner}/{repo}/milestones"],
    deleteComment: [
      "DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}"
    ],
    deleteLabel: ["DELETE /repos/{owner}/{repo}/labels/{name}"],
    deleteMilestone: [
      "DELETE /repos/{owner}/{repo}/milestones/{milestone_number}"
    ],
    get: ["GET /repos/{owner}/{repo}/issues/{issue_number}"],
    getComment: ["GET /repos/{owner}/{repo}/issues/comments/{comment_id}"],
    getEvent: ["GET /repos/{owner}/{repo}/issues/events/{event_id}"],
    getLabel: ["GET /repos/{owner}/{repo}/labels/{name}"],
    getMilestone: ["GET /repos/{owner}/{repo}/milestones/{milestone_number}"],
    list: ["GET /issues"],
    listAssignees: ["GET /repos/{owner}/{repo}/assignees"],
    listComments: ["GET /repos/{owner}/{repo}/issues/{issue_number}/comments"],
    listCommentsForRepo: ["GET /repos/{owner}/{repo}/issues/comments"],
    listEvents: ["GET /repos/{owner}/{repo}/issues/{issue_number}/events"],
    listEventsForRepo: ["GET /repos/{owner}/{repo}/issues/events"],
    listEventsForTimeline: [
      "GET /repos/{owner}/{repo}/issues/{issue_number}/timeline"
    ],
    listForAuthenticatedUser: ["GET /user/issues"],
    listForOrg: ["GET /orgs/{org}/issues"],
    listForRepo: ["GET /repos/{owner}/{repo}/issues"],
    listLabelsForMilestone: [
      "GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels"
    ],
    listLabelsForRepo: ["GET /repos/{owner}/{repo}/labels"],
    listLabelsOnIssue: [
      "GET /repos/{owner}/{repo}/issues/{issue_number}/labels"
    ],
    listMilestones: ["GET /repos/{owner}/{repo}/milestones"],
    lock: ["PUT /repos/{owner}/{repo}/issues/{issue_number}/lock"],
    removeAllLabels: [
      "DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels"
    ],
    removeAssignees: [
      "DELETE /repos/{owner}/{repo}/issues/{issue_number}/assignees"
    ],
    removeLabel: [
      "DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels/{name}"
    ],
    setLabels: ["PUT /repos/{owner}/{repo}/issues/{issue_number}/labels"],
    unlock: ["DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock"],
    update: ["PATCH /repos/{owner}/{repo}/issues/{issue_number}"],
    updateComment: ["PATCH /repos/{owner}/{repo}/issues/comments/{comment_id}"],
    updateLabel: ["PATCH /repos/{owner}/{repo}/labels/{name}"],
    updateMilestone: [
      "PATCH /repos/{owner}/{repo}/milestones/{milestone_number}"
    ]
  },
  licenses: {
    get: ["GET /licenses/{license}"],
    getAllCommonlyUsed: ["GET /licenses"],
    getForRepo: ["GET /repos/{owner}/{repo}/license"]
  },
  markdown: {
    render: ["POST /markdown"],
    renderRaw: [
      "POST /markdown/raw",
      { headers: { "content-type": "text/plain; charset=utf-8" } }
    ]
  },
  meta: {
    get: ["GET /meta"],
    getAllVersions: ["GET /versions"],
    getOctocat: ["GET /octocat"],
    getZen: ["GET /zen"],
    root: ["GET /"]
  },
  migrations: {
    cancelImport: [
      "DELETE /repos/{owner}/{repo}/import",
      {},
      {
        deprecated: "octokit.rest.migrations.cancelImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#cancel-an-import"
      }
    ],
    deleteArchiveForAuthenticatedUser: [
      "DELETE /user/migrations/{migration_id}/archive"
    ],
    deleteArchiveForOrg: [
      "DELETE /orgs/{org}/migrations/{migration_id}/archive"
    ],
    downloadArchiveForOrg: [
      "GET /orgs/{org}/migrations/{migration_id}/archive"
    ],
    getArchiveForAuthenticatedUser: [
      "GET /user/migrations/{migration_id}/archive"
    ],
    getCommitAuthors: [
      "GET /repos/{owner}/{repo}/import/authors",
      {},
      {
        deprecated: "octokit.rest.migrations.getCommitAuthors() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-commit-authors"
      }
    ],
    getImportStatus: [
      "GET /repos/{owner}/{repo}/import",
      {},
      {
        deprecated: "octokit.rest.migrations.getImportStatus() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-an-import-status"
      }
    ],
    getLargeFiles: [
      "GET /repos/{owner}/{repo}/import/large_files",
      {},
      {
        deprecated: "octokit.rest.migrations.getLargeFiles() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-large-files"
      }
    ],
    getStatusForAuthenticatedUser: ["GET /user/migrations/{migration_id}"],
    getStatusForOrg: ["GET /orgs/{org}/migrations/{migration_id}"],
    listForAuthenticatedUser: ["GET /user/migrations"],
    listForOrg: ["GET /orgs/{org}/migrations"],
    listReposForAuthenticatedUser: [
      "GET /user/migrations/{migration_id}/repositories"
    ],
    listReposForOrg: ["GET /orgs/{org}/migrations/{migration_id}/repositories"],
    listReposForUser: [
      "GET /user/migrations/{migration_id}/repositories",
      {},
      { renamed: ["migrations", "listReposForAuthenticatedUser"] }
    ],
    mapCommitAuthor: [
      "PATCH /repos/{owner}/{repo}/import/authors/{author_id}",
      {},
      {
        deprecated: "octokit.rest.migrations.mapCommitAuthor() is deprecated, see https://docs.github.com/rest/migrations/source-imports#map-a-commit-author"
      }
    ],
    setLfsPreference: [
      "PATCH /repos/{owner}/{repo}/import/lfs",
      {},
      {
        deprecated: "octokit.rest.migrations.setLfsPreference() is deprecated, see https://docs.github.com/rest/migrations/source-imports#update-git-lfs-preference"
      }
    ],
    startForAuthenticatedUser: ["POST /user/migrations"],
    startForOrg: ["POST /orgs/{org}/migrations"],
    startImport: [
      "PUT /repos/{owner}/{repo}/import",
      {},
      {
        deprecated: "octokit.rest.migrations.startImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#start-an-import"
      }
    ],
    unlockRepoForAuthenticatedUser: [
      "DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock"
    ],
    unlockRepoForOrg: [
      "DELETE /orgs/{org}/migrations/{migration_id}/repos/{repo_name}/lock"
    ],
    updateImport: [
      "PATCH /repos/{owner}/{repo}/import",
      {},
      {
        deprecated: "octokit.rest.migrations.updateImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#update-an-import"
      }
    ]
  },
  oidc: {
    getOidcCustomSubTemplateForOrg: [
      "GET /orgs/{org}/actions/oidc/customization/sub"
    ],
    updateOidcCustomSubTemplateForOrg: [
      "PUT /orgs/{org}/actions/oidc/customization/sub"
    ]
  },
  orgs: {
    addSecurityManagerTeam: [
      "PUT /orgs/{org}/security-managers/teams/{team_slug}"
    ],
    assignTeamToOrgRole: [
      "PUT /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}"
    ],
    assignUserToOrgRole: [
      "PUT /orgs/{org}/organization-roles/users/{username}/{role_id}"
    ],
    blockUser: ["PUT /orgs/{org}/blocks/{username}"],
    cancelInvitation: ["DELETE /orgs/{org}/invitations/{invitation_id}"],
    checkBlockedUser: ["GET /orgs/{org}/blocks/{username}"],
    checkMembershipForUser: ["GET /orgs/{org}/members/{username}"],
    checkPublicMembershipForUser: ["GET /orgs/{org}/public_members/{username}"],
    convertMemberToOutsideCollaborator: [
      "PUT /orgs/{org}/outside_collaborators/{username}"
    ],
    createCustomOrganizationRole: ["POST /orgs/{org}/organization-roles"],
    createInvitation: ["POST /orgs/{org}/invitations"],
    createOrUpdateCustomProperties: ["PATCH /orgs/{org}/properties/schema"],
    createOrUpdateCustomPropertiesValuesForRepos: [
      "PATCH /orgs/{org}/properties/values"
    ],
    createOrUpdateCustomProperty: [
      "PUT /orgs/{org}/properties/schema/{custom_property_name}"
    ],
    createWebhook: ["POST /orgs/{org}/hooks"],
    delete: ["DELETE /orgs/{org}"],
    deleteCustomOrganizationRole: [
      "DELETE /orgs/{org}/organization-roles/{role_id}"
    ],
    deleteWebhook: ["DELETE /orgs/{org}/hooks/{hook_id}"],
    enableOrDisableSecurityProductOnAllOrgRepos: [
      "POST /orgs/{org}/{security_product}/{enablement}"
    ],
    get: ["GET /orgs/{org}"],
    getAllCustomProperties: ["GET /orgs/{org}/properties/schema"],
    getCustomProperty: [
      "GET /orgs/{org}/properties/schema/{custom_property_name}"
    ],
    getMembershipForAuthenticatedUser: ["GET /user/memberships/orgs/{org}"],
    getMembershipForUser: ["GET /orgs/{org}/memberships/{username}"],
    getOrgRole: ["GET /orgs/{org}/organization-roles/{role_id}"],
    getWebhook: ["GET /orgs/{org}/hooks/{hook_id}"],
    getWebhookConfigForOrg: ["GET /orgs/{org}/hooks/{hook_id}/config"],
    getWebhookDelivery: [
      "GET /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}"
    ],
    list: ["GET /organizations"],
    listAppInstallations: ["GET /orgs/{org}/installations"],
    listBlockedUsers: ["GET /orgs/{org}/blocks"],
    listCustomPropertiesValuesForRepos: ["GET /orgs/{org}/properties/values"],
    listFailedInvitations: ["GET /orgs/{org}/failed_invitations"],
    listForAuthenticatedUser: ["GET /user/orgs"],
    listForUser: ["GET /users/{username}/orgs"],
    listInvitationTeams: ["GET /orgs/{org}/invitations/{invitation_id}/teams"],
    listMembers: ["GET /orgs/{org}/members"],
    listMembershipsForAuthenticatedUser: ["GET /user/memberships/orgs"],
    listOrgRoleTeams: ["GET /orgs/{org}/organization-roles/{role_id}/teams"],
    listOrgRoleUsers: ["GET /orgs/{org}/organization-roles/{role_id}/users"],
    listOrgRoles: ["GET /orgs/{org}/organization-roles"],
    listOrganizationFineGrainedPermissions: [
      "GET /orgs/{org}/organization-fine-grained-permissions"
    ],
    listOutsideCollaborators: ["GET /orgs/{org}/outside_collaborators"],
    listPatGrantRepositories: [
      "GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories"
    ],
    listPatGrantRequestRepositories: [
      "GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories"
    ],
    listPatGrantRequests: ["GET /orgs/{org}/personal-access-token-requests"],
    listPatGrants: ["GET /orgs/{org}/personal-access-tokens"],
    listPendingInvitations: ["GET /orgs/{org}/invitations"],
    listPublicMembers: ["GET /orgs/{org}/public_members"],
    listSecurityManagerTeams: ["GET /orgs/{org}/security-managers"],
    listWebhookDeliveries: ["GET /orgs/{org}/hooks/{hook_id}/deliveries"],
    listWebhooks: ["GET /orgs/{org}/hooks"],
    patchCustomOrganizationRole: [
      "PATCH /orgs/{org}/organization-roles/{role_id}"
    ],
    pingWebhook: ["POST /orgs/{org}/hooks/{hook_id}/pings"],
    redeliverWebhookDelivery: [
      "POST /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}/attempts"
    ],
    removeCustomProperty: [
      "DELETE /orgs/{org}/properties/schema/{custom_property_name}"
    ],
    removeMember: ["DELETE /orgs/{org}/members/{username}"],
    removeMembershipForUser: ["DELETE /orgs/{org}/memberships/{username}"],
    removeOutsideCollaborator: [
      "DELETE /orgs/{org}/outside_collaborators/{username}"
    ],
    removePublicMembershipForAuthenticatedUser: [
      "DELETE /orgs/{org}/public_members/{username}"
    ],
    removeSecurityManagerTeam: [
      "DELETE /orgs/{org}/security-managers/teams/{team_slug}"
    ],
    reviewPatGrantRequest: [
      "POST /orgs/{org}/personal-access-token-requests/{pat_request_id}"
    ],
    reviewPatGrantRequestsInBulk: [
      "POST /orgs/{org}/personal-access-token-requests"
    ],
    revokeAllOrgRolesTeam: [
      "DELETE /orgs/{org}/organization-roles/teams/{team_slug}"
    ],
    revokeAllOrgRolesUser: [
      "DELETE /orgs/{org}/organization-roles/users/{username}"
    ],
    revokeOrgRoleTeam: [
      "DELETE /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}"
    ],
    revokeOrgRoleUser: [
      "DELETE /orgs/{org}/organization-roles/users/{username}/{role_id}"
    ],
    setMembershipForUser: ["PUT /orgs/{org}/memberships/{username}"],
    setPublicMembershipForAuthenticatedUser: [
      "PUT /orgs/{org}/public_members/{username}"
    ],
    unblockUser: ["DELETE /orgs/{org}/blocks/{username}"],
    update: ["PATCH /orgs/{org}"],
    updateMembershipForAuthenticatedUser: [
      "PATCH /user/memberships/orgs/{org}"
    ],
    updatePatAccess: ["POST /orgs/{org}/personal-access-tokens/{pat_id}"],
    updatePatAccesses: ["POST /orgs/{org}/personal-access-tokens"],
    updateWebhook: ["PATCH /orgs/{org}/hooks/{hook_id}"],
    updateWebhookConfigForOrg: ["PATCH /orgs/{org}/hooks/{hook_id}/config"]
  },
  packages: {
    deletePackageForAuthenticatedUser: [
      "DELETE /user/packages/{package_type}/{package_name}"
    ],
    deletePackageForOrg: [
      "DELETE /orgs/{org}/packages/{package_type}/{package_name}"
    ],
    deletePackageForUser: [
      "DELETE /users/{username}/packages/{package_type}/{package_name}"
    ],
    deletePackageVersionForAuthenticatedUser: [
      "DELETE /user/packages/{package_type}/{package_name}/versions/{package_version_id}"
    ],
    deletePackageVersionForOrg: [
      "DELETE /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}"
    ],
    deletePackageVersionForUser: [
      "DELETE /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}"
    ],
    getAllPackageVersionsForAPackageOwnedByAnOrg: [
      "GET /orgs/{org}/packages/{package_type}/{package_name}/versions",
      {},
      { renamed: ["packages", "getAllPackageVersionsForPackageOwnedByOrg"] }
    ],
    getAllPackageVersionsForAPackageOwnedByTheAuthenticatedUser: [
      "GET /user/packages/{package_type}/{package_name}/versions",
      {},
      {
        renamed: [
          "packages",
          "getAllPackageVersionsForPackageOwnedByAuthenticatedUser"
        ]
      }
    ],
    getAllPackageVersionsForPackageOwnedByAuthenticatedUser: [
      "GET /user/packages/{package_type}/{package_name}/versions"
    ],
    getAllPackageVersionsForPackageOwnedByOrg: [
      "GET /orgs/{org}/packages/{package_type}/{package_name}/versions"
    ],
    getAllPackageVersionsForPackageOwnedByUser: [
      "GET /users/{username}/packages/{package_type}/{package_name}/versions"
    ],
    getPackageForAuthenticatedUser: [
      "GET /user/packages/{package_type}/{package_name}"
    ],
    getPackageForOrganization: [
      "GET /orgs/{org}/packages/{package_type}/{package_name}"
    ],
    getPackageForUser: [
      "GET /users/{username}/packages/{package_type}/{package_name}"
    ],
    getPackageVersionForAuthenticatedUser: [
      "GET /user/packages/{package_type}/{package_name}/versions/{package_version_id}"
    ],
    getPackageVersionForOrganization: [
      "GET /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}"
    ],
    getPackageVersionForUser: [
      "GET /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}"
    ],
    listDockerMigrationConflictingPackagesForAuthenticatedUser: [
      "GET /user/docker/conflicts"
    ],
    listDockerMigrationConflictingPackagesForOrganization: [
      "GET /orgs/{org}/docker/conflicts"
    ],
    listDockerMigrationConflictingPackagesForUser: [
      "GET /users/{username}/docker/conflicts"
    ],
    listPackagesForAuthenticatedUser: ["GET /user/packages"],
    listPackagesForOrganization: ["GET /orgs/{org}/packages"],
    listPackagesForUser: ["GET /users/{username}/packages"],
    restorePackageForAuthenticatedUser: [
      "POST /user/packages/{package_type}/{package_name}/restore{?token}"
    ],
    restorePackageForOrg: [
      "POST /orgs/{org}/packages/{package_type}/{package_name}/restore{?token}"
    ],
    restorePackageForUser: [
      "POST /users/{username}/packages/{package_type}/{package_name}/restore{?token}"
    ],
    restorePackageVersionForAuthenticatedUser: [
      "POST /user/packages/{package_type}/{package_name}/versions/{package_version_id}/restore"
    ],
    restorePackageVersionForOrg: [
      "POST /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore"
    ],
    restorePackageVersionForUser: [
      "POST /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore"
    ]
  },
  projects: {
    addCollaborator: ["PUT /projects/{project_id}/collaborators/{username}"],
    createCard: ["POST /projects/columns/{column_id}/cards"],
    createColumn: ["POST /projects/{project_id}/columns"],
    createForAuthenticatedUser: ["POST /user/projects"],
    createForOrg: ["POST /orgs/{org}/projects"],
    createForRepo: ["POST /repos/{owner}/{repo}/projects"],
    delete: ["DELETE /projects/{project_id}"],
    deleteCard: ["DELETE /projects/columns/cards/{card_id}"],
    deleteColumn: ["DELETE /projects/columns/{column_id}"],
    get: ["GET /projects/{project_id}"],
    getCard: ["GET /projects/columns/cards/{card_id}"],
    getColumn: ["GET /projects/columns/{column_id}"],
    getPermissionForUser: [
      "GET /projects/{project_id}/collaborators/{username}/permission"
    ],
    listCards: ["GET /projects/columns/{column_id}/cards"],
    listCollaborators: ["GET /projects/{project_id}/collaborators"],
    listColumns: ["GET /projects/{project_id}/columns"],
    listForOrg: ["GET /orgs/{org}/projects"],
    listForRepo: ["GET /repos/{owner}/{repo}/projects"],
    listForUser: ["GET /users/{username}/projects"],
    moveCard: ["POST /projects/columns/cards/{card_id}/moves"],
    moveColumn: ["POST /projects/columns/{column_id}/moves"],
    removeCollaborator: [
      "DELETE /projects/{project_id}/collaborators/{username}"
    ],
    update: ["PATCH /projects/{project_id}"],
    updateCard: ["PATCH /projects/columns/cards/{card_id}"],
    updateColumn: ["PATCH /projects/columns/{column_id}"]
  },
  pulls: {
    checkIfMerged: ["GET /repos/{owner}/{repo}/pulls/{pull_number}/merge"],
    create: ["POST /repos/{owner}/{repo}/pulls"],
    createReplyForReviewComment: [
      "POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies"
    ],
    createReview: ["POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews"],
    createReviewComment: [
      "POST /repos/{owner}/{repo}/pulls/{pull_number}/comments"
    ],
    deletePendingReview: [
      "DELETE /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}"
    ],
    deleteReviewComment: [
      "DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}"
    ],
    dismissReview: [
      "PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/dismissals"
    ],
    get: ["GET /repos/{owner}/{repo}/pulls/{pull_number}"],
    getReview: [
      "GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}"
    ],
    getReviewComment: ["GET /repos/{owner}/{repo}/pulls/comments/{comment_id}"],
    list: ["GET /repos/{owner}/{repo}/pulls"],
    listCommentsForReview: [
      "GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments"
    ],
    listCommits: ["GET /repos/{owner}/{repo}/pulls/{pull_number}/commits"],
    listFiles: ["GET /repos/{owner}/{repo}/pulls/{pull_number}/files"],
    listRequestedReviewers: [
      "GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers"
    ],
    listReviewComments: [
      "GET /repos/{owner}/{repo}/pulls/{pull_number}/comments"
    ],
    listReviewCommentsForRepo: ["GET /repos/{owner}/{repo}/pulls/comments"],
    listReviews: ["GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews"],
    merge: ["PUT /repos/{owner}/{repo}/pulls/{pull_number}/merge"],
    removeRequestedReviewers: [
      "DELETE /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers"
    ],
    requestReviewers: [
      "POST /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers"
    ],
    submitReview: [
      "POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/events"
    ],
    update: ["PATCH /repos/{owner}/{repo}/pulls/{pull_number}"],
    updateBranch: [
      "PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch"
    ],
    updateReview: [
      "PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}"
    ],
    updateReviewComment: [
      "PATCH /repos/{owner}/{repo}/pulls/comments/{comment_id}"
    ]
  },
  rateLimit: { get: ["GET /rate_limit"] },
  reactions: {
    createForCommitComment: [
      "POST /repos/{owner}/{repo}/comments/{comment_id}/reactions"
    ],
    createForIssue: [
      "POST /repos/{owner}/{repo}/issues/{issue_number}/reactions"
    ],
    createForIssueComment: [
      "POST /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions"
    ],
    createForPullRequestReviewComment: [
      "POST /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions"
    ],
    createForRelease: [
      "POST /repos/{owner}/{repo}/releases/{release_id}/reactions"
    ],
    createForTeamDiscussionCommentInOrg: [
      "POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions"
    ],
    createForTeamDiscussionInOrg: [
      "POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions"
    ],
    deleteForCommitComment: [
      "DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}"
    ],
    deleteForIssue: [
      "DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id}"
    ],
    deleteForIssueComment: [
      "DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}"
    ],
    deleteForPullRequestComment: [
      "DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}"
    ],
    deleteForRelease: [
      "DELETE /repos/{owner}/{repo}/releases/{release_id}/reactions/{reaction_id}"
    ],
    deleteForTeamDiscussion: [
      "DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions/{reaction_id}"
    ],
    deleteForTeamDiscussionComment: [
      "DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions/{reaction_id}"
    ],
    listForCommitComment: [
      "GET /repos/{owner}/{repo}/comments/{comment_id}/reactions"
    ],
    listForIssue: ["GET /repos/{owner}/{repo}/issues/{issue_number}/reactions"],
    listForIssueComment: [
      "GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions"
    ],
    listForPullRequestReviewComment: [
      "GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions"
    ],
    listForRelease: [
      "GET /repos/{owner}/{repo}/releases/{release_id}/reactions"
    ],
    listForTeamDiscussionCommentInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions"
    ],
    listForTeamDiscussionInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions"
    ]
  },
  repos: {
    acceptInvitation: [
      "PATCH /user/repository_invitations/{invitation_id}",
      {},
      { renamed: ["repos", "acceptInvitationForAuthenticatedUser"] }
    ],
    acceptInvitationForAuthenticatedUser: [
      "PATCH /user/repository_invitations/{invitation_id}"
    ],
    addAppAccessRestrictions: [
      "POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps",
      {},
      { mapToData: "apps" }
    ],
    addCollaborator: ["PUT /repos/{owner}/{repo}/collaborators/{username}"],
    addStatusCheckContexts: [
      "POST /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts",
      {},
      { mapToData: "contexts" }
    ],
    addTeamAccessRestrictions: [
      "POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams",
      {},
      { mapToData: "teams" }
    ],
    addUserAccessRestrictions: [
      "POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users",
      {},
      { mapToData: "users" }
    ],
    cancelPagesDeployment: [
      "POST /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}/cancel"
    ],
    checkAutomatedSecurityFixes: [
      "GET /repos/{owner}/{repo}/automated-security-fixes"
    ],
    checkCollaborator: ["GET /repos/{owner}/{repo}/collaborators/{username}"],
    checkVulnerabilityAlerts: [
      "GET /repos/{owner}/{repo}/vulnerability-alerts"
    ],
    codeownersErrors: ["GET /repos/{owner}/{repo}/codeowners/errors"],
    compareCommits: ["GET /repos/{owner}/{repo}/compare/{base}...{head}"],
    compareCommitsWithBasehead: [
      "GET /repos/{owner}/{repo}/compare/{basehead}"
    ],
    createAutolink: ["POST /repos/{owner}/{repo}/autolinks"],
    createCommitComment: [
      "POST /repos/{owner}/{repo}/commits/{commit_sha}/comments"
    ],
    createCommitSignatureProtection: [
      "POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures"
    ],
    createCommitStatus: ["POST /repos/{owner}/{repo}/statuses/{sha}"],
    createDeployKey: ["POST /repos/{owner}/{repo}/keys"],
    createDeployment: ["POST /repos/{owner}/{repo}/deployments"],
    createDeploymentBranchPolicy: [
      "POST /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies"
    ],
    createDeploymentProtectionRule: [
      "POST /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules"
    ],
    createDeploymentStatus: [
      "POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses"
    ],
    createDispatchEvent: ["POST /repos/{owner}/{repo}/dispatches"],
    createForAuthenticatedUser: ["POST /user/repos"],
    createFork: ["POST /repos/{owner}/{repo}/forks"],
    createInOrg: ["POST /orgs/{org}/repos"],
    createOrUpdateCustomPropertiesValues: [
      "PATCH /repos/{owner}/{repo}/properties/values"
    ],
    createOrUpdateEnvironment: [
      "PUT /repos/{owner}/{repo}/environments/{environment_name}"
    ],
    createOrUpdateFileContents: ["PUT /repos/{owner}/{repo}/contents/{path}"],
    createOrgRuleset: ["POST /orgs/{org}/rulesets"],
    createPagesDeployment: ["POST /repos/{owner}/{repo}/pages/deployments"],
    createPagesSite: ["POST /repos/{owner}/{repo}/pages"],
    createRelease: ["POST /repos/{owner}/{repo}/releases"],
    createRepoRuleset: ["POST /repos/{owner}/{repo}/rulesets"],
    createTagProtection: ["POST /repos/{owner}/{repo}/tags/protection"],
    createUsingTemplate: [
      "POST /repos/{template_owner}/{template_repo}/generate"
    ],
    createWebhook: ["POST /repos/{owner}/{repo}/hooks"],
    declineInvitation: [
      "DELETE /user/repository_invitations/{invitation_id}",
      {},
      { renamed: ["repos", "declineInvitationForAuthenticatedUser"] }
    ],
    declineInvitationForAuthenticatedUser: [
      "DELETE /user/repository_invitations/{invitation_id}"
    ],
    delete: ["DELETE /repos/{owner}/{repo}"],
    deleteAccessRestrictions: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions"
    ],
    deleteAdminBranchProtection: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins"
    ],
    deleteAnEnvironment: [
      "DELETE /repos/{owner}/{repo}/environments/{environment_name}"
    ],
    deleteAutolink: ["DELETE /repos/{owner}/{repo}/autolinks/{autolink_id}"],
    deleteBranchProtection: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection"
    ],
    deleteCommitComment: ["DELETE /repos/{owner}/{repo}/comments/{comment_id}"],
    deleteCommitSignatureProtection: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures"
    ],
    deleteDeployKey: ["DELETE /repos/{owner}/{repo}/keys/{key_id}"],
    deleteDeployment: [
      "DELETE /repos/{owner}/{repo}/deployments/{deployment_id}"
    ],
    deleteDeploymentBranchPolicy: [
      "DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}"
    ],
    deleteFile: ["DELETE /repos/{owner}/{repo}/contents/{path}"],
    deleteInvitation: [
      "DELETE /repos/{owner}/{repo}/invitations/{invitation_id}"
    ],
    deleteOrgRuleset: ["DELETE /orgs/{org}/rulesets/{ruleset_id}"],
    deletePagesSite: ["DELETE /repos/{owner}/{repo}/pages"],
    deletePullRequestReviewProtection: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews"
    ],
    deleteRelease: ["DELETE /repos/{owner}/{repo}/releases/{release_id}"],
    deleteReleaseAsset: [
      "DELETE /repos/{owner}/{repo}/releases/assets/{asset_id}"
    ],
    deleteRepoRuleset: ["DELETE /repos/{owner}/{repo}/rulesets/{ruleset_id}"],
    deleteTagProtection: [
      "DELETE /repos/{owner}/{repo}/tags/protection/{tag_protection_id}"
    ],
    deleteWebhook: ["DELETE /repos/{owner}/{repo}/hooks/{hook_id}"],
    disableAutomatedSecurityFixes: [
      "DELETE /repos/{owner}/{repo}/automated-security-fixes"
    ],
    disableDeploymentProtectionRule: [
      "DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}"
    ],
    disablePrivateVulnerabilityReporting: [
      "DELETE /repos/{owner}/{repo}/private-vulnerability-reporting"
    ],
    disableVulnerabilityAlerts: [
      "DELETE /repos/{owner}/{repo}/vulnerability-alerts"
    ],
    downloadArchive: [
      "GET /repos/{owner}/{repo}/zipball/{ref}",
      {},
      { renamed: ["repos", "downloadZipballArchive"] }
    ],
    downloadTarballArchive: ["GET /repos/{owner}/{repo}/tarball/{ref}"],
    downloadZipballArchive: ["GET /repos/{owner}/{repo}/zipball/{ref}"],
    enableAutomatedSecurityFixes: [
      "PUT /repos/{owner}/{repo}/automated-security-fixes"
    ],
    enablePrivateVulnerabilityReporting: [
      "PUT /repos/{owner}/{repo}/private-vulnerability-reporting"
    ],
    enableVulnerabilityAlerts: [
      "PUT /repos/{owner}/{repo}/vulnerability-alerts"
    ],
    generateReleaseNotes: [
      "POST /repos/{owner}/{repo}/releases/generate-notes"
    ],
    get: ["GET /repos/{owner}/{repo}"],
    getAccessRestrictions: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions"
    ],
    getAdminBranchProtection: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins"
    ],
    getAllDeploymentProtectionRules: [
      "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules"
    ],
    getAllEnvironments: ["GET /repos/{owner}/{repo}/environments"],
    getAllStatusCheckContexts: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts"
    ],
    getAllTopics: ["GET /repos/{owner}/{repo}/topics"],
    getAppsWithAccessToProtectedBranch: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps"
    ],
    getAutolink: ["GET /repos/{owner}/{repo}/autolinks/{autolink_id}"],
    getBranch: ["GET /repos/{owner}/{repo}/branches/{branch}"],
    getBranchProtection: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection"
    ],
    getBranchRules: ["GET /repos/{owner}/{repo}/rules/branches/{branch}"],
    getClones: ["GET /repos/{owner}/{repo}/traffic/clones"],
    getCodeFrequencyStats: ["GET /repos/{owner}/{repo}/stats/code_frequency"],
    getCollaboratorPermissionLevel: [
      "GET /repos/{owner}/{repo}/collaborators/{username}/permission"
    ],
    getCombinedStatusForRef: ["GET /repos/{owner}/{repo}/commits/{ref}/status"],
    getCommit: ["GET /repos/{owner}/{repo}/commits/{ref}"],
    getCommitActivityStats: ["GET /repos/{owner}/{repo}/stats/commit_activity"],
    getCommitComment: ["GET /repos/{owner}/{repo}/comments/{comment_id}"],
    getCommitSignatureProtection: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures"
    ],
    getCommunityProfileMetrics: ["GET /repos/{owner}/{repo}/community/profile"],
    getContent: ["GET /repos/{owner}/{repo}/contents/{path}"],
    getContributorsStats: ["GET /repos/{owner}/{repo}/stats/contributors"],
    getCustomDeploymentProtectionRule: [
      "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}"
    ],
    getCustomPropertiesValues: ["GET /repos/{owner}/{repo}/properties/values"],
    getDeployKey: ["GET /repos/{owner}/{repo}/keys/{key_id}"],
    getDeployment: ["GET /repos/{owner}/{repo}/deployments/{deployment_id}"],
    getDeploymentBranchPolicy: [
      "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}"
    ],
    getDeploymentStatus: [
      "GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses/{status_id}"
    ],
    getEnvironment: [
      "GET /repos/{owner}/{repo}/environments/{environment_name}"
    ],
    getLatestPagesBuild: ["GET /repos/{owner}/{repo}/pages/builds/latest"],
    getLatestRelease: ["GET /repos/{owner}/{repo}/releases/latest"],
    getOrgRuleSuite: ["GET /orgs/{org}/rulesets/rule-suites/{rule_suite_id}"],
    getOrgRuleSuites: ["GET /orgs/{org}/rulesets/rule-suites"],
    getOrgRuleset: ["GET /orgs/{org}/rulesets/{ruleset_id}"],
    getOrgRulesets: ["GET /orgs/{org}/rulesets"],
    getPages: ["GET /repos/{owner}/{repo}/pages"],
    getPagesBuild: ["GET /repos/{owner}/{repo}/pages/builds/{build_id}"],
    getPagesDeployment: [
      "GET /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}"
    ],
    getPagesHealthCheck: ["GET /repos/{owner}/{repo}/pages/health"],
    getParticipationStats: ["GET /repos/{owner}/{repo}/stats/participation"],
    getPullRequestReviewProtection: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews"
    ],
    getPunchCardStats: ["GET /repos/{owner}/{repo}/stats/punch_card"],
    getReadme: ["GET /repos/{owner}/{repo}/readme"],
    getReadmeInDirectory: ["GET /repos/{owner}/{repo}/readme/{dir}"],
    getRelease: ["GET /repos/{owner}/{repo}/releases/{release_id}"],
    getReleaseAsset: ["GET /repos/{owner}/{repo}/releases/assets/{asset_id}"],
    getReleaseByTag: ["GET /repos/{owner}/{repo}/releases/tags/{tag}"],
    getRepoRuleSuite: [
      "GET /repos/{owner}/{repo}/rulesets/rule-suites/{rule_suite_id}"
    ],
    getRepoRuleSuites: ["GET /repos/{owner}/{repo}/rulesets/rule-suites"],
    getRepoRuleset: ["GET /repos/{owner}/{repo}/rulesets/{ruleset_id}"],
    getRepoRulesets: ["GET /repos/{owner}/{repo}/rulesets"],
    getStatusChecksProtection: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks"
    ],
    getTeamsWithAccessToProtectedBranch: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams"
    ],
    getTopPaths: ["GET /repos/{owner}/{repo}/traffic/popular/paths"],
    getTopReferrers: ["GET /repos/{owner}/{repo}/traffic/popular/referrers"],
    getUsersWithAccessToProtectedBranch: [
      "GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users"
    ],
    getViews: ["GET /repos/{owner}/{repo}/traffic/views"],
    getWebhook: ["GET /repos/{owner}/{repo}/hooks/{hook_id}"],
    getWebhookConfigForRepo: [
      "GET /repos/{owner}/{repo}/hooks/{hook_id}/config"
    ],
    getWebhookDelivery: [
      "GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}"
    ],
    listActivities: ["GET /repos/{owner}/{repo}/activity"],
    listAutolinks: ["GET /repos/{owner}/{repo}/autolinks"],
    listBranches: ["GET /repos/{owner}/{repo}/branches"],
    listBranchesForHeadCommit: [
      "GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head"
    ],
    listCollaborators: ["GET /repos/{owner}/{repo}/collaborators"],
    listCommentsForCommit: [
      "GET /repos/{owner}/{repo}/commits/{commit_sha}/comments"
    ],
    listCommitCommentsForRepo: ["GET /repos/{owner}/{repo}/comments"],
    listCommitStatusesForRef: [
      "GET /repos/{owner}/{repo}/commits/{ref}/statuses"
    ],
    listCommits: ["GET /repos/{owner}/{repo}/commits"],
    listContributors: ["GET /repos/{owner}/{repo}/contributors"],
    listCustomDeploymentRuleIntegrations: [
      "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps"
    ],
    listDeployKeys: ["GET /repos/{owner}/{repo}/keys"],
    listDeploymentBranchPolicies: [
      "GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies"
    ],
    listDeploymentStatuses: [
      "GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses"
    ],
    listDeployments: ["GET /repos/{owner}/{repo}/deployments"],
    listForAuthenticatedUser: ["GET /user/repos"],
    listForOrg: ["GET /orgs/{org}/repos"],
    listForUser: ["GET /users/{username}/repos"],
    listForks: ["GET /repos/{owner}/{repo}/forks"],
    listInvitations: ["GET /repos/{owner}/{repo}/invitations"],
    listInvitationsForAuthenticatedUser: ["GET /user/repository_invitations"],
    listLanguages: ["GET /repos/{owner}/{repo}/languages"],
    listPagesBuilds: ["GET /repos/{owner}/{repo}/pages/builds"],
    listPublic: ["GET /repositories"],
    listPullRequestsAssociatedWithCommit: [
      "GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls"
    ],
    listReleaseAssets: [
      "GET /repos/{owner}/{repo}/releases/{release_id}/assets"
    ],
    listReleases: ["GET /repos/{owner}/{repo}/releases"],
    listTagProtection: ["GET /repos/{owner}/{repo}/tags/protection"],
    listTags: ["GET /repos/{owner}/{repo}/tags"],
    listTeams: ["GET /repos/{owner}/{repo}/teams"],
    listWebhookDeliveries: [
      "GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries"
    ],
    listWebhooks: ["GET /repos/{owner}/{repo}/hooks"],
    merge: ["POST /repos/{owner}/{repo}/merges"],
    mergeUpstream: ["POST /repos/{owner}/{repo}/merge-upstream"],
    pingWebhook: ["POST /repos/{owner}/{repo}/hooks/{hook_id}/pings"],
    redeliverWebhookDelivery: [
      "POST /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}/attempts"
    ],
    removeAppAccessRestrictions: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps",
      {},
      { mapToData: "apps" }
    ],
    removeCollaborator: [
      "DELETE /repos/{owner}/{repo}/collaborators/{username}"
    ],
    removeStatusCheckContexts: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts",
      {},
      { mapToData: "contexts" }
    ],
    removeStatusCheckProtection: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks"
    ],
    removeTeamAccessRestrictions: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams",
      {},
      { mapToData: "teams" }
    ],
    removeUserAccessRestrictions: [
      "DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users",
      {},
      { mapToData: "users" }
    ],
    renameBranch: ["POST /repos/{owner}/{repo}/branches/{branch}/rename"],
    replaceAllTopics: ["PUT /repos/{owner}/{repo}/topics"],
    requestPagesBuild: ["POST /repos/{owner}/{repo}/pages/builds"],
    setAdminBranchProtection: [
      "POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins"
    ],
    setAppAccessRestrictions: [
      "PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps",
      {},
      { mapToData: "apps" }
    ],
    setStatusCheckContexts: [
      "PUT /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts",
      {},
      { mapToData: "contexts" }
    ],
    setTeamAccessRestrictions: [
      "PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams",
      {},
      { mapToData: "teams" }
    ],
    setUserAccessRestrictions: [
      "PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users",
      {},
      { mapToData: "users" }
    ],
    testPushWebhook: ["POST /repos/{owner}/{repo}/hooks/{hook_id}/tests"],
    transfer: ["POST /repos/{owner}/{repo}/transfer"],
    update: ["PATCH /repos/{owner}/{repo}"],
    updateBranchProtection: [
      "PUT /repos/{owner}/{repo}/branches/{branch}/protection"
    ],
    updateCommitComment: ["PATCH /repos/{owner}/{repo}/comments/{comment_id}"],
    updateDeploymentBranchPolicy: [
      "PUT /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}"
    ],
    updateInformationAboutPagesSite: ["PUT /repos/{owner}/{repo}/pages"],
    updateInvitation: [
      "PATCH /repos/{owner}/{repo}/invitations/{invitation_id}"
    ],
    updateOrgRuleset: ["PUT /orgs/{org}/rulesets/{ruleset_id}"],
    updatePullRequestReviewProtection: [
      "PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews"
    ],
    updateRelease: ["PATCH /repos/{owner}/{repo}/releases/{release_id}"],
    updateReleaseAsset: [
      "PATCH /repos/{owner}/{repo}/releases/assets/{asset_id}"
    ],
    updateRepoRuleset: ["PUT /repos/{owner}/{repo}/rulesets/{ruleset_id}"],
    updateStatusCheckPotection: [
      "PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks",
      {},
      { renamed: ["repos", "updateStatusCheckProtection"] }
    ],
    updateStatusCheckProtection: [
      "PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks"
    ],
    updateWebhook: ["PATCH /repos/{owner}/{repo}/hooks/{hook_id}"],
    updateWebhookConfigForRepo: [
      "PATCH /repos/{owner}/{repo}/hooks/{hook_id}/config"
    ],
    uploadReleaseAsset: [
      "POST /repos/{owner}/{repo}/releases/{release_id}/assets{?name,label}",
      { baseUrl: "https://uploads.github.com" }
    ]
  },
  search: {
    code: ["GET /search/code"],
    commits: ["GET /search/commits"],
    issuesAndPullRequests: ["GET /search/issues"],
    labels: ["GET /search/labels"],
    repos: ["GET /search/repositories"],
    topics: ["GET /search/topics"],
    users: ["GET /search/users"]
  },
  secretScanning: {
    getAlert: [
      "GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}"
    ],
    listAlertsForEnterprise: [
      "GET /enterprises/{enterprise}/secret-scanning/alerts"
    ],
    listAlertsForOrg: ["GET /orgs/{org}/secret-scanning/alerts"],
    listAlertsForRepo: ["GET /repos/{owner}/{repo}/secret-scanning/alerts"],
    listLocationsForAlert: [
      "GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations"
    ],
    updateAlert: [
      "PATCH /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}"
    ]
  },
  securityAdvisories: {
    createFork: [
      "POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/forks"
    ],
    createPrivateVulnerabilityReport: [
      "POST /repos/{owner}/{repo}/security-advisories/reports"
    ],
    createRepositoryAdvisory: [
      "POST /repos/{owner}/{repo}/security-advisories"
    ],
    createRepositoryAdvisoryCveRequest: [
      "POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/cve"
    ],
    getGlobalAdvisory: ["GET /advisories/{ghsa_id}"],
    getRepositoryAdvisory: [
      "GET /repos/{owner}/{repo}/security-advisories/{ghsa_id}"
    ],
    listGlobalAdvisories: ["GET /advisories"],
    listOrgRepositoryAdvisories: ["GET /orgs/{org}/security-advisories"],
    listRepositoryAdvisories: ["GET /repos/{owner}/{repo}/security-advisories"],
    updateRepositoryAdvisory: [
      "PATCH /repos/{owner}/{repo}/security-advisories/{ghsa_id}"
    ]
  },
  teams: {
    addOrUpdateMembershipForUserInOrg: [
      "PUT /orgs/{org}/teams/{team_slug}/memberships/{username}"
    ],
    addOrUpdateProjectPermissionsInOrg: [
      "PUT /orgs/{org}/teams/{team_slug}/projects/{project_id}"
    ],
    addOrUpdateRepoPermissionsInOrg: [
      "PUT /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}"
    ],
    checkPermissionsForProjectInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/projects/{project_id}"
    ],
    checkPermissionsForRepoInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}"
    ],
    create: ["POST /orgs/{org}/teams"],
    createDiscussionCommentInOrg: [
      "POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments"
    ],
    createDiscussionInOrg: ["POST /orgs/{org}/teams/{team_slug}/discussions"],
    deleteDiscussionCommentInOrg: [
      "DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}"
    ],
    deleteDiscussionInOrg: [
      "DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}"
    ],
    deleteInOrg: ["DELETE /orgs/{org}/teams/{team_slug}"],
    getByName: ["GET /orgs/{org}/teams/{team_slug}"],
    getDiscussionCommentInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}"
    ],
    getDiscussionInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}"
    ],
    getMembershipForUserInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/memberships/{username}"
    ],
    list: ["GET /orgs/{org}/teams"],
    listChildInOrg: ["GET /orgs/{org}/teams/{team_slug}/teams"],
    listDiscussionCommentsInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments"
    ],
    listDiscussionsInOrg: ["GET /orgs/{org}/teams/{team_slug}/discussions"],
    listForAuthenticatedUser: ["GET /user/teams"],
    listMembersInOrg: ["GET /orgs/{org}/teams/{team_slug}/members"],
    listPendingInvitationsInOrg: [
      "GET /orgs/{org}/teams/{team_slug}/invitations"
    ],
    listProjectsInOrg: ["GET /orgs/{org}/teams/{team_slug}/projects"],
    listReposInOrg: ["GET /orgs/{org}/teams/{team_slug}/repos"],
    removeMembershipForUserInOrg: [
      "DELETE /orgs/{org}/teams/{team_slug}/memberships/{username}"
    ],
    removeProjectInOrg: [
      "DELETE /orgs/{org}/teams/{team_slug}/projects/{project_id}"
    ],
    removeRepoInOrg: [
      "DELETE /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}"
    ],
    updateDiscussionCommentInOrg: [
      "PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}"
    ],
    updateDiscussionInOrg: [
      "PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}"
    ],
    updateInOrg: ["PATCH /orgs/{org}/teams/{team_slug}"]
  },
  users: {
    addEmailForAuthenticated: [
      "POST /user/emails",
      {},
      { renamed: ["users", "addEmailForAuthenticatedUser"] }
    ],
    addEmailForAuthenticatedUser: ["POST /user/emails"],
    addSocialAccountForAuthenticatedUser: ["POST /user/social_accounts"],
    block: ["PUT /user/blocks/{username}"],
    checkBlocked: ["GET /user/blocks/{username}"],
    checkFollowingForUser: ["GET /users/{username}/following/{target_user}"],
    checkPersonIsFollowedByAuthenticated: ["GET /user/following/{username}"],
    createGpgKeyForAuthenticated: [
      "POST /user/gpg_keys",
      {},
      { renamed: ["users", "createGpgKeyForAuthenticatedUser"] }
    ],
    createGpgKeyForAuthenticatedUser: ["POST /user/gpg_keys"],
    createPublicSshKeyForAuthenticated: [
      "POST /user/keys",
      {},
      { renamed: ["users", "createPublicSshKeyForAuthenticatedUser"] }
    ],
    createPublicSshKeyForAuthenticatedUser: ["POST /user/keys"],
    createSshSigningKeyForAuthenticatedUser: ["POST /user/ssh_signing_keys"],
    deleteEmailForAuthenticated: [
      "DELETE /user/emails",
      {},
      { renamed: ["users", "deleteEmailForAuthenticatedUser"] }
    ],
    deleteEmailForAuthenticatedUser: ["DELETE /user/emails"],
    deleteGpgKeyForAuthenticated: [
      "DELETE /user/gpg_keys/{gpg_key_id}",
      {},
      { renamed: ["users", "deleteGpgKeyForAuthenticatedUser"] }
    ],
    deleteGpgKeyForAuthenticatedUser: ["DELETE /user/gpg_keys/{gpg_key_id}"],
    deletePublicSshKeyForAuthenticated: [
      "DELETE /user/keys/{key_id}",
      {},
      { renamed: ["users", "deletePublicSshKeyForAuthenticatedUser"] }
    ],
    deletePublicSshKeyForAuthenticatedUser: ["DELETE /user/keys/{key_id}"],
    deleteSocialAccountForAuthenticatedUser: ["DELETE /user/social_accounts"],
    deleteSshSigningKeyForAuthenticatedUser: [
      "DELETE /user/ssh_signing_keys/{ssh_signing_key_id}"
    ],
    follow: ["PUT /user/following/{username}"],
    getAuthenticated: ["GET /user"],
    getByUsername: ["GET /users/{username}"],
    getContextForUser: ["GET /users/{username}/hovercard"],
    getGpgKeyForAuthenticated: [
      "GET /user/gpg_keys/{gpg_key_id}",
      {},
      { renamed: ["users", "getGpgKeyForAuthenticatedUser"] }
    ],
    getGpgKeyForAuthenticatedUser: ["GET /user/gpg_keys/{gpg_key_id}"],
    getPublicSshKeyForAuthenticated: [
      "GET /user/keys/{key_id}",
      {},
      { renamed: ["users", "getPublicSshKeyForAuthenticatedUser"] }
    ],
    getPublicSshKeyForAuthenticatedUser: ["GET /user/keys/{key_id}"],
    getSshSigningKeyForAuthenticatedUser: [
      "GET /user/ssh_signing_keys/{ssh_signing_key_id}"
    ],
    list: ["GET /users"],
    listBlockedByAuthenticated: [
      "GET /user/blocks",
      {},
      { renamed: ["users", "listBlockedByAuthenticatedUser"] }
    ],
    listBlockedByAuthenticatedUser: ["GET /user/blocks"],
    listEmailsForAuthenticated: [
      "GET /user/emails",
      {},
      { renamed: ["users", "listEmailsForAuthenticatedUser"] }
    ],
    listEmailsForAuthenticatedUser: ["GET /user/emails"],
    listFollowedByAuthenticated: [
      "GET /user/following",
      {},
      { renamed: ["users", "listFollowedByAuthenticatedUser"] }
    ],
    listFollowedByAuthenticatedUser: ["GET /user/following"],
    listFollowersForAuthenticatedUser: ["GET /user/followers"],
    listFollowersForUser: ["GET /users/{username}/followers"],
    listFollowingForUser: ["GET /users/{username}/following"],
    listGpgKeysForAuthenticated: [
      "GET /user/gpg_keys",
      {},
      { renamed: ["users", "listGpgKeysForAuthenticatedUser"] }
    ],
    listGpgKeysForAuthenticatedUser: ["GET /user/gpg_keys"],
    listGpgKeysForUser: ["GET /users/{username}/gpg_keys"],
    listPublicEmailsForAuthenticated: [
      "GET /user/public_emails",
      {},
      { renamed: ["users", "listPublicEmailsForAuthenticatedUser"] }
    ],
    listPublicEmailsForAuthenticatedUser: ["GET /user/public_emails"],
    listPublicKeysForUser: ["GET /users/{username}/keys"],
    listPublicSshKeysForAuthenticated: [
      "GET /user/keys",
      {},
      { renamed: ["users", "listPublicSshKeysForAuthenticatedUser"] }
    ],
    listPublicSshKeysForAuthenticatedUser: ["GET /user/keys"],
    listSocialAccountsForAuthenticatedUser: ["GET /user/social_accounts"],
    listSocialAccountsForUser: ["GET /users/{username}/social_accounts"],
    listSshSigningKeysForAuthenticatedUser: ["GET /user/ssh_signing_keys"],
    listSshSigningKeysForUser: ["GET /users/{username}/ssh_signing_keys"],
    setPrimaryEmailVisibilityForAuthenticated: [
      "PATCH /user/email/visibility",
      {},
      { renamed: ["users", "setPrimaryEmailVisibilityForAuthenticatedUser"] }
    ],
    setPrimaryEmailVisibilityForAuthenticatedUser: [
      "PATCH /user/email/visibility"
    ],
    unblock: ["DELETE /user/blocks/{username}"],
    unfollow: ["DELETE /user/following/{username}"],
    updateAuthenticated: ["PATCH /user"]
  }
};
var endpoints_default = Endpoints;

// pkg/dist-src/endpoints-to-methods.js
var endpointMethodsMap = /* @__PURE__ */ new Map();
for (const [scope, endpoints] of Object.entries(endpoints_default)) {
  for (const [methodName, endpoint] of Object.entries(endpoints)) {
    const [route, defaults, decorations] = endpoint;
    const [method, url] = route.split(/ /);
    const endpointDefaults = Object.assign(
      {
        method,
        url
      },
      defaults
    );
    if (!endpointMethodsMap.has(scope)) {
      endpointMethodsMap.set(scope, /* @__PURE__ */ new Map());
    }
    endpointMethodsMap.get(scope).set(methodName, {
      scope,
      methodName,
      endpointDefaults,
      decorations
    });
  }
}
var handler = {
  has({ scope }, methodName) {
    return endpointMethodsMap.get(scope).has(methodName);
  },
  getOwnPropertyDescriptor(target, methodName) {
    return {
      value: this.get(target, methodName),
      // ensures method is in the cache
      configurable: true,
      writable: true,
      enumerable: true
    };
  },
  defineProperty(target, methodName, descriptor) {
    Object.defineProperty(target.cache, methodName, descriptor);
    return true;
  },
  deleteProperty(target, methodName) {
    delete target.cache[methodName];
    return true;
  },
  ownKeys({ scope }) {
    return [...endpointMethodsMap.get(scope).keys()];
  },
  set(target, methodName, value) {
    return target.cache[methodName] = value;
  },
  get({ octokit, scope, cache }, methodName) {
    if (cache[methodName]) {
      return cache[methodName];
    }
    const method = endpointMethodsMap.get(scope).get(methodName);
    if (!method) {
      return void 0;
    }
    const { endpointDefaults, decorations } = method;
    if (decorations) {
      cache[methodName] = decorate(
        octokit,
        scope,
        methodName,
        endpointDefaults,
        decorations
      );
    } else {
      cache[methodName] = octokit.request.defaults(endpointDefaults);
    }
    return cache[methodName];
  }
};
function endpointsToMethods(octokit) {
  const newMethods = {};
  for (const scope of endpointMethodsMap.keys()) {
    newMethods[scope] = new Proxy({ octokit, scope, cache: {} }, handler);
  }
  return newMethods;
}
function decorate(octokit, scope, methodName, defaults, decorations) {
  const requestWithDefaults = octokit.request.defaults(defaults);
  function withDecorations(...args) {
    let options = requestWithDefaults.endpoint.merge(...args);
    if (decorations.mapToData) {
      options = Object.assign({}, options, {
        data: options[decorations.mapToData],
        [decorations.mapToData]: void 0
      });
      return requestWithDefaults(options);
    }
    if (decorations.renamed) {
      const [newScope, newMethodName] = decorations.renamed;
      octokit.log.warn(
        `octokit.${scope}.${methodName}() has been renamed to octokit.${newScope}.${newMethodName}()`
      );
    }
    if (decorations.deprecated) {
      octokit.log.warn(decorations.deprecated);
    }
    if (decorations.renamedParameters) {
      const options2 = requestWithDefaults.endpoint.merge(...args);
      for (const [name, alias] of Object.entries(
        decorations.renamedParameters
      )) {
        if (name in options2) {
          octokit.log.warn(
            `"${name}" parameter is deprecated for "octokit.${scope}.${methodName}()". Use "${alias}" instead`
          );
          if (!(alias in options2)) {
            options2[alias] = options2[name];
          }
          delete options2[name];
        }
      }
      return requestWithDefaults(options2);
    }
    return requestWithDefaults(...args);
  }
  return Object.assign(withDecorations, requestWithDefaults);
}

// pkg/dist-src/index.js
function restEndpointMethods(octokit) {
  const api = endpointsToMethods(octokit);
  return {
    rest: api
  };
}
restEndpointMethods.VERSION = VERSION;
function legacyRestEndpointMethods(octokit) {
  const api = endpointsToMethods(octokit);
  return {
    ...api,
    rest: api
  };
}
legacyRestEndpointMethods.VERSION = VERSION;
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 3708:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";

var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var dist_src_exports = {};
__export(dist_src_exports, {
  RequestError: () => RequestError
});
module.exports = __toCommonJS(dist_src_exports);
var import_deprecation = __nccwpck_require__(4150);
var import_once = __toESM(__nccwpck_require__(5560));
var logOnceCode = (0, import_once.default)((deprecation) => console.warn(deprecation));
var logOnceHeaders = (0, import_once.default)((deprecation) => console.warn(deprecation));
var RequestError = class extends Error {
  constructor(message, statusCode, options) {
    super(message);
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }
    this.name = "HttpError";
    this.status = statusCode;
    let headers;
    if ("headers" in options && typeof options.headers !== "undefined") {
      headers = options.headers;
    }
    if ("response" in options) {
      this.response = options.response;
      headers = options.response.headers;
    }
    const requestCopy = Object.assign({}, options.request);
    if (options.request.headers.authorization) {
      requestCopy.headers = Object.assign({}, options.request.headers, {
        authorization: options.request.headers.authorization.replace(
          /(?<! ) .*$/,
          " [REDACTED]"
        )
      });
    }
    requestCopy.url = requestCopy.url.replace(/\bclient_secret=\w+/g, "client_secret=[REDACTED]").replace(/\baccess_token=\w+/g, "access_token=[REDACTED]");
    this.request = requestCopy;
    Object.defineProperty(this, "code", {
      get() {
        logOnceCode(
          new import_deprecation.Deprecation(
            "[@octokit/request-error] `error.code` is deprecated, use `error.status`."
          )
        );
        return statusCode;
      }
    });
    Object.defineProperty(this, "headers", {
      get() {
        logOnceHeaders(
          new import_deprecation.Deprecation(
            "[@octokit/request-error] `error.headers` is deprecated, use `error.response.headers`."
          )
        );
        return headers || {};
      }
    });
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 8636:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// pkg/dist-src/index.js
var dist_src_exports = {};
__export(dist_src_exports, {
  request: () => request
});
module.exports = __toCommonJS(dist_src_exports);
var import_endpoint = __nccwpck_require__(4471);
var import_universal_user_agent = __nccwpck_require__(3843);

// pkg/dist-src/version.js
var VERSION = "8.4.1";

// pkg/dist-src/is-plain-object.js
function isPlainObject(value) {
  if (typeof value !== "object" || value === null)
    return false;
  if (Object.prototype.toString.call(value) !== "[object Object]")
    return false;
  const proto = Object.getPrototypeOf(value);
  if (proto === null)
    return true;
  const Ctor = Object.prototype.hasOwnProperty.call(proto, "constructor") && proto.constructor;
  return typeof Ctor === "function" && Ctor instanceof Ctor && Function.prototype.call(Ctor) === Function.prototype.call(value);
}

// pkg/dist-src/fetch-wrapper.js
var import_request_error = __nccwpck_require__(3708);

// pkg/dist-src/get-buffer-response.js
function getBufferResponse(response) {
  return response.arrayBuffer();
}

// pkg/dist-src/fetch-wrapper.js
function fetchWrapper(requestOptions) {
  var _a, _b, _c, _d;
  const log = requestOptions.request && requestOptions.request.log ? requestOptions.request.log : console;
  const parseSuccessResponseBody = ((_a = requestOptions.request) == null ? void 0 : _a.parseSuccessResponseBody) !== false;
  if (isPlainObject(requestOptions.body) || Array.isArray(requestOptions.body)) {
    requestOptions.body = JSON.stringify(requestOptions.body);
  }
  let headers = {};
  let status;
  let url;
  let { fetch } = globalThis;
  if ((_b = requestOptions.request) == null ? void 0 : _b.fetch) {
    fetch = requestOptions.request.fetch;
  }
  if (!fetch) {
    throw new Error(
      "fetch is not set. Please pass a fetch implementation as new Octokit({ request: { fetch }}). Learn more at https://github.com/octokit/octokit.js/#fetch-missing"
    );
  }
  return fetch(requestOptions.url, {
    method: requestOptions.method,
    body: requestOptions.body,
    redirect: (_c = requestOptions.request) == null ? void 0 : _c.redirect,
    headers: requestOptions.headers,
    signal: (_d = requestOptions.request) == null ? void 0 : _d.signal,
    // duplex must be set if request.body is ReadableStream or Async Iterables.
    // See https://fetch.spec.whatwg.org/#dom-requestinit-duplex.
    ...requestOptions.body && { duplex: "half" }
  }).then(async (response) => {
    url = response.url;
    status = response.status;
    for (const keyAndValue of response.headers) {
      headers[keyAndValue[0]] = keyAndValue[1];
    }
    if ("deprecation" in headers) {
      const matches = headers.link && headers.link.match(/<([^<>]+)>; rel="deprecation"/);
      const deprecationLink = matches && matches.pop();
      log.warn(
        `[@octokit/request] "${requestOptions.method} ${requestOptions.url}" is deprecated. It is scheduled to be removed on ${headers.sunset}${deprecationLink ? `. See ${deprecationLink}` : ""}`
      );
    }
    if (status === 204 || status === 205) {
      return;
    }
    if (requestOptions.method === "HEAD") {
      if (status < 400) {
        return;
      }
      throw new import_request_error.RequestError(response.statusText, status, {
        response: {
          url,
          status,
          headers,
          data: void 0
        },
        request: requestOptions
      });
    }
    if (status === 304) {
      throw new import_request_error.RequestError("Not modified", status, {
        response: {
          url,
          status,
          headers,
          data: await getResponseData(response)
        },
        request: requestOptions
      });
    }
    if (status >= 400) {
      const data = await getResponseData(response);
      const error = new import_request_error.RequestError(toErrorMessage(data), status, {
        response: {
          url,
          status,
          headers,
          data
        },
        request: requestOptions
      });
      throw error;
    }
    return parseSuccessResponseBody ? await getResponseData(response) : response.body;
  }).then((data) => {
    return {
      status,
      url,
      headers,
      data
    };
  }).catch((error) => {
    if (error instanceof import_request_error.RequestError)
      throw error;
    else if (error.name === "AbortError")
      throw error;
    let message = error.message;
    if (error.name === "TypeError" && "cause" in error) {
      if (error.cause instanceof Error) {
        message = error.cause.message;
      } else if (typeof error.cause === "string") {
        message = error.cause;
      }
    }
    throw new import_request_error.RequestError(message, 500, {
      request: requestOptions
    });
  });
}
async function getResponseData(response) {
  const contentType = response.headers.get("content-type");
  if (/application\/json/.test(contentType)) {
    return response.json().catch(() => response.text()).catch(() => "");
  }
  if (!contentType || /^text\/|charset=utf-8$/.test(contentType)) {
    return response.text();
  }
  return getBufferResponse(response);
}
function toErrorMessage(data) {
  if (typeof data === "string")
    return data;
  let suffix;
  if ("documentation_url" in data) {
    suffix = ` - ${data.documentation_url}`;
  } else {
    suffix = "";
  }
  if ("message" in data) {
    if (Array.isArray(data.errors)) {
      return `${data.message}: ${data.errors.map(JSON.stringify).join(", ")}${suffix}`;
    }
    return `${data.message}${suffix}`;
  }
  return `Unknown error: ${JSON.stringify(data)}`;
}

// pkg/dist-src/with-defaults.js
function withDefaults(oldEndpoint, newDefaults) {
  const endpoint2 = oldEndpoint.defaults(newDefaults);
  const newApi = function(route, parameters) {
    const endpointOptions = endpoint2.merge(route, parameters);
    if (!endpointOptions.request || !endpointOptions.request.hook) {
      return fetchWrapper(endpoint2.parse(endpointOptions));
    }
    const request2 = (route2, parameters2) => {
      return fetchWrapper(
        endpoint2.parse(endpoint2.merge(route2, parameters2))
      );
    };
    Object.assign(request2, {
      endpoint: endpoint2,
      defaults: withDefaults.bind(null, endpoint2)
    });
    return endpointOptions.request.hook(request2, endpointOptions);
  };
  return Object.assign(newApi, {
    endpoint: endpoint2,
    defaults: withDefaults.bind(null, endpoint2)
  });
}

// pkg/dist-src/index.js
var request = withDefaults(import_endpoint.endpoint, {
  headers: {
    "user-agent": `octokit-request.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`
  }
});
// Annotate the CommonJS export names for ESM import in node:
0 && (0);


/***/ }),

/***/ 2732:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

var register = __nccwpck_require__(1063);
var addHook = __nccwpck_require__(2027);
var removeHook = __nccwpck_require__(9934);

// bind with array of arguments: https://stackoverflow.com/a/21792913
var bind = Function.bind;
var bindable = bind.bind(bind);

function bindApi(hook, state, name) {
  var removeHookRef = bindable(removeHook, null).apply(
    null,
    name ? [state, name] : [state]
  );
  hook.api = { remove: removeHookRef };
  hook.remove = removeHookRef;
  ["before", "error", "after", "wrap"].forEach(function (kind) {
    var args = name ? [state, kind, name] : [state, kind];
    hook[kind] = hook.api[kind] = bindable(addHook, null).apply(null, args);
  });
}

function HookSingular() {
  var singularHookName = "h";
  var singularHookState = {
    registry: {},
  };
  var singularHook = register.bind(null, singularHookState, singularHookName);
  bindApi(singularHook, singularHookState, singularHookName);
  return singularHook;
}

function HookCollection() {
  var state = {
    registry: {},
  };

  var hook = register.bind(null, state);
  bindApi(hook, state);

  return hook;
}

var collectionHookDeprecationMessageDisplayed = false;
function Hook() {
  if (!collectionHookDeprecationMessageDisplayed) {
    console.warn(
      '[before-after-hook]: "Hook()" repurposing warning, use "Hook.Collection()". Read more: https://git.io/upgrade-before-after-hook-to-1.4'
    );
    collectionHookDeprecationMessageDisplayed = true;
  }
  return HookCollection();
}

Hook.Singular = HookSingular.bind();
Hook.Collection = HookCollection.bind();

module.exports = Hook;
// expose constructors as a named property for TypeScript
module.exports.Hook = Hook;
module.exports.Singular = Hook.Singular;
module.exports.Collection = Hook.Collection;


/***/ }),

/***/ 2027:
/***/ ((module) => {

module.exports = addHook;

function addHook(state, kind, name, hook) {
  var orig = hook;
  if (!state.registry[name]) {
    state.registry[name] = [];
  }

  if (kind === "before") {
    hook = function (method, options) {
      return Promise.resolve()
        .then(orig.bind(null, options))
        .then(method.bind(null, options));
    };
  }

  if (kind === "after") {
    hook = function (method, options) {
      var result;
      return Promise.resolve()
        .then(method.bind(null, options))
        .then(function (result_) {
          result = result_;
          return orig(result, options);
        })
        .then(function () {
          return result;
        });
    };
  }

  if (kind === "error") {
    hook = function (method, options) {
      return Promise.resolve()
        .then(method.bind(null, options))
        .catch(function (error) {
          return orig(error, options);
        });
    };
  }

  state.registry[name].push({
    hook: hook,
    orig: orig,
  });
}


/***/ }),

/***/ 1063:
/***/ ((module) => {

module.exports = register;

function register(state, name, method, options) {
  if (typeof method !== "function") {
    throw new Error("method for before hook must be a function");
  }

  if (!options) {
    options = {};
  }

  if (Array.isArray(name)) {
    return name.reverse().reduce(function (callback, name) {
      return register.bind(null, state, name, callback, options);
    }, method)();
  }

  return Promise.resolve().then(function () {
    if (!state.registry[name]) {
      return method(options);
    }

    return state.registry[name].reduce(function (method, registered) {
      return registered.hook.bind(null, method, options);
    }, method)();
  });
}


/***/ }),

/***/ 9934:
/***/ ((module) => {

module.exports = removeHook;

function removeHook(state, name, method) {
  if (!state.registry[name]) {
    return;
  }

  var index = state.registry[name]
    .map(function (registered) {
      return registered.orig;
    })
    .indexOf(method);

  if (index === -1) {
    return;
  }

  state.registry[name].splice(index, 1);
}


/***/ }),

/***/ 4150:
/***/ ((__unused_webpack_module, exports) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({ value: true }));

class Deprecation extends Error {
  constructor(message) {
    super(message); // Maintains proper stack trace (only available on V8)

    /* istanbul ignore next */

    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }

    this.name = 'Deprecation';
  }

}

exports.Deprecation = Deprecation;


/***/ }),

/***/ 5560:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

var wrappy = __nccwpck_require__(8264)
module.exports = wrappy(once)
module.exports.strict = wrappy(onceStrict)

once.proto = once(function () {
  Object.defineProperty(Function.prototype, 'once', {
    value: function () {
      return once(this)
    },
    configurable: true
  })

  Object.defineProperty(Function.prototype, 'onceStrict', {
    value: function () {
      return onceStrict(this)
    },
    configurable: true
  })
})

function once (fn) {
  var f = function () {
    if (f.called) return f.value
    f.called = true
    return f.value = fn.apply(this, arguments)
  }
  f.called = false
  return f
}

function onceStrict (fn) {
  var f = function () {
    if (f.called)
      throw new Error(f.onceError)
    f.called = true
    return f.value = fn.apply(this, arguments)
  }
  var name = fn.name || 'Function wrapped with `once`'
  f.onceError = name + " shouldn't be called more than once"
  f.called = false
  return f
}


/***/ }),

/***/ 770:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

module.exports = __nccwpck_require__(218);


/***/ }),

/***/ 218:
/***/ ((__unused_webpack_module, exports, __nccwpck_require__) => {

"use strict";


var net = __nccwpck_require__(9278);
var tls = __nccwpck_require__(4756);
var http = __nccwpck_require__(8611);
var https = __nccwpck_require__(5692);
var events = __nccwpck_require__(4434);
var assert = __nccwpck_require__(2613);
var util = __nccwpck_require__(9023);


exports.httpOverHttp = httpOverHttp;
exports.httpsOverHttp = httpsOverHttp;
exports.httpOverHttps = httpOverHttps;
exports.httpsOverHttps = httpsOverHttps;


function httpOverHttp(options) {
  var agent = new TunnelingAgent(options);
  agent.request = http.request;
  return agent;
}

function httpsOverHttp(options) {
  var agent = new TunnelingAgent(options);
  agent.request = http.request;
  agent.createSocket = createSecureSocket;
  agent.defaultPort = 443;
  return agent;
}

function httpOverHttps(options) {
  var agent = new TunnelingAgent(options);
  agent.request = https.request;
  return agent;
}

function httpsOverHttps(options) {
  var agent = new TunnelingAgent(options);
  agent.request = https.request;
  agent.createSocket = createSecureSocket;
  agent.defaultPort = 443;
  return agent;
}


function TunnelingAgent(options) {
  var self = this;
  self.options = options || {};
  self.proxyOptions = self.options.proxy || {};
  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;
  self.requests = [];
  self.sockets = [];

  self.on('free', function onFree(socket, host, port, localAddress) {
    var options = toOptions(host, port, localAddress);
    for (var i = 0, len = self.requests.length; i < len; ++i) {
      var pending = self.requests[i];
      if (pending.host === options.host && pending.port === options.port) {
        // Detect the request to connect same origin server,
        // reuse the connection.
        self.requests.splice(i, 1);
        pending.request.onSocket(socket);
        return;
      }
    }
    socket.destroy();
    self.removeSocket(socket);
  });
}
util.inherits(TunnelingAgent, events.EventEmitter);

TunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {
  var self = this;
  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));

  if (self.sockets.length >= this.maxSockets) {
    // We are over limit so we'll add it to the queue.
    self.requests.push(options);
    return;
  }

  // If we are under maxSockets create a new one.
  self.createSocket(options, function(socket) {
    socket.on('free', onFree);
    socket.on('close', onCloseOrRemove);
    socket.on('agentRemove', onCloseOrRemove);
    req.onSocket(socket);

    function onFree() {
      self.emit('free', socket, options);
    }

    function onCloseOrRemove(err) {
      self.removeSocket(socket);
      socket.removeListener('free', onFree);
      socket.removeListener('close', onCloseOrRemove);
      socket.removeListener('agentRemove', onCloseOrRemove);
    }
  });
};

TunnelingAgent.prototype.createSocket = function createSocket(options, cb) {
  var self = this;
  var placeholder = {};
  self.sockets.push(placeholder);

  var connectOptions = mergeOptions({}, self.proxyOptions, {
    method: 'CONNECT',
    path: options.host + ':' + options.port,
    agent: false,
    headers: {
      host: options.host + ':' + options.port
    }
  });
  if (options.localAddress) {
    connectOptions.localAddress = options.localAddress;
  }
  if (connectOptions.proxyAuth) {
    connectOptions.headers = connectOptions.headers || {};
    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +
        new Buffer(connectOptions.proxyAuth).toString('base64');
  }

  debug('making CONNECT request');
  var connectReq = self.request(connectOptions);
  connectReq.useChunkedEncodingByDefault = false; // for v0.6
  connectReq.once('response', onResponse); // for v0.6
  connectReq.once('upgrade', onUpgrade);   // for v0.6
  connectReq.once('connect', onConnect);   // for v0.7 or later
  connectReq.once('error', onError);
  connectReq.end();

  function onResponse(res) {
    // Very hacky. This is necessary to avoid http-parser leaks.
    res.upgrade = true;
  }

  function onUpgrade(res, socket, head) {
    // Hacky.
    process.nextTick(function() {
      onConnect(res, socket, head);
    });
  }

  function onConnect(res, socket, head) {
    connectReq.removeAllListeners();
    socket.removeAllListeners();

    if (res.statusCode !== 200) {
      debug('tunneling socket could not be established, statusCode=%d',
        res.statusCode);
      socket.destroy();
      var error = new Error('tunneling socket could not be established, ' +
        'statusCode=' + res.statusCode);
      error.code = 'ECONNRESET';
      options.request.emit('error', error);
      self.removeSocket(placeholder);
      return;
    }
    if (head.length > 0) {
      debug('got illegal response body from proxy');
      socket.destroy();
      var error = new Error('got illegal response body from proxy');
      error.code = 'ECONNRESET';
      options.request.emit('error', error);
      self.removeSocket(placeholder);
      return;
    }
    debug('tunneling connection has established');
    self.sockets[self.sockets.indexOf(placeholder)] = socket;
    return cb(socket);
  }

  function onError(cause) {
    connectReq.removeAllListeners();

    debug('tunneling socket could not be established, cause=%s\n',
          cause.message, cause.stack);
    var error = new Error('tunneling socket could not be established, ' +
                          'cause=' + cause.message);
    error.code = 'ECONNRESET';
    options.request.emit('error', error);
    self.removeSocket(placeholder);
  }
};

TunnelingAgent.prototype.removeSocket = function removeSocket(socket) {
  var pos = this.sockets.indexOf(socket)
  if (pos === -1) {
    return;
  }
  this.sockets.splice(pos, 1);

  var pending = this.requests.shift();
  if (pending) {
    // If we have pending requests and a socket gets closed a new one
    // needs to be created to take over in the pool for the one that closed.
    this.createSocket(pending, function(socket) {
      pending.request.onSocket(socket);
    });
  }
};

function createSecureSocket(options, cb) {
  var self = this;
  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {
    var hostHeader = options.request.getHeader('host');
    var tlsOptions = mergeOptions({}, self.options, {
      socket: socket,
      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host
    });

    // 0 is dummy port for v0.6
    var secureSocket = tls.connect(0, tlsOptions);
    self.sockets[self.sockets.indexOf(socket)] = secureSocket;
    cb(secureSocket);
  });
}


function toOptions(host, port, localAddress) {
  if (typeof host === 'string') { // since v0.10
    return {
      host: host,
      port: port,
      localAddress: localAddress
    };
  }
  return host; // for v0.11 or later
}

function mergeOptions(target) {
  for (var i = 1, len = arguments.length; i < len; ++i) {
    var overrides = arguments[i];
    if (typeof overrides === 'object') {
      var keys = Object.keys(overrides);
      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {
        var k = keys[j];
        if (overrides[k] !== undefined) {
          target[k] = overrides[k];
        }
      }
    }
  }
  return target;
}


var debug;
if (process.env.NODE_DEBUG && /\btunnel\b/.test(process.env.NODE_DEBUG)) {
  debug = function() {
    var args = Array.prototype.slice.call(arguments);
    if (typeof args[0] === 'string') {
      args[0] = 'TUNNEL: ' + args[0];
    } else {
      args.unshift('TUNNEL:');
    }
    console.error.apply(console, args);
  }
} else {
  debug = function() {};
}
exports.debug = debug; // for test


/***/ }),

/***/ 6752:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const Client = __nccwpck_require__(6197)
const Dispatcher = __nccwpck_require__(992)
const errors = __nccwpck_require__(8707)
const Pool = __nccwpck_require__(5076)
const BalancedPool = __nccwpck_require__(1093)
const Agent = __nccwpck_require__(9965)
const util = __nccwpck_require__(3440)
const { InvalidArgumentError } = errors
const api = __nccwpck_require__(6615)
const buildConnector = __nccwpck_require__(9136)
const MockClient = __nccwpck_require__(7365)
const MockAgent = __nccwpck_require__(7501)
const MockPool = __nccwpck_require__(4004)
const mockErrors = __nccwpck_require__(2429)
const ProxyAgent = __nccwpck_require__(2720)
const RetryHandler = __nccwpck_require__(3573)
const { getGlobalDispatcher, setGlobalDispatcher } = __nccwpck_require__(2581)
const DecoratorHandler = __nccwpck_require__(8840)
const RedirectHandler = __nccwpck_require__(8299)
const createRedirectInterceptor = __nccwpck_require__(4415)

let hasCrypto
try {
  __nccwpck_require__(6982)
  hasCrypto = true
} catch {
  hasCrypto = false
}

Object.assign(Dispatcher.prototype, api)

module.exports.Dispatcher = Dispatcher
module.exports.Client = Client
module.exports.Pool = Pool
module.exports.BalancedPool = BalancedPool
module.exports.Agent = Agent
module.exports.ProxyAgent = ProxyAgent
module.exports.RetryHandler = RetryHandler

module.exports.DecoratorHandler = DecoratorHandler
module.exports.RedirectHandler = RedirectHandler
module.exports.createRedirectInterceptor = createRedirectInterceptor

module.exports.buildConnector = buildConnector
module.exports.errors = errors

function makeDispatcher (fn) {
  return (url, opts, handler) => {
    if (typeof opts === 'function') {
      handler = opts
      opts = null
    }

    if (!url || (typeof url !== 'string' && typeof url !== 'object' && !(url instanceof URL))) {
      throw new InvalidArgumentError('invalid url')
    }

    if (opts != null && typeof opts !== 'object') {
      throw new InvalidArgumentError('invalid opts')
    }

    if (opts && opts.path != null) {
      if (typeof opts.path !== 'string') {
        throw new InvalidArgumentError('invalid opts.path')
      }

      let path = opts.path
      if (!opts.path.startsWith('/')) {
        path = `/${path}`
      }

      url = new URL(util.parseOrigin(url).origin + path)
    } else {
      if (!opts) {
        opts = typeof url === 'object' ? url : {}
      }

      url = util.parseURL(url)
    }

    const { agent, dispatcher = getGlobalDispatcher() } = opts

    if (agent) {
      throw new InvalidArgumentError('unsupported opts.agent. Did you mean opts.client?')
    }

    return fn.call(dispatcher, {
      ...opts,
      origin: url.origin,
      path: url.search ? `${url.pathname}${url.search}` : url.pathname,
      method: opts.method || (opts.body ? 'PUT' : 'GET')
    }, handler)
  }
}

module.exports.setGlobalDispatcher = setGlobalDispatcher
module.exports.getGlobalDispatcher = getGlobalDispatcher

if (util.nodeMajor > 16 || (util.nodeMajor === 16 && util.nodeMinor >= 8)) {
  let fetchImpl = null
  module.exports.fetch = async function fetch (resource) {
    if (!fetchImpl) {
      fetchImpl = (__nccwpck_require__(2315).fetch)
    }

    try {
      return await fetchImpl(...arguments)
    } catch (err) {
      if (typeof err === 'object') {
        Error.captureStackTrace(err, this)
      }

      throw err
    }
  }
  module.exports.Headers = __nccwpck_require__(6349).Headers
  module.exports.Response = __nccwpck_require__(8676).Response
  module.exports.Request = __nccwpck_require__(5194).Request
  module.exports.FormData = __nccwpck_require__(3073).FormData
  module.exports.File = __nccwpck_require__(3041).File
  module.exports.FileReader = __nccwpck_require__(2160).FileReader

  const { setGlobalOrigin, getGlobalOrigin } = __nccwpck_require__(5628)

  module.exports.setGlobalOrigin = setGlobalOrigin
  module.exports.getGlobalOrigin = getGlobalOrigin

  const { CacheStorage } = __nccwpck_require__(4738)
  const { kConstruct } = __nccwpck_require__(296)

  // Cache & CacheStorage are tightly coupled with fetch. Even if it may run
  // in an older version of Node, it doesn't have any use without fetch.
  module.exports.caches = new CacheStorage(kConstruct)
}

if (util.nodeMajor >= 16) {
  const { deleteCookie, getCookies, getSetCookies, setCookie } = __nccwpck_require__(3168)

  module.exports.deleteCookie = deleteCookie
  module.exports.getCookies = getCookies
  module.exports.getSetCookies = getSetCookies
  module.exports.setCookie = setCookie

  const { parseMIMEType, serializeAMimeType } = __nccwpck_require__(4322)

  module.exports.parseMIMEType = parseMIMEType
  module.exports.serializeAMimeType = serializeAMimeType
}

if (util.nodeMajor >= 18 && hasCrypto) {
  const { WebSocket } = __nccwpck_require__(5171)

  module.exports.WebSocket = WebSocket
}

module.exports.request = makeDispatcher(api.request)
module.exports.stream = makeDispatcher(api.stream)
module.exports.pipeline = makeDispatcher(api.pipeline)
module.exports.connect = makeDispatcher(api.connect)
module.exports.upgrade = makeDispatcher(api.upgrade)

module.exports.MockClient = MockClient
module.exports.MockPool = MockPool
module.exports.MockAgent = MockAgent
module.exports.mockErrors = mockErrors


/***/ }),

/***/ 9965:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { InvalidArgumentError } = __nccwpck_require__(8707)
const { kClients, kRunning, kClose, kDestroy, kDispatch, kInterceptors } = __nccwpck_require__(6443)
const DispatcherBase = __nccwpck_require__(1)
const Pool = __nccwpck_require__(5076)
const Client = __nccwpck_require__(6197)
const util = __nccwpck_require__(3440)
const createRedirectInterceptor = __nccwpck_require__(4415)
const { WeakRef, FinalizationRegistry } = __nccwpck_require__(3194)()

const kOnConnect = Symbol('onConnect')
const kOnDisconnect = Symbol('onDisconnect')
const kOnConnectionError = Symbol('onConnectionError')
const kMaxRedirections = Symbol('maxRedirections')
const kOnDrain = Symbol('onDrain')
const kFactory = Symbol('factory')
const kFinalizer = Symbol('finalizer')
const kOptions = Symbol('options')

function defaultFactory (origin, opts) {
  return opts && opts.connections === 1
    ? new Client(origin, opts)
    : new Pool(origin, opts)
}

class Agent extends DispatcherBase {
  constructor ({ factory = defaultFactory, maxRedirections = 0, connect, ...options } = {}) {
    super()

    if (typeof factory !== 'function') {
      throw new InvalidArgumentError('factory must be a function.')
    }

    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {
      throw new InvalidArgumentError('connect must be a function or an object')
    }

    if (!Number.isInteger(maxRedirections) || maxRedirections < 0) {
      throw new InvalidArgumentError('maxRedirections must be a positive number')
    }

    if (connect && typeof connect !== 'function') {
      connect = { ...connect }
    }

    this[kInterceptors] = options.interceptors && options.interceptors.Agent && Array.isArray(options.interceptors.Agent)
      ? options.interceptors.Agent
      : [createRedirectInterceptor({ maxRedirections })]

    this[kOptions] = { ...util.deepClone(options), connect }
    this[kOptions].interceptors = options.interceptors
      ? { ...options.interceptors }
      : undefined
    this[kMaxRedirections] = maxRedirections
    this[kFactory] = factory
    this[kClients] = new Map()
    this[kFinalizer] = new FinalizationRegistry(/* istanbul ignore next: gc is undeterministic */ key => {
      const ref = this[kClients].get(key)
      if (ref !== undefined && ref.deref() === undefined) {
        this[kClients].delete(key)
      }
    })

    const agent = this

    this[kOnDrain] = (origin, targets) => {
      agent.emit('drain', origin, [agent, ...targets])
    }

    this[kOnConnect] = (origin, targets) => {
      agent.emit('connect', origin, [agent, ...targets])
    }

    this[kOnDisconnect] = (origin, targets, err) => {
      agent.emit('disconnect', origin, [agent, ...targets], err)
    }

    this[kOnConnectionError] = (origin, targets, err) => {
      agent.emit('connectionError', origin, [agent, ...targets], err)
    }
  }

  get [kRunning] () {
    let ret = 0
    for (const ref of this[kClients].values()) {
      const client = ref.deref()
      /* istanbul ignore next: gc is undeterministic */
      if (client) {
        ret += client[kRunning]
      }
    }
    return ret
  }

  [kDispatch] (opts, handler) {
    let key
    if (opts.origin && (typeof opts.origin === 'string' || opts.origin instanceof URL)) {
      key = String(opts.origin)
    } else {
      throw new InvalidArgumentError('opts.origin must be a non-empty string or URL.')
    }

    const ref = this[kClients].get(key)

    let dispatcher = ref ? ref.deref() : null
    if (!dispatcher) {
      dispatcher = this[kFactory](opts.origin, this[kOptions])
        .on('drain', this[kOnDrain])
        .on('connect', this[kOnConnect])
        .on('disconnect', this[kOnDisconnect])
        .on('connectionError', this[kOnConnectionError])

      this[kClients].set(key, new WeakRef(dispatcher))
      this[kFinalizer].register(dispatcher, key)
    }

    return dispatcher.dispatch(opts, handler)
  }

  async [kClose] () {
    const closePromises = []
    for (const ref of this[kClients].values()) {
      const client = ref.deref()
      /* istanbul ignore else: gc is undeterministic */
      if (client) {
        closePromises.push(client.close())
      }
    }

    await Promise.all(closePromises)
  }

  async [kDestroy] (err) {
    const destroyPromises = []
    for (const ref of this[kClients].values()) {
      const client = ref.deref()
      /* istanbul ignore else: gc is undeterministic */
      if (client) {
        destroyPromises.push(client.destroy(err))
      }
    }

    await Promise.all(destroyPromises)
  }
}

module.exports = Agent


/***/ }),

/***/ 158:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

const { addAbortListener } = __nccwpck_require__(3440)
const { RequestAbortedError } = __nccwpck_require__(8707)

const kListener = Symbol('kListener')
const kSignal = Symbol('kSignal')

function abort (self) {
  if (self.abort) {
    self.abort()
  } else {
    self.onError(new RequestAbortedError())
  }
}

function addSignal (self, signal) {
  self[kSignal] = null
  self[kListener] = null

  if (!signal) {
    return
  }

  if (signal.aborted) {
    abort(self)
    return
  }

  self[kSignal] = signal
  self[kListener] = () => {
    abort(self)
  }

  addAbortListener(self[kSignal], self[kListener])
}

function removeSignal (self) {
  if (!self[kSignal]) {
    return
  }

  if ('removeEventListener' in self[kSignal]) {
    self[kSignal].removeEventListener('abort', self[kListener])
  } else {
    self[kSignal].removeListener('abort', self[kListener])
  }

  self[kSignal] = null
  self[kListener] = null
}

module.exports = {
  addSignal,
  removeSignal
}


/***/ }),

/***/ 4660:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { AsyncResource } = __nccwpck_require__(290)
const { InvalidArgumentError, RequestAbortedError, SocketError } = __nccwpck_require__(8707)
const util = __nccwpck_require__(3440)
const { addSignal, removeSignal } = __nccwpck_require__(158)

class ConnectHandler extends AsyncResource {
  constructor (opts, callback) {
    if (!opts || typeof opts !== 'object') {
      throw new InvalidArgumentError('invalid opts')
    }

    if (typeof callback !== 'function') {
      throw new InvalidArgumentError('invalid callback')
    }

    const { signal, opaque, responseHeaders } = opts

    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
    }

    super('UNDICI_CONNECT')

    this.opaque = opaque || null
    this.responseHeaders = responseHeaders || null
    this.callback = callback
    this.abort = null

    addSignal(this, signal)
  }

  onConnect (abort, context) {
    if (!this.callback) {
      throw new RequestAbortedError()
    }

    this.abort = abort
    this.context = context
  }

  onHeaders () {
    throw new SocketError('bad connect', null)
  }

  onUpgrade (statusCode, rawHeaders, socket) {
    const { callback, opaque, context } = this

    removeSignal(this)

    this.callback = null

    let headers = rawHeaders
    // Indicates is an HTTP2Session
    if (headers != null) {
      headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)
    }

    this.runInAsyncScope(callback, null, null, {
      statusCode,
      headers,
      socket,
      opaque,
      context
    })
  }

  onError (err) {
    const { callback, opaque } = this

    removeSignal(this)

    if (callback) {
      this.callback = null
      queueMicrotask(() => {
        this.runInAsyncScope(callback, null, err, { opaque })
      })
    }
  }
}

function connect (opts, callback) {
  if (callback === undefined) {
    return new Promise((resolve, reject) => {
      connect.call(this, opts, (err, data) => {
        return err ? reject(err) : resolve(data)
      })
    })
  }

  try {
    const connectHandler = new ConnectHandler(opts, callback)
    this.dispatch({ ...opts, method: 'CONNECT' }, connectHandler)
  } catch (err) {
    if (typeof callback !== 'function') {
      throw err
    }
    const opaque = opts && opts.opaque
    queueMicrotask(() => callback(err, { opaque }))
  }
}

module.exports = connect


/***/ }),

/***/ 6862:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const {
  Readable,
  Duplex,
  PassThrough
} = __nccwpck_require__(2203)
const {
  InvalidArgumentError,
  InvalidReturnValueError,
  RequestAbortedError
} = __nccwpck_require__(8707)
const util = __nccwpck_require__(3440)
const { AsyncResource } = __nccwpck_require__(290)
const { addSignal, removeSignal } = __nccwpck_require__(158)
const assert = __nccwpck_require__(2613)

const kResume = Symbol('resume')

class PipelineRequest extends Readable {
  constructor () {
    super({ autoDestroy: true })

    this[kResume] = null
  }

  _read () {
    const { [kResume]: resume } = this

    if (resume) {
      this[kResume] = null
      resume()
    }
  }

  _destroy (err, callback) {
    this._read()

    callback(err)
  }
}

class PipelineResponse extends Readable {
  constructor (resume) {
    super({ autoDestroy: true })
    this[kResume] = resume
  }

  _read () {
    this[kResume]()
  }

  _destroy (err, callback) {
    if (!err && !this._readableState.endEmitted) {
      err = new RequestAbortedError()
    }

    callback(err)
  }
}

class PipelineHandler extends AsyncResource {
  constructor (opts, handler) {
    if (!opts || typeof opts !== 'object') {
      throw new InvalidArgumentError('invalid opts')
    }

    if (typeof handler !== 'function') {
      throw new InvalidArgumentError('invalid handler')
    }

    const { signal, method, opaque, onInfo, responseHeaders } = opts

    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
    }

    if (method === 'CONNECT') {
      throw new InvalidArgumentError('invalid method')
    }

    if (onInfo && typeof onInfo !== 'function') {
      throw new InvalidArgumentError('invalid onInfo callback')
    }

    super('UNDICI_PIPELINE')

    this.opaque = opaque || null
    this.responseHeaders = responseHeaders || null
    this.handler = handler
    this.abort = null
    this.context = null
    this.onInfo = onInfo || null

    this.req = new PipelineRequest().on('error', util.nop)

    this.ret = new Duplex({
      readableObjectMode: opts.objectMode,
      autoDestroy: true,
      read: () => {
        const { body } = this

        if (body && body.resume) {
          body.resume()
        }
      },
      write: (chunk, encoding, callback) => {
        const { req } = this

        if (req.push(chunk, encoding) || req._readableState.destroyed) {
          callback()
        } else {
          req[kResume] = callback
        }
      },
      destroy: (err, callback) => {
        const { body, req, res, ret, abort } = this

        if (!err && !ret._readableState.endEmitted) {
          err = new RequestAbortedError()
        }

        if (abort && err) {
          abort()
        }

        util.destroy(body, err)
        util.destroy(req, err)
        util.destroy(res, err)

        removeSignal(this)

        callback(err)
      }
    }).on('prefinish', () => {
      const { req } = this

      // Node < 15 does not call _final in same tick.
      req.push(null)
    })

    this.res = null

    addSignal(this, signal)
  }

  onConnect (abort, context) {
    const { ret, res } = this

    assert(!res, 'pipeline cannot be retried')

    if (ret.destroyed) {
      throw new RequestAbortedError()
    }

    this.abort = abort
    this.context = context
  }

  onHeaders (statusCode, rawHeaders, resume) {
    const { opaque, handler, context } = this

    if (statusCode < 200) {
      if (this.onInfo) {
        const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)
        this.onInfo({ statusCode, headers })
      }
      return
    }

    this.res = new PipelineResponse(resume)

    let body
    try {
      this.handler = null
      const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)
      body = this.runInAsyncScope(handler, null, {
        statusCode,
        headers,
        opaque,
        body: this.res,
        context
      })
    } catch (err) {
      this.res.on('error', util.nop)
      throw err
    }

    if (!body || typeof body.on !== 'function') {
      throw new InvalidReturnValueError('expected Readable')
    }

    body
      .on('data', (chunk) => {
        const { ret, body } = this

        if (!ret.push(chunk) && body.pause) {
          body.pause()
        }
      })
      .on('error', (err) => {
        const { ret } = this

        util.destroy(ret, err)
      })
      .on('end', () => {
        const { ret } = this

        ret.push(null)
      })
      .on('close', () => {
        const { ret } = this

        if (!ret._readableState.ended) {
          util.destroy(ret, new RequestAbortedError())
        }
      })

    this.body = body
  }

  onData (chunk) {
    const { res } = this
    return res.push(chunk)
  }

  onComplete (trailers) {
    const { res } = this
    res.push(null)
  }

  onError (err) {
    const { ret } = this
    this.handler = null
    util.destroy(ret, err)
  }
}

function pipeline (opts, handler) {
  try {
    const pipelineHandler = new PipelineHandler(opts, handler)
    this.dispatch({ ...opts, body: pipelineHandler.req }, pipelineHandler)
    return pipelineHandler.ret
  } catch (err) {
    return new PassThrough().destroy(err)
  }
}

module.exports = pipeline


/***/ }),

/***/ 4043:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const Readable = __nccwpck_require__(9927)
const {
  InvalidArgumentError,
  RequestAbortedError
} = __nccwpck_require__(8707)
const util = __nccwpck_require__(3440)
const { getResolveErrorBodyCallback } = __nccwpck_require__(7655)
const { AsyncResource } = __nccwpck_require__(290)
const { addSignal, removeSignal } = __nccwpck_require__(158)

class RequestHandler extends AsyncResource {
  constructor (opts, callback) {
    if (!opts || typeof opts !== 'object') {
      throw new InvalidArgumentError('invalid opts')
    }

    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError, highWaterMark } = opts

    try {
      if (typeof callback !== 'function') {
        throw new InvalidArgumentError('invalid callback')
      }

      if (highWaterMark && (typeof highWaterMark !== 'number' || highWaterMark < 0)) {
        throw new InvalidArgumentError('invalid highWaterMark')
      }

      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
      }

      if (method === 'CONNECT') {
        throw new InvalidArgumentError('invalid method')
      }

      if (onInfo && typeof onInfo !== 'function') {
        throw new InvalidArgumentError('invalid onInfo callback')
      }

      super('UNDICI_REQUEST')
    } catch (err) {
      if (util.isStream(body)) {
        util.destroy(body.on('error', util.nop), err)
      }
      throw err
    }

    this.responseHeaders = responseHeaders || null
    this.opaque = opaque || null
    this.callback = callback
    this.res = null
    this.abort = null
    this.body = body
    this.trailers = {}
    this.context = null
    this.onInfo = onInfo || null
    this.throwOnError = throwOnError
    this.highWaterMark = highWaterMark

    if (util.isStream(body)) {
      body.on('error', (err) => {
        this.onError(err)
      })
    }

    addSignal(this, signal)
  }

  onConnect (abort, context) {
    if (!this.callback) {
      throw new RequestAbortedError()
    }

    this.abort = abort
    this.context = context
  }

  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
    const { callback, opaque, abort, context, responseHeaders, highWaterMark } = this

    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)

    if (statusCode < 200) {
      if (this.onInfo) {
        this.onInfo({ statusCode, headers })
      }
      return
    }

    const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers
    const contentType = parsedHeaders['content-type']
    const body = new Readable({ resume, abort, contentType, highWaterMark })

    this.callback = null
    this.res = body
    if (callback !== null) {
      if (this.throwOnError && statusCode >= 400) {
        this.runInAsyncScope(getResolveErrorBodyCallback, null,
          { callback, body, contentType, statusCode, statusMessage, headers }
        )
      } else {
        this.runInAsyncScope(callback, null, null, {
          statusCode,
          headers,
          trailers: this.trailers,
          opaque,
          body,
          context
        })
      }
    }
  }

  onData (chunk) {
    const { res } = this
    return res.push(chunk)
  }

  onComplete (trailers) {
    const { res } = this

    removeSignal(this)

    util.parseHeaders(trailers, this.trailers)

    res.push(null)
  }

  onError (err) {
    const { res, callback, body, opaque } = this

    removeSignal(this)

    if (callback) {
      // TODO: Does this need queueMicrotask?
      this.callback = null
      queueMicrotask(() => {
        this.runInAsyncScope(callback, null, err, { opaque })
      })
    }

    if (res) {
      this.res = null
      // Ensure all queued handlers are invoked before destroying res.
      queueMicrotask(() => {
        util.destroy(res, err)
      })
    }

    if (body) {
      this.body = null
      util.destroy(body, err)
    }
  }
}

function request (opts, callback) {
  if (callback === undefined) {
    return new Promise((resolve, reject) => {
      request.call(this, opts, (err, data) => {
        return err ? reject(err) : resolve(data)
      })
    })
  }

  try {
    this.dispatch(opts, new RequestHandler(opts, callback))
  } catch (err) {
    if (typeof callback !== 'function') {
      throw err
    }
    const opaque = opts && opts.opaque
    queueMicrotask(() => callback(err, { opaque }))
  }
}

module.exports = request
module.exports.RequestHandler = RequestHandler


/***/ }),

/***/ 3560:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { finished, PassThrough } = __nccwpck_require__(2203)
const {
  InvalidArgumentError,
  InvalidReturnValueError,
  RequestAbortedError
} = __nccwpck_require__(8707)
const util = __nccwpck_require__(3440)
const { getResolveErrorBodyCallback } = __nccwpck_require__(7655)
const { AsyncResource } = __nccwpck_require__(290)
const { addSignal, removeSignal } = __nccwpck_require__(158)

class StreamHandler extends AsyncResource {
  constructor (opts, factory, callback) {
    if (!opts || typeof opts !== 'object') {
      throw new InvalidArgumentError('invalid opts')
    }

    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError } = opts

    try {
      if (typeof callback !== 'function') {
        throw new InvalidArgumentError('invalid callback')
      }

      if (typeof factory !== 'function') {
        throw new InvalidArgumentError('invalid factory')
      }

      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
      }

      if (method === 'CONNECT') {
        throw new InvalidArgumentError('invalid method')
      }

      if (onInfo && typeof onInfo !== 'function') {
        throw new InvalidArgumentError('invalid onInfo callback')
      }

      super('UNDICI_STREAM')
    } catch (err) {
      if (util.isStream(body)) {
        util.destroy(body.on('error', util.nop), err)
      }
      throw err
    }

    this.responseHeaders = responseHeaders || null
    this.opaque = opaque || null
    this.factory = factory
    this.callback = callback
    this.res = null
    this.abort = null
    this.context = null
    this.trailers = null
    this.body = body
    this.onInfo = onInfo || null
    this.throwOnError = throwOnError || false

    if (util.isStream(body)) {
      body.on('error', (err) => {
        this.onError(err)
      })
    }

    addSignal(this, signal)
  }

  onConnect (abort, context) {
    if (!this.callback) {
      throw new RequestAbortedError()
    }

    this.abort = abort
    this.context = context
  }

  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
    const { factory, opaque, context, callback, responseHeaders } = this

    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)

    if (statusCode < 200) {
      if (this.onInfo) {
        this.onInfo({ statusCode, headers })
      }
      return
    }

    this.factory = null

    let res

    if (this.throwOnError && statusCode >= 400) {
      const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers
      const contentType = parsedHeaders['content-type']
      res = new PassThrough()

      this.callback = null
      this.runInAsyncScope(getResolveErrorBodyCallback, null,
        { callback, body: res, contentType, statusCode, statusMessage, headers }
      )
    } else {
      if (factory === null) {
        return
      }

      res = this.runInAsyncScope(factory, null, {
        statusCode,
        headers,
        opaque,
        context
      })

      if (
        !res ||
        typeof res.write !== 'function' ||
        typeof res.end !== 'function' ||
        typeof res.on !== 'function'
      ) {
        throw new InvalidReturnValueError('expected Writable')
      }

      // TODO: Avoid finished. It registers an unnecessary amount of listeners.
      finished(res, { readable: false }, (err) => {
        const { callback, res, opaque, trailers, abort } = this

        this.res = null
        if (err || !res.readable) {
          util.destroy(res, err)
        }

        this.callback = null
        this.runInAsyncScope(callback, null, err || null, { opaque, trailers })

        if (err) {
          abort()
        }
      })
    }

    res.on('drain', resume)

    this.res = res

    const needDrain = res.writableNeedDrain !== undefined
      ? res.writableNeedDrain
      : res._writableState && res._writableState.needDrain

    return needDrain !== true
  }

  onData (chunk) {
    const { res } = this

    return res ? res.write(chunk) : true
  }

  onComplete (trailers) {
    const { res } = this

    removeSignal(this)

    if (!res) {
      return
    }

    this.trailers = util.parseHeaders(trailers)

    res.end()
  }

  onError (err) {
    const { res, callback, opaque, body } = this

    removeSignal(this)

    this.factory = null

    if (res) {
      this.res = null
      util.destroy(res, err)
    } else if (callback) {
      this.callback = null
      queueMicrotask(() => {
        this.runInAsyncScope(callback, null, err, { opaque })
      })
    }

    if (body) {
      this.body = null
      util.destroy(body, err)
    }
  }
}

function stream (opts, factory, callback) {
  if (callback === undefined) {
    return new Promise((resolve, reject) => {
      stream.call(this, opts, factory, (err, data) => {
        return err ? reject(err) : resolve(data)
      })
    })
  }

  try {
    this.dispatch(opts, new StreamHandler(opts, factory, callback))
  } catch (err) {
    if (typeof callback !== 'function') {
      throw err
    }
    const opaque = opts && opts.opaque
    queueMicrotask(() => callback(err, { opaque }))
  }
}

module.exports = stream


/***/ }),

/***/ 1882:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { InvalidArgumentError, RequestAbortedError, SocketError } = __nccwpck_require__(8707)
const { AsyncResource } = __nccwpck_require__(290)
const util = __nccwpck_require__(3440)
const { addSignal, removeSignal } = __nccwpck_require__(158)
const assert = __nccwpck_require__(2613)

class UpgradeHandler extends AsyncResource {
  constructor (opts, callback) {
    if (!opts || typeof opts !== 'object') {
      throw new InvalidArgumentError('invalid opts')
    }

    if (typeof callback !== 'function') {
      throw new InvalidArgumentError('invalid callback')
    }

    const { signal, opaque, responseHeaders } = opts

    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
    }

    super('UNDICI_UPGRADE')

    this.responseHeaders = responseHeaders || null
    this.opaque = opaque || null
    this.callback = callback
    this.abort = null
    this.context = null

    addSignal(this, signal)
  }

  onConnect (abort, context) {
    if (!this.callback) {
      throw new RequestAbortedError()
    }

    this.abort = abort
    this.context = null
  }

  onHeaders () {
    throw new SocketError('bad upgrade', null)
  }

  onUpgrade (statusCode, rawHeaders, socket) {
    const { callback, opaque, context } = this

    assert.strictEqual(statusCode, 101)

    removeSignal(this)

    this.callback = null
    const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)
    this.runInAsyncScope(callback, null, null, {
      headers,
      socket,
      opaque,
      context
    })
  }

  onError (err) {
    const { callback, opaque } = this

    removeSignal(this)

    if (callback) {
      this.callback = null
      queueMicrotask(() => {
        this.runInAsyncScope(callback, null, err, { opaque })
      })
    }
  }
}

function upgrade (opts, callback) {
  if (callback === undefined) {
    return new Promise((resolve, reject) => {
      upgrade.call(this, opts, (err, data) => {
        return err ? reject(err) : resolve(data)
      })
    })
  }

  try {
    const upgradeHandler = new UpgradeHandler(opts, callback)
    this.dispatch({
      ...opts,
      method: opts.method || 'GET',
      upgrade: opts.protocol || 'Websocket'
    }, upgradeHandler)
  } catch (err) {
    if (typeof callback !== 'function') {
      throw err
    }
    const opaque = opts && opts.opaque
    queueMicrotask(() => callback(err, { opaque }))
  }
}

module.exports = upgrade


/***/ }),

/***/ 6615:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


module.exports.request = __nccwpck_require__(4043)
module.exports.stream = __nccwpck_require__(3560)
module.exports.pipeline = __nccwpck_require__(6862)
module.exports.upgrade = __nccwpck_require__(1882)
module.exports.connect = __nccwpck_require__(4660)


/***/ }),

/***/ 9927:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";
// Ported from https://github.com/nodejs/undici/pull/907



const assert = __nccwpck_require__(2613)
const { Readable } = __nccwpck_require__(2203)
const { RequestAbortedError, NotSupportedError, InvalidArgumentError } = __nccwpck_require__(8707)
const util = __nccwpck_require__(3440)
const { ReadableStreamFrom, toUSVString } = __nccwpck_require__(3440)

let Blob

const kConsume = Symbol('kConsume')
const kReading = Symbol('kReading')
const kBody = Symbol('kBody')
const kAbort = Symbol('abort')
const kContentType = Symbol('kContentType')

const noop = () => {}

module.exports = class BodyReadable extends Readable {
  constructor ({
    resume,
    abort,
    contentType = '',
    highWaterMark = 64 * 1024 // Same as nodejs fs streams.
  }) {
    super({
      autoDestroy: true,
      read: resume,
      highWaterMark
    })

    this._readableState.dataEmitted = false

    this[kAbort] = abort
    this[kConsume] = null
    this[kBody] = null
    this[kContentType] = contentType

    // Is stream being consumed through Readable API?
    // This is an optimization so that we avoid checking
    // for 'data' and 'readable' listeners in the hot path
    // inside push().
    this[kReading] = false
  }

  destroy (err) {
    if (this.destroyed) {
      // Node < 16
      return this
    }

    if (!err && !this._readableState.endEmitted) {
      err = new RequestAbortedError()
    }

    if (err) {
      this[kAbort]()
    }

    return super.destroy(err)
  }

  emit (ev, ...args) {
    if (ev === 'data') {
      // Node < 16.7
      this._readableState.dataEmitted = true
    } else if (ev === 'error') {
      // Node < 16
      this._readableState.errorEmitted = true
    }
    return super.emit(ev, ...args)
  }

  on (ev, ...args) {
    if (ev === 'data' || ev === 'readable') {
      this[kReading] = true
    }
    return super.on(ev, ...args)
  }

  addListener (ev, ...args) {
    return this.on(ev, ...args)
  }

  off (ev, ...args) {
    const ret = super.off(ev, ...args)
    if (ev === 'data' || ev === 'readable') {
      this[kReading] = (
        this.listenerCount('data') > 0 ||
        this.listenerCount('readable') > 0
      )
    }
    return ret
  }

  removeListener (ev, ...args) {
    return this.off(ev, ...args)
  }

  push (chunk) {
    if (this[kConsume] && chunk !== null && this.readableLength === 0) {
      consumePush(this[kConsume], chunk)
      return this[kReading] ? super.push(chunk) : true
    }
    return super.push(chunk)
  }

  // https://fetch.spec.whatwg.org/#dom-body-text
  async text () {
    return consume(this, 'text')
  }

  // https://fetch.spec.whatwg.org/#dom-body-json
  async json () {
    return consume(this, 'json')
  }

  // https://fetch.spec.whatwg.org/#dom-body-blob
  async blob () {
    return consume(this, 'blob')
  }

  // https://fetch.spec.whatwg.org/#dom-body-arraybuffer
  async arrayBuffer () {
    return consume(this, 'arrayBuffer')
  }

  // https://fetch.spec.whatwg.org/#dom-body-formdata
  async formData () {
    // TODO: Implement.
    throw new NotSupportedError()
  }

  // https://fetch.spec.whatwg.org/#dom-body-bodyused
  get bodyUsed () {
    return util.isDisturbed(this)
  }

  // https://fetch.spec.whatwg.org/#dom-body-body
  get body () {
    if (!this[kBody]) {
      this[kBody] = ReadableStreamFrom(this)
      if (this[kConsume]) {
        // TODO: Is this the best way to force a lock?
        this[kBody].getReader() // Ensure stream is locked.
        assert(this[kBody].locked)
      }
    }
    return this[kBody]
  }

  dump (opts) {
    let limit = opts && Number.isFinite(opts.limit) ? opts.limit : 262144
    const signal = opts && opts.signal

    if (signal) {
      try {
        if (typeof signal !== 'object' || !('aborted' in signal)) {
          throw new InvalidArgumentError('signal must be an AbortSignal')
        }
        util.throwIfAborted(signal)
      } catch (err) {
        return Promise.reject(err)
      }
    }

    if (this.closed) {
      return Promise.resolve(null)
    }

    return new Promise((resolve, reject) => {
      const signalListenerCleanup = signal
        ? util.addAbortListener(signal, () => {
          this.destroy()
        })
        : noop

      this
        .on('close', function () {
          signalListenerCleanup()
          if (signal && signal.aborted) {
            reject(signal.reason || Object.assign(new Error('The operation was aborted'), { name: 'AbortError' }))
          } else {
            resolve(null)
          }
        })
        .on('error', noop)
        .on('data', function (chunk) {
          limit -= chunk.length
          if (limit <= 0) {
            this.destroy()
          }
        })
        .resume()
    })
  }
}

// https://streams.spec.whatwg.org/#readablestream-locked
function isLocked (self) {
  // Consume is an implicit lock.
  return (self[kBody] && self[kBody].locked === true) || self[kConsume]
}

// https://fetch.spec.whatwg.org/#body-unusable
function isUnusable (self) {
  return util.isDisturbed(self) || isLocked(self)
}

async function consume (stream, type) {
  if (isUnusable(stream)) {
    throw new TypeError('unusable')
  }

  assert(!stream[kConsume])

  return new Promise((resolve, reject) => {
    stream[kConsume] = {
      type,
      stream,
      resolve,
      reject,
      length: 0,
      body: []
    }

    stream
      .on('error', function (err) {
        consumeFinish(this[kConsume], err)
      })
      .on('close', function () {
        if (this[kConsume].body !== null) {
          consumeFinish(this[kConsume], new RequestAbortedError())
        }
      })

    process.nextTick(consumeStart, stream[kConsume])
  })
}

function consumeStart (consume) {
  if (consume.body === null) {
    return
  }

  const { _readableState: state } = consume.stream

  for (const chunk of state.buffer) {
    consumePush(consume, chunk)
  }

  if (state.endEmitted) {
    consumeEnd(this[kConsume])
  } else {
    consume.stream.on('end', function () {
      consumeEnd(this[kConsume])
    })
  }

  consume.stream.resume()

  while (consume.stream.read() != null) {
    // Loop
  }
}

function consumeEnd (consume) {
  const { type, body, resolve, stream, length } = consume

  try {
    if (type === 'text') {
      resolve(toUSVString(Buffer.concat(body)))
    } else if (type === 'json') {
      resolve(JSON.parse(Buffer.concat(body)))
    } else if (type === 'arrayBuffer') {
      const dst = new Uint8Array(length)

      let pos = 0
      for (const buf of body) {
        dst.set(buf, pos)
        pos += buf.byteLength
      }

      resolve(dst.buffer)
    } else if (type === 'blob') {
      if (!Blob) {
        Blob = (__nccwpck_require__(181).Blob)
      }
      resolve(new Blob(body, { type: stream[kContentType] }))
    }

    consumeFinish(consume)
  } catch (err) {
    stream.destroy(err)
  }
}

function consumePush (consume, chunk) {
  consume.length += chunk.length
  consume.body.push(chunk)
}

function consumeFinish (consume, err) {
  if (consume.body === null) {
    return
  }

  if (err) {
    consume.reject(err)
  } else {
    consume.resolve()
  }

  consume.type = null
  consume.stream = null
  consume.resolve = null
  consume.reject = null
  consume.length = 0
  consume.body = null
}


/***/ }),

/***/ 7655:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

const assert = __nccwpck_require__(2613)
const {
  ResponseStatusCodeError
} = __nccwpck_require__(8707)
const { toUSVString } = __nccwpck_require__(3440)

async function getResolveErrorBodyCallback ({ callback, body, contentType, statusCode, statusMessage, headers }) {
  assert(body)

  let chunks = []
  let limit = 0

  for await (const chunk of body) {
    chunks.push(chunk)
    limit += chunk.length
    if (limit > 128 * 1024) {
      chunks = null
      break
    }
  }

  if (statusCode === 204 || !contentType || !chunks) {
    process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers))
    return
  }

  try {
    if (contentType.startsWith('application/json')) {
      const payload = JSON.parse(toUSVString(Buffer.concat(chunks)))
      process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers, payload))
      return
    }

    if (contentType.startsWith('text/')) {
      const payload = toUSVString(Buffer.concat(chunks))
      process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers, payload))
      return
    }
  } catch (err) {
    // Process in a fallback if error
  }

  process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers))
}

module.exports = { getResolveErrorBodyCallback }


/***/ }),

/***/ 1093:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const {
  BalancedPoolMissingUpstreamError,
  InvalidArgumentError
} = __nccwpck_require__(8707)
const {
  PoolBase,
  kClients,
  kNeedDrain,
  kAddClient,
  kRemoveClient,
  kGetDispatcher
} = __nccwpck_require__(8640)
const Pool = __nccwpck_require__(5076)
const { kUrl, kInterceptors } = __nccwpck_require__(6443)
const { parseOrigin } = __nccwpck_require__(3440)
const kFactory = Symbol('factory')

const kOptions = Symbol('options')
const kGreatestCommonDivisor = Symbol('kGreatestCommonDivisor')
const kCurrentWeight = Symbol('kCurrentWeight')
const kIndex = Symbol('kIndex')
const kWeight = Symbol('kWeight')
const kMaxWeightPerServer = Symbol('kMaxWeightPerServer')
const kErrorPenalty = Symbol('kErrorPenalty')

function getGreatestCommonDivisor (a, b) {
  if (b === 0) return a
  return getGreatestCommonDivisor(b, a % b)
}

function defaultFactory (origin, opts) {
  return new Pool(origin, opts)
}

class BalancedPool extends PoolBase {
  constructor (upstreams = [], { factory = defaultFactory, ...opts } = {}) {
    super()

    this[kOptions] = opts
    this[kIndex] = -1
    this[kCurrentWeight] = 0

    this[kMaxWeightPerServer] = this[kOptions].maxWeightPerServer || 100
    this[kErrorPenalty] = this[kOptions].errorPenalty || 15

    if (!Array.isArray(upstreams)) {
      upstreams = [upstreams]
    }

    if (typeof factory !== 'function') {
      throw new InvalidArgumentError('factory must be a function.')
    }

    this[kInterceptors] = opts.interceptors && opts.interceptors.BalancedPool && Array.isArray(opts.interceptors.BalancedPool)
      ? opts.interceptors.BalancedPool
      : []
    this[kFactory] = factory

    for (const upstream of upstreams) {
      this.addUpstream(upstream)
    }
    this._updateBalancedPoolStats()
  }

  addUpstream (upstream) {
    const upstreamOrigin = parseOrigin(upstream).origin

    if (this[kClients].find((pool) => (
      pool[kUrl].origin === upstreamOrigin &&
      pool.closed !== true &&
      pool.destroyed !== true
    ))) {
      return this
    }
    const pool = this[kFactory](upstreamOrigin, Object.assign({}, this[kOptions]))

    this[kAddClient](pool)
    pool.on('connect', () => {
      pool[kWeight] = Math.min(this[kMaxWeightPerServer], pool[kWeight] + this[kErrorPenalty])
    })

    pool.on('connectionError', () => {
      pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])
      this._updateBalancedPoolStats()
    })

    pool.on('disconnect', (...args) => {
      const err = args[2]
      if (err && err.code === 'UND_ERR_SOCKET') {
        // decrease the weight of the pool.
        pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])
        this._updateBalancedPoolStats()
      }
    })

    for (const client of this[kClients]) {
      client[kWeight] = this[kMaxWeightPerServer]
    }

    this._updateBalancedPoolStats()

    return this
  }

  _updateBalancedPoolStats () {
    this[kGreatestCommonDivisor] = this[kClients].map(p => p[kWeight]).reduce(getGreatestCommonDivisor, 0)
  }

  removeUpstream (upstream) {
    const upstreamOrigin = parseOrigin(upstream).origin

    const pool = this[kClients].find((pool) => (
      pool[kUrl].origin === upstreamOrigin &&
      pool.closed !== true &&
      pool.destroyed !== true
    ))

    if (pool) {
      this[kRemoveClient](pool)
    }

    return this
  }

  get upstreams () {
    return this[kClients]
      .filter(dispatcher => dispatcher.closed !== true && dispatcher.destroyed !== true)
      .map((p) => p[kUrl].origin)
  }

  [kGetDispatcher] () {
    // We validate that pools is greater than 0,
    // otherwise we would have to wait until an upstream
    // is added, which might never happen.
    if (this[kClients].length === 0) {
      throw new BalancedPoolMissingUpstreamError()
    }

    const dispatcher = this[kClients].find(dispatcher => (
      !dispatcher[kNeedDrain] &&
      dispatcher.closed !== true &&
      dispatcher.destroyed !== true
    ))

    if (!dispatcher) {
      return
    }

    const allClientsBusy = this[kClients].map(pool => pool[kNeedDrain]).reduce((a, b) => a && b, true)

    if (allClientsBusy) {
      return
    }

    let counter = 0

    let maxWeightIndex = this[kClients].findIndex(pool => !pool[kNeedDrain])

    while (counter++ < this[kClients].length) {
      this[kIndex] = (this[kIndex] + 1) % this[kClients].length
      const pool = this[kClients][this[kIndex]]

      // find pool index with the largest weight
      if (pool[kWeight] > this[kClients][maxWeightIndex][kWeight] && !pool[kNeedDrain]) {
        maxWeightIndex = this[kIndex]
      }

      // decrease the current weight every `this[kClients].length`.
      if (this[kIndex] === 0) {
        // Set the current weight to the next lower weight.
        this[kCurrentWeight] = this[kCurrentWeight] - this[kGreatestCommonDivisor]

        if (this[kCurrentWeight] <= 0) {
          this[kCurrentWeight] = this[kMaxWeightPerServer]
        }
      }
      if (pool[kWeight] >= this[kCurrentWeight] && (!pool[kNeedDrain])) {
        return pool
      }
    }

    this[kCurrentWeight] = this[kClients][maxWeightIndex][kWeight]
    this[kIndex] = maxWeightIndex
    return this[kClients][maxWeightIndex]
  }
}

module.exports = BalancedPool


/***/ }),

/***/ 479:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { kConstruct } = __nccwpck_require__(296)
const { urlEquals, fieldValues: getFieldValues } = __nccwpck_require__(3993)
const { kEnumerableProperty, isDisturbed } = __nccwpck_require__(3440)
const { kHeadersList } = __nccwpck_require__(6443)
const { webidl } = __nccwpck_require__(4222)
const { Response, cloneResponse } = __nccwpck_require__(8676)
const { Request } = __nccwpck_require__(5194)
const { kState, kHeaders, kGuard, kRealm } = __nccwpck_require__(9710)
const { fetching } = __nccwpck_require__(2315)
const { urlIsHttpHttpsScheme, createDeferredPromise, readAllBytes } = __nccwpck_require__(5523)
const assert = __nccwpck_require__(2613)
const { getGlobalDispatcher } = __nccwpck_require__(2581)

/**
 * @see https://w3c.github.io/ServiceWorker/#dfn-cache-batch-operation
 * @typedef {Object} CacheBatchOperation
 * @property {'delete' | 'put'} type
 * @property {any} request
 * @property {any} response
 * @property {import('../../types/cache').CacheQueryOptions} options
 */

/**
 * @see https://w3c.github.io/ServiceWorker/#dfn-request-response-list
 * @typedef {[any, any][]} requestResponseList
 */

class Cache {
  /**
   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-request-response-list
   * @type {requestResponseList}
   */
  #relevantRequestResponseList

  constructor () {
    if (arguments[0] !== kConstruct) {
      webidl.illegalConstructor()
    }

    this.#relevantRequestResponseList = arguments[1]
  }

  async match (request, options = {}) {
    webidl.brandCheck(this, Cache)
    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.match' })

    request = webidl.converters.RequestInfo(request)
    options = webidl.converters.CacheQueryOptions(options)

    const p = await this.matchAll(request, options)

    if (p.length === 0) {
      return
    }

    return p[0]
  }

  async matchAll (request = undefined, options = {}) {
    webidl.brandCheck(this, Cache)

    if (request !== undefined) request = webidl.converters.RequestInfo(request)
    options = webidl.converters.CacheQueryOptions(options)

    // 1.
    let r = null

    // 2.
    if (request !== undefined) {
      if (request instanceof Request) {
        // 2.1.1
        r = request[kState]

        // 2.1.2
        if (r.method !== 'GET' && !options.ignoreMethod) {
          return []
        }
      } else if (typeof request === 'string') {
        // 2.2.1
        r = new Request(request)[kState]
      }
    }

    // 5.
    // 5.1
    const responses = []

    // 5.2
    if (request === undefined) {
      // 5.2.1
      for (const requestResponse of this.#relevantRequestResponseList) {
        responses.push(requestResponse[1])
      }
    } else { // 5.3
      // 5.3.1
      const requestResponses = this.#queryCache(r, options)

      // 5.3.2
      for (const requestResponse of requestResponses) {
        responses.push(requestResponse[1])
      }
    }

    // 5.4
    // We don't implement CORs so we don't need to loop over the responses, yay!

    // 5.5.1
    const responseList = []

    // 5.5.2
    for (const response of responses) {
      // 5.5.2.1
      const responseObject = new Response(response.body?.source ?? null)
      const body = responseObject[kState].body
      responseObject[kState] = response
      responseObject[kState].body = body
      responseObject[kHeaders][kHeadersList] = response.headersList
      responseObject[kHeaders][kGuard] = 'immutable'

      responseList.push(responseObject)
    }

    // 6.
    return Object.freeze(responseList)
  }

  async add (request) {
    webidl.brandCheck(this, Cache)
    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.add' })

    request = webidl.converters.RequestInfo(request)

    // 1.
    const requests = [request]

    // 2.
    const responseArrayPromise = this.addAll(requests)

    // 3.
    return await responseArrayPromise
  }

  async addAll (requests) {
    webidl.brandCheck(this, Cache)
    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.addAll' })

    requests = webidl.converters['sequence<RequestInfo>'](requests)

    // 1.
    const responsePromises = []

    // 2.
    const requestList = []

    // 3.
    for (const request of requests) {
      if (typeof request === 'string') {
        continue
      }

      // 3.1
      const r = request[kState]

      // 3.2
      if (!urlIsHttpHttpsScheme(r.url) || r.method !== 'GET') {
        throw webidl.errors.exception({
          header: 'Cache.addAll',
          message: 'Expected http/s scheme when method is not GET.'
        })
      }
    }

    // 4.
    /** @type {ReturnType<typeof fetching>[]} */
    const fetchControllers = []

    // 5.
    for (const request of requests) {
      // 5.1
      const r = new Request(request)[kState]

      // 5.2
      if (!urlIsHttpHttpsScheme(r.url)) {
        throw webidl.errors.exception({
          header: 'Cache.addAll',
          message: 'Expected http/s scheme.'
        })
      }

      // 5.4
      r.initiator = 'fetch'
      r.destination = 'subresource'

      // 5.5
      requestList.push(r)

      // 5.6
      const responsePromise = createDeferredPromise()

      // 5.7
      fetchControllers.push(fetching({
        request: r,
        dispatcher: getGlobalDispatcher(),
        processResponse (response) {
          // 1.
          if (response.type === 'error' || response.status === 206 || response.status < 200 || response.status > 299) {
            responsePromise.reject(webidl.errors.exception({
              header: 'Cache.addAll',
              message: 'Received an invalid status code or the request failed.'
            }))
          } else if (response.headersList.contains('vary')) { // 2.
            // 2.1
            const fieldValues = getFieldValues(response.headersList.get('vary'))

            // 2.2
            for (const fieldValue of fieldValues) {
              // 2.2.1
              if (fieldValue === '*') {
                responsePromise.reject(webidl.errors.exception({
                  header: 'Cache.addAll',
                  message: 'invalid vary field value'
                }))

                for (const controller of fetchControllers) {
                  controller.abort()
                }

                return
              }
            }
          }
        },
        processResponseEndOfBody (response) {
          // 1.
          if (response.aborted) {
            responsePromise.reject(new DOMException('aborted', 'AbortError'))
            return
          }

          // 2.
          responsePromise.resolve(response)
        }
      }))

      // 5.8
      responsePromises.push(responsePromise.promise)
    }

    // 6.
    const p = Promise.all(responsePromises)

    // 7.
    const responses = await p

    // 7.1
    const operations = []

    // 7.2
    let index = 0

    // 7.3
    for (const response of responses) {
      // 7.3.1
      /** @type {CacheBatchOperation} */
      const operation = {
        type: 'put', // 7.3.2
        request: requestList[index], // 7.3.3
        response // 7.3.4
      }

      operations.push(operation) // 7.3.5

      index++ // 7.3.6
    }

    // 7.5
    const cacheJobPromise = createDeferredPromise()

    // 7.6.1
    let errorData = null

    // 7.6.2
    try {
      this.#batchCacheOperations(operations)
    } catch (e) {
      errorData = e
    }

    // 7.6.3
    queueMicrotask(() => {
      // 7.6.3.1
      if (errorData === null) {
        cacheJobPromise.resolve(undefined)
      } else {
        // 7.6.3.2
        cacheJobPromise.reject(errorData)
      }
    })

    // 7.7
    return cacheJobPromise.promise
  }

  async put (request, response) {
    webidl.brandCheck(this, Cache)
    webidl.argumentLengthCheck(arguments, 2, { header: 'Cache.put' })

    request = webidl.converters.RequestInfo(request)
    response = webidl.converters.Response(response)

    // 1.
    let innerRequest = null

    // 2.
    if (request instanceof Request) {
      innerRequest = request[kState]
    } else { // 3.
      innerRequest = new Request(request)[kState]
    }

    // 4.
    if (!urlIsHttpHttpsScheme(innerRequest.url) || innerRequest.method !== 'GET') {
      throw webidl.errors.exception({
        header: 'Cache.put',
        message: 'Expected an http/s scheme when method is not GET'
      })
    }

    // 5.
    const innerResponse = response[kState]

    // 6.
    if (innerResponse.status === 206) {
      throw webidl.errors.exception({
        header: 'Cache.put',
        message: 'Got 206 status'
      })
    }

    // 7.
    if (innerResponse.headersList.contains('vary')) {
      // 7.1.
      const fieldValues = getFieldValues(innerResponse.headersList.get('vary'))

      // 7.2.
      for (const fieldValue of fieldValues) {
        // 7.2.1
        if (fieldValue === '*') {
          throw webidl.errors.exception({
            header: 'Cache.put',
            message: 'Got * vary field value'
          })
        }
      }
    }

    // 8.
    if (innerResponse.body && (isDisturbed(innerResponse.body.stream) || innerResponse.body.stream.locked)) {
      throw webidl.errors.exception({
        header: 'Cache.put',
        message: 'Response body is locked or disturbed'
      })
    }

    // 9.
    const clonedResponse = cloneResponse(innerResponse)

    // 10.
    const bodyReadPromise = createDeferredPromise()

    // 11.
    if (innerResponse.body != null) {
      // 11.1
      const stream = innerResponse.body.stream

      // 11.2
      const reader = stream.getReader()

      // 11.3
      readAllBytes(reader).then(bodyReadPromise.resolve, bodyReadPromise.reject)
    } else {
      bodyReadPromise.resolve(undefined)
    }

    // 12.
    /** @type {CacheBatchOperation[]} */
    const operations = []

    // 13.
    /** @type {CacheBatchOperation} */
    const operation = {
      type: 'put', // 14.
      request: innerRequest, // 15.
      response: clonedResponse // 16.
    }

    // 17.
    operations.push(operation)

    // 19.
    const bytes = await bodyReadPromise.promise

    if (clonedResponse.body != null) {
      clonedResponse.body.source = bytes
    }

    // 19.1
    const cacheJobPromise = createDeferredPromise()

    // 19.2.1
    let errorData = null

    // 19.2.2
    try {
      this.#batchCacheOperations(operations)
    } catch (e) {
      errorData = e
    }

    // 19.2.3
    queueMicrotask(() => {
      // 19.2.3.1
      if (errorData === null) {
        cacheJobPromise.resolve()
      } else { // 19.2.3.2
        cacheJobPromise.reject(errorData)
      }
    })

    return cacheJobPromise.promise
  }

  async delete (request, options = {}) {
    webidl.brandCheck(this, Cache)
    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.delete' })

    request = webidl.converters.RequestInfo(request)
    options = webidl.converters.CacheQueryOptions(options)

    /**
     * @type {Request}
     */
    let r = null

    if (request instanceof Request) {
      r = request[kState]

      if (r.method !== 'GET' && !options.ignoreMethod) {
        return false
      }
    } else {
      assert(typeof request === 'string')

      r = new Request(request)[kState]
    }

    /** @type {CacheBatchOperation[]} */
    const operations = []

    /** @type {CacheBatchOperation} */
    const operation = {
      type: 'delete',
      request: r,
      options
    }

    operations.push(operation)

    const cacheJobPromise = createDeferredPromise()

    let errorData = null
    let requestResponses

    try {
      requestResponses = this.#batchCacheOperations(operations)
    } catch (e) {
      errorData = e
    }

    queueMicrotask(() => {
      if (errorData === null) {
        cacheJobPromise.resolve(!!requestResponses?.length)
      } else {
        cacheJobPromise.reject(errorData)
      }
    })

    return cacheJobPromise.promise
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#dom-cache-keys
   * @param {any} request
   * @param {import('../../types/cache').CacheQueryOptions} options
   * @returns {readonly Request[]}
   */
  async keys (request = undefined, options = {}) {
    webidl.brandCheck(this, Cache)

    if (request !== undefined) request = webidl.converters.RequestInfo(request)
    options = webidl.converters.CacheQueryOptions(options)

    // 1.
    let r = null

    // 2.
    if (request !== undefined) {
      // 2.1
      if (request instanceof Request) {
        // 2.1.1
        r = request[kState]

        // 2.1.2
        if (r.method !== 'GET' && !options.ignoreMethod) {
          return []
        }
      } else if (typeof request === 'string') { // 2.2
        r = new Request(request)[kState]
      }
    }

    // 4.
    const promise = createDeferredPromise()

    // 5.
    // 5.1
    const requests = []

    // 5.2
    if (request === undefined) {
      // 5.2.1
      for (const requestResponse of this.#relevantRequestResponseList) {
        // 5.2.1.1
        requests.push(requestResponse[0])
      }
    } else { // 5.3
      // 5.3.1
      const requestResponses = this.#queryCache(r, options)

      // 5.3.2
      for (const requestResponse of requestResponses) {
        // 5.3.2.1
        requests.push(requestResponse[0])
      }
    }

    // 5.4
    queueMicrotask(() => {
      // 5.4.1
      const requestList = []

      // 5.4.2
      for (const request of requests) {
        const requestObject = new Request('https://a')
        requestObject[kState] = request
        requestObject[kHeaders][kHeadersList] = request.headersList
        requestObject[kHeaders][kGuard] = 'immutable'
        requestObject[kRealm] = request.client

        // 5.4.2.1
        requestList.push(requestObject)
      }

      // 5.4.3
      promise.resolve(Object.freeze(requestList))
    })

    return promise.promise
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#batch-cache-operations-algorithm
   * @param {CacheBatchOperation[]} operations
   * @returns {requestResponseList}
   */
  #batchCacheOperations (operations) {
    // 1.
    const cache = this.#relevantRequestResponseList

    // 2.
    const backupCache = [...cache]

    // 3.
    const addedItems = []

    // 4.1
    const resultList = []

    try {
      // 4.2
      for (const operation of operations) {
        // 4.2.1
        if (operation.type !== 'delete' && operation.type !== 'put') {
          throw webidl.errors.exception({
            header: 'Cache.#batchCacheOperations',
            message: 'operation type does not match "delete" or "put"'
          })
        }

        // 4.2.2
        if (operation.type === 'delete' && operation.response != null) {
          throw webidl.errors.exception({
            header: 'Cache.#batchCacheOperations',
            message: 'delete operation should not have an associated response'
          })
        }

        // 4.2.3
        if (this.#queryCache(operation.request, operation.options, addedItems).length) {
          throw new DOMException('???', 'InvalidStateError')
        }

        // 4.2.4
        let requestResponses

        // 4.2.5
        if (operation.type === 'delete') {
          // 4.2.5.1
          requestResponses = this.#queryCache(operation.request, operation.options)

          // TODO: the spec is wrong, this is needed to pass WPTs
          if (requestResponses.length === 0) {
            return []
          }

          // 4.2.5.2
          for (const requestResponse of requestResponses) {
            const idx = cache.indexOf(requestResponse)
            assert(idx !== -1)

            // 4.2.5.2.1
            cache.splice(idx, 1)
          }
        } else if (operation.type === 'put') { // 4.2.6
          // 4.2.6.1
          if (operation.response == null) {
            throw webidl.errors.exception({
              header: 'Cache.#batchCacheOperations',
              message: 'put operation should have an associated response'
            })
          }

          // 4.2.6.2
          const r = operation.request

          // 4.2.6.3
          if (!urlIsHttpHttpsScheme(r.url)) {
            throw webidl.errors.exception({
              header: 'Cache.#batchCacheOperations',
              message: 'expected http or https scheme'
            })
          }

          // 4.2.6.4
          if (r.method !== 'GET') {
            throw webidl.errors.exception({
              header: 'Cache.#batchCacheOperations',
              message: 'not get method'
            })
          }

          // 4.2.6.5
          if (operation.options != null) {
            throw webidl.errors.exception({
              header: 'Cache.#batchCacheOperations',
              message: 'options must not be defined'
            })
          }

          // 4.2.6.6
          requestResponses = this.#queryCache(operation.request)

          // 4.2.6.7
          for (const requestResponse of requestResponses) {
            const idx = cache.indexOf(requestResponse)
            assert(idx !== -1)

            // 4.2.6.7.1
            cache.splice(idx, 1)
          }

          // 4.2.6.8
          cache.push([operation.request, operation.response])

          // 4.2.6.10
          addedItems.push([operation.request, operation.response])
        }

        // 4.2.7
        resultList.push([operation.request, operation.response])
      }

      // 4.3
      return resultList
    } catch (e) { // 5.
      // 5.1
      this.#relevantRequestResponseList.length = 0

      // 5.2
      this.#relevantRequestResponseList = backupCache

      // 5.3
      throw e
    }
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#query-cache
   * @param {any} requestQuery
   * @param {import('../../types/cache').CacheQueryOptions} options
   * @param {requestResponseList} targetStorage
   * @returns {requestResponseList}
   */
  #queryCache (requestQuery, options, targetStorage) {
    /** @type {requestResponseList} */
    const resultList = []

    const storage = targetStorage ?? this.#relevantRequestResponseList

    for (const requestResponse of storage) {
      const [cachedRequest, cachedResponse] = requestResponse
      if (this.#requestMatchesCachedItem(requestQuery, cachedRequest, cachedResponse, options)) {
        resultList.push(requestResponse)
      }
    }

    return resultList
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#request-matches-cached-item-algorithm
   * @param {any} requestQuery
   * @param {any} request
   * @param {any | null} response
   * @param {import('../../types/cache').CacheQueryOptions | undefined} options
   * @returns {boolean}
   */
  #requestMatchesCachedItem (requestQuery, request, response = null, options) {
    // if (options?.ignoreMethod === false && request.method === 'GET') {
    //   return false
    // }

    const queryURL = new URL(requestQuery.url)

    const cachedURL = new URL(request.url)

    if (options?.ignoreSearch) {
      cachedURL.search = ''

      queryURL.search = ''
    }

    if (!urlEquals(queryURL, cachedURL, true)) {
      return false
    }

    if (
      response == null ||
      options?.ignoreVary ||
      !response.headersList.contains('vary')
    ) {
      return true
    }

    const fieldValues = getFieldValues(response.headersList.get('vary'))

    for (const fieldValue of fieldValues) {
      if (fieldValue === '*') {
        return false
      }

      const requestValue = request.headersList.get(fieldValue)
      const queryValue = requestQuery.headersList.get(fieldValue)

      // If one has the header and the other doesn't, or one has
      // a different value than the other, return false
      if (requestValue !== queryValue) {
        return false
      }
    }

    return true
  }
}

Object.defineProperties(Cache.prototype, {
  [Symbol.toStringTag]: {
    value: 'Cache',
    configurable: true
  },
  match: kEnumerableProperty,
  matchAll: kEnumerableProperty,
  add: kEnumerableProperty,
  addAll: kEnumerableProperty,
  put: kEnumerableProperty,
  delete: kEnumerableProperty,
  keys: kEnumerableProperty
})

const cacheQueryOptionConverters = [
  {
    key: 'ignoreSearch',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'ignoreMethod',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'ignoreVary',
    converter: webidl.converters.boolean,
    defaultValue: false
  }
]

webidl.converters.CacheQueryOptions = webidl.dictionaryConverter(cacheQueryOptionConverters)

webidl.converters.MultiCacheQueryOptions = webidl.dictionaryConverter([
  ...cacheQueryOptionConverters,
  {
    key: 'cacheName',
    converter: webidl.converters.DOMString
  }
])

webidl.converters.Response = webidl.interfaceConverter(Response)

webidl.converters['sequence<RequestInfo>'] = webidl.sequenceConverter(
  webidl.converters.RequestInfo
)

module.exports = {
  Cache
}


/***/ }),

/***/ 4738:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { kConstruct } = __nccwpck_require__(296)
const { Cache } = __nccwpck_require__(479)
const { webidl } = __nccwpck_require__(4222)
const { kEnumerableProperty } = __nccwpck_require__(3440)

class CacheStorage {
  /**
   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-name-to-cache-map
   * @type {Map<string, import('./cache').requestResponseList}
   */
  #caches = new Map()

  constructor () {
    if (arguments[0] !== kConstruct) {
      webidl.illegalConstructor()
    }
  }

  async match (request, options = {}) {
    webidl.brandCheck(this, CacheStorage)
    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.match' })

    request = webidl.converters.RequestInfo(request)
    options = webidl.converters.MultiCacheQueryOptions(options)

    // 1.
    if (options.cacheName != null) {
      // 1.1.1.1
      if (this.#caches.has(options.cacheName)) {
        // 1.1.1.1.1
        const cacheList = this.#caches.get(options.cacheName)
        const cache = new Cache(kConstruct, cacheList)

        return await cache.match(request, options)
      }
    } else { // 2.
      // 2.2
      for (const cacheList of this.#caches.values()) {
        const cache = new Cache(kConstruct, cacheList)

        // 2.2.1.2
        const response = await cache.match(request, options)

        if (response !== undefined) {
          return response
        }
      }
    }
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#cache-storage-has
   * @param {string} cacheName
   * @returns {Promise<boolean>}
   */
  async has (cacheName) {
    webidl.brandCheck(this, CacheStorage)
    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.has' })

    cacheName = webidl.converters.DOMString(cacheName)

    // 2.1.1
    // 2.2
    return this.#caches.has(cacheName)
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#dom-cachestorage-open
   * @param {string} cacheName
   * @returns {Promise<Cache>}
   */
  async open (cacheName) {
    webidl.brandCheck(this, CacheStorage)
    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.open' })

    cacheName = webidl.converters.DOMString(cacheName)

    // 2.1
    if (this.#caches.has(cacheName)) {
      // await caches.open('v1') !== await caches.open('v1')

      // 2.1.1
      const cache = this.#caches.get(cacheName)

      // 2.1.1.1
      return new Cache(kConstruct, cache)
    }

    // 2.2
    const cache = []

    // 2.3
    this.#caches.set(cacheName, cache)

    // 2.4
    return new Cache(kConstruct, cache)
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#cache-storage-delete
   * @param {string} cacheName
   * @returns {Promise<boolean>}
   */
  async delete (cacheName) {
    webidl.brandCheck(this, CacheStorage)
    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.delete' })

    cacheName = webidl.converters.DOMString(cacheName)

    return this.#caches.delete(cacheName)
  }

  /**
   * @see https://w3c.github.io/ServiceWorker/#cache-storage-keys
   * @returns {string[]}
   */
  async keys () {
    webidl.brandCheck(this, CacheStorage)

    // 2.1
    const keys = this.#caches.keys()

    // 2.2
    return [...keys]
  }
}

Object.defineProperties(CacheStorage.prototype, {
  [Symbol.toStringTag]: {
    value: 'CacheStorage',
    configurable: true
  },
  match: kEnumerableProperty,
  has: kEnumerableProperty,
  open: kEnumerableProperty,
  delete: kEnumerableProperty,
  keys: kEnumerableProperty
})

module.exports = {
  CacheStorage
}


/***/ }),

/***/ 296:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


module.exports = {
  kConstruct: (__nccwpck_require__(6443).kConstruct)
}


/***/ }),

/***/ 3993:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const assert = __nccwpck_require__(2613)
const { URLSerializer } = __nccwpck_require__(4322)
const { isValidHeaderName } = __nccwpck_require__(5523)

/**
 * @see https://url.spec.whatwg.org/#concept-url-equals
 * @param {URL} A
 * @param {URL} B
 * @param {boolean | undefined} excludeFragment
 * @returns {boolean}
 */
function urlEquals (A, B, excludeFragment = false) {
  const serializedA = URLSerializer(A, excludeFragment)

  const serializedB = URLSerializer(B, excludeFragment)

  return serializedA === serializedB
}

/**
 * @see https://github.com/chromium/chromium/blob/694d20d134cb553d8d89e5500b9148012b1ba299/content/browser/cache_storage/cache_storage_cache.cc#L260-L262
 * @param {string} header
 */
function fieldValues (header) {
  assert(header !== null)

  const values = []

  for (let value of header.split(',')) {
    value = value.trim()

    if (!value.length) {
      continue
    } else if (!isValidHeaderName(value)) {
      continue
    }

    values.push(value)
  }

  return values
}

module.exports = {
  urlEquals,
  fieldValues
}


/***/ }),

/***/ 6197:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";
// @ts-check



/* global WebAssembly */

const assert = __nccwpck_require__(2613)
const net = __nccwpck_require__(9278)
const http = __nccwpck_require__(8611)
const { pipeline } = __nccwpck_require__(2203)
const util = __nccwpck_require__(3440)
const timers = __nccwpck_require__(8804)
const Request = __nccwpck_require__(4655)
const DispatcherBase = __nccwpck_require__(1)
const {
  RequestContentLengthMismatchError,
  ResponseContentLengthMismatchError,
  InvalidArgumentError,
  RequestAbortedError,
  HeadersTimeoutError,
  HeadersOverflowError,
  SocketError,
  InformationalError,
  BodyTimeoutError,
  HTTPParserError,
  ResponseExceededMaxSizeError,
  ClientDestroyedError
} = __nccwpck_require__(8707)
const buildConnector = __nccwpck_require__(9136)
const {
  kUrl,
  kReset,
  kServerName,
  kClient,
  kBusy,
  kParser,
  kConnect,
  kBlocking,
  kResuming,
  kRunning,
  kPending,
  kSize,
  kWriting,
  kQueue,
  kConnected,
  kConnecting,
  kNeedDrain,
  kNoRef,
  kKeepAliveDefaultTimeout,
  kHostHeader,
  kPendingIdx,
  kRunningIdx,
  kError,
  kPipelining,
  kSocket,
  kKeepAliveTimeoutValue,
  kMaxHeadersSize,
  kKeepAliveMaxTimeout,
  kKeepAliveTimeoutThreshold,
  kHeadersTimeout,
  kBodyTimeout,
  kStrictContentLength,
  kConnector,
  kMaxRedirections,
  kMaxRequests,
  kCounter,
  kClose,
  kDestroy,
  kDispatch,
  kInterceptors,
  kLocalAddress,
  kMaxResponseSize,
  kHTTPConnVersion,
  // HTTP2
  kHost,
  kHTTP2Session,
  kHTTP2SessionState,
  kHTTP2BuildRequest,
  kHTTP2CopyHeaders,
  kHTTP1BuildRequest
} = __nccwpck_require__(6443)

/** @type {import('http2')} */
let http2
try {
  http2 = __nccwpck_require__(5675)
} catch {
  // @ts-ignore
  http2 = { constants: {} }
}

const {
  constants: {
    HTTP2_HEADER_AUTHORITY,
    HTTP2_HEADER_METHOD,
    HTTP2_HEADER_PATH,
    HTTP2_HEADER_SCHEME,
    HTTP2_HEADER_CONTENT_LENGTH,
    HTTP2_HEADER_EXPECT,
    HTTP2_HEADER_STATUS
  }
} = http2

// Experimental
let h2ExperimentalWarned = false

const FastBuffer = Buffer[Symbol.species]

const kClosedResolve = Symbol('kClosedResolve')

const channels = {}

try {
  const diagnosticsChannel = __nccwpck_require__(1637)
  channels.sendHeaders = diagnosticsChannel.channel('undici:client:sendHeaders')
  channels.beforeConnect = diagnosticsChannel.channel('undici:client:beforeConnect')
  channels.connectError = diagnosticsChannel.channel('undici:client:connectError')
  channels.connected = diagnosticsChannel.channel('undici:client:connected')
} catch {
  channels.sendHeaders = { hasSubscribers: false }
  channels.beforeConnect = { hasSubscribers: false }
  channels.connectError = { hasSubscribers: false }
  channels.connected = { hasSubscribers: false }
}

/**
 * @type {import('../types/client').default}
 */
class Client extends DispatcherBase {
  /**
   *
   * @param {string|URL} url
   * @param {import('../types/client').Client.Options} options
   */
  constructor (url, {
    interceptors,
    maxHeaderSize,
    headersTimeout,
    socketTimeout,
    requestTimeout,
    connectTimeout,
    bodyTimeout,
    idleTimeout,
    keepAlive,
    keepAliveTimeout,
    maxKeepAliveTimeout,
    keepAliveMaxTimeout,
    keepAliveTimeoutThreshold,
    socketPath,
    pipelining,
    tls,
    strictContentLength,
    maxCachedSessions,
    maxRedirections,
    connect,
    maxRequestsPerClient,
    localAddress,
    maxResponseSize,
    autoSelectFamily,
    autoSelectFamilyAttemptTimeout,
    // h2
    allowH2,
    maxConcurrentStreams
  } = {}) {
    super()

    if (keepAlive !== undefined) {
      throw new InvalidArgumentError('unsupported keepAlive, use pipelining=0 instead')
    }

    if (socketTimeout !== undefined) {
      throw new InvalidArgumentError('unsupported socketTimeout, use headersTimeout & bodyTimeout instead')
    }

    if (requestTimeout !== undefined) {
      throw new InvalidArgumentError('unsupported requestTimeout, use headersTimeout & bodyTimeout instead')
    }

    if (idleTimeout !== undefined) {
      throw new InvalidArgumentError('unsupported idleTimeout, use keepAliveTimeout instead')
    }

    if (maxKeepAliveTimeout !== undefined) {
      throw new InvalidArgumentError('unsupported maxKeepAliveTimeout, use keepAliveMaxTimeout instead')
    }

    if (maxHeaderSize != null && !Number.isFinite(maxHeaderSize)) {
      throw new InvalidArgumentError('invalid maxHeaderSize')
    }

    if (socketPath != null && typeof socketPath !== 'string') {
      throw new InvalidArgumentError('invalid socketPath')
    }

    if (connectTimeout != null && (!Number.isFinite(connectTimeout) || connectTimeout < 0)) {
      throw new InvalidArgumentError('invalid connectTimeout')
    }

    if (keepAliveTimeout != null && (!Number.isFinite(keepAliveTimeout) || keepAliveTimeout <= 0)) {
      throw new InvalidArgumentError('invalid keepAliveTimeout')
    }

    if (keepAliveMaxTimeout != null && (!Number.isFinite(keepAliveMaxTimeout) || keepAliveMaxTimeout <= 0)) {
      throw new InvalidArgumentError('invalid keepAliveMaxTimeout')
    }

    if (keepAliveTimeoutThreshold != null && !Number.isFinite(keepAliveTimeoutThreshold)) {
      throw new InvalidArgumentError('invalid keepAliveTimeoutThreshold')
    }

    if (headersTimeout != null && (!Number.isInteger(headersTimeout) || headersTimeout < 0)) {
      throw new InvalidArgumentError('headersTimeout must be a positive integer or zero')
    }

    if (bodyTimeout != null && (!Number.isInteger(bodyTimeout) || bodyTimeout < 0)) {
      throw new InvalidArgumentError('bodyTimeout must be a positive integer or zero')
    }

    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {
      throw new InvalidArgumentError('connect must be a function or an object')
    }

    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {
      throw new InvalidArgumentError('maxRedirections must be a positive number')
    }

    if (maxRequestsPerClient != null && (!Number.isInteger(maxRequestsPerClient) || maxRequestsPerClient < 0)) {
      throw new InvalidArgumentError('maxRequestsPerClient must be a positive number')
    }

    if (localAddress != null && (typeof localAddress !== 'string' || net.isIP(localAddress) === 0)) {
      throw new InvalidArgumentError('localAddress must be valid string IP address')
    }

    if (maxResponseSize != null && (!Number.isInteger(maxResponseSize) || maxResponseSize < -1)) {
      throw new InvalidArgumentError('maxResponseSize must be a positive number')
    }

    if (
      autoSelectFamilyAttemptTimeout != null &&
      (!Number.isInteger(autoSelectFamilyAttemptTimeout) || autoSelectFamilyAttemptTimeout < -1)
    ) {
      throw new InvalidArgumentError('autoSelectFamilyAttemptTimeout must be a positive number')
    }

    // h2
    if (allowH2 != null && typeof allowH2 !== 'boolean') {
      throw new InvalidArgumentError('allowH2 must be a valid boolean value')
    }

    if (maxConcurrentStreams != null && (typeof maxConcurrentStreams !== 'number' || maxConcurrentStreams < 1)) {
      throw new InvalidArgumentError('maxConcurrentStreams must be a possitive integer, greater than 0')
    }

    if (typeof connect !== 'function') {
      connect = buildConnector({
        ...tls,
        maxCachedSessions,
        allowH2,
        socketPath,
        timeout: connectTimeout,
        ...(util.nodeHasAutoSelectFamily && autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),
        ...connect
      })
    }

    this[kInterceptors] = interceptors && interceptors.Client && Array.isArray(interceptors.Client)
      ? interceptors.Client
      : [createRedirectInterceptor({ maxRedirections })]
    this[kUrl] = util.parseOrigin(url)
    this[kConnector] = connect
    this[kSocket] = null
    this[kPipelining] = pipelining != null ? pipelining : 1
    this[kMaxHeadersSize] = maxHeaderSize || http.maxHeaderSize
    this[kKeepAliveDefaultTimeout] = keepAliveTimeout == null ? 4e3 : keepAliveTimeout
    this[kKeepAliveMaxTimeout] = keepAliveMaxTimeout == null ? 600e3 : keepAliveMaxTimeout
    this[kKeepAliveTimeoutThreshold] = keepAliveTimeoutThreshold == null ? 1e3 : keepAliveTimeoutThreshold
    this[kKeepAliveTimeoutValue] = this[kKeepAliveDefaultTimeout]
    this[kServerName] = null
    this[kLocalAddress] = localAddress != null ? localAddress : null
    this[kResuming] = 0 // 0, idle, 1, scheduled, 2 resuming
    this[kNeedDrain] = 0 // 0, idle, 1, scheduled, 2 resuming
    this[kHostHeader] = `host: ${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}\r\n`
    this[kBodyTimeout] = bodyTimeout != null ? bodyTimeout : 300e3
    this[kHeadersTimeout] = headersTimeout != null ? headersTimeout : 300e3
    this[kStrictContentLength] = strictContentLength == null ? true : strictContentLength
    this[kMaxRedirections] = maxRedirections
    this[kMaxRequests] = maxRequestsPerClient
    this[kClosedResolve] = null
    this[kMaxResponseSize] = maxResponseSize > -1 ? maxResponseSize : -1
    this[kHTTPConnVersion] = 'h1'

    // HTTP/2
    this[kHTTP2Session] = null
    this[kHTTP2SessionState] = !allowH2
      ? null
      : {
        // streams: null, // Fixed queue of streams - For future support of `push`
          openStreams: 0, // Keep track of them to decide wether or not unref the session
          maxConcurrentStreams: maxConcurrentStreams != null ? maxConcurrentStreams : 100 // Max peerConcurrentStreams for a Node h2 server
        }
    this[kHost] = `${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}`

    // kQueue is built up of 3 sections separated by
    // the kRunningIdx and kPendingIdx indices.
    // |   complete   |   running   |   pending   |
    //                ^ kRunningIdx ^ kPendingIdx ^ kQueue.length
    // kRunningIdx points to the first running element.
    // kPendingIdx points to the first pending element.
    // This implements a fast queue with an amortized
    // time of O(1).

    this[kQueue] = []
    this[kRunningIdx] = 0
    this[kPendingIdx] = 0
  }

  get pipelining () {
    return this[kPipelining]
  }

  set pipelining (value) {
    this[kPipelining] = value
    resume(this, true)
  }

  get [kPending] () {
    return this[kQueue].length - this[kPendingIdx]
  }

  get [kRunning] () {
    return this[kPendingIdx] - this[kRunningIdx]
  }

  get [kSize] () {
    return this[kQueue].length - this[kRunningIdx]
  }

  get [kConnected] () {
    return !!this[kSocket] && !this[kConnecting] && !this[kSocket].destroyed
  }

  get [kBusy] () {
    const socket = this[kSocket]
    return (
      (socket && (socket[kReset] || socket[kWriting] || socket[kBlocking])) ||
      (this[kSize] >= (this[kPipelining] || 1)) ||
      this[kPending] > 0
    )
  }

  /* istanbul ignore: only used for test */
  [kConnect] (cb) {
    connect(this)
    this.once('connect', cb)
  }

  [kDispatch] (opts, handler) {
    const origin = opts.origin || this[kUrl].origin

    const request = this[kHTTPConnVersion] === 'h2'
      ? Request[kHTTP2BuildRequest](origin, opts, handler)
      : Request[kHTTP1BuildRequest](origin, opts, handler)

    this[kQueue].push(request)
    if (this[kResuming]) {
      // Do nothing.
    } else if (util.bodyLength(request.body) == null && util.isIterable(request.body)) {
      // Wait a tick in case stream/iterator is ended in the same tick.
      this[kResuming] = 1
      process.nextTick(resume, this)
    } else {
      resume(this, true)
    }

    if (this[kResuming] && this[kNeedDrain] !== 2 && this[kBusy]) {
      this[kNeedDrain] = 2
    }

    return this[kNeedDrain] < 2
  }

  async [kClose] () {
    // TODO: for H2 we need to gracefully flush the remaining enqueued
    // request and close each stream.
    return new Promise((resolve) => {
      if (!this[kSize]) {
        resolve(null)
      } else {
        this[kClosedResolve] = resolve
      }
    })
  }

  async [kDestroy] (err) {
    return new Promise((resolve) => {
      const requests = this[kQueue].splice(this[kPendingIdx])
      for (let i = 0; i < requests.length; i++) {
        const request = requests[i]
        errorRequest(this, request, err)
      }

      const callback = () => {
        if (this[kClosedResolve]) {
          // TODO (fix): Should we error here with ClientDestroyedError?
          this[kClosedResolve]()
          this[kClosedResolve] = null
        }
        resolve()
      }

      if (this[kHTTP2Session] != null) {
        util.destroy(this[kHTTP2Session], err)
        this[kHTTP2Session] = null
        this[kHTTP2SessionState] = null
      }

      if (!this[kSocket]) {
        queueMicrotask(callback)
      } else {
        util.destroy(this[kSocket].on('close', callback), err)
      }

      resume(this)
    })
  }
}

function onHttp2SessionError (err) {
  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')

  this[kSocket][kError] = err

  onError(this[kClient], err)
}

function onHttp2FrameError (type, code, id) {
  const err = new InformationalError(`HTTP/2: "frameError" received - type ${type}, code ${code}`)

  if (id === 0) {
    this[kSocket][kError] = err
    onError(this[kClient], err)
  }
}

function onHttp2SessionEnd () {
  util.destroy(this, new SocketError('other side closed'))
  util.destroy(this[kSocket], new SocketError('other side closed'))
}

function onHTTP2GoAway (code) {
  const client = this[kClient]
  const err = new InformationalError(`HTTP/2: "GOAWAY" frame received with code ${code}`)
  client[kSocket] = null
  client[kHTTP2Session] = null

  if (client.destroyed) {
    assert(this[kPending] === 0)

    // Fail entire queue.
    const requests = client[kQueue].splice(client[kRunningIdx])
    for (let i = 0; i < requests.length; i++) {
      const request = requests[i]
      errorRequest(this, request, err)
    }
  } else if (client[kRunning] > 0) {
    // Fail head of pipeline.
    const request = client[kQueue][client[kRunningIdx]]
    client[kQueue][client[kRunningIdx]++] = null

    errorRequest(client, request, err)
  }

  client[kPendingIdx] = client[kRunningIdx]

  assert(client[kRunning] === 0)

  client.emit('disconnect',
    client[kUrl],
    [client],
    err
  )

  resume(client)
}

const constants = __nccwpck_require__(2824)
const createRedirectInterceptor = __nccwpck_require__(4415)
const EMPTY_BUF = Buffer.alloc(0)

async function lazyllhttp () {
  const llhttpWasmData = process.env.JEST_WORKER_ID ? __nccwpck_require__(3870) : undefined

  let mod
  try {
    mod = await WebAssembly.compile(Buffer.from(__nccwpck_require__(3434), 'base64'))
  } catch (e) {
    /* istanbul ignore next */

    // We could check if the error was caused by the simd option not
    // being enabled, but the occurring of this other error
    // * https://github.com/emscripten-core/emscripten/issues/11495
    // got me to remove that check to avoid breaking Node 12.
    mod = await WebAssembly.compile(Buffer.from(llhttpWasmData || __nccwpck_require__(3870), 'base64'))
  }

  return await WebAssembly.instantiate(mod, {
    env: {
      /* eslint-disable camelcase */

      wasm_on_url: (p, at, len) => {
        /* istanbul ignore next */
        return 0
      },
      wasm_on_status: (p, at, len) => {
        assert.strictEqual(currentParser.ptr, p)
        const start = at - currentBufferPtr + currentBufferRef.byteOffset
        return currentParser.onStatus(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
      },
      wasm_on_message_begin: (p) => {
        assert.strictEqual(currentParser.ptr, p)
        return currentParser.onMessageBegin() || 0
      },
      wasm_on_header_field: (p, at, len) => {
        assert.strictEqual(currentParser.ptr, p)
        const start = at - currentBufferPtr + currentBufferRef.byteOffset
        return currentParser.onHeaderField(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
      },
      wasm_on_header_value: (p, at, len) => {
        assert.strictEqual(currentParser.ptr, p)
        const start = at - currentBufferPtr + currentBufferRef.byteOffset
        return currentParser.onHeaderValue(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
      },
      wasm_on_headers_complete: (p, statusCode, upgrade, shouldKeepAlive) => {
        assert.strictEqual(currentParser.ptr, p)
        return currentParser.onHeadersComplete(statusCode, Boolean(upgrade), Boolean(shouldKeepAlive)) || 0
      },
      wasm_on_body: (p, at, len) => {
        assert.strictEqual(currentParser.ptr, p)
        const start = at - currentBufferPtr + currentBufferRef.byteOffset
        return currentParser.onBody(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
      },
      wasm_on_message_complete: (p) => {
        assert.strictEqual(currentParser.ptr, p)
        return currentParser.onMessageComplete() || 0
      }

      /* eslint-enable camelcase */
    }
  })
}

let llhttpInstance = null
let llhttpPromise = lazyllhttp()
llhttpPromise.catch()

let currentParser = null
let currentBufferRef = null
let currentBufferSize = 0
let currentBufferPtr = null

const TIMEOUT_HEADERS = 1
const TIMEOUT_BODY = 2
const TIMEOUT_IDLE = 3

class Parser {
  constructor (client, socket, { exports }) {
    assert(Number.isFinite(client[kMaxHeadersSize]) && client[kMaxHeadersSize] > 0)

    this.llhttp = exports
    this.ptr = this.llhttp.llhttp_alloc(constants.TYPE.RESPONSE)
    this.client = client
    this.socket = socket
    this.timeout = null
    this.timeoutValue = null
    this.timeoutType = null
    this.statusCode = null
    this.statusText = ''
    this.upgrade = false
    this.headers = []
    this.headersSize = 0
    this.headersMaxSize = client[kMaxHeadersSize]
    this.shouldKeepAlive = false
    this.paused = false
    this.resume = this.resume.bind(this)

    this.bytesRead = 0

    this.keepAlive = ''
    this.contentLength = ''
    this.connection = ''
    this.maxResponseSize = client[kMaxResponseSize]
  }

  setTimeout (value, type) {
    this.timeoutType = type
    if (value !== this.timeoutValue) {
      timers.clearTimeout(this.timeout)
      if (value) {
        this.timeout = timers.setTimeout(onParserTimeout, value, this)
        // istanbul ignore else: only for jest
        if (this.timeout.unref) {
          this.timeout.unref()
        }
      } else {
        this.timeout = null
      }
      this.timeoutValue = value
    } else if (this.timeout) {
      // istanbul ignore else: only for jest
      if (this.timeout.refresh) {
        this.timeout.refresh()
      }
    }
  }

  resume () {
    if (this.socket.destroyed || !this.paused) {
      return
    }

    assert(this.ptr != null)
    assert(currentParser == null)

    this.llhttp.llhttp_resume(this.ptr)

    assert(this.timeoutType === TIMEOUT_BODY)
    if (this.timeout) {
      // istanbul ignore else: only for jest
      if (this.timeout.refresh) {
        this.timeout.refresh()
      }
    }

    this.paused = false
    this.execute(this.socket.read() || EMPTY_BUF) // Flush parser.
    this.readMore()
  }

  readMore () {
    while (!this.paused && this.ptr) {
      const chunk = this.socket.read()
      if (chunk === null) {
        break
      }
      this.execute(chunk)
    }
  }

  execute (data) {
    assert(this.ptr != null)
    assert(currentParser == null)
    assert(!this.paused)

    const { socket, llhttp } = this

    if (data.length > currentBufferSize) {
      if (currentBufferPtr) {
        llhttp.free(currentBufferPtr)
      }
      currentBufferSize = Math.ceil(data.length / 4096) * 4096
      currentBufferPtr = llhttp.malloc(currentBufferSize)
    }

    new Uint8Array(llhttp.memory.buffer, currentBufferPtr, currentBufferSize).set(data)

    // Call `execute` on the wasm parser.
    // We pass the `llhttp_parser` pointer address, the pointer address of buffer view data,
    // and finally the length of bytes to parse.
    // The return value is an error code or `constants.ERROR.OK`.
    try {
      let ret

      try {
        currentBufferRef = data
        currentParser = this
        ret = llhttp.llhttp_execute(this.ptr, currentBufferPtr, data.length)
        /* eslint-disable-next-line no-useless-catch */
      } catch (err) {
        /* istanbul ignore next: difficult to make a test case for */
        throw err
      } finally {
        currentParser = null
        currentBufferRef = null
      }

      const offset = llhttp.llhttp_get_error_pos(this.ptr) - currentBufferPtr

      if (ret === constants.ERROR.PAUSED_UPGRADE) {
        this.onUpgrade(data.slice(offset))
      } else if (ret === constants.ERROR.PAUSED) {
        this.paused = true
        socket.unshift(data.slice(offset))
      } else if (ret !== constants.ERROR.OK) {
        const ptr = llhttp.llhttp_get_error_reason(this.ptr)
        let message = ''
        /* istanbul ignore else: difficult to make a test case for */
        if (ptr) {
          const len = new Uint8Array(llhttp.memory.buffer, ptr).indexOf(0)
          message =
            'Response does not match the HTTP/1.1 protocol (' +
            Buffer.from(llhttp.memory.buffer, ptr, len).toString() +
            ')'
        }
        throw new HTTPParserError(message, constants.ERROR[ret], data.slice(offset))
      }
    } catch (err) {
      util.destroy(socket, err)
    }
  }

  destroy () {
    assert(this.ptr != null)
    assert(currentParser == null)

    this.llhttp.llhttp_free(this.ptr)
    this.ptr = null

    timers.clearTimeout(this.timeout)
    this.timeout = null
    this.timeoutValue = null
    this.timeoutType = null

    this.paused = false
  }

  onStatus (buf) {
    this.statusText = buf.toString()
  }

  onMessageBegin () {
    const { socket, client } = this

    /* istanbul ignore next: difficult to make a test case for */
    if (socket.destroyed) {
      return -1
    }

    const request = client[kQueue][client[kRunningIdx]]
    if (!request) {
      return -1
    }
  }

  onHeaderField (buf) {
    const len = this.headers.length

    if ((len & 1) === 0) {
      this.headers.push(buf)
    } else {
      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])
    }

    this.trackHeader(buf.length)
  }

  onHeaderValue (buf) {
    let len = this.headers.length

    if ((len & 1) === 1) {
      this.headers.push(buf)
      len += 1
    } else {
      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])
    }

    const key = this.headers[len - 2]
    if (key.length === 10 && key.toString().toLowerCase() === 'keep-alive') {
      this.keepAlive += buf.toString()
    } else if (key.length === 10 && key.toString().toLowerCase() === 'connection') {
      this.connection += buf.toString()
    } else if (key.length === 14 && key.toString().toLowerCase() === 'content-length') {
      this.contentLength += buf.toString()
    }

    this.trackHeader(buf.length)
  }

  trackHeader (len) {
    this.headersSize += len
    if (this.headersSize >= this.headersMaxSize) {
      util.destroy(this.socket, new HeadersOverflowError())
    }
  }

  onUpgrade (head) {
    const { upgrade, client, socket, headers, statusCode } = this

    assert(upgrade)

    const request = client[kQueue][client[kRunningIdx]]
    assert(request)

    assert(!socket.destroyed)
    assert(socket === client[kSocket])
    assert(!this.paused)
    assert(request.upgrade || request.method === 'CONNECT')

    this.statusCode = null
    this.statusText = ''
    this.shouldKeepAlive = null

    assert(this.headers.length % 2 === 0)
    this.headers = []
    this.headersSize = 0

    socket.unshift(head)

    socket[kParser].destroy()
    socket[kParser] = null

    socket[kClient] = null
    socket[kError] = null
    socket
      .removeListener('error', onSocketError)
      .removeListener('readable', onSocketReadable)
      .removeListener('end', onSocketEnd)
      .removeListener('close', onSocketClose)

    client[kSocket] = null
    client[kQueue][client[kRunningIdx]++] = null
    client.emit('disconnect', client[kUrl], [client], new InformationalError('upgrade'))

    try {
      request.onUpgrade(statusCode, headers, socket)
    } catch (err) {
      util.destroy(socket, err)
    }

    resume(client)
  }

  onHeadersComplete (statusCode, upgrade, shouldKeepAlive) {
    const { client, socket, headers, statusText } = this

    /* istanbul ignore next: difficult to make a test case for */
    if (socket.destroyed) {
      return -1
    }

    const request = client[kQueue][client[kRunningIdx]]

    /* istanbul ignore next: difficult to make a test case for */
    if (!request) {
      return -1
    }

    assert(!this.upgrade)
    assert(this.statusCode < 200)

    if (statusCode === 100) {
      util.destroy(socket, new SocketError('bad response', util.getSocketInfo(socket)))
      return -1
    }

    /* this can only happen if server is misbehaving */
    if (upgrade && !request.upgrade) {
      util.destroy(socket, new SocketError('bad upgrade', util.getSocketInfo(socket)))
      return -1
    }

    assert.strictEqual(this.timeoutType, TIMEOUT_HEADERS)

    this.statusCode = statusCode
    this.shouldKeepAlive = (
      shouldKeepAlive ||
      // Override llhttp value which does not allow keepAlive for HEAD.
      (request.method === 'HEAD' && !socket[kReset] && this.connection.toLowerCase() === 'keep-alive')
    )

    if (this.statusCode >= 200) {
      const bodyTimeout = request.bodyTimeout != null
        ? request.bodyTimeout
        : client[kBodyTimeout]
      this.setTimeout(bodyTimeout, TIMEOUT_BODY)
    } else if (this.timeout) {
      // istanbul ignore else: only for jest
      if (this.timeout.refresh) {
        this.timeout.refresh()
      }
    }

    if (request.method === 'CONNECT') {
      assert(client[kRunning] === 1)
      this.upgrade = true
      return 2
    }

    if (upgrade) {
      assert(client[kRunning] === 1)
      this.upgrade = true
      return 2
    }

    assert(this.headers.length % 2 === 0)
    this.headers = []
    this.headersSize = 0

    if (this.shouldKeepAlive && client[kPipelining]) {
      const keepAliveTimeout = this.keepAlive ? util.parseKeepAliveTimeout(this.keepAlive) : null

      if (keepAliveTimeout != null) {
        const timeout = Math.min(
          keepAliveTimeout - client[kKeepAliveTimeoutThreshold],
          client[kKeepAliveMaxTimeout]
        )
        if (timeout <= 0) {
          socket[kReset] = true
        } else {
          client[kKeepAliveTimeoutValue] = timeout
        }
      } else {
        client[kKeepAliveTimeoutValue] = client[kKeepAliveDefaultTimeout]
      }
    } else {
      // Stop more requests from being dispatched.
      socket[kReset] = true
    }

    const pause = request.onHeaders(statusCode, headers, this.resume, statusText) === false

    if (request.aborted) {
      return -1
    }

    if (request.method === 'HEAD') {
      return 1
    }

    if (statusCode < 200) {
      return 1
    }

    if (socket[kBlocking]) {
      socket[kBlocking] = false
      resume(client)
    }

    return pause ? constants.ERROR.PAUSED : 0
  }

  onBody (buf) {
    const { client, socket, statusCode, maxResponseSize } = this

    if (socket.destroyed) {
      return -1
    }

    const request = client[kQueue][client[kRunningIdx]]
    assert(request)

    assert.strictEqual(this.timeoutType, TIMEOUT_BODY)
    if (this.timeout) {
      // istanbul ignore else: only for jest
      if (this.timeout.refresh) {
        this.timeout.refresh()
      }
    }

    assert(statusCode >= 200)

    if (maxResponseSize > -1 && this.bytesRead + buf.length > maxResponseSize) {
      util.destroy(socket, new ResponseExceededMaxSizeError())
      return -1
    }

    this.bytesRead += buf.length

    if (request.onData(buf) === false) {
      return constants.ERROR.PAUSED
    }
  }

  onMessageComplete () {
    const { client, socket, statusCode, upgrade, headers, contentLength, bytesRead, shouldKeepAlive } = this

    if (socket.destroyed && (!statusCode || shouldKeepAlive)) {
      return -1
    }

    if (upgrade) {
      return
    }

    const request = client[kQueue][client[kRunningIdx]]
    assert(request)

    assert(statusCode >= 100)

    this.statusCode = null
    this.statusText = ''
    this.bytesRead = 0
    this.contentLength = ''
    this.keepAlive = ''
    this.connection = ''

    assert(this.headers.length % 2 === 0)
    this.headers = []
    this.headersSize = 0

    if (statusCode < 200) {
      return
    }

    /* istanbul ignore next: should be handled by llhttp? */
    if (request.method !== 'HEAD' && contentLength && bytesRead !== parseInt(contentLength, 10)) {
      util.destroy(socket, new ResponseContentLengthMismatchError())
      return -1
    }

    request.onComplete(headers)

    client[kQueue][client[kRunningIdx]++] = null

    if (socket[kWriting]) {
      assert.strictEqual(client[kRunning], 0)
      // Response completed before request.
      util.destroy(socket, new InformationalError('reset'))
      return constants.ERROR.PAUSED
    } else if (!shouldKeepAlive) {
      util.destroy(socket, new InformationalError('reset'))
      return constants.ERROR.PAUSED
    } else if (socket[kReset] && client[kRunning] === 0) {
      // Destroy socket once all requests have completed.
      // The request at the tail of the pipeline is the one
      // that requested reset and no further requests should
      // have been queued since then.
      util.destroy(socket, new InformationalError('reset'))
      return constants.ERROR.PAUSED
    } else if (client[kPipelining] === 1) {
      // We must wait a full event loop cycle to reuse this socket to make sure
      // that non-spec compliant servers are not closing the connection even if they
      // said they won't.
      setImmediate(resume, client)
    } else {
      resume(client)
    }
  }
}

function onParserTimeout (parser) {
  const { socket, timeoutType, client } = parser

  /* istanbul ignore else */
  if (timeoutType === TIMEOUT_HEADERS) {
    if (!socket[kWriting] || socket.writableNeedDrain || client[kRunning] > 1) {
      assert(!parser.paused, 'cannot be paused while waiting for headers')
      util.destroy(socket, new HeadersTimeoutError())
    }
  } else if (timeoutType === TIMEOUT_BODY) {
    if (!parser.paused) {
      util.destroy(socket, new BodyTimeoutError())
    }
  } else if (timeoutType === TIMEOUT_IDLE) {
    assert(client[kRunning] === 0 && client[kKeepAliveTimeoutValue])
    util.destroy(socket, new InformationalError('socket idle timeout'))
  }
}

function onSocketReadable () {
  const { [kParser]: parser } = this
  if (parser) {
    parser.readMore()
  }
}

function onSocketError (err) {
  const { [kClient]: client, [kParser]: parser } = this

  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')

  if (client[kHTTPConnVersion] !== 'h2') {
    // On Mac OS, we get an ECONNRESET even if there is a full body to be forwarded
    // to the user.
    if (err.code === 'ECONNRESET' && parser.statusCode && !parser.shouldKeepAlive) {
      // We treat all incoming data so for as a valid response.
      parser.onMessageComplete()
      return
    }
  }

  this[kError] = err

  onError(this[kClient], err)
}

function onError (client, err) {
  if (
    client[kRunning] === 0 &&
    err.code !== 'UND_ERR_INFO' &&
    err.code !== 'UND_ERR_SOCKET'
  ) {
    // Error is not caused by running request and not a recoverable
    // socket error.

    assert(client[kPendingIdx] === client[kRunningIdx])

    const requests = client[kQueue].splice(client[kRunningIdx])
    for (let i = 0; i < requests.length; i++) {
      const request = requests[i]
      errorRequest(client, request, err)
    }
    assert(client[kSize] === 0)
  }
}

function onSocketEnd () {
  const { [kParser]: parser, [kClient]: client } = this

  if (client[kHTTPConnVersion] !== 'h2') {
    if (parser.statusCode && !parser.shouldKeepAlive) {
      // We treat all incoming data so far as a valid response.
      parser.onMessageComplete()
      return
    }
  }

  util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)))
}

function onSocketClose () {
  const { [kClient]: client, [kParser]: parser } = this

  if (client[kHTTPConnVersion] === 'h1' && parser) {
    if (!this[kError] && parser.statusCode && !parser.shouldKeepAlive) {
      // We treat all incoming data so far as a valid response.
      parser.onMessageComplete()
    }

    this[kParser].destroy()
    this[kParser] = null
  }

  const err = this[kError] || new SocketError('closed', util.getSocketInfo(this))

  client[kSocket] = null

  if (client.destroyed) {
    assert(client[kPending] === 0)

    // Fail entire queue.
    const requests = client[kQueue].splice(client[kRunningIdx])
    for (let i = 0; i < requests.length; i++) {
      const request = requests[i]
      errorRequest(client, request, err)
    }
  } else if (client[kRunning] > 0 && err.code !== 'UND_ERR_INFO') {
    // Fail head of pipeline.
    const request = client[kQueue][client[kRunningIdx]]
    client[kQueue][client[kRunningIdx]++] = null

    errorRequest(client, request, err)
  }

  client[kPendingIdx] = client[kRunningIdx]

  assert(client[kRunning] === 0)

  client.emit('disconnect', client[kUrl], [client], err)

  resume(client)
}

async function connect (client) {
  assert(!client[kConnecting])
  assert(!client[kSocket])

  let { host, hostname, protocol, port } = client[kUrl]

  // Resolve ipv6
  if (hostname[0] === '[') {
    const idx = hostname.indexOf(']')

    assert(idx !== -1)
    const ip = hostname.substring(1, idx)

    assert(net.isIP(ip))
    hostname = ip
  }

  client[kConnecting] = true

  if (channels.beforeConnect.hasSubscribers) {
    channels.beforeConnect.publish({
      connectParams: {
        host,
        hostname,
        protocol,
        port,
        servername: client[kServerName],
        localAddress: client[kLocalAddress]
      },
      connector: client[kConnector]
    })
  }

  try {
    const socket = await new Promise((resolve, reject) => {
      client[kConnector]({
        host,
        hostname,
        protocol,
        port,
        servername: client[kServerName],
        localAddress: client[kLocalAddress]
      }, (err, socket) => {
        if (err) {
          reject(err)
        } else {
          resolve(socket)
        }
      })
    })

    if (client.destroyed) {
      util.destroy(socket.on('error', () => {}), new ClientDestroyedError())
      return
    }

    client[kConnecting] = false

    assert(socket)

    const isH2 = socket.alpnProtocol === 'h2'
    if (isH2) {
      if (!h2ExperimentalWarned) {
        h2ExperimentalWarned = true
        process.emitWarning('H2 support is experimental, expect them to change at any time.', {
          code: 'UNDICI-H2'
        })
      }

      const session = http2.connect(client[kUrl], {
        createConnection: () => socket,
        peerMaxConcurrentStreams: client[kHTTP2SessionState].maxConcurrentStreams
      })

      client[kHTTPConnVersion] = 'h2'
      session[kClient] = client
      session[kSocket] = socket
      session.on('error', onHttp2SessionError)
      session.on('frameError', onHttp2FrameError)
      session.on('end', onHttp2SessionEnd)
      session.on('goaway', onHTTP2GoAway)
      session.on('close', onSocketClose)
      session.unref()

      client[kHTTP2Session] = session
      socket[kHTTP2Session] = session
    } else {
      if (!llhttpInstance) {
        llhttpInstance = await llhttpPromise
        llhttpPromise = null
      }

      socket[kNoRef] = false
      socket[kWriting] = false
      socket[kReset] = false
      socket[kBlocking] = false
      socket[kParser] = new Parser(client, socket, llhttpInstance)
    }

    socket[kCounter] = 0
    socket[kMaxRequests] = client[kMaxRequests]
    socket[kClient] = client
    socket[kError] = null

    socket
      .on('error', onSocketError)
      .on('readable', onSocketReadable)
      .on('end', onSocketEnd)
      .on('close', onSocketClose)

    client[kSocket] = socket

    if (channels.connected.hasSubscribers) {
      channels.connected.publish({
        connectParams: {
          host,
          hostname,
          protocol,
          port,
          servername: client[kServerName],
          localAddress: client[kLocalAddress]
        },
        connector: client[kConnector],
        socket
      })
    }
    client.emit('connect', client[kUrl], [client])
  } catch (err) {
    if (client.destroyed) {
      return
    }

    client[kConnecting] = false

    if (channels.connectError.hasSubscribers) {
      channels.connectError.publish({
        connectParams: {
          host,
          hostname,
          protocol,
          port,
          servername: client[kServerName],
          localAddress: client[kLocalAddress]
        },
        connector: client[kConnector],
        error: err
      })
    }

    if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {
      assert(client[kRunning] === 0)
      while (client[kPending] > 0 && client[kQueue][client[kPendingIdx]].servername === client[kServerName]) {
        const request = client[kQueue][client[kPendingIdx]++]
        errorRequest(client, request, err)
      }
    } else {
      onError(client, err)
    }

    client.emit('connectionError', client[kUrl], [client], err)
  }

  resume(client)
}

function emitDrain (client) {
  client[kNeedDrain] = 0
  client.emit('drain', client[kUrl], [client])
}

function resume (client, sync) {
  if (client[kResuming] === 2) {
    return
  }

  client[kResuming] = 2

  _resume(client, sync)
  client[kResuming] = 0

  if (client[kRunningIdx] > 256) {
    client[kQueue].splice(0, client[kRunningIdx])
    client[kPendingIdx] -= client[kRunningIdx]
    client[kRunningIdx] = 0
  }
}

function _resume (client, sync) {
  while (true) {
    if (client.destroyed) {
      assert(client[kPending] === 0)
      return
    }

    if (client[kClosedResolve] && !client[kSize]) {
      client[kClosedResolve]()
      client[kClosedResolve] = null
      return
    }

    const socket = client[kSocket]

    if (socket && !socket.destroyed && socket.alpnProtocol !== 'h2') {
      if (client[kSize] === 0) {
        if (!socket[kNoRef] && socket.unref) {
          socket.unref()
          socket[kNoRef] = true
        }
      } else if (socket[kNoRef] && socket.ref) {
        socket.ref()
        socket[kNoRef] = false
      }

      if (client[kSize] === 0) {
        if (socket[kParser].timeoutType !== TIMEOUT_IDLE) {
          socket[kParser].setTimeout(client[kKeepAliveTimeoutValue], TIMEOUT_IDLE)
        }
      } else if (client[kRunning] > 0 && socket[kParser].statusCode < 200) {
        if (socket[kParser].timeoutType !== TIMEOUT_HEADERS) {
          const request = client[kQueue][client[kRunningIdx]]
          const headersTimeout = request.headersTimeout != null
            ? request.headersTimeout
            : client[kHeadersTimeout]
          socket[kParser].setTimeout(headersTimeout, TIMEOUT_HEADERS)
        }
      }
    }

    if (client[kBusy]) {
      client[kNeedDrain] = 2
    } else if (client[kNeedDrain] === 2) {
      if (sync) {
        client[kNeedDrain] = 1
        process.nextTick(emitDrain, client)
      } else {
        emitDrain(client)
      }
      continue
    }

    if (client[kPending] === 0) {
      return
    }

    if (client[kRunning] >= (client[kPipelining] || 1)) {
      return
    }

    const request = client[kQueue][client[kPendingIdx]]

    if (client[kUrl].protocol === 'https:' && client[kServerName] !== request.servername) {
      if (client[kRunning] > 0) {
        return
      }

      client[kServerName] = request.servername

      if (socket && socket.servername !== request.servername) {
        util.destroy(socket, new InformationalError('servername changed'))
        return
      }
    }

    if (client[kConnecting]) {
      return
    }

    if (!socket && !client[kHTTP2Session]) {
      connect(client)
      return
    }

    if (socket.destroyed || socket[kWriting] || socket[kReset] || socket[kBlocking]) {
      return
    }

    if (client[kRunning] > 0 && !request.idempotent) {
      // Non-idempotent request cannot be retried.
      // Ensure that no other requests are inflight and
      // could cause failure.
      return
    }

    if (client[kRunning] > 0 && (request.upgrade || request.method === 'CONNECT')) {
      // Don't dispatch an upgrade until all preceding requests have completed.
      // A misbehaving server might upgrade the connection before all pipelined
      // request has completed.
      return
    }

    if (client[kRunning] > 0 && util.bodyLength(request.body) !== 0 &&
      (util.isStream(request.body) || util.isAsyncIterable(request.body))) {
      // Request with stream or iterator body can error while other requests
      // are inflight and indirectly error those as well.
      // Ensure this doesn't happen by waiting for inflight
      // to complete before dispatching.

      // Request with stream or iterator body cannot be retried.
      // Ensure that no other requests are inflight and
      // could cause failure.
      return
    }

    if (!request.aborted && write(client, request)) {
      client[kPendingIdx]++
    } else {
      client[kQueue].splice(client[kPendingIdx], 1)
    }
  }
}

// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2
function shouldSendContentLength (method) {
  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'
}

function write (client, request) {
  if (client[kHTTPConnVersion] === 'h2') {
    writeH2(client, client[kHTTP2Session], request)
    return
  }

  const { body, method, path, host, upgrade, headers, blocking, reset } = request

  // https://tools.ietf.org/html/rfc7231#section-4.3.1
  // https://tools.ietf.org/html/rfc7231#section-4.3.2
  // https://tools.ietf.org/html/rfc7231#section-4.3.5

  // Sending a payload body on a request that does not
  // expect it can cause undefined behavior on some
  // servers and corrupt connection state. Do not
  // re-use the connection for further requests.

  const expectsPayload = (
    method === 'PUT' ||
    method === 'POST' ||
    method === 'PATCH'
  )

  if (body && typeof body.read === 'function') {
    // Try to read EOF in order to get length.
    body.read(0)
  }

  const bodyLength = util.bodyLength(body)

  let contentLength = bodyLength

  if (contentLength === null) {
    contentLength = request.contentLength
  }

  if (contentLength === 0 && !expectsPayload) {
    // https://tools.ietf.org/html/rfc7230#section-3.3.2
    // A user agent SHOULD NOT send a Content-Length header field when
    // the request message does not contain a payload body and the method
    // semantics do not anticipate such a body.

    contentLength = null
  }

  // https://github.com/nodejs/undici/issues/2046
  // A user agent may send a Content-Length header with 0 value, this should be allowed.
  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength !== null && request.contentLength !== contentLength) {
    if (client[kStrictContentLength]) {
      errorRequest(client, request, new RequestContentLengthMismatchError())
      return false
    }

    process.emitWarning(new RequestContentLengthMismatchError())
  }

  const socket = client[kSocket]

  try {
    request.onConnect((err) => {
      if (request.aborted || request.completed) {
        return
      }

      errorRequest(client, request, err || new RequestAbortedError())

      util.destroy(socket, new InformationalError('aborted'))
    })
  } catch (err) {
    errorRequest(client, request, err)
  }

  if (request.aborted) {
    return false
  }

  if (method === 'HEAD') {
    // https://github.com/mcollina/undici/issues/258
    // Close after a HEAD request to interop with misbehaving servers
    // that may send a body in the response.

    socket[kReset] = true
  }

  if (upgrade || method === 'CONNECT') {
    // On CONNECT or upgrade, block pipeline from dispatching further
    // requests on this connection.

    socket[kReset] = true
  }

  if (reset != null) {
    socket[kReset] = reset
  }

  if (client[kMaxRequests] && socket[kCounter]++ >= client[kMaxRequests]) {
    socket[kReset] = true
  }

  if (blocking) {
    socket[kBlocking] = true
  }

  let header = `${method} ${path} HTTP/1.1\r\n`

  if (typeof host === 'string') {
    header += `host: ${host}\r\n`
  } else {
    header += client[kHostHeader]
  }

  if (upgrade) {
    header += `connection: upgrade\r\nupgrade: ${upgrade}\r\n`
  } else if (client[kPipelining] && !socket[kReset]) {
    header += 'connection: keep-alive\r\n'
  } else {
    header += 'connection: close\r\n'
  }

  if (headers) {
    header += headers
  }

  if (channels.sendHeaders.hasSubscribers) {
    channels.sendHeaders.publish({ request, headers: header, socket })
  }

  /* istanbul ignore else: assertion */
  if (!body || bodyLength === 0) {
    if (contentLength === 0) {
      socket.write(`${header}content-length: 0\r\n\r\n`, 'latin1')
    } else {
      assert(contentLength === null, 'no body must not have content length')
      socket.write(`${header}\r\n`, 'latin1')
    }
    request.onRequestSent()
  } else if (util.isBuffer(body)) {
    assert(contentLength === body.byteLength, 'buffer body must have content length')

    socket.cork()
    socket.write(`${header}content-length: ${contentLength}\r\n\r\n`, 'latin1')
    socket.write(body)
    socket.uncork()
    request.onBodySent(body)
    request.onRequestSent()
    if (!expectsPayload) {
      socket[kReset] = true
    }
  } else if (util.isBlobLike(body)) {
    if (typeof body.stream === 'function') {
      writeIterable({ body: body.stream(), client, request, socket, contentLength, header, expectsPayload })
    } else {
      writeBlob({ body, client, request, socket, contentLength, header, expectsPayload })
    }
  } else if (util.isStream(body)) {
    writeStream({ body, client, request, socket, contentLength, header, expectsPayload })
  } else if (util.isIterable(body)) {
    writeIterable({ body, client, request, socket, contentLength, header, expectsPayload })
  } else {
    assert(false)
  }

  return true
}

function writeH2 (client, session, request) {
  const { body, method, path, host, upgrade, expectContinue, signal, headers: reqHeaders } = request

  let headers
  if (typeof reqHeaders === 'string') headers = Request[kHTTP2CopyHeaders](reqHeaders.trim())
  else headers = reqHeaders

  if (upgrade) {
    errorRequest(client, request, new Error('Upgrade not supported for H2'))
    return false
  }

  try {
    // TODO(HTTP/2): Should we call onConnect immediately or on stream ready event?
    request.onConnect((err) => {
      if (request.aborted || request.completed) {
        return
      }

      errorRequest(client, request, err || new RequestAbortedError())
    })
  } catch (err) {
    errorRequest(client, request, err)
  }

  if (request.aborted) {
    return false
  }

  /** @type {import('node:http2').ClientHttp2Stream} */
  let stream
  const h2State = client[kHTTP2SessionState]

  headers[HTTP2_HEADER_AUTHORITY] = host || client[kHost]
  headers[HTTP2_HEADER_METHOD] = method

  if (method === 'CONNECT') {
    session.ref()
    // we are already connected, streams are pending, first request
    // will create a new stream. We trigger a request to create the stream and wait until
    // `ready` event is triggered
    // We disabled endStream to allow the user to write to the stream
    stream = session.request(headers, { endStream: false, signal })

    if (stream.id && !stream.pending) {
      request.onUpgrade(null, null, stream)
      ++h2State.openStreams
    } else {
      stream.once('ready', () => {
        request.onUpgrade(null, null, stream)
        ++h2State.openStreams
      })
    }

    stream.once('close', () => {
      h2State.openStreams -= 1
      // TODO(HTTP/2): unref only if current streams count is 0
      if (h2State.openStreams === 0) session.unref()
    })

    return true
  }

  // https://tools.ietf.org/html/rfc7540#section-8.3
  // :path and :scheme headers must be omited when sending CONNECT

  headers[HTTP2_HEADER_PATH] = path
  headers[HTTP2_HEADER_SCHEME] = 'https'

  // https://tools.ietf.org/html/rfc7231#section-4.3.1
  // https://tools.ietf.org/html/rfc7231#section-4.3.2
  // https://tools.ietf.org/html/rfc7231#section-4.3.5

  // Sending a payload body on a request that does not
  // expect it can cause undefined behavior on some
  // servers and corrupt connection state. Do not
  // re-use the connection for further requests.

  const expectsPayload = (
    method === 'PUT' ||
    method === 'POST' ||
    method === 'PATCH'
  )

  if (body && typeof body.read === 'function') {
    // Try to read EOF in order to get length.
    body.read(0)
  }

  let contentLength = util.bodyLength(body)

  if (contentLength == null) {
    contentLength = request.contentLength
  }

  if (contentLength === 0 || !expectsPayload) {
    // https://tools.ietf.org/html/rfc7230#section-3.3.2
    // A user agent SHOULD NOT send a Content-Length header field when
    // the request message does not contain a payload body and the method
    // semantics do not anticipate such a body.

    contentLength = null
  }

  // https://github.com/nodejs/undici/issues/2046
  // A user agent may send a Content-Length header with 0 value, this should be allowed.
  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength != null && request.contentLength !== contentLength) {
    if (client[kStrictContentLength]) {
      errorRequest(client, request, new RequestContentLengthMismatchError())
      return false
    }

    process.emitWarning(new RequestContentLengthMismatchError())
  }

  if (contentLength != null) {
    assert(body, 'no body must not have content length')
    headers[HTTP2_HEADER_CONTENT_LENGTH] = `${contentLength}`
  }

  session.ref()

  const shouldEndStream = method === 'GET' || method === 'HEAD'
  if (expectContinue) {
    headers[HTTP2_HEADER_EXPECT] = '100-continue'
    stream = session.request(headers, { endStream: shouldEndStream, signal })

    stream.once('continue', writeBodyH2)
  } else {
    stream = session.request(headers, {
      endStream: shouldEndStream,
      signal
    })
    writeBodyH2()
  }

  // Increment counter as we have new several streams open
  ++h2State.openStreams

  stream.once('response', headers => {
    const { [HTTP2_HEADER_STATUS]: statusCode, ...realHeaders } = headers

    if (request.onHeaders(Number(statusCode), realHeaders, stream.resume.bind(stream), '') === false) {
      stream.pause()
    }
  })

  stream.once('end', () => {
    request.onComplete([])
  })

  stream.on('data', (chunk) => {
    if (request.onData(chunk) === false) {
      stream.pause()
    }
  })

  stream.once('close', () => {
    h2State.openStreams -= 1
    // TODO(HTTP/2): unref only if current streams count is 0
    if (h2State.openStreams === 0) {
      session.unref()
    }
  })

  stream.once('error', function (err) {
    if (client[kHTTP2Session] && !client[kHTTP2Session].destroyed && !this.closed && !this.destroyed) {
      h2State.streams -= 1
      util.destroy(stream, err)
    }
  })

  stream.once('frameError', (type, code) => {
    const err = new InformationalError(`HTTP/2: "frameError" received - type ${type}, code ${code}`)
    errorRequest(client, request, err)

    if (client[kHTTP2Session] && !client[kHTTP2Session].destroyed && !this.closed && !this.destroyed) {
      h2State.streams -= 1
      util.destroy(stream, err)
    }
  })

  // stream.on('aborted', () => {
  //   // TODO(HTTP/2): Support aborted
  // })

  // stream.on('timeout', () => {
  //   // TODO(HTTP/2): Support timeout
  // })

  // stream.on('push', headers => {
  //   // TODO(HTTP/2): Suppor push
  // })

  // stream.on('trailers', headers => {
  //   // TODO(HTTP/2): Support trailers
  // })

  return true

  function writeBodyH2 () {
    /* istanbul ignore else: assertion */
    if (!body) {
      request.onRequestSent()
    } else if (util.isBuffer(body)) {
      assert(contentLength === body.byteLength, 'buffer body must have content length')
      stream.cork()
      stream.write(body)
      stream.uncork()
      stream.end()
      request.onBodySent(body)
      request.onRequestSent()
    } else if (util.isBlobLike(body)) {
      if (typeof body.stream === 'function') {
        writeIterable({
          client,
          request,
          contentLength,
          h2stream: stream,
          expectsPayload,
          body: body.stream(),
          socket: client[kSocket],
          header: ''
        })
      } else {
        writeBlob({
          body,
          client,
          request,
          contentLength,
          expectsPayload,
          h2stream: stream,
          header: '',
          socket: client[kSocket]
        })
      }
    } else if (util.isStream(body)) {
      writeStream({
        body,
        client,
        request,
        contentLength,
        expectsPayload,
        socket: client[kSocket],
        h2stream: stream,
        header: ''
      })
    } else if (util.isIterable(body)) {
      writeIterable({
        body,
        client,
        request,
        contentLength,
        expectsPayload,
        header: '',
        h2stream: stream,
        socket: client[kSocket]
      })
    } else {
      assert(false)
    }
  }
}

function writeStream ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {
  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined')

  if (client[kHTTPConnVersion] === 'h2') {
    // For HTTP/2, is enough to pipe the stream
    const pipe = pipeline(
      body,
      h2stream,
      (err) => {
        if (err) {
          util.destroy(body, err)
          util.destroy(h2stream, err)
        } else {
          request.onRequestSent()
        }
      }
    )

    pipe.on('data', onPipeData)
    pipe.once('end', () => {
      pipe.removeListener('data', onPipeData)
      util.destroy(pipe)
    })

    function onPipeData (chunk) {
      request.onBodySent(chunk)
    }

    return
  }

  let finished = false

  const writer = new AsyncWriter({ socket, request, contentLength, client, expectsPayload, header })

  const onData = function (chunk) {
    if (finished) {
      return
    }

    try {
      if (!writer.write(chunk) && this.pause) {
        this.pause()
      }
    } catch (err) {
      util.destroy(this, err)
    }
  }
  const onDrain = function () {
    if (finished) {
      return
    }

    if (body.resume) {
      body.resume()
    }
  }
  const onAbort = function () {
    if (finished) {
      return
    }
    const err = new RequestAbortedError()
    queueMicrotask(() => onFinished(err))
  }
  const onFinished = function (err) {
    if (finished) {
      return
    }

    finished = true

    assert(socket.destroyed || (socket[kWriting] && client[kRunning] <= 1))

    socket
      .off('drain', onDrain)
      .off('error', onFinished)

    body
      .removeListener('data', onData)
      .removeListener('end', onFinished)
      .removeListener('error', onFinished)
      .removeListener('close', onAbort)

    if (!err) {
      try {
        writer.end()
      } catch (er) {
        err = er
      }
    }

    writer.destroy(err)

    if (err && (err.code !== 'UND_ERR_INFO' || err.message !== 'reset')) {
      util.destroy(body, err)
    } else {
      util.destroy(body)
    }
  }

  body
    .on('data', onData)
    .on('end', onFinished)
    .on('error', onFinished)
    .on('close', onAbort)

  if (body.resume) {
    body.resume()
  }

  socket
    .on('drain', onDrain)
    .on('error', onFinished)
}

async function writeBlob ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {
  assert(contentLength === body.size, 'blob body must have content length')

  const isH2 = client[kHTTPConnVersion] === 'h2'
  try {
    if (contentLength != null && contentLength !== body.size) {
      throw new RequestContentLengthMismatchError()
    }

    const buffer = Buffer.from(await body.arrayBuffer())

    if (isH2) {
      h2stream.cork()
      h2stream.write(buffer)
      h2stream.uncork()
    } else {
      socket.cork()
      socket.write(`${header}content-length: ${contentLength}\r\n\r\n`, 'latin1')
      socket.write(buffer)
      socket.uncork()
    }

    request.onBodySent(buffer)
    request.onRequestSent()

    if (!expectsPayload) {
      socket[kReset] = true
    }

    resume(client)
  } catch (err) {
    util.destroy(isH2 ? h2stream : socket, err)
  }
}

async function writeIterable ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {
  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined')

  let callback = null
  function onDrain () {
    if (callback) {
      const cb = callback
      callback = null
      cb()
    }
  }

  const waitForDrain = () => new Promise((resolve, reject) => {
    assert(callback === null)

    if (socket[kError]) {
      reject(socket[kError])
    } else {
      callback = resolve
    }
  })

  if (client[kHTTPConnVersion] === 'h2') {
    h2stream
      .on('close', onDrain)
      .on('drain', onDrain)

    try {
      // It's up to the user to somehow abort the async iterable.
      for await (const chunk of body) {
        if (socket[kError]) {
          throw socket[kError]
        }

        const res = h2stream.write(chunk)
        request.onBodySent(chunk)
        if (!res) {
          await waitForDrain()
        }
      }
    } catch (err) {
      h2stream.destroy(err)
    } finally {
      request.onRequestSent()
      h2stream.end()
      h2stream
        .off('close', onDrain)
        .off('drain', onDrain)
    }

    return
  }

  socket
    .on('close', onDrain)
    .on('drain', onDrain)

  const writer = new AsyncWriter({ socket, request, contentLength, client, expectsPayload, header })
  try {
    // It's up to the user to somehow abort the async iterable.
    for await (const chunk of body) {
      if (socket[kError]) {
        throw socket[kError]
      }

      if (!writer.write(chunk)) {
        await waitForDrain()
      }
    }

    writer.end()
  } catch (err) {
    writer.destroy(err)
  } finally {
    socket
      .off('close', onDrain)
      .off('drain', onDrain)
  }
}

class AsyncWriter {
  constructor ({ socket, request, contentLength, client, expectsPayload, header }) {
    this.socket = socket
    this.request = request
    this.contentLength = contentLength
    this.client = client
    this.bytesWritten = 0
    this.expectsPayload = expectsPayload
    this.header = header

    socket[kWriting] = true
  }

  write (chunk) {
    const { socket, request, contentLength, client, bytesWritten, expectsPayload, header } = this

    if (socket[kError]) {
      throw socket[kError]
    }

    if (socket.destroyed) {
      return false
    }

    const len = Buffer.byteLength(chunk)
    if (!len) {
      return true
    }

    // We should defer writing chunks.
    if (contentLength !== null && bytesWritten + len > contentLength) {
      if (client[kStrictContentLength]) {
        throw new RequestContentLengthMismatchError()
      }

      process.emitWarning(new RequestContentLengthMismatchError())
    }

    socket.cork()

    if (bytesWritten === 0) {
      if (!expectsPayload) {
        socket[kReset] = true
      }

      if (contentLength === null) {
        socket.write(`${header}transfer-encoding: chunked\r\n`, 'latin1')
      } else {
        socket.write(`${header}content-length: ${contentLength}\r\n\r\n`, 'latin1')
      }
    }

    if (contentLength === null) {
      socket.write(`\r\n${len.toString(16)}\r\n`, 'latin1')
    }

    this.bytesWritten += len

    const ret = socket.write(chunk)

    socket.uncork()

    request.onBodySent(chunk)

    if (!ret) {
      if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {
        // istanbul ignore else: only for jest
        if (socket[kParser].timeout.refresh) {
          socket[kParser].timeout.refresh()
        }
      }
    }

    return ret
  }

  end () {
    const { socket, contentLength, client, bytesWritten, expectsPayload, header, request } = this
    request.onRequestSent()

    socket[kWriting] = false

    if (socket[kError]) {
      throw socket[kError]
    }

    if (socket.destroyed) {
      return
    }

    if (bytesWritten === 0) {
      if (expectsPayload) {
        // https://tools.ietf.org/html/rfc7230#section-3.3.2
        // A user agent SHOULD send a Content-Length in a request message when
        // no Transfer-Encoding is sent and the request method defines a meaning
        // for an enclosed payload body.

        socket.write(`${header}content-length: 0\r\n\r\n`, 'latin1')
      } else {
        socket.write(`${header}\r\n`, 'latin1')
      }
    } else if (contentLength === null) {
      socket.write('\r\n0\r\n\r\n', 'latin1')
    }

    if (contentLength !== null && bytesWritten !== contentLength) {
      if (client[kStrictContentLength]) {
        throw new RequestContentLengthMismatchError()
      } else {
        process.emitWarning(new RequestContentLengthMismatchError())
      }
    }

    if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {
      // istanbul ignore else: only for jest
      if (socket[kParser].timeout.refresh) {
        socket[kParser].timeout.refresh()
      }
    }

    resume(client)
  }

  destroy (err) {
    const { socket, client } = this

    socket[kWriting] = false

    if (err) {
      assert(client[kRunning] <= 1, 'pipeline should only contain this request')
      util.destroy(socket, err)
    }
  }
}

function errorRequest (client, request, err) {
  try {
    request.onError(err)
    assert(request.aborted)
  } catch (err) {
    client.emit('error', err)
  }
}

module.exports = Client


/***/ }),

/***/ 3194:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


/* istanbul ignore file: only for Node 12 */

const { kConnected, kSize } = __nccwpck_require__(6443)

class CompatWeakRef {
  constructor (value) {
    this.value = value
  }

  deref () {
    return this.value[kConnected] === 0 && this.value[kSize] === 0
      ? undefined
      : this.value
  }
}

class CompatFinalizer {
  constructor (finalizer) {
    this.finalizer = finalizer
  }

  register (dispatcher, key) {
    if (dispatcher.on) {
      dispatcher.on('disconnect', () => {
        if (dispatcher[kConnected] === 0 && dispatcher[kSize] === 0) {
          this.finalizer(key)
        }
      })
    }
  }
}

module.exports = function () {
  // FIXME: remove workaround when the Node bug is fixed
  // https://github.com/nodejs/node/issues/49344#issuecomment-1741776308
  if (process.env.NODE_V8_COVERAGE) {
    return {
      WeakRef: CompatWeakRef,
      FinalizationRegistry: CompatFinalizer
    }
  }
  return {
    WeakRef: global.WeakRef || CompatWeakRef,
    FinalizationRegistry: global.FinalizationRegistry || CompatFinalizer
  }
}


/***/ }),

/***/ 9237:
/***/ ((module) => {

"use strict";


// https://wicg.github.io/cookie-store/#cookie-maximum-attribute-value-size
const maxAttributeValueSize = 1024

// https://wicg.github.io/cookie-store/#cookie-maximum-name-value-pair-size
const maxNameValuePairSize = 4096

module.exports = {
  maxAttributeValueSize,
  maxNameValuePairSize
}


/***/ }),

/***/ 3168:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { parseSetCookie } = __nccwpck_require__(8915)
const { stringify } = __nccwpck_require__(3834)
const { webidl } = __nccwpck_require__(4222)
const { Headers } = __nccwpck_require__(6349)

/**
 * @typedef {Object} Cookie
 * @property {string} name
 * @property {string} value
 * @property {Date|number|undefined} expires
 * @property {number|undefined} maxAge
 * @property {string|undefined} domain
 * @property {string|undefined} path
 * @property {boolean|undefined} secure
 * @property {boolean|undefined} httpOnly
 * @property {'Strict'|'Lax'|'None'} sameSite
 * @property {string[]} unparsed
 */

/**
 * @param {Headers} headers
 * @returns {Record<string, string>}
 */
function getCookies (headers) {
  webidl.argumentLengthCheck(arguments, 1, { header: 'getCookies' })

  webidl.brandCheck(headers, Headers, { strict: false })

  const cookie = headers.get('cookie')
  const out = {}

  if (!cookie) {
    return out
  }

  for (const piece of cookie.split(';')) {
    const [name, ...value] = piece.split('=')

    out[name.trim()] = value.join('=')
  }

  return out
}

/**
 * @param {Headers} headers
 * @param {string} name
 * @param {{ path?: string, domain?: string }|undefined} attributes
 * @returns {void}
 */
function deleteCookie (headers, name, attributes) {
  webidl.argumentLengthCheck(arguments, 2, { header: 'deleteCookie' })

  webidl.brandCheck(headers, Headers, { strict: false })

  name = webidl.converters.DOMString(name)
  attributes = webidl.converters.DeleteCookieAttributes(attributes)

  // Matches behavior of
  // https://github.com/denoland/deno_std/blob/63827b16330b82489a04614027c33b7904e08be5/http/cookie.ts#L278
  setCookie(headers, {
    name,
    value: '',
    expires: new Date(0),
    ...attributes
  })
}

/**
 * @param {Headers} headers
 * @returns {Cookie[]}
 */
function getSetCookies (headers) {
  webidl.argumentLengthCheck(arguments, 1, { header: 'getSetCookies' })

  webidl.brandCheck(headers, Headers, { strict: false })

  const cookies = headers.getSetCookie()

  if (!cookies) {
    return []
  }

  return cookies.map((pair) => parseSetCookie(pair))
}

/**
 * @param {Headers} headers
 * @param {Cookie} cookie
 * @returns {void}
 */
function setCookie (headers, cookie) {
  webidl.argumentLengthCheck(arguments, 2, { header: 'setCookie' })

  webidl.brandCheck(headers, Headers, { strict: false })

  cookie = webidl.converters.Cookie(cookie)

  const str = stringify(cookie)

  if (str) {
    headers.append('Set-Cookie', stringify(cookie))
  }
}

webidl.converters.DeleteCookieAttributes = webidl.dictionaryConverter([
  {
    converter: webidl.nullableConverter(webidl.converters.DOMString),
    key: 'path',
    defaultValue: null
  },
  {
    converter: webidl.nullableConverter(webidl.converters.DOMString),
    key: 'domain',
    defaultValue: null
  }
])

webidl.converters.Cookie = webidl.dictionaryConverter([
  {
    converter: webidl.converters.DOMString,
    key: 'name'
  },
  {
    converter: webidl.converters.DOMString,
    key: 'value'
  },
  {
    converter: webidl.nullableConverter((value) => {
      if (typeof value === 'number') {
        return webidl.converters['unsigned long long'](value)
      }

      return new Date(value)
    }),
    key: 'expires',
    defaultValue: null
  },
  {
    converter: webidl.nullableConverter(webidl.converters['long long']),
    key: 'maxAge',
    defaultValue: null
  },
  {
    converter: webidl.nullableConverter(webidl.converters.DOMString),
    key: 'domain',
    defaultValue: null
  },
  {
    converter: webidl.nullableConverter(webidl.converters.DOMString),
    key: 'path',
    defaultValue: null
  },
  {
    converter: webidl.nullableConverter(webidl.converters.boolean),
    key: 'secure',
    defaultValue: null
  },
  {
    converter: webidl.nullableConverter(webidl.converters.boolean),
    key: 'httpOnly',
    defaultValue: null
  },
  {
    converter: webidl.converters.USVString,
    key: 'sameSite',
    allowedValues: ['Strict', 'Lax', 'None']
  },
  {
    converter: webidl.sequenceConverter(webidl.converters.DOMString),
    key: 'unparsed',
    defaultValue: []
  }
])

module.exports = {
  getCookies,
  deleteCookie,
  getSetCookies,
  setCookie
}


/***/ }),

/***/ 8915:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { maxNameValuePairSize, maxAttributeValueSize } = __nccwpck_require__(9237)
const { isCTLExcludingHtab } = __nccwpck_require__(3834)
const { collectASequenceOfCodePointsFast } = __nccwpck_require__(4322)
const assert = __nccwpck_require__(2613)

/**
 * @description Parses the field-value attributes of a set-cookie header string.
 * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4
 * @param {string} header
 * @returns if the header is invalid, null will be returned
 */
function parseSetCookie (header) {
  // 1. If the set-cookie-string contains a %x00-08 / %x0A-1F / %x7F
  //    character (CTL characters excluding HTAB): Abort these steps and
  //    ignore the set-cookie-string entirely.
  if (isCTLExcludingHtab(header)) {
    return null
  }

  let nameValuePair = ''
  let unparsedAttributes = ''
  let name = ''
  let value = ''

  // 2. If the set-cookie-string contains a %x3B (";") character:
  if (header.includes(';')) {
    // 1. The name-value-pair string consists of the characters up to,
    //    but not including, the first %x3B (";"), and the unparsed-
    //    attributes consist of the remainder of the set-cookie-string
    //    (including the %x3B (";") in question).
    const position = { position: 0 }

    nameValuePair = collectASequenceOfCodePointsFast(';', header, position)
    unparsedAttributes = header.slice(position.position)
  } else {
    // Otherwise:

    // 1. The name-value-pair string consists of all the characters
    //    contained in the set-cookie-string, and the unparsed-
    //    attributes is the empty string.
    nameValuePair = header
  }

  // 3. If the name-value-pair string lacks a %x3D ("=") character, then
  //    the name string is empty, and the value string is the value of
  //    name-value-pair.
  if (!nameValuePair.includes('=')) {
    value = nameValuePair
  } else {
    //    Otherwise, the name string consists of the characters up to, but
    //    not including, the first %x3D ("=") character, and the (possibly
    //    empty) value string consists of the characters after the first
    //    %x3D ("=") character.
    const position = { position: 0 }
    name = collectASequenceOfCodePointsFast(
      '=',
      nameValuePair,
      position
    )
    value = nameValuePair.slice(position.position + 1)
  }

  // 4. Remove any leading or trailing WSP characters from the name
  //    string and the value string.
  name = name.trim()
  value = value.trim()

  // 5. If the sum of the lengths of the name string and the value string
  //    is more than 4096 octets, abort these steps and ignore the set-
  //    cookie-string entirely.
  if (name.length + value.length > maxNameValuePairSize) {
    return null
  }

  // 6. The cookie-name is the name string, and the cookie-value is the
  //    value string.
  return {
    name, value, ...parseUnparsedAttributes(unparsedAttributes)
  }
}

/**
 * Parses the remaining attributes of a set-cookie header
 * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4
 * @param {string} unparsedAttributes
 * @param {[Object.<string, unknown>]={}} cookieAttributeList
 */
function parseUnparsedAttributes (unparsedAttributes, cookieAttributeList = {}) {
  // 1. If the unparsed-attributes string is empty, skip the rest of
  //    these steps.
  if (unparsedAttributes.length === 0) {
    return cookieAttributeList
  }

  // 2. Discard the first character of the unparsed-attributes (which
  //    will be a %x3B (";") character).
  assert(unparsedAttributes[0] === ';')
  unparsedAttributes = unparsedAttributes.slice(1)

  let cookieAv = ''

  // 3. If the remaining unparsed-attributes contains a %x3B (";")
  //    character:
  if (unparsedAttributes.includes(';')) {
    // 1. Consume the characters of the unparsed-attributes up to, but
    //    not including, the first %x3B (";") character.
    cookieAv = collectASequenceOfCodePointsFast(
      ';',
      unparsedAttributes,
      { position: 0 }
    )
    unparsedAttributes = unparsedAttributes.slice(cookieAv.length)
  } else {
    // Otherwise:

    // 1. Consume the remainder of the unparsed-attributes.
    cookieAv = unparsedAttributes
    unparsedAttributes = ''
  }

  // Let the cookie-av string be the characters consumed in this step.

  let attributeName = ''
  let attributeValue = ''

  // 4. If the cookie-av string contains a %x3D ("=") character:
  if (cookieAv.includes('=')) {
    // 1. The (possibly empty) attribute-name string consists of the
    //    characters up to, but not including, the first %x3D ("=")
    //    character, and the (possibly empty) attribute-value string
    //    consists of the characters after the first %x3D ("=")
    //    character.
    const position = { position: 0 }

    attributeName = collectASequenceOfCodePointsFast(
      '=',
      cookieAv,
      position
    )
    attributeValue = cookieAv.slice(position.position + 1)
  } else {
    // Otherwise:

    // 1. The attribute-name string consists of the entire cookie-av
    //    string, and the attribute-value string is empty.
    attributeName = cookieAv
  }

  // 5. Remove any leading or trailing WSP characters from the attribute-
  //    name string and the attribute-value string.
  attributeName = attributeName.trim()
  attributeValue = attributeValue.trim()

  // 6. If the attribute-value is longer than 1024 octets, ignore the
  //    cookie-av string and return to Step 1 of this algorithm.
  if (attributeValue.length > maxAttributeValueSize) {
    return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
  }

  // 7. Process the attribute-name and attribute-value according to the
  //    requirements in the following subsections.  (Notice that
  //    attributes with unrecognized attribute-names are ignored.)
  const attributeNameLowercase = attributeName.toLowerCase()

  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.1
  // If the attribute-name case-insensitively matches the string
  // "Expires", the user agent MUST process the cookie-av as follows.
  if (attributeNameLowercase === 'expires') {
    // 1. Let the expiry-time be the result of parsing the attribute-value
    //    as cookie-date (see Section 5.1.1).
    const expiryTime = new Date(attributeValue)

    // 2. If the attribute-value failed to parse as a cookie date, ignore
    //    the cookie-av.

    cookieAttributeList.expires = expiryTime
  } else if (attributeNameLowercase === 'max-age') {
    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.2
    // If the attribute-name case-insensitively matches the string "Max-
    // Age", the user agent MUST process the cookie-av as follows.

    // 1. If the first character of the attribute-value is not a DIGIT or a
    //    "-" character, ignore the cookie-av.
    const charCode = attributeValue.charCodeAt(0)

    if ((charCode < 48 || charCode > 57) && attributeValue[0] !== '-') {
      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
    }

    // 2. If the remainder of attribute-value contains a non-DIGIT
    //    character, ignore the cookie-av.
    if (!/^\d+$/.test(attributeValue)) {
      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
    }

    // 3. Let delta-seconds be the attribute-value converted to an integer.
    const deltaSeconds = Number(attributeValue)

    // 4. Let cookie-age-limit be the maximum age of the cookie (which
    //    SHOULD be 400 days or less, see Section 4.1.2.2).

    // 5. Set delta-seconds to the smaller of its present value and cookie-
    //    age-limit.
    // deltaSeconds = Math.min(deltaSeconds * 1000, maxExpiresMs)

    // 6. If delta-seconds is less than or equal to zero (0), let expiry-
    //    time be the earliest representable date and time.  Otherwise, let
    //    the expiry-time be the current date and time plus delta-seconds
    //    seconds.
    // const expiryTime = deltaSeconds <= 0 ? Date.now() : Date.now() + deltaSeconds

    // 7. Append an attribute to the cookie-attribute-list with an
    //    attribute-name of Max-Age and an attribute-value of expiry-time.
    cookieAttributeList.maxAge = deltaSeconds
  } else if (attributeNameLowercase === 'domain') {
    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.3
    // If the attribute-name case-insensitively matches the string "Domain",
    // the user agent MUST process the cookie-av as follows.

    // 1. Let cookie-domain be the attribute-value.
    let cookieDomain = attributeValue

    // 2. If cookie-domain starts with %x2E ("."), let cookie-domain be
    //    cookie-domain without its leading %x2E (".").
    if (cookieDomain[0] === '.') {
      cookieDomain = cookieDomain.slice(1)
    }

    // 3. Convert the cookie-domain to lower case.
    cookieDomain = cookieDomain.toLowerCase()

    // 4. Append an attribute to the cookie-attribute-list with an
    //    attribute-name of Domain and an attribute-value of cookie-domain.
    cookieAttributeList.domain = cookieDomain
  } else if (attributeNameLowercase === 'path') {
    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.4
    // If the attribute-name case-insensitively matches the string "Path",
    // the user agent MUST process the cookie-av as follows.

    // 1. If the attribute-value is empty or if the first character of the
    //    attribute-value is not %x2F ("/"):
    let cookiePath = ''
    if (attributeValue.length === 0 || attributeValue[0] !== '/') {
      // 1. Let cookie-path be the default-path.
      cookiePath = '/'
    } else {
      // Otherwise:

      // 1. Let cookie-path be the attribute-value.
      cookiePath = attributeValue
    }

    // 2. Append an attribute to the cookie-attribute-list with an
    //    attribute-name of Path and an attribute-value of cookie-path.
    cookieAttributeList.path = cookiePath
  } else if (attributeNameLowercase === 'secure') {
    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.5
    // If the attribute-name case-insensitively matches the string "Secure",
    // the user agent MUST append an attribute to the cookie-attribute-list
    // with an attribute-name of Secure and an empty attribute-value.

    cookieAttributeList.secure = true
  } else if (attributeNameLowercase === 'httponly') {
    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.6
    // If the attribute-name case-insensitively matches the string
    // "HttpOnly", the user agent MUST append an attribute to the cookie-
    // attribute-list with an attribute-name of HttpOnly and an empty
    // attribute-value.

    cookieAttributeList.httpOnly = true
  } else if (attributeNameLowercase === 'samesite') {
    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.7
    // If the attribute-name case-insensitively matches the string
    // "SameSite", the user agent MUST process the cookie-av as follows:

    // 1. Let enforcement be "Default".
    let enforcement = 'Default'

    const attributeValueLowercase = attributeValue.toLowerCase()
    // 2. If cookie-av's attribute-value is a case-insensitive match for
    //    "None", set enforcement to "None".
    if (attributeValueLowercase.includes('none')) {
      enforcement = 'None'
    }

    // 3. If cookie-av's attribute-value is a case-insensitive match for
    //    "Strict", set enforcement to "Strict".
    if (attributeValueLowercase.includes('strict')) {
      enforcement = 'Strict'
    }

    // 4. If cookie-av's attribute-value is a case-insensitive match for
    //    "Lax", set enforcement to "Lax".
    if (attributeValueLowercase.includes('lax')) {
      enforcement = 'Lax'
    }

    // 5. Append an attribute to the cookie-attribute-list with an
    //    attribute-name of "SameSite" and an attribute-value of
    //    enforcement.
    cookieAttributeList.sameSite = enforcement
  } else {
    cookieAttributeList.unparsed ??= []

    cookieAttributeList.unparsed.push(`${attributeName}=${attributeValue}`)
  }

  // 8. Return to Step 1 of this algorithm.
  return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
}

module.exports = {
  parseSetCookie,
  parseUnparsedAttributes
}


/***/ }),

/***/ 3834:
/***/ ((module) => {

"use strict";


/**
 * @param {string} value
 * @returns {boolean}
 */
function isCTLExcludingHtab (value) {
  if (value.length === 0) {
    return false
  }

  for (const char of value) {
    const code = char.charCodeAt(0)

    if (
      (code >= 0x00 || code <= 0x08) ||
      (code >= 0x0A || code <= 0x1F) ||
      code === 0x7F
    ) {
      return false
    }
  }
}

/**
 CHAR           = <any US-ASCII character (octets 0 - 127)>
 token          = 1*<any CHAR except CTLs or separators>
 separators     = "(" | ")" | "<" | ">" | "@"
                | "," | ";" | ":" | "\" | <">
                | "/" | "[" | "]" | "?" | "="
                | "{" | "}" | SP | HT
 * @param {string} name
 */
function validateCookieName (name) {
  for (const char of name) {
    const code = char.charCodeAt(0)

    if (
      (code <= 0x20 || code > 0x7F) ||
      char === '(' ||
      char === ')' ||
      char === '>' ||
      char === '<' ||
      char === '@' ||
      char === ',' ||
      char === ';' ||
      char === ':' ||
      char === '\\' ||
      char === '"' ||
      char === '/' ||
      char === '[' ||
      char === ']' ||
      char === '?' ||
      char === '=' ||
      char === '{' ||
      char === '}'
    ) {
      throw new Error('Invalid cookie name')
    }
  }
}

/**
 cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )
 cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E
                       ; US-ASCII characters excluding CTLs,
                       ; whitespace DQUOTE, comma, semicolon,
                       ; and backslash
 * @param {string} value
 */
function validateCookieValue (value) {
  for (const char of value) {
    const code = char.charCodeAt(0)

    if (
      code < 0x21 || // exclude CTLs (0-31)
      code === 0x22 ||
      code === 0x2C ||
      code === 0x3B ||
      code === 0x5C ||
      code > 0x7E // non-ascii
    ) {
      throw new Error('Invalid header value')
    }
  }
}

/**
 * path-value        = <any CHAR except CTLs or ";">
 * @param {string} path
 */
function validateCookiePath (path) {
  for (const char of path) {
    const code = char.charCodeAt(0)

    if (code < 0x21 || char === ';') {
      throw new Error('Invalid cookie path')
    }
  }
}

/**
 * I have no idea why these values aren't allowed to be honest,
 * but Deno tests these. - Khafra
 * @param {string} domain
 */
function validateCookieDomain (domain) {
  if (
    domain.startsWith('-') ||
    domain.endsWith('.') ||
    domain.endsWith('-')
  ) {
    throw new Error('Invalid cookie domain')
  }
}

/**
 * @see https://www.rfc-editor.org/rfc/rfc7231#section-7.1.1.1
 * @param {number|Date} date
  IMF-fixdate  = day-name "," SP date1 SP time-of-day SP GMT
  ; fixed length/zone/capitalization subset of the format
  ; see Section 3.3 of [RFC5322]

  day-name     = %x4D.6F.6E ; "Mon", case-sensitive
              / %x54.75.65 ; "Tue", case-sensitive
              / %x57.65.64 ; "Wed", case-sensitive
              / %x54.68.75 ; "Thu", case-sensitive
              / %x46.72.69 ; "Fri", case-sensitive
              / %x53.61.74 ; "Sat", case-sensitive
              / %x53.75.6E ; "Sun", case-sensitive
  date1        = day SP month SP year
                  ; e.g., 02 Jun 1982

  day          = 2DIGIT
  month        = %x4A.61.6E ; "Jan", case-sensitive
              / %x46.65.62 ; "Feb", case-sensitive
              / %x4D.61.72 ; "Mar", case-sensitive
              / %x41.70.72 ; "Apr", case-sensitive
              / %x4D.61.79 ; "May", case-sensitive
              / %x4A.75.6E ; "Jun", case-sensitive
              / %x4A.75.6C ; "Jul", case-sensitive
              / %x41.75.67 ; "Aug", case-sensitive
              / %x53.65.70 ; "Sep", case-sensitive
              / %x4F.63.74 ; "Oct", case-sensitive
              / %x4E.6F.76 ; "Nov", case-sensitive
              / %x44.65.63 ; "Dec", case-sensitive
  year         = 4DIGIT

  GMT          = %x47.4D.54 ; "GMT", case-sensitive

  time-of-day  = hour ":" minute ":" second
              ; 00:00:00 - 23:59:60 (leap second)

  hour         = 2DIGIT
  minute       = 2DIGIT
  second       = 2DIGIT
 */
function toIMFDate (date) {
  if (typeof date === 'number') {
    date = new Date(date)
  }

  const days = [
    'Sun', 'Mon', 'Tue', 'Wed',
    'Thu', 'Fri', 'Sat'
  ]

  const months = [
    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'
  ]

  const dayName = days[date.getUTCDay()]
  const day = date.getUTCDate().toString().padStart(2, '0')
  const month = months[date.getUTCMonth()]
  const year = date.getUTCFullYear()
  const hour = date.getUTCHours().toString().padStart(2, '0')
  const minute = date.getUTCMinutes().toString().padStart(2, '0')
  const second = date.getUTCSeconds().toString().padStart(2, '0')

  return `${dayName}, ${day} ${month} ${year} ${hour}:${minute}:${second} GMT`
}

/**
 max-age-av        = "Max-Age=" non-zero-digit *DIGIT
                       ; In practice, both expires-av and max-age-av
                       ; are limited to dates representable by the
                       ; user agent.
 * @param {number} maxAge
 */
function validateCookieMaxAge (maxAge) {
  if (maxAge < 0) {
    throw new Error('Invalid cookie max-age')
  }
}

/**
 * @see https://www.rfc-editor.org/rfc/rfc6265#section-4.1.1
 * @param {import('./index').Cookie} cookie
 */
function stringify (cookie) {
  if (cookie.name.length === 0) {
    return null
  }

  validateCookieName(cookie.name)
  validateCookieValue(cookie.value)

  const out = [`${cookie.name}=${cookie.value}`]

  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.1
  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.2
  if (cookie.name.startsWith('__Secure-')) {
    cookie.secure = true
  }

  if (cookie.name.startsWith('__Host-')) {
    cookie.secure = true
    cookie.domain = null
    cookie.path = '/'
  }

  if (cookie.secure) {
    out.push('Secure')
  }

  if (cookie.httpOnly) {
    out.push('HttpOnly')
  }

  if (typeof cookie.maxAge === 'number') {
    validateCookieMaxAge(cookie.maxAge)
    out.push(`Max-Age=${cookie.maxAge}`)
  }

  if (cookie.domain) {
    validateCookieDomain(cookie.domain)
    out.push(`Domain=${cookie.domain}`)
  }

  if (cookie.path) {
    validateCookiePath(cookie.path)
    out.push(`Path=${cookie.path}`)
  }

  if (cookie.expires && cookie.expires.toString() !== 'Invalid Date') {
    out.push(`Expires=${toIMFDate(cookie.expires)}`)
  }

  if (cookie.sameSite) {
    out.push(`SameSite=${cookie.sameSite}`)
  }

  for (const part of cookie.unparsed) {
    if (!part.includes('=')) {
      throw new Error('Invalid unparsed')
    }

    const [key, ...value] = part.split('=')

    out.push(`${key.trim()}=${value.join('=')}`)
  }

  return out.join('; ')
}

module.exports = {
  isCTLExcludingHtab,
  validateCookieName,
  validateCookiePath,
  validateCookieValue,
  toIMFDate,
  stringify
}


/***/ }),

/***/ 9136:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const net = __nccwpck_require__(9278)
const assert = __nccwpck_require__(2613)
const util = __nccwpck_require__(3440)
const { InvalidArgumentError, ConnectTimeoutError } = __nccwpck_require__(8707)

let tls // include tls conditionally since it is not always available

// TODO: session re-use does not wait for the first
// connection to resolve the session and might therefore
// resolve the same servername multiple times even when
// re-use is enabled.

let SessionCache
// FIXME: remove workaround when the Node bug is fixed
// https://github.com/nodejs/node/issues/49344#issuecomment-1741776308
if (global.FinalizationRegistry && !process.env.NODE_V8_COVERAGE) {
  SessionCache = class WeakSessionCache {
    constructor (maxCachedSessions) {
      this._maxCachedSessions = maxCachedSessions
      this._sessionCache = new Map()
      this._sessionRegistry = new global.FinalizationRegistry((key) => {
        if (this._sessionCache.size < this._maxCachedSessions) {
          return
        }

        const ref = this._sessionCache.get(key)
        if (ref !== undefined && ref.deref() === undefined) {
          this._sessionCache.delete(key)
        }
      })
    }

    get (sessionKey) {
      const ref = this._sessionCache.get(sessionKey)
      return ref ? ref.deref() : null
    }

    set (sessionKey, session) {
      if (this._maxCachedSessions === 0) {
        return
      }

      this._sessionCache.set(sessionKey, new WeakRef(session))
      this._sessionRegistry.register(session, sessionKey)
    }
  }
} else {
  SessionCache = class SimpleSessionCache {
    constructor (maxCachedSessions) {
      this._maxCachedSessions = maxCachedSessions
      this._sessionCache = new Map()
    }

    get (sessionKey) {
      return this._sessionCache.get(sessionKey)
    }

    set (sessionKey, session) {
      if (this._maxCachedSessions === 0) {
        return
      }

      if (this._sessionCache.size >= this._maxCachedSessions) {
        // remove the oldest session
        const { value: oldestKey } = this._sessionCache.keys().next()
        this._sessionCache.delete(oldestKey)
      }

      this._sessionCache.set(sessionKey, session)
    }
  }
}

function buildConnector ({ allowH2, maxCachedSessions, socketPath, timeout, ...opts }) {
  if (maxCachedSessions != null && (!Number.isInteger(maxCachedSessions) || maxCachedSessions < 0)) {
    throw new InvalidArgumentError('maxCachedSessions must be a positive integer or zero')
  }

  const options = { path: socketPath, ...opts }
  const sessionCache = new SessionCache(maxCachedSessions == null ? 100 : maxCachedSessions)
  timeout = timeout == null ? 10e3 : timeout
  allowH2 = allowH2 != null ? allowH2 : false
  return function connect ({ hostname, host, protocol, port, servername, localAddress, httpSocket }, callback) {
    let socket
    if (protocol === 'https:') {
      if (!tls) {
        tls = __nccwpck_require__(4756)
      }
      servername = servername || options.servername || util.getServerName(host) || null

      const sessionKey = servername || hostname
      const session = sessionCache.get(sessionKey) || null

      assert(sessionKey)

      socket = tls.connect({
        highWaterMark: 16384, // TLS in node can't have bigger HWM anyway...
        ...options,
        servername,
        session,
        localAddress,
        // TODO(HTTP/2): Add support for h2c
        ALPNProtocols: allowH2 ? ['http/1.1', 'h2'] : ['http/1.1'],
        socket: httpSocket, // upgrade socket connection
        port: port || 443,
        host: hostname
      })

      socket
        .on('session', function (session) {
          // TODO (fix): Can a session become invalid once established? Don't think so?
          sessionCache.set(sessionKey, session)
        })
    } else {
      assert(!httpSocket, 'httpSocket can only be sent on TLS update')
      socket = net.connect({
        highWaterMark: 64 * 1024, // Same as nodejs fs streams.
        ...options,
        localAddress,
        port: port || 80,
        host: hostname
      })
    }

    // Set TCP keep alive options on the socket here instead of in connect() for the case of assigning the socket
    if (options.keepAlive == null || options.keepAlive) {
      const keepAliveInitialDelay = options.keepAliveInitialDelay === undefined ? 60e3 : options.keepAliveInitialDelay
      socket.setKeepAlive(true, keepAliveInitialDelay)
    }

    const cancelTimeout = setupTimeout(() => onConnectTimeout(socket), timeout)

    socket
      .setNoDelay(true)
      .once(protocol === 'https:' ? 'secureConnect' : 'connect', function () {
        cancelTimeout()

        if (callback) {
          const cb = callback
          callback = null
          cb(null, this)
        }
      })
      .on('error', function (err) {
        cancelTimeout()

        if (callback) {
          const cb = callback
          callback = null
          cb(err)
        }
      })

    return socket
  }
}

function setupTimeout (onConnectTimeout, timeout) {
  if (!timeout) {
    return () => {}
  }

  let s1 = null
  let s2 = null
  const timeoutId = setTimeout(() => {
    // setImmediate is added to make sure that we priotorise socket error events over timeouts
    s1 = setImmediate(() => {
      if (process.platform === 'win32') {
        // Windows needs an extra setImmediate probably due to implementation differences in the socket logic
        s2 = setImmediate(() => onConnectTimeout())
      } else {
        onConnectTimeout()
      }
    })
  }, timeout)
  return () => {
    clearTimeout(timeoutId)
    clearImmediate(s1)
    clearImmediate(s2)
  }
}

function onConnectTimeout (socket) {
  util.destroy(socket, new ConnectTimeoutError())
}

module.exports = buildConnector


/***/ }),

/***/ 735:
/***/ ((module) => {

"use strict";


/** @type {Record<string, string | undefined>} */
const headerNameLowerCasedRecord = {}

// https://developer.mozilla.org/docs/Web/HTTP/Headers
const wellknownHeaderNames = [
  'Accept',
  'Accept-Encoding',
  'Accept-Language',
  'Accept-Ranges',
  'Access-Control-Allow-Credentials',
  'Access-Control-Allow-Headers',
  'Access-Control-Allow-Methods',
  'Access-Control-Allow-Origin',
  'Access-Control-Expose-Headers',
  'Access-Control-Max-Age',
  'Access-Control-Request-Headers',
  'Access-Control-Request-Method',
  'Age',
  'Allow',
  'Alt-Svc',
  'Alt-Used',
  'Authorization',
  'Cache-Control',
  'Clear-Site-Data',
  'Connection',
  'Content-Disposition',
  'Content-Encoding',
  'Content-Language',
  'Content-Length',
  'Content-Location',
  'Content-Range',
  'Content-Security-Policy',
  'Content-Security-Policy-Report-Only',
  'Content-Type',
  'Cookie',
  'Cross-Origin-Embedder-Policy',
  'Cross-Origin-Opener-Policy',
  'Cross-Origin-Resource-Policy',
  'Date',
  'Device-Memory',
  'Downlink',
  'ECT',
  'ETag',
  'Expect',
  'Expect-CT',
  'Expires',
  'Forwarded',
  'From',
  'Host',
  'If-Match',
  'If-Modified-Since',
  'If-None-Match',
  'If-Range',
  'If-Unmodified-Since',
  'Keep-Alive',
  'Last-Modified',
  'Link',
  'Location',
  'Max-Forwards',
  'Origin',
  'Permissions-Policy',
  'Pragma',
  'Proxy-Authenticate',
  'Proxy-Authorization',
  'RTT',
  'Range',
  'Referer',
  'Referrer-Policy',
  'Refresh',
  'Retry-After',
  'Sec-WebSocket-Accept',
  'Sec-WebSocket-Extensions',
  'Sec-WebSocket-Key',
  'Sec-WebSocket-Protocol',
  'Sec-WebSocket-Version',
  'Server',
  'Server-Timing',
  'Service-Worker-Allowed',
  'Service-Worker-Navigation-Preload',
  'Set-Cookie',
  'SourceMap',
  'Strict-Transport-Security',
  'Supports-Loading-Mode',
  'TE',
  'Timing-Allow-Origin',
  'Trailer',
  'Transfer-Encoding',
  'Upgrade',
  'Upgrade-Insecure-Requests',
  'User-Agent',
  'Vary',
  'Via',
  'WWW-Authenticate',
  'X-Content-Type-Options',
  'X-DNS-Prefetch-Control',
  'X-Frame-Options',
  'X-Permitted-Cross-Domain-Policies',
  'X-Powered-By',
  'X-Requested-With',
  'X-XSS-Protection'
]

for (let i = 0; i < wellknownHeaderNames.length; ++i) {
  const key = wellknownHeaderNames[i]
  const lowerCasedKey = key.toLowerCase()
  headerNameLowerCasedRecord[key] = headerNameLowerCasedRecord[lowerCasedKey] =
    lowerCasedKey
}

// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.
Object.setPrototypeOf(headerNameLowerCasedRecord, null)

module.exports = {
  wellknownHeaderNames,
  headerNameLowerCasedRecord
}


/***/ }),

/***/ 8707:
/***/ ((module) => {

"use strict";


class UndiciError extends Error {
  constructor (message) {
    super(message)
    this.name = 'UndiciError'
    this.code = 'UND_ERR'
  }
}

class ConnectTimeoutError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, ConnectTimeoutError)
    this.name = 'ConnectTimeoutError'
    this.message = message || 'Connect Timeout Error'
    this.code = 'UND_ERR_CONNECT_TIMEOUT'
  }
}

class HeadersTimeoutError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, HeadersTimeoutError)
    this.name = 'HeadersTimeoutError'
    this.message = message || 'Headers Timeout Error'
    this.code = 'UND_ERR_HEADERS_TIMEOUT'
  }
}

class HeadersOverflowError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, HeadersOverflowError)
    this.name = 'HeadersOverflowError'
    this.message = message || 'Headers Overflow Error'
    this.code = 'UND_ERR_HEADERS_OVERFLOW'
  }
}

class BodyTimeoutError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, BodyTimeoutError)
    this.name = 'BodyTimeoutError'
    this.message = message || 'Body Timeout Error'
    this.code = 'UND_ERR_BODY_TIMEOUT'
  }
}

class ResponseStatusCodeError extends UndiciError {
  constructor (message, statusCode, headers, body) {
    super(message)
    Error.captureStackTrace(this, ResponseStatusCodeError)
    this.name = 'ResponseStatusCodeError'
    this.message = message || 'Response Status Code Error'
    this.code = 'UND_ERR_RESPONSE_STATUS_CODE'
    this.body = body
    this.status = statusCode
    this.statusCode = statusCode
    this.headers = headers
  }
}

class InvalidArgumentError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, InvalidArgumentError)
    this.name = 'InvalidArgumentError'
    this.message = message || 'Invalid Argument Error'
    this.code = 'UND_ERR_INVALID_ARG'
  }
}

class InvalidReturnValueError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, InvalidReturnValueError)
    this.name = 'InvalidReturnValueError'
    this.message = message || 'Invalid Return Value Error'
    this.code = 'UND_ERR_INVALID_RETURN_VALUE'
  }
}

class RequestAbortedError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, RequestAbortedError)
    this.name = 'AbortError'
    this.message = message || 'Request aborted'
    this.code = 'UND_ERR_ABORTED'
  }
}

class InformationalError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, InformationalError)
    this.name = 'InformationalError'
    this.message = message || 'Request information'
    this.code = 'UND_ERR_INFO'
  }
}

class RequestContentLengthMismatchError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, RequestContentLengthMismatchError)
    this.name = 'RequestContentLengthMismatchError'
    this.message = message || 'Request body length does not match content-length header'
    this.code = 'UND_ERR_REQ_CONTENT_LENGTH_MISMATCH'
  }
}

class ResponseContentLengthMismatchError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, ResponseContentLengthMismatchError)
    this.name = 'ResponseContentLengthMismatchError'
    this.message = message || 'Response body length does not match content-length header'
    this.code = 'UND_ERR_RES_CONTENT_LENGTH_MISMATCH'
  }
}

class ClientDestroyedError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, ClientDestroyedError)
    this.name = 'ClientDestroyedError'
    this.message = message || 'The client is destroyed'
    this.code = 'UND_ERR_DESTROYED'
  }
}

class ClientClosedError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, ClientClosedError)
    this.name = 'ClientClosedError'
    this.message = message || 'The client is closed'
    this.code = 'UND_ERR_CLOSED'
  }
}

class SocketError extends UndiciError {
  constructor (message, socket) {
    super(message)
    Error.captureStackTrace(this, SocketError)
    this.name = 'SocketError'
    this.message = message || 'Socket error'
    this.code = 'UND_ERR_SOCKET'
    this.socket = socket
  }
}

class NotSupportedError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, NotSupportedError)
    this.name = 'NotSupportedError'
    this.message = message || 'Not supported error'
    this.code = 'UND_ERR_NOT_SUPPORTED'
  }
}

class BalancedPoolMissingUpstreamError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, NotSupportedError)
    this.name = 'MissingUpstreamError'
    this.message = message || 'No upstream has been added to the BalancedPool'
    this.code = 'UND_ERR_BPL_MISSING_UPSTREAM'
  }
}

class HTTPParserError extends Error {
  constructor (message, code, data) {
    super(message)
    Error.captureStackTrace(this, HTTPParserError)
    this.name = 'HTTPParserError'
    this.code = code ? `HPE_${code}` : undefined
    this.data = data ? data.toString() : undefined
  }
}

class ResponseExceededMaxSizeError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, ResponseExceededMaxSizeError)
    this.name = 'ResponseExceededMaxSizeError'
    this.message = message || 'Response content exceeded max size'
    this.code = 'UND_ERR_RES_EXCEEDED_MAX_SIZE'
  }
}

class RequestRetryError extends UndiciError {
  constructor (message, code, { headers, data }) {
    super(message)
    Error.captureStackTrace(this, RequestRetryError)
    this.name = 'RequestRetryError'
    this.message = message || 'Request retry error'
    this.code = 'UND_ERR_REQ_RETRY'
    this.statusCode = code
    this.data = data
    this.headers = headers
  }
}

module.exports = {
  HTTPParserError,
  UndiciError,
  HeadersTimeoutError,
  HeadersOverflowError,
  BodyTimeoutError,
  RequestContentLengthMismatchError,
  ConnectTimeoutError,
  ResponseStatusCodeError,
  InvalidArgumentError,
  InvalidReturnValueError,
  RequestAbortedError,
  ClientDestroyedError,
  ClientClosedError,
  InformationalError,
  SocketError,
  NotSupportedError,
  ResponseContentLengthMismatchError,
  BalancedPoolMissingUpstreamError,
  ResponseExceededMaxSizeError,
  RequestRetryError
}


/***/ }),

/***/ 4655:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const {
  InvalidArgumentError,
  NotSupportedError
} = __nccwpck_require__(8707)
const assert = __nccwpck_require__(2613)
const { kHTTP2BuildRequest, kHTTP2CopyHeaders, kHTTP1BuildRequest } = __nccwpck_require__(6443)
const util = __nccwpck_require__(3440)

// tokenRegExp and headerCharRegex have been lifted from
// https://github.com/nodejs/node/blob/main/lib/_http_common.js

/**
 * Verifies that the given val is a valid HTTP token
 * per the rules defined in RFC 7230
 * See https://tools.ietf.org/html/rfc7230#section-3.2.6
 */
const tokenRegExp = /^[\^_`a-zA-Z\-0-9!#$%&'*+.|~]+$/

/**
 * Matches if val contains an invalid field-vchar
 *  field-value    = *( field-content / obs-fold )
 *  field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]
 *  field-vchar    = VCHAR / obs-text
 */
const headerCharRegex = /[^\t\x20-\x7e\x80-\xff]/

// Verifies that a given path is valid does not contain control chars \x00 to \x20
const invalidPathRegex = /[^\u0021-\u00ff]/

const kHandler = Symbol('handler')

const channels = {}

let extractBody

try {
  const diagnosticsChannel = __nccwpck_require__(1637)
  channels.create = diagnosticsChannel.channel('undici:request:create')
  channels.bodySent = diagnosticsChannel.channel('undici:request:bodySent')
  channels.headers = diagnosticsChannel.channel('undici:request:headers')
  channels.trailers = diagnosticsChannel.channel('undici:request:trailers')
  channels.error = diagnosticsChannel.channel('undici:request:error')
} catch {
  channels.create = { hasSubscribers: false }
  channels.bodySent = { hasSubscribers: false }
  channels.headers = { hasSubscribers: false }
  channels.trailers = { hasSubscribers: false }
  channels.error = { hasSubscribers: false }
}

class Request {
  constructor (origin, {
    path,
    method,
    body,
    headers,
    query,
    idempotent,
    blocking,
    upgrade,
    headersTimeout,
    bodyTimeout,
    reset,
    throwOnError,
    expectContinue
  }, handler) {
    if (typeof path !== 'string') {
      throw new InvalidArgumentError('path must be a string')
    } else if (
      path[0] !== '/' &&
      !(path.startsWith('http://') || path.startsWith('https://')) &&
      method !== 'CONNECT'
    ) {
      throw new InvalidArgumentError('path must be an absolute URL or start with a slash')
    } else if (invalidPathRegex.exec(path) !== null) {
      throw new InvalidArgumentError('invalid request path')
    }

    if (typeof method !== 'string') {
      throw new InvalidArgumentError('method must be a string')
    } else if (tokenRegExp.exec(method) === null) {
      throw new InvalidArgumentError('invalid request method')
    }

    if (upgrade && typeof upgrade !== 'string') {
      throw new InvalidArgumentError('upgrade must be a string')
    }

    if (headersTimeout != null && (!Number.isFinite(headersTimeout) || headersTimeout < 0)) {
      throw new InvalidArgumentError('invalid headersTimeout')
    }

    if (bodyTimeout != null && (!Number.isFinite(bodyTimeout) || bodyTimeout < 0)) {
      throw new InvalidArgumentError('invalid bodyTimeout')
    }

    if (reset != null && typeof reset !== 'boolean') {
      throw new InvalidArgumentError('invalid reset')
    }

    if (expectContinue != null && typeof expectContinue !== 'boolean') {
      throw new InvalidArgumentError('invalid expectContinue')
    }

    this.headersTimeout = headersTimeout

    this.bodyTimeout = bodyTimeout

    this.throwOnError = throwOnError === true

    this.method = method

    this.abort = null

    if (body == null) {
      this.body = null
    } else if (util.isStream(body)) {
      this.body = body

      const rState = this.body._readableState
      if (!rState || !rState.autoDestroy) {
        this.endHandler = function autoDestroy () {
          util.destroy(this)
        }
        this.body.on('end', this.endHandler)
      }

      this.errorHandler = err => {
        if (this.abort) {
          this.abort(err)
        } else {
          this.error = err
        }
      }
      this.body.on('error', this.errorHandler)
    } else if (util.isBuffer(body)) {
      this.body = body.byteLength ? body : null
    } else if (ArrayBuffer.isView(body)) {
      this.body = body.buffer.byteLength ? Buffer.from(body.buffer, body.byteOffset, body.byteLength) : null
    } else if (body instanceof ArrayBuffer) {
      this.body = body.byteLength ? Buffer.from(body) : null
    } else if (typeof body === 'string') {
      this.body = body.length ? Buffer.from(body) : null
    } else if (util.isFormDataLike(body) || util.isIterable(body) || util.isBlobLike(body)) {
      this.body = body
    } else {
      throw new InvalidArgumentError('body must be a string, a Buffer, a Readable stream, an iterable, or an async iterable')
    }

    this.completed = false

    this.aborted = false

    this.upgrade = upgrade || null

    this.path = query ? util.buildURL(path, query) : path

    this.origin = origin

    this.idempotent = idempotent == null
      ? method === 'HEAD' || method === 'GET'
      : idempotent

    this.blocking = blocking == null ? false : blocking

    this.reset = reset == null ? null : reset

    this.host = null

    this.contentLength = null

    this.contentType = null

    this.headers = ''

    // Only for H2
    this.expectContinue = expectContinue != null ? expectContinue : false

    if (Array.isArray(headers)) {
      if (headers.length % 2 !== 0) {
        throw new InvalidArgumentError('headers array must be even')
      }
      for (let i = 0; i < headers.length; i += 2) {
        processHeader(this, headers[i], headers[i + 1])
      }
    } else if (headers && typeof headers === 'object') {
      const keys = Object.keys(headers)
      for (let i = 0; i < keys.length; i++) {
        const key = keys[i]
        processHeader(this, key, headers[key])
      }
    } else if (headers != null) {
      throw new InvalidArgumentError('headers must be an object or an array')
    }

    if (util.isFormDataLike(this.body)) {
      if (util.nodeMajor < 16 || (util.nodeMajor === 16 && util.nodeMinor < 8)) {
        throw new InvalidArgumentError('Form-Data bodies are only supported in node v16.8 and newer.')
      }

      if (!extractBody) {
        extractBody = (__nccwpck_require__(8923).extractBody)
      }

      const [bodyStream, contentType] = extractBody(body)
      if (this.contentType == null) {
        this.contentType = contentType
        this.headers += `content-type: ${contentType}\r\n`
      }
      this.body = bodyStream.stream
      this.contentLength = bodyStream.length
    } else if (util.isBlobLike(body) && this.contentType == null && body.type) {
      this.contentType = body.type
      this.headers += `content-type: ${body.type}\r\n`
    }

    util.validateHandler(handler, method, upgrade)

    this.servername = util.getServerName(this.host)

    this[kHandler] = handler

    if (channels.create.hasSubscribers) {
      channels.create.publish({ request: this })
    }
  }

  onBodySent (chunk) {
    if (this[kHandler].onBodySent) {
      try {
        return this[kHandler].onBodySent(chunk)
      } catch (err) {
        this.abort(err)
      }
    }
  }

  onRequestSent () {
    if (channels.bodySent.hasSubscribers) {
      channels.bodySent.publish({ request: this })
    }

    if (this[kHandler].onRequestSent) {
      try {
        return this[kHandler].onRequestSent()
      } catch (err) {
        this.abort(err)
      }
    }
  }

  onConnect (abort) {
    assert(!this.aborted)
    assert(!this.completed)

    if (this.error) {
      abort(this.error)
    } else {
      this.abort = abort
      return this[kHandler].onConnect(abort)
    }
  }

  onHeaders (statusCode, headers, resume, statusText) {
    assert(!this.aborted)
    assert(!this.completed)

    if (channels.headers.hasSubscribers) {
      channels.headers.publish({ request: this, response: { statusCode, headers, statusText } })
    }

    try {
      return this[kHandler].onHeaders(statusCode, headers, resume, statusText)
    } catch (err) {
      this.abort(err)
    }
  }

  onData (chunk) {
    assert(!this.aborted)
    assert(!this.completed)

    try {
      return this[kHandler].onData(chunk)
    } catch (err) {
      this.abort(err)
      return false
    }
  }

  onUpgrade (statusCode, headers, socket) {
    assert(!this.aborted)
    assert(!this.completed)

    return this[kHandler].onUpgrade(statusCode, headers, socket)
  }

  onComplete (trailers) {
    this.onFinally()

    assert(!this.aborted)

    this.completed = true
    if (channels.trailers.hasSubscribers) {
      channels.trailers.publish({ request: this, trailers })
    }

    try {
      return this[kHandler].onComplete(trailers)
    } catch (err) {
      // TODO (fix): This might be a bad idea?
      this.onError(err)
    }
  }

  onError (error) {
    this.onFinally()

    if (channels.error.hasSubscribers) {
      channels.error.publish({ request: this, error })
    }

    if (this.aborted) {
      return
    }
    this.aborted = true

    return this[kHandler].onError(error)
  }

  onFinally () {
    if (this.errorHandler) {
      this.body.off('error', this.errorHandler)
      this.errorHandler = null
    }

    if (this.endHandler) {
      this.body.off('end', this.endHandler)
      this.endHandler = null
    }
  }

  // TODO: adjust to support H2
  addHeader (key, value) {
    processHeader(this, key, value)
    return this
  }

  static [kHTTP1BuildRequest] (origin, opts, handler) {
    // TODO: Migrate header parsing here, to make Requests
    // HTTP agnostic
    return new Request(origin, opts, handler)
  }

  static [kHTTP2BuildRequest] (origin, opts, handler) {
    const headers = opts.headers
    opts = { ...opts, headers: null }

    const request = new Request(origin, opts, handler)

    request.headers = {}

    if (Array.isArray(headers)) {
      if (headers.length % 2 !== 0) {
        throw new InvalidArgumentError('headers array must be even')
      }
      for (let i = 0; i < headers.length; i += 2) {
        processHeader(request, headers[i], headers[i + 1], true)
      }
    } else if (headers && typeof headers === 'object') {
      const keys = Object.keys(headers)
      for (let i = 0; i < keys.length; i++) {
        const key = keys[i]
        processHeader(request, key, headers[key], true)
      }
    } else if (headers != null) {
      throw new InvalidArgumentError('headers must be an object or an array')
    }

    return request
  }

  static [kHTTP2CopyHeaders] (raw) {
    const rawHeaders = raw.split('\r\n')
    const headers = {}

    for (const header of rawHeaders) {
      const [key, value] = header.split(': ')

      if (value == null || value.length === 0) continue

      if (headers[key]) headers[key] += `,${value}`
      else headers[key] = value
    }

    return headers
  }
}

function processHeaderValue (key, val, skipAppend) {
  if (val && typeof val === 'object') {
    throw new InvalidArgumentError(`invalid ${key} header`)
  }

  val = val != null ? `${val}` : ''

  if (headerCharRegex.exec(val) !== null) {
    throw new InvalidArgumentError(`invalid ${key} header`)
  }

  return skipAppend ? val : `${key}: ${val}\r\n`
}

function processHeader (request, key, val, skipAppend = false) {
  if (val && (typeof val === 'object' && !Array.isArray(val))) {
    throw new InvalidArgumentError(`invalid ${key} header`)
  } else if (val === undefined) {
    return
  }

  if (
    request.host === null &&
    key.length === 4 &&
    key.toLowerCase() === 'host'
  ) {
    if (headerCharRegex.exec(val) !== null) {
      throw new InvalidArgumentError(`invalid ${key} header`)
    }
    // Consumed by Client
    request.host = val
  } else if (
    request.contentLength === null &&
    key.length === 14 &&
    key.toLowerCase() === 'content-length'
  ) {
    request.contentLength = parseInt(val, 10)
    if (!Number.isFinite(request.contentLength)) {
      throw new InvalidArgumentError('invalid content-length header')
    }
  } else if (
    request.contentType === null &&
    key.length === 12 &&
    key.toLowerCase() === 'content-type'
  ) {
    request.contentType = val
    if (skipAppend) request.headers[key] = processHeaderValue(key, val, skipAppend)
    else request.headers += processHeaderValue(key, val)
  } else if (
    key.length === 17 &&
    key.toLowerCase() === 'transfer-encoding'
  ) {
    throw new InvalidArgumentError('invalid transfer-encoding header')
  } else if (
    key.length === 10 &&
    key.toLowerCase() === 'connection'
  ) {
    const value = typeof val === 'string' ? val.toLowerCase() : null
    if (value !== 'close' && value !== 'keep-alive') {
      throw new InvalidArgumentError('invalid connection header')
    } else if (value === 'close') {
      request.reset = true
    }
  } else if (
    key.length === 10 &&
    key.toLowerCase() === 'keep-alive'
  ) {
    throw new InvalidArgumentError('invalid keep-alive header')
  } else if (
    key.length === 7 &&
    key.toLowerCase() === 'upgrade'
  ) {
    throw new InvalidArgumentError('invalid upgrade header')
  } else if (
    key.length === 6 &&
    key.toLowerCase() === 'expect'
  ) {
    throw new NotSupportedError('expect header not supported')
  } else if (tokenRegExp.exec(key) === null) {
    throw new InvalidArgumentError('invalid header key')
  } else {
    if (Array.isArray(val)) {
      for (let i = 0; i < val.length; i++) {
        if (skipAppend) {
          if (request.headers[key]) request.headers[key] += `,${processHeaderValue(key, val[i], skipAppend)}`
          else request.headers[key] = processHeaderValue(key, val[i], skipAppend)
        } else {
          request.headers += processHeaderValue(key, val[i])
        }
      }
    } else {
      if (skipAppend) request.headers[key] = processHeaderValue(key, val, skipAppend)
      else request.headers += processHeaderValue(key, val)
    }
  }
}

module.exports = Request


/***/ }),

/***/ 6443:
/***/ ((module) => {

module.exports = {
  kClose: Symbol('close'),
  kDestroy: Symbol('destroy'),
  kDispatch: Symbol('dispatch'),
  kUrl: Symbol('url'),
  kWriting: Symbol('writing'),
  kResuming: Symbol('resuming'),
  kQueue: Symbol('queue'),
  kConnect: Symbol('connect'),
  kConnecting: Symbol('connecting'),
  kHeadersList: Symbol('headers list'),
  kKeepAliveDefaultTimeout: Symbol('default keep alive timeout'),
  kKeepAliveMaxTimeout: Symbol('max keep alive timeout'),
  kKeepAliveTimeoutThreshold: Symbol('keep alive timeout threshold'),
  kKeepAliveTimeoutValue: Symbol('keep alive timeout'),
  kKeepAlive: Symbol('keep alive'),
  kHeadersTimeout: Symbol('headers timeout'),
  kBodyTimeout: Symbol('body timeout'),
  kServerName: Symbol('server name'),
  kLocalAddress: Symbol('local address'),
  kHost: Symbol('host'),
  kNoRef: Symbol('no ref'),
  kBodyUsed: Symbol('used'),
  kRunning: Symbol('running'),
  kBlocking: Symbol('blocking'),
  kPending: Symbol('pending'),
  kSize: Symbol('size'),
  kBusy: Symbol('busy'),
  kQueued: Symbol('queued'),
  kFree: Symbol('free'),
  kConnected: Symbol('connected'),
  kClosed: Symbol('closed'),
  kNeedDrain: Symbol('need drain'),
  kReset: Symbol('reset'),
  kDestroyed: Symbol.for('nodejs.stream.destroyed'),
  kMaxHeadersSize: Symbol('max headers size'),
  kRunningIdx: Symbol('running index'),
  kPendingIdx: Symbol('pending index'),
  kError: Symbol('error'),
  kClients: Symbol('clients'),
  kClient: Symbol('client'),
  kParser: Symbol('parser'),
  kOnDestroyed: Symbol('destroy callbacks'),
  kPipelining: Symbol('pipelining'),
  kSocket: Symbol('socket'),
  kHostHeader: Symbol('host header'),
  kConnector: Symbol('connector'),
  kStrictContentLength: Symbol('strict content length'),
  kMaxRedirections: Symbol('maxRedirections'),
  kMaxRequests: Symbol('maxRequestsPerClient'),
  kProxy: Symbol('proxy agent options'),
  kCounter: Symbol('socket request counter'),
  kInterceptors: Symbol('dispatch interceptors'),
  kMaxResponseSize: Symbol('max response size'),
  kHTTP2Session: Symbol('http2Session'),
  kHTTP2SessionState: Symbol('http2Session state'),
  kHTTP2BuildRequest: Symbol('http2 build request'),
  kHTTP1BuildRequest: Symbol('http1 build request'),
  kHTTP2CopyHeaders: Symbol('http2 copy headers'),
  kHTTPConnVersion: Symbol('http connection version'),
  kRetryHandlerDefaultRetry: Symbol('retry agent default retry'),
  kConstruct: Symbol('constructable')
}


/***/ }),

/***/ 3440:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const assert = __nccwpck_require__(2613)
const { kDestroyed, kBodyUsed } = __nccwpck_require__(6443)
const { IncomingMessage } = __nccwpck_require__(8611)
const stream = __nccwpck_require__(2203)
const net = __nccwpck_require__(9278)
const { InvalidArgumentError } = __nccwpck_require__(8707)
const { Blob } = __nccwpck_require__(181)
const nodeUtil = __nccwpck_require__(9023)
const { stringify } = __nccwpck_require__(3480)
const { headerNameLowerCasedRecord } = __nccwpck_require__(735)

const [nodeMajor, nodeMinor] = process.versions.node.split('.').map(v => Number(v))

function nop () {}

function isStream (obj) {
  return obj && typeof obj === 'object' && typeof obj.pipe === 'function' && typeof obj.on === 'function'
}

// based on https://github.com/node-fetch/fetch-blob/blob/8ab587d34080de94140b54f07168451e7d0b655e/index.js#L229-L241 (MIT License)
function isBlobLike (object) {
  return (Blob && object instanceof Blob) || (
    object &&
    typeof object === 'object' &&
    (typeof object.stream === 'function' ||
      typeof object.arrayBuffer === 'function') &&
    /^(Blob|File)$/.test(object[Symbol.toStringTag])
  )
}

function buildURL (url, queryParams) {
  if (url.includes('?') || url.includes('#')) {
    throw new Error('Query params cannot be passed when url already contains "?" or "#".')
  }

  const stringified = stringify(queryParams)

  if (stringified) {
    url += '?' + stringified
  }

  return url
}

function parseURL (url) {
  if (typeof url === 'string') {
    url = new URL(url)

    if (!/^https?:/.test(url.origin || url.protocol)) {
      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')
    }

    return url
  }

  if (!url || typeof url !== 'object') {
    throw new InvalidArgumentError('Invalid URL: The URL argument must be a non-null object.')
  }

  if (!/^https?:/.test(url.origin || url.protocol)) {
    throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')
  }

  if (!(url instanceof URL)) {
    if (url.port != null && url.port !== '' && !Number.isFinite(parseInt(url.port))) {
      throw new InvalidArgumentError('Invalid URL: port must be a valid integer or a string representation of an integer.')
    }

    if (url.path != null && typeof url.path !== 'string') {
      throw new InvalidArgumentError('Invalid URL path: the path must be a string or null/undefined.')
    }

    if (url.pathname != null && typeof url.pathname !== 'string') {
      throw new InvalidArgumentError('Invalid URL pathname: the pathname must be a string or null/undefined.')
    }

    if (url.hostname != null && typeof url.hostname !== 'string') {
      throw new InvalidArgumentError('Invalid URL hostname: the hostname must be a string or null/undefined.')
    }

    if (url.origin != null && typeof url.origin !== 'string') {
      throw new InvalidArgumentError('Invalid URL origin: the origin must be a string or null/undefined.')
    }

    const port = url.port != null
      ? url.port
      : (url.protocol === 'https:' ? 443 : 80)
    let origin = url.origin != null
      ? url.origin
      : `${url.protocol}//${url.hostname}:${port}`
    let path = url.path != null
      ? url.path
      : `${url.pathname || ''}${url.search || ''}`

    if (origin.endsWith('/')) {
      origin = origin.substring(0, origin.length - 1)
    }

    if (path && !path.startsWith('/')) {
      path = `/${path}`
    }
    // new URL(path, origin) is unsafe when `path` contains an absolute URL
    // From https://developer.mozilla.org/en-US/docs/Web/API/URL/URL:
    // If first parameter is a relative URL, second param is required, and will be used as the base URL.
    // If first parameter is an absolute URL, a given second param will be ignored.
    url = new URL(origin + path)
  }

  return url
}

function parseOrigin (url) {
  url = parseURL(url)

  if (url.pathname !== '/' || url.search || url.hash) {
    throw new InvalidArgumentError('invalid url')
  }

  return url
}

function getHostname (host) {
  if (host[0] === '[') {
    const idx = host.indexOf(']')

    assert(idx !== -1)
    return host.substring(1, idx)
  }

  const idx = host.indexOf(':')
  if (idx === -1) return host

  return host.substring(0, idx)
}

// IP addresses are not valid server names per RFC6066
// > Currently, the only server names supported are DNS hostnames
function getServerName (host) {
  if (!host) {
    return null
  }

  assert.strictEqual(typeof host, 'string')

  const servername = getHostname(host)
  if (net.isIP(servername)) {
    return ''
  }

  return servername
}

function deepClone (obj) {
  return JSON.parse(JSON.stringify(obj))
}

function isAsyncIterable (obj) {
  return !!(obj != null && typeof obj[Symbol.asyncIterator] === 'function')
}

function isIterable (obj) {
  return !!(obj != null && (typeof obj[Symbol.iterator] === 'function' || typeof obj[Symbol.asyncIterator] === 'function'))
}

function bodyLength (body) {
  if (body == null) {
    return 0
  } else if (isStream(body)) {
    const state = body._readableState
    return state && state.objectMode === false && state.ended === true && Number.isFinite(state.length)
      ? state.length
      : null
  } else if (isBlobLike(body)) {
    return body.size != null ? body.size : null
  } else if (isBuffer(body)) {
    return body.byteLength
  }

  return null
}

function isDestroyed (stream) {
  return !stream || !!(stream.destroyed || stream[kDestroyed])
}

function isReadableAborted (stream) {
  const state = stream && stream._readableState
  return isDestroyed(stream) && state && !state.endEmitted
}

function destroy (stream, err) {
  if (stream == null || !isStream(stream) || isDestroyed(stream)) {
    return
  }

  if (typeof stream.destroy === 'function') {
    if (Object.getPrototypeOf(stream).constructor === IncomingMessage) {
      // See: https://github.com/nodejs/node/pull/38505/files
      stream.socket = null
    }

    stream.destroy(err)
  } else if (err) {
    process.nextTick((stream, err) => {
      stream.emit('error', err)
    }, stream, err)
  }

  if (stream.destroyed !== true) {
    stream[kDestroyed] = true
  }
}

const KEEPALIVE_TIMEOUT_EXPR = /timeout=(\d+)/
function parseKeepAliveTimeout (val) {
  const m = val.toString().match(KEEPALIVE_TIMEOUT_EXPR)
  return m ? parseInt(m[1], 10) * 1000 : null
}

/**
 * Retrieves a header name and returns its lowercase value.
 * @param {string | Buffer} value Header name
 * @returns {string}
 */
function headerNameToString (value) {
  return headerNameLowerCasedRecord[value] || value.toLowerCase()
}

function parseHeaders (headers, obj = {}) {
  // For H2 support
  if (!Array.isArray(headers)) return headers

  for (let i = 0; i < headers.length; i += 2) {
    const key = headers[i].toString().toLowerCase()
    let val = obj[key]

    if (!val) {
      if (Array.isArray(headers[i + 1])) {
        obj[key] = headers[i + 1].map(x => x.toString('utf8'))
      } else {
        obj[key] = headers[i + 1].toString('utf8')
      }
    } else {
      if (!Array.isArray(val)) {
        val = [val]
        obj[key] = val
      }
      val.push(headers[i + 1].toString('utf8'))
    }
  }

  // See https://github.com/nodejs/node/pull/46528
  if ('content-length' in obj && 'content-disposition' in obj) {
    obj['content-disposition'] = Buffer.from(obj['content-disposition']).toString('latin1')
  }

  return obj
}

function parseRawHeaders (headers) {
  const ret = []
  let hasContentLength = false
  let contentDispositionIdx = -1

  for (let n = 0; n < headers.length; n += 2) {
    const key = headers[n + 0].toString()
    const val = headers[n + 1].toString('utf8')

    if (key.length === 14 && (key === 'content-length' || key.toLowerCase() === 'content-length')) {
      ret.push(key, val)
      hasContentLength = true
    } else if (key.length === 19 && (key === 'content-disposition' || key.toLowerCase() === 'content-disposition')) {
      contentDispositionIdx = ret.push(key, val) - 1
    } else {
      ret.push(key, val)
    }
  }

  // See https://github.com/nodejs/node/pull/46528
  if (hasContentLength && contentDispositionIdx !== -1) {
    ret[contentDispositionIdx] = Buffer.from(ret[contentDispositionIdx]).toString('latin1')
  }

  return ret
}

function isBuffer (buffer) {
  // See, https://github.com/mcollina/undici/pull/319
  return buffer instanceof Uint8Array || Buffer.isBuffer(buffer)
}

function validateHandler (handler, method, upgrade) {
  if (!handler || typeof handler !== 'object') {
    throw new InvalidArgumentError('handler must be an object')
  }

  if (typeof handler.onConnect !== 'function') {
    throw new InvalidArgumentError('invalid onConnect method')
  }

  if (typeof handler.onError !== 'function') {
    throw new InvalidArgumentError('invalid onError method')
  }

  if (typeof handler.onBodySent !== 'function' && handler.onBodySent !== undefined) {
    throw new InvalidArgumentError('invalid onBodySent method')
  }

  if (upgrade || method === 'CONNECT') {
    if (typeof handler.onUpgrade !== 'function') {
      throw new InvalidArgumentError('invalid onUpgrade method')
    }
  } else {
    if (typeof handler.onHeaders !== 'function') {
      throw new InvalidArgumentError('invalid onHeaders method')
    }

    if (typeof handler.onData !== 'function') {
      throw new InvalidArgumentError('invalid onData method')
    }

    if (typeof handler.onComplete !== 'function') {
      throw new InvalidArgumentError('invalid onComplete method')
    }
  }
}

// A body is disturbed if it has been read from and it cannot
// be re-used without losing state or data.
function isDisturbed (body) {
  return !!(body && (
    stream.isDisturbed
      ? stream.isDisturbed(body) || body[kBodyUsed] // TODO (fix): Why is body[kBodyUsed] needed?
      : body[kBodyUsed] ||
        body.readableDidRead ||
        (body._readableState && body._readableState.dataEmitted) ||
        isReadableAborted(body)
  ))
}

function isErrored (body) {
  return !!(body && (
    stream.isErrored
      ? stream.isErrored(body)
      : /state: 'errored'/.test(nodeUtil.inspect(body)
      )))
}

function isReadable (body) {
  return !!(body && (
    stream.isReadable
      ? stream.isReadable(body)
      : /state: 'readable'/.test(nodeUtil.inspect(body)
      )))
}

function getSocketInfo (socket) {
  return {
    localAddress: socket.localAddress,
    localPort: socket.localPort,
    remoteAddress: socket.remoteAddress,
    remotePort: socket.remotePort,
    remoteFamily: socket.remoteFamily,
    timeout: socket.timeout,
    bytesWritten: socket.bytesWritten,
    bytesRead: socket.bytesRead
  }
}

async function * convertIterableToBuffer (iterable) {
  for await (const chunk of iterable) {
    yield Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk)
  }
}

let ReadableStream
function ReadableStreamFrom (iterable) {
  if (!ReadableStream) {
    ReadableStream = (__nccwpck_require__(3774).ReadableStream)
  }

  if (ReadableStream.from) {
    return ReadableStream.from(convertIterableToBuffer(iterable))
  }

  let iterator
  return new ReadableStream(
    {
      async start () {
        iterator = iterable[Symbol.asyncIterator]()
      },
      async pull (controller) {
        const { done, value } = await iterator.next()
        if (done) {
          queueMicrotask(() => {
            controller.close()
          })
        } else {
          const buf = Buffer.isBuffer(value) ? value : Buffer.from(value)
          controller.enqueue(new Uint8Array(buf))
        }
        return controller.desiredSize > 0
      },
      async cancel (reason) {
        await iterator.return()
      }
    },
    0
  )
}

// The chunk should be a FormData instance and contains
// all the required methods.
function isFormDataLike (object) {
  return (
    object &&
    typeof object === 'object' &&
    typeof object.append === 'function' &&
    typeof object.delete === 'function' &&
    typeof object.get === 'function' &&
    typeof object.getAll === 'function' &&
    typeof object.has === 'function' &&
    typeof object.set === 'function' &&
    object[Symbol.toStringTag] === 'FormData'
  )
}

function throwIfAborted (signal) {
  if (!signal) { return }
  if (typeof signal.throwIfAborted === 'function') {
    signal.throwIfAborted()
  } else {
    if (signal.aborted) {
      // DOMException not available < v17.0.0
      const err = new Error('The operation was aborted')
      err.name = 'AbortError'
      throw err
    }
  }
}

function addAbortListener (signal, listener) {
  if ('addEventListener' in signal) {
    signal.addEventListener('abort', listener, { once: true })
    return () => signal.removeEventListener('abort', listener)
  }
  signal.addListener('abort', listener)
  return () => signal.removeListener('abort', listener)
}

const hasToWellFormed = !!String.prototype.toWellFormed

/**
 * @param {string} val
 */
function toUSVString (val) {
  if (hasToWellFormed) {
    return `${val}`.toWellFormed()
  } else if (nodeUtil.toUSVString) {
    return nodeUtil.toUSVString(val)
  }

  return `${val}`
}

// Parsed accordingly to RFC 9110
// https://www.rfc-editor.org/rfc/rfc9110#field.content-range
function parseRangeHeader (range) {
  if (range == null || range === '') return { start: 0, end: null, size: null }

  const m = range ? range.match(/^bytes (\d+)-(\d+)\/(\d+)?$/) : null
  return m
    ? {
        start: parseInt(m[1]),
        end: m[2] ? parseInt(m[2]) : null,
        size: m[3] ? parseInt(m[3]) : null
      }
    : null
}

const kEnumerableProperty = Object.create(null)
kEnumerableProperty.enumerable = true

module.exports = {
  kEnumerableProperty,
  nop,
  isDisturbed,
  isErrored,
  isReadable,
  toUSVString,
  isReadableAborted,
  isBlobLike,
  parseOrigin,
  parseURL,
  getServerName,
  isStream,
  isIterable,
  isAsyncIterable,
  isDestroyed,
  headerNameToString,
  parseRawHeaders,
  parseHeaders,
  parseKeepAliveTimeout,
  destroy,
  bodyLength,
  deepClone,
  ReadableStreamFrom,
  isBuffer,
  validateHandler,
  getSocketInfo,
  isFormDataLike,
  buildURL,
  throwIfAborted,
  addAbortListener,
  parseRangeHeader,
  nodeMajor,
  nodeMinor,
  nodeHasAutoSelectFamily: nodeMajor > 18 || (nodeMajor === 18 && nodeMinor >= 13),
  safeHTTPMethods: ['GET', 'HEAD', 'OPTIONS', 'TRACE']
}


/***/ }),

/***/ 1:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const Dispatcher = __nccwpck_require__(992)
const {
  ClientDestroyedError,
  ClientClosedError,
  InvalidArgumentError
} = __nccwpck_require__(8707)
const { kDestroy, kClose, kDispatch, kInterceptors } = __nccwpck_require__(6443)

const kDestroyed = Symbol('destroyed')
const kClosed = Symbol('closed')
const kOnDestroyed = Symbol('onDestroyed')
const kOnClosed = Symbol('onClosed')
const kInterceptedDispatch = Symbol('Intercepted Dispatch')

class DispatcherBase extends Dispatcher {
  constructor () {
    super()

    this[kDestroyed] = false
    this[kOnDestroyed] = null
    this[kClosed] = false
    this[kOnClosed] = []
  }

  get destroyed () {
    return this[kDestroyed]
  }

  get closed () {
    return this[kClosed]
  }

  get interceptors () {
    return this[kInterceptors]
  }

  set interceptors (newInterceptors) {
    if (newInterceptors) {
      for (let i = newInterceptors.length - 1; i >= 0; i--) {
        const interceptor = this[kInterceptors][i]
        if (typeof interceptor !== 'function') {
          throw new InvalidArgumentError('interceptor must be an function')
        }
      }
    }

    this[kInterceptors] = newInterceptors
  }

  close (callback) {
    if (callback === undefined) {
      return new Promise((resolve, reject) => {
        this.close((err, data) => {
          return err ? reject(err) : resolve(data)
        })
      })
    }

    if (typeof callback !== 'function') {
      throw new InvalidArgumentError('invalid callback')
    }

    if (this[kDestroyed]) {
      queueMicrotask(() => callback(new ClientDestroyedError(), null))
      return
    }

    if (this[kClosed]) {
      if (this[kOnClosed]) {
        this[kOnClosed].push(callback)
      } else {
        queueMicrotask(() => callback(null, null))
      }
      return
    }

    this[kClosed] = true
    this[kOnClosed].push(callback)

    const onClosed = () => {
      const callbacks = this[kOnClosed]
      this[kOnClosed] = null
      for (let i = 0; i < callbacks.length; i++) {
        callbacks[i](null, null)
      }
    }

    // Should not error.
    this[kClose]()
      .then(() => this.destroy())
      .then(() => {
        queueMicrotask(onClosed)
      })
  }

  destroy (err, callback) {
    if (typeof err === 'function') {
      callback = err
      err = null
    }

    if (callback === undefined) {
      return new Promise((resolve, reject) => {
        this.destroy(err, (err, data) => {
          return err ? /* istanbul ignore next: should never error */ reject(err) : resolve(data)
        })
      })
    }

    if (typeof callback !== 'function') {
      throw new InvalidArgumentError('invalid callback')
    }

    if (this[kDestroyed]) {
      if (this[kOnDestroyed]) {
        this[kOnDestroyed].push(callback)
      } else {
        queueMicrotask(() => callback(null, null))
      }
      return
    }

    if (!err) {
      err = new ClientDestroyedError()
    }

    this[kDestroyed] = true
    this[kOnDestroyed] = this[kOnDestroyed] || []
    this[kOnDestroyed].push(callback)

    const onDestroyed = () => {
      const callbacks = this[kOnDestroyed]
      this[kOnDestroyed] = null
      for (let i = 0; i < callbacks.length; i++) {
        callbacks[i](null, null)
      }
    }

    // Should not error.
    this[kDestroy](err).then(() => {
      queueMicrotask(onDestroyed)
    })
  }

  [kInterceptedDispatch] (opts, handler) {
    if (!this[kInterceptors] || this[kInterceptors].length === 0) {
      this[kInterceptedDispatch] = this[kDispatch]
      return this[kDispatch](opts, handler)
    }

    let dispatch = this[kDispatch].bind(this)
    for (let i = this[kInterceptors].length - 1; i >= 0; i--) {
      dispatch = this[kInterceptors][i](dispatch)
    }
    this[kInterceptedDispatch] = dispatch
    return dispatch(opts, handler)
  }

  dispatch (opts, handler) {
    if (!handler || typeof handler !== 'object') {
      throw new InvalidArgumentError('handler must be an object')
    }

    try {
      if (!opts || typeof opts !== 'object') {
        throw new InvalidArgumentError('opts must be an object.')
      }

      if (this[kDestroyed] || this[kOnDestroyed]) {
        throw new ClientDestroyedError()
      }

      if (this[kClosed]) {
        throw new ClientClosedError()
      }

      return this[kInterceptedDispatch](opts, handler)
    } catch (err) {
      if (typeof handler.onError !== 'function') {
        throw new InvalidArgumentError('invalid onError method')
      }

      handler.onError(err)

      return false
    }
  }
}

module.exports = DispatcherBase


/***/ }),

/***/ 992:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const EventEmitter = __nccwpck_require__(4434)

class Dispatcher extends EventEmitter {
  dispatch () {
    throw new Error('not implemented')
  }

  close () {
    throw new Error('not implemented')
  }

  destroy () {
    throw new Error('not implemented')
  }
}

module.exports = Dispatcher


/***/ }),

/***/ 8923:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const Busboy = __nccwpck_require__(9581)
const util = __nccwpck_require__(3440)
const {
  ReadableStreamFrom,
  isBlobLike,
  isReadableStreamLike,
  readableStreamClose,
  createDeferredPromise,
  fullyReadBody
} = __nccwpck_require__(5523)
const { FormData } = __nccwpck_require__(3073)
const { kState } = __nccwpck_require__(9710)
const { webidl } = __nccwpck_require__(4222)
const { DOMException, structuredClone } = __nccwpck_require__(7326)
const { Blob, File: NativeFile } = __nccwpck_require__(181)
const { kBodyUsed } = __nccwpck_require__(6443)
const assert = __nccwpck_require__(2613)
const { isErrored } = __nccwpck_require__(3440)
const { isUint8Array, isArrayBuffer } = __nccwpck_require__(8253)
const { File: UndiciFile } = __nccwpck_require__(3041)
const { parseMIMEType, serializeAMimeType } = __nccwpck_require__(4322)

let random
try {
  const crypto = __nccwpck_require__(7598)
  random = (max) => crypto.randomInt(0, max)
} catch {
  random = (max) => Math.floor(Math.random(max))
}

let ReadableStream = globalThis.ReadableStream

/** @type {globalThis['File']} */
const File = NativeFile ?? UndiciFile
const textEncoder = new TextEncoder()
const textDecoder = new TextDecoder()

// https://fetch.spec.whatwg.org/#concept-bodyinit-extract
function extractBody (object, keepalive = false) {
  if (!ReadableStream) {
    ReadableStream = (__nccwpck_require__(3774).ReadableStream)
  }

  // 1. Let stream be null.
  let stream = null

  // 2. If object is a ReadableStream object, then set stream to object.
  if (object instanceof ReadableStream) {
    stream = object
  } else if (isBlobLike(object)) {
    // 3. Otherwise, if object is a Blob object, set stream to the
    //    result of running objects get stream.
    stream = object.stream()
  } else {
    // 4. Otherwise, set stream to a new ReadableStream object, and set
    //    up stream.
    stream = new ReadableStream({
      async pull (controller) {
        controller.enqueue(
          typeof source === 'string' ? textEncoder.encode(source) : source
        )
        queueMicrotask(() => readableStreamClose(controller))
      },
      start () {},
      type: undefined
    })
  }

  // 5. Assert: stream is a ReadableStream object.
  assert(isReadableStreamLike(stream))

  // 6. Let action be null.
  let action = null

  // 7. Let source be null.
  let source = null

  // 8. Let length be null.
  let length = null

  // 9. Let type be null.
  let type = null

  // 10. Switch on object:
  if (typeof object === 'string') {
    // Set source to the UTF-8 encoding of object.
    // Note: setting source to a Uint8Array here breaks some mocking assumptions.
    source = object

    // Set type to `text/plain;charset=UTF-8`.
    type = 'text/plain;charset=UTF-8'
  } else if (object instanceof URLSearchParams) {
    // URLSearchParams

    // spec says to run application/x-www-form-urlencoded on body.list
    // this is implemented in Node.js as apart of an URLSearchParams instance toString method
    // See: https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L490
    // and https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L1100

    // Set source to the result of running the application/x-www-form-urlencoded serializer with objects list.
    source = object.toString()

    // Set type to `application/x-www-form-urlencoded;charset=UTF-8`.
    type = 'application/x-www-form-urlencoded;charset=UTF-8'
  } else if (isArrayBuffer(object)) {
    // BufferSource/ArrayBuffer

    // Set source to a copy of the bytes held by object.
    source = new Uint8Array(object.slice())
  } else if (ArrayBuffer.isView(object)) {
    // BufferSource/ArrayBufferView

    // Set source to a copy of the bytes held by object.
    source = new Uint8Array(object.buffer.slice(object.byteOffset, object.byteOffset + object.byteLength))
  } else if (util.isFormDataLike(object)) {
    const boundary = `----formdata-undici-0${`${random(1e11)}`.padStart(11, '0')}`
    const prefix = `--${boundary}\r\nContent-Disposition: form-data`

    /*! formdata-polyfill. MIT License. Jimmy Wrting <https://jimmy.warting.se/opensource> */
    const escape = (str) =>
      str.replace(/\n/g, '%0A').replace(/\r/g, '%0D').replace(/"/g, '%22')
    const normalizeLinefeeds = (value) => value.replace(/\r?\n|\r/g, '\r\n')

    // Set action to this step: run the multipart/form-data
    // encoding algorithm, with objects entry list and UTF-8.
    // - This ensures that the body is immutable and can't be changed afterwords
    // - That the content-length is calculated in advance.
    // - And that all parts are pre-encoded and ready to be sent.

    const blobParts = []
    const rn = new Uint8Array([13, 10]) // '\r\n'
    length = 0
    let hasUnknownSizeValue = false

    for (const [name, value] of object) {
      if (typeof value === 'string') {
        const chunk = textEncoder.encode(prefix +
          `; name="${escape(normalizeLinefeeds(name))}"` +
          `\r\n\r\n${normalizeLinefeeds(value)}\r\n`)
        blobParts.push(chunk)
        length += chunk.byteLength
      } else {
        const chunk = textEncoder.encode(`${prefix}; name="${escape(normalizeLinefeeds(name))}"` +
          (value.name ? `; filename="${escape(value.name)}"` : '') + '\r\n' +
          `Content-Type: ${
            value.type || 'application/octet-stream'
          }\r\n\r\n`)
        blobParts.push(chunk, value, rn)
        if (typeof value.size === 'number') {
          length += chunk.byteLength + value.size + rn.byteLength
        } else {
          hasUnknownSizeValue = true
        }
      }
    }

    const chunk = textEncoder.encode(`--${boundary}--`)
    blobParts.push(chunk)
    length += chunk.byteLength
    if (hasUnknownSizeValue) {
      length = null
    }

    // Set source to object.
    source = object

    action = async function * () {
      for (const part of blobParts) {
        if (part.stream) {
          yield * part.stream()
        } else {
          yield part
        }
      }
    }

    // Set type to `multipart/form-data; boundary=`,
    // followed by the multipart/form-data boundary string generated
    // by the multipart/form-data encoding algorithm.
    type = 'multipart/form-data; boundary=' + boundary
  } else if (isBlobLike(object)) {
    // Blob

    // Set source to object.
    source = object

    // Set length to objects size.
    length = object.size

    // If objects type attribute is not the empty byte sequence, set
    // type to its value.
    if (object.type) {
      type = object.type
    }
  } else if (typeof object[Symbol.asyncIterator] === 'function') {
    // If keepalive is true, then throw a TypeError.
    if (keepalive) {
      throw new TypeError('keepalive')
    }

    // If object is disturbed or locked, then throw a TypeError.
    if (util.isDisturbed(object) || object.locked) {
      throw new TypeError(
        'Response body object should not be disturbed or locked'
      )
    }

    stream =
      object instanceof ReadableStream ? object : ReadableStreamFrom(object)
  }

  // 11. If source is a byte sequence, then set action to a
  // step that returns source and length to sources length.
  if (typeof source === 'string' || util.isBuffer(source)) {
    length = Buffer.byteLength(source)
  }

  // 12. If action is non-null, then run these steps in in parallel:
  if (action != null) {
    // Run action.
    let iterator
    stream = new ReadableStream({
      async start () {
        iterator = action(object)[Symbol.asyncIterator]()
      },
      async pull (controller) {
        const { value, done } = await iterator.next()
        if (done) {
          // When running action is done, close stream.
          queueMicrotask(() => {
            controller.close()
          })
        } else {
          // Whenever one or more bytes are available and stream is not errored,
          // enqueue a Uint8Array wrapping an ArrayBuffer containing the available
          // bytes into stream.
          if (!isErrored(stream)) {
            controller.enqueue(new Uint8Array(value))
          }
        }
        return controller.desiredSize > 0
      },
      async cancel (reason) {
        await iterator.return()
      },
      type: undefined
    })
  }

  // 13. Let body be a body whose stream is stream, source is source,
  // and length is length.
  const body = { stream, source, length }

  // 14. Return (body, type).
  return [body, type]
}

// https://fetch.spec.whatwg.org/#bodyinit-safely-extract
function safelyExtractBody (object, keepalive = false) {
  if (!ReadableStream) {
    // istanbul ignore next
    ReadableStream = (__nccwpck_require__(3774).ReadableStream)
  }

  // To safely extract a body and a `Content-Type` value from
  // a byte sequence or BodyInit object object, run these steps:

  // 1. If object is a ReadableStream object, then:
  if (object instanceof ReadableStream) {
    // Assert: object is neither disturbed nor locked.
    // istanbul ignore next
    assert(!util.isDisturbed(object), 'The body has already been consumed.')
    // istanbul ignore next
    assert(!object.locked, 'The stream is locked.')
  }

  // 2. Return the results of extracting object.
  return extractBody(object, keepalive)
}

function cloneBody (body) {
  // To clone a body body, run these steps:

  // https://fetch.spec.whatwg.org/#concept-body-clone

  // 1. Let  out1, out2  be the result of teeing bodys stream.
  const [out1, out2] = body.stream.tee()
  const out2Clone = structuredClone(out2, { transfer: [out2] })
  // This, for whatever reasons, unrefs out2Clone which allows
  // the process to exit by itself.
  const [, finalClone] = out2Clone.tee()

  // 2. Set bodys stream to out1.
  body.stream = out1

  // 3. Return a body whose stream is out2 and other members are copied from body.
  return {
    stream: finalClone,
    length: body.length,
    source: body.source
  }
}

async function * consumeBody (body) {
  if (body) {
    if (isUint8Array(body)) {
      yield body
    } else {
      const stream = body.stream

      if (util.isDisturbed(stream)) {
        throw new TypeError('The body has already been consumed.')
      }

      if (stream.locked) {
        throw new TypeError('The stream is locked.')
      }

      // Compat.
      stream[kBodyUsed] = true

      yield * stream
    }
  }
}

function throwIfAborted (state) {
  if (state.aborted) {
    throw new DOMException('The operation was aborted.', 'AbortError')
  }
}

function bodyMixinMethods (instance) {
  const methods = {
    blob () {
      // The blob() method steps are to return the result of
      // running consume body with this and the following step
      // given a byte sequence bytes: return a Blob whose
      // contents are bytes and whose type attribute is thiss
      // MIME type.
      return specConsumeBody(this, (bytes) => {
        let mimeType = bodyMimeType(this)

        if (mimeType === 'failure') {
          mimeType = ''
        } else if (mimeType) {
          mimeType = serializeAMimeType(mimeType)
        }

        // Return a Blob whose contents are bytes and type attribute
        // is mimeType.
        return new Blob([bytes], { type: mimeType })
      }, instance)
    },

    arrayBuffer () {
      // The arrayBuffer() method steps are to return the result
      // of running consume body with this and the following step
      // given a byte sequence bytes: return a new ArrayBuffer
      // whose contents are bytes.
      return specConsumeBody(this, (bytes) => {
        return new Uint8Array(bytes).buffer
      }, instance)
    },

    text () {
      // The text() method steps are to return the result of running
      // consume body with this and UTF-8 decode.
      return specConsumeBody(this, utf8DecodeBytes, instance)
    },

    json () {
      // The json() method steps are to return the result of running
      // consume body with this and parse JSON from bytes.
      return specConsumeBody(this, parseJSONFromBytes, instance)
    },

    async formData () {
      webidl.brandCheck(this, instance)

      throwIfAborted(this[kState])

      const contentType = this.headers.get('Content-Type')

      // If mimeTypes essence is "multipart/form-data", then:
      if (/multipart\/form-data/.test(contentType)) {
        const headers = {}
        for (const [key, value] of this.headers) headers[key.toLowerCase()] = value

        const responseFormData = new FormData()

        let busboy

        try {
          busboy = new Busboy({
            headers,
            preservePath: true
          })
        } catch (err) {
          throw new DOMException(`${err}`, 'AbortError')
        }

        busboy.on('field', (name, value) => {
          responseFormData.append(name, value)
        })
        busboy.on('file', (name, value, filename, encoding, mimeType) => {
          const chunks = []

          if (encoding === 'base64' || encoding.toLowerCase() === 'base64') {
            let base64chunk = ''

            value.on('data', (chunk) => {
              base64chunk += chunk.toString().replace(/[\r\n]/gm, '')

              const end = base64chunk.length - base64chunk.length % 4
              chunks.push(Buffer.from(base64chunk.slice(0, end), 'base64'))

              base64chunk = base64chunk.slice(end)
            })
            value.on('end', () => {
              chunks.push(Buffer.from(base64chunk, 'base64'))
              responseFormData.append(name, new File(chunks, filename, { type: mimeType }))
            })
          } else {
            value.on('data', (chunk) => {
              chunks.push(chunk)
            })
            value.on('end', () => {
              responseFormData.append(name, new File(chunks, filename, { type: mimeType }))
            })
          }
        })

        const busboyResolve = new Promise((resolve, reject) => {
          busboy.on('finish', resolve)
          busboy.on('error', (err) => reject(new TypeError(err)))
        })

        if (this.body !== null) for await (const chunk of consumeBody(this[kState].body)) busboy.write(chunk)
        busboy.end()
        await busboyResolve

        return responseFormData
      } else if (/application\/x-www-form-urlencoded/.test(contentType)) {
        // Otherwise, if mimeTypes essence is "application/x-www-form-urlencoded", then:

        // 1. Let entries be the result of parsing bytes.
        let entries
        try {
          let text = ''
          // application/x-www-form-urlencoded parser will keep the BOM.
          // https://url.spec.whatwg.org/#concept-urlencoded-parser
          // Note that streaming decoder is stateful and cannot be reused
          const streamingDecoder = new TextDecoder('utf-8', { ignoreBOM: true })

          for await (const chunk of consumeBody(this[kState].body)) {
            if (!isUint8Array(chunk)) {
              throw new TypeError('Expected Uint8Array chunk')
            }
            text += streamingDecoder.decode(chunk, { stream: true })
          }
          text += streamingDecoder.decode()
          entries = new URLSearchParams(text)
        } catch (err) {
          // istanbul ignore next: Unclear when new URLSearchParams can fail on a string.
          // 2. If entries is failure, then throw a TypeError.
          throw Object.assign(new TypeError(), { cause: err })
        }

        // 3. Return a new FormData object whose entries are entries.
        const formData = new FormData()
        for (const [name, value] of entries) {
          formData.append(name, value)
        }
        return formData
      } else {
        // Wait a tick before checking if the request has been aborted.
        // Otherwise, a TypeError can be thrown when an AbortError should.
        await Promise.resolve()

        throwIfAborted(this[kState])

        // Otherwise, throw a TypeError.
        throw webidl.errors.exception({
          header: `${instance.name}.formData`,
          message: 'Could not parse content as FormData.'
        })
      }
    }
  }

  return methods
}

function mixinBody (prototype) {
  Object.assign(prototype.prototype, bodyMixinMethods(prototype))
}

/**
 * @see https://fetch.spec.whatwg.org/#concept-body-consume-body
 * @param {Response|Request} object
 * @param {(value: unknown) => unknown} convertBytesToJSValue
 * @param {Response|Request} instance
 */
async function specConsumeBody (object, convertBytesToJSValue, instance) {
  webidl.brandCheck(object, instance)

  throwIfAborted(object[kState])

  // 1. If object is unusable, then return a promise rejected
  //    with a TypeError.
  if (bodyUnusable(object[kState].body)) {
    throw new TypeError('Body is unusable')
  }

  // 2. Let promise be a new promise.
  const promise = createDeferredPromise()

  // 3. Let errorSteps given error be to reject promise with error.
  const errorSteps = (error) => promise.reject(error)

  // 4. Let successSteps given a byte sequence data be to resolve
  //    promise with the result of running convertBytesToJSValue
  //    with data. If that threw an exception, then run errorSteps
  //    with that exception.
  const successSteps = (data) => {
    try {
      promise.resolve(convertBytesToJSValue(data))
    } catch (e) {
      errorSteps(e)
    }
  }

  // 5. If objects body is null, then run successSteps with an
  //    empty byte sequence.
  if (object[kState].body == null) {
    successSteps(new Uint8Array())
    return promise.promise
  }

  // 6. Otherwise, fully read objects body given successSteps,
  //    errorSteps, and objects relevant global object.
  await fullyReadBody(object[kState].body, successSteps, errorSteps)

  // 7. Return promise.
  return promise.promise
}

// https://fetch.spec.whatwg.org/#body-unusable
function bodyUnusable (body) {
  // An object including the Body interface mixin is
  // said to be unusable if its body is non-null and
  // its bodys stream is disturbed or locked.
  return body != null && (body.stream.locked || util.isDisturbed(body.stream))
}

/**
 * @see https://encoding.spec.whatwg.org/#utf-8-decode
 * @param {Buffer} buffer
 */
function utf8DecodeBytes (buffer) {
  if (buffer.length === 0) {
    return ''
  }

  // 1. Let buffer be the result of peeking three bytes from
  //    ioQueue, converted to a byte sequence.

  // 2. If buffer is 0xEF 0xBB 0xBF, then read three
  //    bytes from ioQueue. (Do nothing with those bytes.)
  if (buffer[0] === 0xEF && buffer[1] === 0xBB && buffer[2] === 0xBF) {
    buffer = buffer.subarray(3)
  }

  // 3. Process a queue with an instance of UTF-8s
  //    decoder, ioQueue, output, and "replacement".
  const output = textDecoder.decode(buffer)

  // 4. Return output.
  return output
}

/**
 * @see https://infra.spec.whatwg.org/#parse-json-bytes-to-a-javascript-value
 * @param {Uint8Array} bytes
 */
function parseJSONFromBytes (bytes) {
  return JSON.parse(utf8DecodeBytes(bytes))
}

/**
 * @see https://fetch.spec.whatwg.org/#concept-body-mime-type
 * @param {import('./response').Response|import('./request').Request} object
 */
function bodyMimeType (object) {
  const { headersList } = object[kState]
  const contentType = headersList.get('content-type')

  if (contentType === null) {
    return 'failure'
  }

  return parseMIMEType(contentType)
}

module.exports = {
  extractBody,
  safelyExtractBody,
  cloneBody,
  mixinBody
}


/***/ }),

/***/ 7326:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { MessageChannel, receiveMessageOnPort } = __nccwpck_require__(8167)

const corsSafeListedMethods = ['GET', 'HEAD', 'POST']
const corsSafeListedMethodsSet = new Set(corsSafeListedMethods)

const nullBodyStatus = [101, 204, 205, 304]

const redirectStatus = [301, 302, 303, 307, 308]
const redirectStatusSet = new Set(redirectStatus)

// https://fetch.spec.whatwg.org/#block-bad-port
const badPorts = [
  '1', '7', '9', '11', '13', '15', '17', '19', '20', '21', '22', '23', '25', '37', '42', '43', '53', '69', '77', '79',
  '87', '95', '101', '102', '103', '104', '109', '110', '111', '113', '115', '117', '119', '123', '135', '137',
  '139', '143', '161', '179', '389', '427', '465', '512', '513', '514', '515', '526', '530', '531', '532',
  '540', '548', '554', '556', '563', '587', '601', '636', '989', '990', '993', '995', '1719', '1720', '1723',
  '2049', '3659', '4045', '5060', '5061', '6000', '6566', '6665', '6666', '6667', '6668', '6669', '6697',
  '10080'
]

const badPortsSet = new Set(badPorts)

// https://w3c.github.io/webappsec-referrer-policy/#referrer-policies
const referrerPolicy = [
  '',
  'no-referrer',
  'no-referrer-when-downgrade',
  'same-origin',
  'origin',
  'strict-origin',
  'origin-when-cross-origin',
  'strict-origin-when-cross-origin',
  'unsafe-url'
]
const referrerPolicySet = new Set(referrerPolicy)

const requestRedirect = ['follow', 'manual', 'error']

const safeMethods = ['GET', 'HEAD', 'OPTIONS', 'TRACE']
const safeMethodsSet = new Set(safeMethods)

const requestMode = ['navigate', 'same-origin', 'no-cors', 'cors']

const requestCredentials = ['omit', 'same-origin', 'include']

const requestCache = [
  'default',
  'no-store',
  'reload',
  'no-cache',
  'force-cache',
  'only-if-cached'
]

// https://fetch.spec.whatwg.org/#request-body-header-name
const requestBodyHeader = [
  'content-encoding',
  'content-language',
  'content-location',
  'content-type',
  // See https://github.com/nodejs/undici/issues/2021
  // 'Content-Length' is a forbidden header name, which is typically
  // removed in the Headers implementation. However, undici doesn't
  // filter out headers, so we add it here.
  'content-length'
]

// https://fetch.spec.whatwg.org/#enumdef-requestduplex
const requestDuplex = [
  'half'
]

// http://fetch.spec.whatwg.org/#forbidden-method
const forbiddenMethods = ['CONNECT', 'TRACE', 'TRACK']
const forbiddenMethodsSet = new Set(forbiddenMethods)

const subresource = [
  'audio',
  'audioworklet',
  'font',
  'image',
  'manifest',
  'paintworklet',
  'script',
  'style',
  'track',
  'video',
  'xslt',
  ''
]
const subresourceSet = new Set(subresource)

/** @type {globalThis['DOMException']} */
const DOMException = globalThis.DOMException ?? (() => {
  // DOMException was only made a global in Node v17.0.0,
  // but fetch supports >= v16.8.
  try {
    atob('~')
  } catch (err) {
    return Object.getPrototypeOf(err).constructor
  }
})()

let channel

/** @type {globalThis['structuredClone']} */
const structuredClone =
  globalThis.structuredClone ??
  // https://github.com/nodejs/node/blob/b27ae24dcc4251bad726d9d84baf678d1f707fed/lib/internal/structured_clone.js
  // structuredClone was added in v17.0.0, but fetch supports v16.8
  function structuredClone (value, options = undefined) {
    if (arguments.length === 0) {
      throw new TypeError('missing argument')
    }

    if (!channel) {
      channel = new MessageChannel()
    }
    channel.port1.unref()
    channel.port2.unref()
    channel.port1.postMessage(value, options?.transfer)
    return receiveMessageOnPort(channel.port2).message
  }

module.exports = {
  DOMException,
  structuredClone,
  subresource,
  forbiddenMethods,
  requestBodyHeader,
  referrerPolicy,
  requestRedirect,
  requestMode,
  requestCredentials,
  requestCache,
  redirectStatus,
  corsSafeListedMethods,
  nullBodyStatus,
  safeMethods,
  badPorts,
  requestDuplex,
  subresourceSet,
  badPortsSet,
  redirectStatusSet,
  corsSafeListedMethodsSet,
  safeMethodsSet,
  forbiddenMethodsSet,
  referrerPolicySet
}


/***/ }),

/***/ 4322:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

const assert = __nccwpck_require__(2613)
const { atob } = __nccwpck_require__(181)
const { isomorphicDecode } = __nccwpck_require__(5523)

const encoder = new TextEncoder()

/**
 * @see https://mimesniff.spec.whatwg.org/#http-token-code-point
 */
const HTTP_TOKEN_CODEPOINTS = /^[!#$%&'*+-.^_|~A-Za-z0-9]+$/
const HTTP_WHITESPACE_REGEX = /(\u000A|\u000D|\u0009|\u0020)/ // eslint-disable-line
/**
 * @see https://mimesniff.spec.whatwg.org/#http-quoted-string-token-code-point
 */
const HTTP_QUOTED_STRING_TOKENS = /[\u0009|\u0020-\u007E|\u0080-\u00FF]/ // eslint-disable-line

// https://fetch.spec.whatwg.org/#data-url-processor
/** @param {URL} dataURL */
function dataURLProcessor (dataURL) {
  // 1. Assert: dataURLs scheme is "data".
  assert(dataURL.protocol === 'data:')

  // 2. Let input be the result of running the URL
  // serializer on dataURL with exclude fragment
  // set to true.
  let input = URLSerializer(dataURL, true)

  // 3. Remove the leading "data:" string from input.
  input = input.slice(5)

  // 4. Let position point at the start of input.
  const position = { position: 0 }

  // 5. Let mimeType be the result of collecting a
  // sequence of code points that are not equal
  // to U+002C (,), given position.
  let mimeType = collectASequenceOfCodePointsFast(
    ',',
    input,
    position
  )

  // 6. Strip leading and trailing ASCII whitespace
  // from mimeType.
  // Undici implementation note: we need to store the
  // length because if the mimetype has spaces removed,
  // the wrong amount will be sliced from the input in
  // step #9
  const mimeTypeLength = mimeType.length
  mimeType = removeASCIIWhitespace(mimeType, true, true)

  // 7. If position is past the end of input, then
  // return failure
  if (position.position >= input.length) {
    return 'failure'
  }

  // 8. Advance position by 1.
  position.position++

  // 9. Let encodedBody be the remainder of input.
  const encodedBody = input.slice(mimeTypeLength + 1)

  // 10. Let body be the percent-decoding of encodedBody.
  let body = stringPercentDecode(encodedBody)

  // 11. If mimeType ends with U+003B (;), followed by
  // zero or more U+0020 SPACE, followed by an ASCII
  // case-insensitive match for "base64", then:
  if (/;(\u0020){0,}base64$/i.test(mimeType)) {
    // 1. Let stringBody be the isomorphic decode of body.
    const stringBody = isomorphicDecode(body)

    // 2. Set body to the forgiving-base64 decode of
    // stringBody.
    body = forgivingBase64(stringBody)

    // 3. If body is failure, then return failure.
    if (body === 'failure') {
      return 'failure'
    }

    // 4. Remove the last 6 code points from mimeType.
    mimeType = mimeType.slice(0, -6)

    // 5. Remove trailing U+0020 SPACE code points from mimeType,
    // if any.
    mimeType = mimeType.replace(/(\u0020)+$/, '')

    // 6. Remove the last U+003B (;) code point from mimeType.
    mimeType = mimeType.slice(0, -1)
  }

  // 12. If mimeType starts with U+003B (;), then prepend
  // "text/plain" to mimeType.
  if (mimeType.startsWith(';')) {
    mimeType = 'text/plain' + mimeType
  }

  // 13. Let mimeTypeRecord be the result of parsing
  // mimeType.
  let mimeTypeRecord = parseMIMEType(mimeType)

  // 14. If mimeTypeRecord is failure, then set
  // mimeTypeRecord to text/plain;charset=US-ASCII.
  if (mimeTypeRecord === 'failure') {
    mimeTypeRecord = parseMIMEType('text/plain;charset=US-ASCII')
  }

  // 15. Return a new data: URL struct whose MIME
  // type is mimeTypeRecord and body is body.
  // https://fetch.spec.whatwg.org/#data-url-struct
  return { mimeType: mimeTypeRecord, body }
}

// https://url.spec.whatwg.org/#concept-url-serializer
/**
 * @param {URL} url
 * @param {boolean} excludeFragment
 */
function URLSerializer (url, excludeFragment = false) {
  if (!excludeFragment) {
    return url.href
  }

  const href = url.href
  const hashLength = url.hash.length

  return hashLength === 0 ? href : href.substring(0, href.length - hashLength)
}

// https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points
/**
 * @param {(char: string) => boolean} condition
 * @param {string} input
 * @param {{ position: number }} position
 */
function collectASequenceOfCodePoints (condition, input, position) {
  // 1. Let result be the empty string.
  let result = ''

  // 2. While position doesnt point past the end of input and the
  // code point at position within input meets the condition condition:
  while (position.position < input.length && condition(input[position.position])) {
    // 1. Append that code point to the end of result.
    result += input[position.position]

    // 2. Advance position by 1.
    position.position++
  }

  // 3. Return result.
  return result
}

/**
 * A faster collectASequenceOfCodePoints that only works when comparing a single character.
 * @param {string} char
 * @param {string} input
 * @param {{ position: number }} position
 */
function collectASequenceOfCodePointsFast (char, input, position) {
  const idx = input.indexOf(char, position.position)
  const start = position.position

  if (idx === -1) {
    position.position = input.length
    return input.slice(start)
  }

  position.position = idx
  return input.slice(start, position.position)
}

// https://url.spec.whatwg.org/#string-percent-decode
/** @param {string} input */
function stringPercentDecode (input) {
  // 1. Let bytes be the UTF-8 encoding of input.
  const bytes = encoder.encode(input)

  // 2. Return the percent-decoding of bytes.
  return percentDecode(bytes)
}

// https://url.spec.whatwg.org/#percent-decode
/** @param {Uint8Array} input */
function percentDecode (input) {
  // 1. Let output be an empty byte sequence.
  /** @type {number[]} */
  const output = []

  // 2. For each byte byte in input:
  for (let i = 0; i < input.length; i++) {
    const byte = input[i]

    // 1. If byte is not 0x25 (%), then append byte to output.
    if (byte !== 0x25) {
      output.push(byte)

    // 2. Otherwise, if byte is 0x25 (%) and the next two bytes
    // after byte in input are not in the ranges
    // 0x30 (0) to 0x39 (9), 0x41 (A) to 0x46 (F),
    // and 0x61 (a) to 0x66 (f), all inclusive, append byte
    // to output.
    } else if (
      byte === 0x25 &&
      !/^[0-9A-Fa-f]{2}$/i.test(String.fromCharCode(input[i + 1], input[i + 2]))
    ) {
      output.push(0x25)

    // 3. Otherwise:
    } else {
      // 1. Let bytePoint be the two bytes after byte in input,
      // decoded, and then interpreted as hexadecimal number.
      const nextTwoBytes = String.fromCharCode(input[i + 1], input[i + 2])
      const bytePoint = Number.parseInt(nextTwoBytes, 16)

      // 2. Append a byte whose value is bytePoint to output.
      output.push(bytePoint)

      // 3. Skip the next two bytes in input.
      i += 2
    }
  }

  // 3. Return output.
  return Uint8Array.from(output)
}

// https://mimesniff.spec.whatwg.org/#parse-a-mime-type
/** @param {string} input */
function parseMIMEType (input) {
  // 1. Remove any leading and trailing HTTP whitespace
  // from input.
  input = removeHTTPWhitespace(input, true, true)

  // 2. Let position be a position variable for input,
  // initially pointing at the start of input.
  const position = { position: 0 }

  // 3. Let type be the result of collecting a sequence
  // of code points that are not U+002F (/) from
  // input, given position.
  const type = collectASequenceOfCodePointsFast(
    '/',
    input,
    position
  )

  // 4. If type is the empty string or does not solely
  // contain HTTP token code points, then return failure.
  // https://mimesniff.spec.whatwg.org/#http-token-code-point
  if (type.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(type)) {
    return 'failure'
  }

  // 5. If position is past the end of input, then return
  // failure
  if (position.position > input.length) {
    return 'failure'
  }

  // 6. Advance position by 1. (This skips past U+002F (/).)
  position.position++

  // 7. Let subtype be the result of collecting a sequence of
  // code points that are not U+003B (;) from input, given
  // position.
  let subtype = collectASequenceOfCodePointsFast(
    ';',
    input,
    position
  )

  // 8. Remove any trailing HTTP whitespace from subtype.
  subtype = removeHTTPWhitespace(subtype, false, true)

  // 9. If subtype is the empty string or does not solely
  // contain HTTP token code points, then return failure.
  if (subtype.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(subtype)) {
    return 'failure'
  }

  const typeLowercase = type.toLowerCase()
  const subtypeLowercase = subtype.toLowerCase()

  // 10. Let mimeType be a new MIME type record whose type
  // is type, in ASCII lowercase, and subtype is subtype,
  // in ASCII lowercase.
  // https://mimesniff.spec.whatwg.org/#mime-type
  const mimeType = {
    type: typeLowercase,
    subtype: subtypeLowercase,
    /** @type {Map<string, string>} */
    parameters: new Map(),
    // https://mimesniff.spec.whatwg.org/#mime-type-essence
    essence: `${typeLowercase}/${subtypeLowercase}`
  }

  // 11. While position is not past the end of input:
  while (position.position < input.length) {
    // 1. Advance position by 1. (This skips past U+003B (;).)
    position.position++

    // 2. Collect a sequence of code points that are HTTP
    // whitespace from input given position.
    collectASequenceOfCodePoints(
      // https://fetch.spec.whatwg.org/#http-whitespace
      char => HTTP_WHITESPACE_REGEX.test(char),
      input,
      position
    )

    // 3. Let parameterName be the result of collecting a
    // sequence of code points that are not U+003B (;)
    // or U+003D (=) from input, given position.
    let parameterName = collectASequenceOfCodePoints(
      (char) => char !== ';' && char !== '=',
      input,
      position
    )

    // 4. Set parameterName to parameterName, in ASCII
    // lowercase.
    parameterName = parameterName.toLowerCase()

    // 5. If position is not past the end of input, then:
    if (position.position < input.length) {
      // 1. If the code point at position within input is
      // U+003B (;), then continue.
      if (input[position.position] === ';') {
        continue
      }

      // 2. Advance position by 1. (This skips past U+003D (=).)
      position.position++
    }

    // 6. If position is past the end of input, then break.
    if (position.position > input.length) {
      break
    }

    // 7. Let parameterValue be null.
    let parameterValue = null

    // 8. If the code point at position within input is
    // U+0022 ("), then:
    if (input[position.position] === '"') {
      // 1. Set parameterValue to the result of collecting
      // an HTTP quoted string from input, given position
      // and the extract-value flag.
      parameterValue = collectAnHTTPQuotedString(input, position, true)

      // 2. Collect a sequence of code points that are not
      // U+003B (;) from input, given position.
      collectASequenceOfCodePointsFast(
        ';',
        input,
        position
      )

    // 9. Otherwise:
    } else {
      // 1. Set parameterValue to the result of collecting
      // a sequence of code points that are not U+003B (;)
      // from input, given position.
      parameterValue = collectASequenceOfCodePointsFast(
        ';',
        input,
        position
      )

      // 2. Remove any trailing HTTP whitespace from parameterValue.
      parameterValue = removeHTTPWhitespace(parameterValue, false, true)

      // 3. If parameterValue is the empty string, then continue.
      if (parameterValue.length === 0) {
        continue
      }
    }

    // 10. If all of the following are true
    // - parameterName is not the empty string
    // - parameterName solely contains HTTP token code points
    // - parameterValue solely contains HTTP quoted-string token code points
    // - mimeTypes parameters[parameterName] does not exist
    // then set mimeTypes parameters[parameterName] to parameterValue.
    if (
      parameterName.length !== 0 &&
      HTTP_TOKEN_CODEPOINTS.test(parameterName) &&
      (parameterValue.length === 0 || HTTP_QUOTED_STRING_TOKENS.test(parameterValue)) &&
      !mimeType.parameters.has(parameterName)
    ) {
      mimeType.parameters.set(parameterName, parameterValue)
    }
  }

  // 12. Return mimeType.
  return mimeType
}

// https://infra.spec.whatwg.org/#forgiving-base64-decode
/** @param {string} data */
function forgivingBase64 (data) {
  // 1. Remove all ASCII whitespace from data.
  data = data.replace(/[\u0009\u000A\u000C\u000D\u0020]/g, '')  // eslint-disable-line

  // 2. If datas code point length divides by 4 leaving
  // no remainder, then:
  if (data.length % 4 === 0) {
    // 1. If data ends with one or two U+003D (=) code points,
    // then remove them from data.
    data = data.replace(/=?=$/, '')
  }

  // 3. If datas code point length divides by 4 leaving
  // a remainder of 1, then return failure.
  if (data.length % 4 === 1) {
    return 'failure'
  }

  // 4. If data contains a code point that is not one of
  //  U+002B (+)
  //  U+002F (/)
  //  ASCII alphanumeric
  // then return failure.
  if (/[^+/0-9A-Za-z]/.test(data)) {
    return 'failure'
  }

  const binary = atob(data)
  const bytes = new Uint8Array(binary.length)

  for (let byte = 0; byte < binary.length; byte++) {
    bytes[byte] = binary.charCodeAt(byte)
  }

  return bytes
}

// https://fetch.spec.whatwg.org/#collect-an-http-quoted-string
// tests: https://fetch.spec.whatwg.org/#example-http-quoted-string
/**
 * @param {string} input
 * @param {{ position: number }} position
 * @param {boolean?} extractValue
 */
function collectAnHTTPQuotedString (input, position, extractValue) {
  // 1. Let positionStart be position.
  const positionStart = position.position

  // 2. Let value be the empty string.
  let value = ''

  // 3. Assert: the code point at position within input
  // is U+0022 (").
  assert(input[position.position] === '"')

  // 4. Advance position by 1.
  position.position++

  // 5. While true:
  while (true) {
    // 1. Append the result of collecting a sequence of code points
    // that are not U+0022 (") or U+005C (\) from input, given
    // position, to value.
    value += collectASequenceOfCodePoints(
      (char) => char !== '"' && char !== '\\',
      input,
      position
    )

    // 2. If position is past the end of input, then break.
    if (position.position >= input.length) {
      break
    }

    // 3. Let quoteOrBackslash be the code point at position within
    // input.
    const quoteOrBackslash = input[position.position]

    // 4. Advance position by 1.
    position.position++

    // 5. If quoteOrBackslash is U+005C (\), then:
    if (quoteOrBackslash === '\\') {
      // 1. If position is past the end of input, then append
      // U+005C (\) to value and break.
      if (position.position >= input.length) {
        value += '\\'
        break
      }

      // 2. Append the code point at position within input to value.
      value += input[position.position]

      // 3. Advance position by 1.
      position.position++

    // 6. Otherwise:
    } else {
      // 1. Assert: quoteOrBackslash is U+0022 (").
      assert(quoteOrBackslash === '"')

      // 2. Break.
      break
    }
  }

  // 6. If the extract-value flag is set, then return value.
  if (extractValue) {
    return value
  }

  // 7. Return the code points from positionStart to position,
  // inclusive, within input.
  return input.slice(positionStart, position.position)
}

/**
 * @see https://mimesniff.spec.whatwg.org/#serialize-a-mime-type
 */
function serializeAMimeType (mimeType) {
  assert(mimeType !== 'failure')
  const { parameters, essence } = mimeType

  // 1. Let serialization be the concatenation of mimeTypes
  //    type, U+002F (/), and mimeTypes subtype.
  let serialization = essence

  // 2. For each name  value of mimeTypes parameters:
  for (let [name, value] of parameters.entries()) {
    // 1. Append U+003B (;) to serialization.
    serialization += ';'

    // 2. Append name to serialization.
    serialization += name

    // 3. Append U+003D (=) to serialization.
    serialization += '='

    // 4. If value does not solely contain HTTP token code
    //    points or value is the empty string, then:
    if (!HTTP_TOKEN_CODEPOINTS.test(value)) {
      // 1. Precede each occurence of U+0022 (") or
      //    U+005C (\) in value with U+005C (\).
      value = value.replace(/(\\|")/g, '\\$1')

      // 2. Prepend U+0022 (") to value.
      value = '"' + value

      // 3. Append U+0022 (") to value.
      value += '"'
    }

    // 5. Append value to serialization.
    serialization += value
  }

  // 3. Return serialization.
  return serialization
}

/**
 * @see https://fetch.spec.whatwg.org/#http-whitespace
 * @param {string} char
 */
function isHTTPWhiteSpace (char) {
  return char === '\r' || char === '\n' || char === '\t' || char === ' '
}

/**
 * @see https://fetch.spec.whatwg.org/#http-whitespace
 * @param {string} str
 */
function removeHTTPWhitespace (str, leading = true, trailing = true) {
  let lead = 0
  let trail = str.length - 1

  if (leading) {
    for (; lead < str.length && isHTTPWhiteSpace(str[lead]); lead++);
  }

  if (trailing) {
    for (; trail > 0 && isHTTPWhiteSpace(str[trail]); trail--);
  }

  return str.slice(lead, trail + 1)
}

/**
 * @see https://infra.spec.whatwg.org/#ascii-whitespace
 * @param {string} char
 */
function isASCIIWhitespace (char) {
  return char === '\r' || char === '\n' || char === '\t' || char === '\f' || char === ' '
}

/**
 * @see https://infra.spec.whatwg.org/#strip-leading-and-trailing-ascii-whitespace
 */
function removeASCIIWhitespace (str, leading = true, trailing = true) {
  let lead = 0
  let trail = str.length - 1

  if (leading) {
    for (; lead < str.length && isASCIIWhitespace(str[lead]); lead++);
  }

  if (trailing) {
    for (; trail > 0 && isASCIIWhitespace(str[trail]); trail--);
  }

  return str.slice(lead, trail + 1)
}

module.exports = {
  dataURLProcessor,
  URLSerializer,
  collectASequenceOfCodePoints,
  collectASequenceOfCodePointsFast,
  stringPercentDecode,
  parseMIMEType,
  collectAnHTTPQuotedString,
  serializeAMimeType
}


/***/ }),

/***/ 3041:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { Blob, File: NativeFile } = __nccwpck_require__(181)
const { types } = __nccwpck_require__(9023)
const { kState } = __nccwpck_require__(9710)
const { isBlobLike } = __nccwpck_require__(5523)
const { webidl } = __nccwpck_require__(4222)
const { parseMIMEType, serializeAMimeType } = __nccwpck_require__(4322)
const { kEnumerableProperty } = __nccwpck_require__(3440)
const encoder = new TextEncoder()

class File extends Blob {
  constructor (fileBits, fileName, options = {}) {
    // The File constructor is invoked with two or three parameters, depending
    // on whether the optional dictionary parameter is used. When the File()
    // constructor is invoked, user agents must run the following steps:
    webidl.argumentLengthCheck(arguments, 2, { header: 'File constructor' })

    fileBits = webidl.converters['sequence<BlobPart>'](fileBits)
    fileName = webidl.converters.USVString(fileName)
    options = webidl.converters.FilePropertyBag(options)

    // 1. Let bytes be the result of processing blob parts given fileBits and
    // options.
    // Note: Blob handles this for us

    // 2. Let n be the fileName argument to the constructor.
    const n = fileName

    // 3. Process FilePropertyBag dictionary argument by running the following
    // substeps:

    //    1. If the type member is provided and is not the empty string, let t
    //    be set to the type dictionary member. If t contains any characters
    //    outside the range U+0020 to U+007E, then set t to the empty string
    //    and return from these substeps.
    //    2. Convert every character in t to ASCII lowercase.
    let t = options.type
    let d

    // eslint-disable-next-line no-labels
    substep: {
      if (t) {
        t = parseMIMEType(t)

        if (t === 'failure') {
          t = ''
          // eslint-disable-next-line no-labels
          break substep
        }

        t = serializeAMimeType(t).toLowerCase()
      }

      //    3. If the lastModified member is provided, let d be set to the
      //    lastModified dictionary member. If it is not provided, set d to the
      //    current date and time represented as the number of milliseconds since
      //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).
      d = options.lastModified
    }

    // 4. Return a new File object F such that:
    // F refers to the bytes byte sequence.
    // F.size is set to the number of total bytes in bytes.
    // F.name is set to n.
    // F.type is set to t.
    // F.lastModified is set to d.

    super(processBlobParts(fileBits, options), { type: t })
    this[kState] = {
      name: n,
      lastModified: d,
      type: t
    }
  }

  get name () {
    webidl.brandCheck(this, File)

    return this[kState].name
  }

  get lastModified () {
    webidl.brandCheck(this, File)

    return this[kState].lastModified
  }

  get type () {
    webidl.brandCheck(this, File)

    return this[kState].type
  }
}

class FileLike {
  constructor (blobLike, fileName, options = {}) {
    // TODO: argument idl type check

    // The File constructor is invoked with two or three parameters, depending
    // on whether the optional dictionary parameter is used. When the File()
    // constructor is invoked, user agents must run the following steps:

    // 1. Let bytes be the result of processing blob parts given fileBits and
    // options.

    // 2. Let n be the fileName argument to the constructor.
    const n = fileName

    // 3. Process FilePropertyBag dictionary argument by running the following
    // substeps:

    //    1. If the type member is provided and is not the empty string, let t
    //    be set to the type dictionary member. If t contains any characters
    //    outside the range U+0020 to U+007E, then set t to the empty string
    //    and return from these substeps.
    //    TODO
    const t = options.type

    //    2. Convert every character in t to ASCII lowercase.
    //    TODO

    //    3. If the lastModified member is provided, let d be set to the
    //    lastModified dictionary member. If it is not provided, set d to the
    //    current date and time represented as the number of milliseconds since
    //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).
    const d = options.lastModified ?? Date.now()

    // 4. Return a new File object F such that:
    // F refers to the bytes byte sequence.
    // F.size is set to the number of total bytes in bytes.
    // F.name is set to n.
    // F.type is set to t.
    // F.lastModified is set to d.

    this[kState] = {
      blobLike,
      name: n,
      type: t,
      lastModified: d
    }
  }

  stream (...args) {
    webidl.brandCheck(this, FileLike)

    return this[kState].blobLike.stream(...args)
  }

  arrayBuffer (...args) {
    webidl.brandCheck(this, FileLike)

    return this[kState].blobLike.arrayBuffer(...args)
  }

  slice (...args) {
    webidl.brandCheck(this, FileLike)

    return this[kState].blobLike.slice(...args)
  }

  text (...args) {
    webidl.brandCheck(this, FileLike)

    return this[kState].blobLike.text(...args)
  }

  get size () {
    webidl.brandCheck(this, FileLike)

    return this[kState].blobLike.size
  }

  get type () {
    webidl.brandCheck(this, FileLike)

    return this[kState].blobLike.type
  }

  get name () {
    webidl.brandCheck(this, FileLike)

    return this[kState].name
  }

  get lastModified () {
    webidl.brandCheck(this, FileLike)

    return this[kState].lastModified
  }

  get [Symbol.toStringTag] () {
    return 'File'
  }
}

Object.defineProperties(File.prototype, {
  [Symbol.toStringTag]: {
    value: 'File',
    configurable: true
  },
  name: kEnumerableProperty,
  lastModified: kEnumerableProperty
})

webidl.converters.Blob = webidl.interfaceConverter(Blob)

webidl.converters.BlobPart = function (V, opts) {
  if (webidl.util.Type(V) === 'Object') {
    if (isBlobLike(V)) {
      return webidl.converters.Blob(V, { strict: false })
    }

    if (
      ArrayBuffer.isView(V) ||
      types.isAnyArrayBuffer(V)
    ) {
      return webidl.converters.BufferSource(V, opts)
    }
  }

  return webidl.converters.USVString(V, opts)
}

webidl.converters['sequence<BlobPart>'] = webidl.sequenceConverter(
  webidl.converters.BlobPart
)

// https://www.w3.org/TR/FileAPI/#dfn-FilePropertyBag
webidl.converters.FilePropertyBag = webidl.dictionaryConverter([
  {
    key: 'lastModified',
    converter: webidl.converters['long long'],
    get defaultValue () {
      return Date.now()
    }
  },
  {
    key: 'type',
    converter: webidl.converters.DOMString,
    defaultValue: ''
  },
  {
    key: 'endings',
    converter: (value) => {
      value = webidl.converters.DOMString(value)
      value = value.toLowerCase()

      if (value !== 'native') {
        value = 'transparent'
      }

      return value
    },
    defaultValue: 'transparent'
  }
])

/**
 * @see https://www.w3.org/TR/FileAPI/#process-blob-parts
 * @param {(NodeJS.TypedArray|Blob|string)[]} parts
 * @param {{ type: string, endings: string }} options
 */
function processBlobParts (parts, options) {
  // 1. Let bytes be an empty sequence of bytes.
  /** @type {NodeJS.TypedArray[]} */
  const bytes = []

  // 2. For each element in parts:
  for (const element of parts) {
    // 1. If element is a USVString, run the following substeps:
    if (typeof element === 'string') {
      // 1. Let s be element.
      let s = element

      // 2. If the endings member of options is "native", set s
      //    to the result of converting line endings to native
      //    of element.
      if (options.endings === 'native') {
        s = convertLineEndingsNative(s)
      }

      // 3. Append the result of UTF-8 encoding s to bytes.
      bytes.push(encoder.encode(s))
    } else if (
      types.isAnyArrayBuffer(element) ||
      types.isTypedArray(element)
    ) {
      // 2. If element is a BufferSource, get a copy of the
      //    bytes held by the buffer source, and append those
      //    bytes to bytes.
      if (!element.buffer) { // ArrayBuffer
        bytes.push(new Uint8Array(element))
      } else {
        bytes.push(
          new Uint8Array(element.buffer, element.byteOffset, element.byteLength)
        )
      }
    } else if (isBlobLike(element)) {
      // 3. If element is a Blob, append the bytes it represents
      //    to bytes.
      bytes.push(element)
    }
  }

  // 3. Return bytes.
  return bytes
}

/**
 * @see https://www.w3.org/TR/FileAPI/#convert-line-endings-to-native
 * @param {string} s
 */
function convertLineEndingsNative (s) {
  // 1. Let native line ending be be the code point U+000A LF.
  let nativeLineEnding = '\n'

  // 2. If the underlying platforms conventions are to
  //    represent newlines as a carriage return and line feed
  //    sequence, set native line ending to the code point
  //    U+000D CR followed by the code point U+000A LF.
  if (process.platform === 'win32') {
    nativeLineEnding = '\r\n'
  }

  return s.replace(/\r?\n/g, nativeLineEnding)
}

// If this function is moved to ./util.js, some tools (such as
// rollup) will warn about circular dependencies. See:
// https://github.com/nodejs/undici/issues/1629
function isFileLike (object) {
  return (
    (NativeFile && object instanceof NativeFile) ||
    object instanceof File || (
      object &&
      (typeof object.stream === 'function' ||
      typeof object.arrayBuffer === 'function') &&
      object[Symbol.toStringTag] === 'File'
    )
  )
}

module.exports = { File, FileLike, isFileLike }


/***/ }),

/***/ 3073:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { isBlobLike, toUSVString, makeIterator } = __nccwpck_require__(5523)
const { kState } = __nccwpck_require__(9710)
const { File: UndiciFile, FileLike, isFileLike } = __nccwpck_require__(3041)
const { webidl } = __nccwpck_require__(4222)
const { Blob, File: NativeFile } = __nccwpck_require__(181)

/** @type {globalThis['File']} */
const File = NativeFile ?? UndiciFile

// https://xhr.spec.whatwg.org/#formdata
class FormData {
  constructor (form) {
    if (form !== undefined) {
      throw webidl.errors.conversionFailed({
        prefix: 'FormData constructor',
        argument: 'Argument 1',
        types: ['undefined']
      })
    }

    this[kState] = []
  }

  append (name, value, filename = undefined) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 2, { header: 'FormData.append' })

    if (arguments.length === 3 && !isBlobLike(value)) {
      throw new TypeError(
        "Failed to execute 'append' on 'FormData': parameter 2 is not of type 'Blob'"
      )
    }

    // 1. Let value be value if given; otherwise blobValue.

    name = webidl.converters.USVString(name)
    value = isBlobLike(value)
      ? webidl.converters.Blob(value, { strict: false })
      : webidl.converters.USVString(value)
    filename = arguments.length === 3
      ? webidl.converters.USVString(filename)
      : undefined

    // 2. Let entry be the result of creating an entry with
    // name, value, and filename if given.
    const entry = makeEntry(name, value, filename)

    // 3. Append entry to thiss entry list.
    this[kState].push(entry)
  }

  delete (name) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.delete' })

    name = webidl.converters.USVString(name)

    // The delete(name) method steps are to remove all entries whose name
    // is name from thiss entry list.
    this[kState] = this[kState].filter(entry => entry.name !== name)
  }

  get (name) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.get' })

    name = webidl.converters.USVString(name)

    // 1. If there is no entry whose name is name in thiss entry list,
    // then return null.
    const idx = this[kState].findIndex((entry) => entry.name === name)
    if (idx === -1) {
      return null
    }

    // 2. Return the value of the first entry whose name is name from
    // thiss entry list.
    return this[kState][idx].value
  }

  getAll (name) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.getAll' })

    name = webidl.converters.USVString(name)

    // 1. If there is no entry whose name is name in thiss entry list,
    // then return the empty list.
    // 2. Return the values of all entries whose name is name, in order,
    // from thiss entry list.
    return this[kState]
      .filter((entry) => entry.name === name)
      .map((entry) => entry.value)
  }

  has (name) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.has' })

    name = webidl.converters.USVString(name)

    // The has(name) method steps are to return true if there is an entry
    // whose name is name in thiss entry list; otherwise false.
    return this[kState].findIndex((entry) => entry.name === name) !== -1
  }

  set (name, value, filename = undefined) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 2, { header: 'FormData.set' })

    if (arguments.length === 3 && !isBlobLike(value)) {
      throw new TypeError(
        "Failed to execute 'set' on 'FormData': parameter 2 is not of type 'Blob'"
      )
    }

    // The set(name, value) and set(name, blobValue, filename) method steps
    // are:

    // 1. Let value be value if given; otherwise blobValue.

    name = webidl.converters.USVString(name)
    value = isBlobLike(value)
      ? webidl.converters.Blob(value, { strict: false })
      : webidl.converters.USVString(value)
    filename = arguments.length === 3
      ? toUSVString(filename)
      : undefined

    // 2. Let entry be the result of creating an entry with name, value, and
    // filename if given.
    const entry = makeEntry(name, value, filename)

    // 3. If there are entries in thiss entry list whose name is name, then
    // replace the first such entry with entry and remove the others.
    const idx = this[kState].findIndex((entry) => entry.name === name)
    if (idx !== -1) {
      this[kState] = [
        ...this[kState].slice(0, idx),
        entry,
        ...this[kState].slice(idx + 1).filter((entry) => entry.name !== name)
      ]
    } else {
      // 4. Otherwise, append entry to thiss entry list.
      this[kState].push(entry)
    }
  }

  entries () {
    webidl.brandCheck(this, FormData)

    return makeIterator(
      () => this[kState].map(pair => [pair.name, pair.value]),
      'FormData',
      'key+value'
    )
  }

  keys () {
    webidl.brandCheck(this, FormData)

    return makeIterator(
      () => this[kState].map(pair => [pair.name, pair.value]),
      'FormData',
      'key'
    )
  }

  values () {
    webidl.brandCheck(this, FormData)

    return makeIterator(
      () => this[kState].map(pair => [pair.name, pair.value]),
      'FormData',
      'value'
    )
  }

  /**
   * @param {(value: string, key: string, self: FormData) => void} callbackFn
   * @param {unknown} thisArg
   */
  forEach (callbackFn, thisArg = globalThis) {
    webidl.brandCheck(this, FormData)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.forEach' })

    if (typeof callbackFn !== 'function') {
      throw new TypeError(
        "Failed to execute 'forEach' on 'FormData': parameter 1 is not of type 'Function'."
      )
    }

    for (const [key, value] of this) {
      callbackFn.apply(thisArg, [value, key, this])
    }
  }
}

FormData.prototype[Symbol.iterator] = FormData.prototype.entries

Object.defineProperties(FormData.prototype, {
  [Symbol.toStringTag]: {
    value: 'FormData',
    configurable: true
  }
})

/**
 * @see https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#create-an-entry
 * @param {string} name
 * @param {string|Blob} value
 * @param {?string} filename
 * @returns
 */
function makeEntry (name, value, filename) {
  // 1. Set name to the result of converting name into a scalar value string.
  // "To convert a string into a scalar value string, replace any surrogates
  //  with U+FFFD."
  // see: https://nodejs.org/dist/latest-v18.x/docs/api/buffer.html#buftostringencoding-start-end
  name = Buffer.from(name).toString('utf8')

  // 2. If value is a string, then set value to the result of converting
  //    value into a scalar value string.
  if (typeof value === 'string') {
    value = Buffer.from(value).toString('utf8')
  } else {
    // 3. Otherwise:

    // 1. If value is not a File object, then set value to a new File object,
    //    representing the same bytes, whose name attribute value is "blob"
    if (!isFileLike(value)) {
      value = value instanceof Blob
        ? new File([value], 'blob', { type: value.type })
        : new FileLike(value, 'blob', { type: value.type })
    }

    // 2. If filename is given, then set value to a new File object,
    //    representing the same bytes, whose name attribute is filename.
    if (filename !== undefined) {
      /** @type {FilePropertyBag} */
      const options = {
        type: value.type,
        lastModified: value.lastModified
      }

      value = (NativeFile && value instanceof NativeFile) || value instanceof UndiciFile
        ? new File([value], filename, options)
        : new FileLike(value, filename, options)
    }
  }

  // 4. Return an entry whose name is name and whose value is value.
  return { name, value }
}

module.exports = { FormData }


/***/ }),

/***/ 5628:
/***/ ((module) => {

"use strict";


// In case of breaking changes, increase the version
// number to avoid conflicts.
const globalOrigin = Symbol.for('undici.globalOrigin.1')

function getGlobalOrigin () {
  return globalThis[globalOrigin]
}

function setGlobalOrigin (newOrigin) {
  if (newOrigin === undefined) {
    Object.defineProperty(globalThis, globalOrigin, {
      value: undefined,
      writable: true,
      enumerable: false,
      configurable: false
    })

    return
  }

  const parsedURL = new URL(newOrigin)

  if (parsedURL.protocol !== 'http:' && parsedURL.protocol !== 'https:') {
    throw new TypeError(`Only http & https urls are allowed, received ${parsedURL.protocol}`)
  }

  Object.defineProperty(globalThis, globalOrigin, {
    value: parsedURL,
    writable: true,
    enumerable: false,
    configurable: false
  })
}

module.exports = {
  getGlobalOrigin,
  setGlobalOrigin
}


/***/ }),

/***/ 6349:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";
// https://github.com/Ethan-Arrowood/undici-fetch



const { kHeadersList, kConstruct } = __nccwpck_require__(6443)
const { kGuard } = __nccwpck_require__(9710)
const { kEnumerableProperty } = __nccwpck_require__(3440)
const {
  makeIterator,
  isValidHeaderName,
  isValidHeaderValue
} = __nccwpck_require__(5523)
const util = __nccwpck_require__(9023)
const { webidl } = __nccwpck_require__(4222)
const assert = __nccwpck_require__(2613)

const kHeadersMap = Symbol('headers map')
const kHeadersSortedMap = Symbol('headers map sorted')

/**
 * @param {number} code
 */
function isHTTPWhiteSpaceCharCode (code) {
  return code === 0x00a || code === 0x00d || code === 0x009 || code === 0x020
}

/**
 * @see https://fetch.spec.whatwg.org/#concept-header-value-normalize
 * @param {string} potentialValue
 */
function headerValueNormalize (potentialValue) {
  //  To normalize a byte sequence potentialValue, remove
  //  any leading and trailing HTTP whitespace bytes from
  //  potentialValue.
  let i = 0; let j = potentialValue.length

  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(j - 1))) --j
  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(i))) ++i

  return i === 0 && j === potentialValue.length ? potentialValue : potentialValue.substring(i, j)
}

function fill (headers, object) {
  // To fill a Headers object headers with a given object object, run these steps:

  // 1. If object is a sequence, then for each header in object:
  // Note: webidl conversion to array has already been done.
  if (Array.isArray(object)) {
    for (let i = 0; i < object.length; ++i) {
      const header = object[i]
      // 1. If header does not contain exactly two items, then throw a TypeError.
      if (header.length !== 2) {
        throw webidl.errors.exception({
          header: 'Headers constructor',
          message: `expected name/value pair to be length 2, found ${header.length}.`
        })
      }

      // 2. Append (headers first item, headers second item) to headers.
      appendHeader(headers, header[0], header[1])
    }
  } else if (typeof object === 'object' && object !== null) {
    // Note: null should throw

    // 2. Otherwise, object is a record, then for each key  value in object,
    //    append (key, value) to headers
    const keys = Object.keys(object)
    for (let i = 0; i < keys.length; ++i) {
      appendHeader(headers, keys[i], object[keys[i]])
    }
  } else {
    throw webidl.errors.conversionFailed({
      prefix: 'Headers constructor',
      argument: 'Argument 1',
      types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']
    })
  }
}

/**
 * @see https://fetch.spec.whatwg.org/#concept-headers-append
 */
function appendHeader (headers, name, value) {
  // 1. Normalize value.
  value = headerValueNormalize(value)

  // 2. If name is not a header name or value is not a
  //    header value, then throw a TypeError.
  if (!isValidHeaderName(name)) {
    throw webidl.errors.invalidArgument({
      prefix: 'Headers.append',
      value: name,
      type: 'header name'
    })
  } else if (!isValidHeaderValue(value)) {
    throw webidl.errors.invalidArgument({
      prefix: 'Headers.append',
      value,
      type: 'header value'
    })
  }

  // 3. If headerss guard is "immutable", then throw a TypeError.
  // 4. Otherwise, if headerss guard is "request" and name is a
  //    forbidden header name, return.
  // Note: undici does not implement forbidden header names
  if (headers[kGuard] === 'immutable') {
    throw new TypeError('immutable')
  } else if (headers[kGuard] === 'request-no-cors') {
    // 5. Otherwise, if headerss guard is "request-no-cors":
    // TODO
  }

  // 6. Otherwise, if headerss guard is "response" and name is a
  //    forbidden response-header name, return.

  // 7. Append (name, value) to headerss header list.
  return headers[kHeadersList].append(name, value)

  // 8. If headerss guard is "request-no-cors", then remove
  //    privileged no-CORS request headers from headers
}

class HeadersList {
  /** @type {[string, string][]|null} */
  cookies = null

  constructor (init) {
    if (init instanceof HeadersList) {
      this[kHeadersMap] = new Map(init[kHeadersMap])
      this[kHeadersSortedMap] = init[kHeadersSortedMap]
      this.cookies = init.cookies === null ? null : [...init.cookies]
    } else {
      this[kHeadersMap] = new Map(init)
      this[kHeadersSortedMap] = null
    }
  }

  // https://fetch.spec.whatwg.org/#header-list-contains
  contains (name) {
    // A header list list contains a header name name if list
    // contains a header whose name is a byte-case-insensitive
    // match for name.
    name = name.toLowerCase()

    return this[kHeadersMap].has(name)
  }

  clear () {
    this[kHeadersMap].clear()
    this[kHeadersSortedMap] = null
    this.cookies = null
  }

  // https://fetch.spec.whatwg.org/#concept-header-list-append
  append (name, value) {
    this[kHeadersSortedMap] = null

    // 1. If list contains name, then set name to the first such
    //    headers name.
    const lowercaseName = name.toLowerCase()
    const exists = this[kHeadersMap].get(lowercaseName)

    // 2. Append (name, value) to list.
    if (exists) {
      const delimiter = lowercaseName === 'cookie' ? '; ' : ', '
      this[kHeadersMap].set(lowercaseName, {
        name: exists.name,
        value: `${exists.value}${delimiter}${value}`
      })
    } else {
      this[kHeadersMap].set(lowercaseName, { name, value })
    }

    if (lowercaseName === 'set-cookie') {
      this.cookies ??= []
      this.cookies.push(value)
    }
  }

  // https://fetch.spec.whatwg.org/#concept-header-list-set
  set (name, value) {
    this[kHeadersSortedMap] = null
    const lowercaseName = name.toLowerCase()

    if (lowercaseName === 'set-cookie') {
      this.cookies = [value]
    }

    // 1. If list contains name, then set the value of
    //    the first such header to value and remove the
    //    others.
    // 2. Otherwise, append header (name, value) to list.
    this[kHeadersMap].set(lowercaseName, { name, value })
  }

  // https://fetch.spec.whatwg.org/#concept-header-list-delete
  delete (name) {
    this[kHeadersSortedMap] = null

    name = name.toLowerCase()

    if (name === 'set-cookie') {
      this.cookies = null
    }

    this[kHeadersMap].delete(name)
  }

  // https://fetch.spec.whatwg.org/#concept-header-list-get
  get (name) {
    const value = this[kHeadersMap].get(name.toLowerCase())

    // 1. If list does not contain name, then return null.
    // 2. Return the values of all headers in list whose name
    //    is a byte-case-insensitive match for name,
    //    separated from each other by 0x2C 0x20, in order.
    return value === undefined ? null : value.value
  }

  * [Symbol.iterator] () {
    // use the lowercased name
    for (const [name, { value }] of this[kHeadersMap]) {
      yield [name, value]
    }
  }

  get entries () {
    const headers = {}

    if (this[kHeadersMap].size) {
      for (const { name, value } of this[kHeadersMap].values()) {
        headers[name] = value
      }
    }

    return headers
  }
}

// https://fetch.spec.whatwg.org/#headers-class
class Headers {
  constructor (init = undefined) {
    if (init === kConstruct) {
      return
    }
    this[kHeadersList] = new HeadersList()

    // The new Headers(init) constructor steps are:

    // 1. Set thiss guard to "none".
    this[kGuard] = 'none'

    // 2. If init is given, then fill this with init.
    if (init !== undefined) {
      init = webidl.converters.HeadersInit(init)
      fill(this, init)
    }
  }

  // https://fetch.spec.whatwg.org/#dom-headers-append
  append (name, value) {
    webidl.brandCheck(this, Headers)

    webidl.argumentLengthCheck(arguments, 2, { header: 'Headers.append' })

    name = webidl.converters.ByteString(name)
    value = webidl.converters.ByteString(value)

    return appendHeader(this, name, value)
  }

  // https://fetch.spec.whatwg.org/#dom-headers-delete
  delete (name) {
    webidl.brandCheck(this, Headers)

    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.delete' })

    name = webidl.converters.ByteString(name)

    // 1. If name is not a header name, then throw a TypeError.
    if (!isValidHeaderName(name)) {
      throw webidl.errors.invalidArgument({
        prefix: 'Headers.delete',
        value: name,
        type: 'header name'
      })
    }

    // 2. If thiss guard is "immutable", then throw a TypeError.
    // 3. Otherwise, if thiss guard is "request" and name is a
    //    forbidden header name, return.
    // 4. Otherwise, if thiss guard is "request-no-cors", name
    //    is not a no-CORS-safelisted request-header name, and
    //    name is not a privileged no-CORS request-header name,
    //    return.
    // 5. Otherwise, if thiss guard is "response" and name is
    //    a forbidden response-header name, return.
    // Note: undici does not implement forbidden header names
    if (this[kGuard] === 'immutable') {
      throw new TypeError('immutable')
    } else if (this[kGuard] === 'request-no-cors') {
      // TODO
    }

    // 6. If thiss header list does not contain name, then
    //    return.
    if (!this[kHeadersList].contains(name)) {
      return
    }

    // 7. Delete name from thiss header list.
    // 8. If thiss guard is "request-no-cors", then remove
    //    privileged no-CORS request headers from this.
    this[kHeadersList].delete(name)
  }

  // https://fetch.spec.whatwg.org/#dom-headers-get
  get (name) {
    webidl.brandCheck(this, Headers)

    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.get' })

    name = webidl.converters.ByteString(name)

    // 1. If name is not a header name, then throw a TypeError.
    if (!isValidHeaderName(name)) {
      throw webidl.errors.invalidArgument({
        prefix: 'Headers.get',
        value: name,
        type: 'header name'
      })
    }

    // 2. Return the result of getting name from thiss header
    //    list.
    return this[kHeadersList].get(name)
  }

  // https://fetch.spec.whatwg.org/#dom-headers-has
  has (name) {
    webidl.brandCheck(this, Headers)

    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.has' })

    name = webidl.converters.ByteString(name)

    // 1. If name is not a header name, then throw a TypeError.
    if (!isValidHeaderName(name)) {
      throw webidl.errors.invalidArgument({
        prefix: 'Headers.has',
        value: name,
        type: 'header name'
      })
    }

    // 2. Return true if thiss header list contains name;
    //    otherwise false.
    return this[kHeadersList].contains(name)
  }

  // https://fetch.spec.whatwg.org/#dom-headers-set
  set (name, value) {
    webidl.brandCheck(this, Headers)

    webidl.argumentLengthCheck(arguments, 2, { header: 'Headers.set' })

    name = webidl.converters.ByteString(name)
    value = webidl.converters.ByteString(value)

    // 1. Normalize value.
    value = headerValueNormalize(value)

    // 2. If name is not a header name or value is not a
    //    header value, then throw a TypeError.
    if (!isValidHeaderName(name)) {
      throw webidl.errors.invalidArgument({
        prefix: 'Headers.set',
        value: name,
        type: 'header name'
      })
    } else if (!isValidHeaderValue(value)) {
      throw webidl.errors.invalidArgument({
        prefix: 'Headers.set',
        value,
        type: 'header value'
      })
    }

    // 3. If thiss guard is "immutable", then throw a TypeError.
    // 4. Otherwise, if thiss guard is "request" and name is a
    //    forbidden header name, return.
    // 5. Otherwise, if thiss guard is "request-no-cors" and
    //    name/value is not a no-CORS-safelisted request-header,
    //    return.
    // 6. Otherwise, if thiss guard is "response" and name is a
    //    forbidden response-header name, return.
    // Note: undici does not implement forbidden header names
    if (this[kGuard] === 'immutable') {
      throw new TypeError('immutable')
    } else if (this[kGuard] === 'request-no-cors') {
      // TODO
    }

    // 7. Set (name, value) in thiss header list.
    // 8. If thiss guard is "request-no-cors", then remove
    //    privileged no-CORS request headers from this
    this[kHeadersList].set(name, value)
  }

  // https://fetch.spec.whatwg.org/#dom-headers-getsetcookie
  getSetCookie () {
    webidl.brandCheck(this, Headers)

    // 1. If thiss header list does not contain `Set-Cookie`, then return  .
    // 2. Return the values of all headers in thiss header list whose name is
    //    a byte-case-insensitive match for `Set-Cookie`, in order.

    const list = this[kHeadersList].cookies

    if (list) {
      return [...list]
    }

    return []
  }

  // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine
  get [kHeadersSortedMap] () {
    if (this[kHeadersList][kHeadersSortedMap]) {
      return this[kHeadersList][kHeadersSortedMap]
    }

    // 1. Let headers be an empty list of headers with the key being the name
    //    and value the value.
    const headers = []

    // 2. Let names be the result of convert header names to a sorted-lowercase
    //    set with all the names of the headers in list.
    const names = [...this[kHeadersList]].sort((a, b) => a[0] < b[0] ? -1 : 1)
    const cookies = this[kHeadersList].cookies

    // 3. For each name of names:
    for (let i = 0; i < names.length; ++i) {
      const [name, value] = names[i]
      // 1. If name is `set-cookie`, then:
      if (name === 'set-cookie') {
        // 1. Let values be a list of all values of headers in list whose name
        //    is a byte-case-insensitive match for name, in order.

        // 2. For each value of values:
        // 1. Append (name, value) to headers.
        for (let j = 0; j < cookies.length; ++j) {
          headers.push([name, cookies[j]])
        }
      } else {
        // 2. Otherwise:

        // 1. Let value be the result of getting name from list.

        // 2. Assert: value is non-null.
        assert(value !== null)

        // 3. Append (name, value) to headers.
        headers.push([name, value])
      }
    }

    this[kHeadersList][kHeadersSortedMap] = headers

    // 4. Return headers.
    return headers
  }

  keys () {
    webidl.brandCheck(this, Headers)

    if (this[kGuard] === 'immutable') {
      const value = this[kHeadersSortedMap]
      return makeIterator(() => value, 'Headers',
        'key')
    }

    return makeIterator(
      () => [...this[kHeadersSortedMap].values()],
      'Headers',
      'key'
    )
  }

  values () {
    webidl.brandCheck(this, Headers)

    if (this[kGuard] === 'immutable') {
      const value = this[kHeadersSortedMap]
      return makeIterator(() => value, 'Headers',
        'value')
    }

    return makeIterator(
      () => [...this[kHeadersSortedMap].values()],
      'Headers',
      'value'
    )
  }

  entries () {
    webidl.brandCheck(this, Headers)

    if (this[kGuard] === 'immutable') {
      const value = this[kHeadersSortedMap]
      return makeIterator(() => value, 'Headers',
        'key+value')
    }

    return makeIterator(
      () => [...this[kHeadersSortedMap].values()],
      'Headers',
      'key+value'
    )
  }

  /**
   * @param {(value: string, key: string, self: Headers) => void} callbackFn
   * @param {unknown} thisArg
   */
  forEach (callbackFn, thisArg = globalThis) {
    webidl.brandCheck(this, Headers)

    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.forEach' })

    if (typeof callbackFn !== 'function') {
      throw new TypeError(
        "Failed to execute 'forEach' on 'Headers': parameter 1 is not of type 'Function'."
      )
    }

    for (const [key, value] of this) {
      callbackFn.apply(thisArg, [value, key, this])
    }
  }

  [Symbol.for('nodejs.util.inspect.custom')] () {
    webidl.brandCheck(this, Headers)

    return this[kHeadersList]
  }
}

Headers.prototype[Symbol.iterator] = Headers.prototype.entries

Object.defineProperties(Headers.prototype, {
  append: kEnumerableProperty,
  delete: kEnumerableProperty,
  get: kEnumerableProperty,
  has: kEnumerableProperty,
  set: kEnumerableProperty,
  getSetCookie: kEnumerableProperty,
  keys: kEnumerableProperty,
  values: kEnumerableProperty,
  entries: kEnumerableProperty,
  forEach: kEnumerableProperty,
  [Symbol.iterator]: { enumerable: false },
  [Symbol.toStringTag]: {
    value: 'Headers',
    configurable: true
  },
  [util.inspect.custom]: {
    enumerable: false
  }
})

webidl.converters.HeadersInit = function (V) {
  if (webidl.util.Type(V) === 'Object') {
    if (V[Symbol.iterator]) {
      return webidl.converters['sequence<sequence<ByteString>>'](V)
    }

    return webidl.converters['record<ByteString, ByteString>'](V)
  }

  throw webidl.errors.conversionFailed({
    prefix: 'Headers constructor',
    argument: 'Argument 1',
    types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']
  })
}

module.exports = {
  fill,
  Headers,
  HeadersList
}


/***/ }),

/***/ 2315:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";
// https://github.com/Ethan-Arrowood/undici-fetch



const {
  Response,
  makeNetworkError,
  makeAppropriateNetworkError,
  filterResponse,
  makeResponse
} = __nccwpck_require__(8676)
const { Headers } = __nccwpck_require__(6349)
const { Request, makeRequest } = __nccwpck_require__(5194)
const zlib = __nccwpck_require__(3106)
const {
  bytesMatch,
  makePolicyContainer,
  clonePolicyContainer,
  requestBadPort,
  TAOCheck,
  appendRequestOriginHeader,
  responseLocationURL,
  requestCurrentURL,
  setRequestReferrerPolicyOnRedirect,
  tryUpgradeRequestToAPotentiallyTrustworthyURL,
  createOpaqueTimingInfo,
  appendFetchMetadata,
  corsCheck,
  crossOriginResourcePolicyCheck,
  determineRequestsReferrer,
  coarsenedSharedCurrentTime,
  createDeferredPromise,
  isBlobLike,
  sameOrigin,
  isCancelled,
  isAborted,
  isErrorLike,
  fullyReadBody,
  readableStreamClose,
  isomorphicEncode,
  urlIsLocal,
  urlIsHttpHttpsScheme,
  urlHasHttpsScheme
} = __nccwpck_require__(5523)
const { kState, kHeaders, kGuard, kRealm } = __nccwpck_require__(9710)
const assert = __nccwpck_require__(2613)
const { safelyExtractBody } = __nccwpck_require__(8923)
const {
  redirectStatusSet,
  nullBodyStatus,
  safeMethodsSet,
  requestBodyHeader,
  subresourceSet,
  DOMException
} = __nccwpck_require__(7326)
const { kHeadersList } = __nccwpck_require__(6443)
const EE = __nccwpck_require__(4434)
const { Readable, pipeline } = __nccwpck_require__(2203)
const { addAbortListener, isErrored, isReadable, nodeMajor, nodeMinor } = __nccwpck_require__(3440)
const { dataURLProcessor, serializeAMimeType } = __nccwpck_require__(4322)
const { TransformStream } = __nccwpck_require__(3774)
const { getGlobalDispatcher } = __nccwpck_require__(2581)
const { webidl } = __nccwpck_require__(4222)
const { STATUS_CODES } = __nccwpck_require__(8611)
const GET_OR_HEAD = ['GET', 'HEAD']

/** @type {import('buffer').resolveObjectURL} */
let resolveObjectURL
let ReadableStream = globalThis.ReadableStream

class Fetch extends EE {
  constructor (dispatcher) {
    super()

    this.dispatcher = dispatcher
    this.connection = null
    this.dump = false
    this.state = 'ongoing'
    // 2 terminated listeners get added per request,
    // but only 1 gets removed. If there are 20 redirects,
    // 21 listeners will be added.
    // See https://github.com/nodejs/undici/issues/1711
    // TODO (fix): Find and fix root cause for leaked listener.
    this.setMaxListeners(21)
  }

  terminate (reason) {
    if (this.state !== 'ongoing') {
      return
    }

    this.state = 'terminated'
    this.connection?.destroy(reason)
    this.emit('terminated', reason)
  }

  // https://fetch.spec.whatwg.org/#fetch-controller-abort
  abort (error) {
    if (this.state !== 'ongoing') {
      return
    }

    // 1. Set controllers state to "aborted".
    this.state = 'aborted'

    // 2. Let fallbackError be an "AbortError" DOMException.
    // 3. Set error to fallbackError if it is not given.
    if (!error) {
      error = new DOMException('The operation was aborted.', 'AbortError')
    }

    // 4. Let serializedError be StructuredSerialize(error).
    //    If that threw an exception, catch it, and let
    //    serializedError be StructuredSerialize(fallbackError).

    // 5. Set controllers serialized abort reason to serializedError.
    this.serializedAbortReason = error

    this.connection?.destroy(error)
    this.emit('terminated', error)
  }
}

// https://fetch.spec.whatwg.org/#fetch-method
function fetch (input, init = {}) {
  webidl.argumentLengthCheck(arguments, 1, { header: 'globalThis.fetch' })

  // 1. Let p be a new promise.
  const p = createDeferredPromise()

  // 2. Let requestObject be the result of invoking the initial value of
  // Request as constructor with input and init as arguments. If this throws
  // an exception, reject p with it and return p.
  let requestObject

  try {
    requestObject = new Request(input, init)
  } catch (e) {
    p.reject(e)
    return p.promise
  }

  // 3. Let request be requestObjects request.
  const request = requestObject[kState]

  // 4. If requestObjects signals aborted flag is set, then:
  if (requestObject.signal.aborted) {
    // 1. Abort the fetch() call with p, request, null, and
    //    requestObjects signals abort reason.
    abortFetch(p, request, null, requestObject.signal.reason)

    // 2. Return p.
    return p.promise
  }

  // 5. Let globalObject be requests clients global object.
  const globalObject = request.client.globalObject

  // 6. If globalObject is a ServiceWorkerGlobalScope object, then set
  // requests service-workers mode to "none".
  if (globalObject?.constructor?.name === 'ServiceWorkerGlobalScope') {
    request.serviceWorkers = 'none'
  }

  // 7. Let responseObject be null.
  let responseObject = null

  // 8. Let relevantRealm be thiss relevant Realm.
  const relevantRealm = null

  // 9. Let locallyAborted be false.
  let locallyAborted = false

  // 10. Let controller be null.
  let controller = null

  // 11. Add the following abort steps to requestObjects signal:
  addAbortListener(
    requestObject.signal,
    () => {
      // 1. Set locallyAborted to true.
      locallyAborted = true

      // 2. Assert: controller is non-null.
      assert(controller != null)

      // 3. Abort controller with requestObjects signals abort reason.
      controller.abort(requestObject.signal.reason)

      // 4. Abort the fetch() call with p, request, responseObject,
      //    and requestObjects signals abort reason.
      abortFetch(p, request, responseObject, requestObject.signal.reason)
    }
  )

  // 12. Let handleFetchDone given response response be to finalize and
  // report timing with response, globalObject, and "fetch".
  const handleFetchDone = (response) =>
    finalizeAndReportTiming(response, 'fetch')

  // 13. Set controller to the result of calling fetch given request,
  // with processResponseEndOfBody set to handleFetchDone, and processResponse
  // given response being these substeps:

  const processResponse = (response) => {
    // 1. If locallyAborted is true, terminate these substeps.
    if (locallyAborted) {
      return Promise.resolve()
    }

    // 2. If responses aborted flag is set, then:
    if (response.aborted) {
      // 1. Let deserializedError be the result of deserialize a serialized
      //    abort reason given controllers serialized abort reason and
      //    relevantRealm.

      // 2. Abort the fetch() call with p, request, responseObject, and
      //    deserializedError.

      abortFetch(p, request, responseObject, controller.serializedAbortReason)
      return Promise.resolve()
    }

    // 3. If response is a network error, then reject p with a TypeError
    // and terminate these substeps.
    if (response.type === 'error') {
      p.reject(
        Object.assign(new TypeError('fetch failed'), { cause: response.error })
      )
      return Promise.resolve()
    }

    // 4. Set responseObject to the result of creating a Response object,
    // given response, "immutable", and relevantRealm.
    responseObject = new Response()
    responseObject[kState] = response
    responseObject[kRealm] = relevantRealm
    responseObject[kHeaders][kHeadersList] = response.headersList
    responseObject[kHeaders][kGuard] = 'immutable'
    responseObject[kHeaders][kRealm] = relevantRealm

    // 5. Resolve p with responseObject.
    p.resolve(responseObject)
  }

  controller = fetching({
    request,
    processResponseEndOfBody: handleFetchDone,
    processResponse,
    dispatcher: init.dispatcher ?? getGlobalDispatcher() // undici
  })

  // 14. Return p.
  return p.promise
}

// https://fetch.spec.whatwg.org/#finalize-and-report-timing
function finalizeAndReportTiming (response, initiatorType = 'other') {
  // 1. If response is an aborted network error, then return.
  if (response.type === 'error' && response.aborted) {
    return
  }

  // 2. If responses URL list is null or empty, then return.
  if (!response.urlList?.length) {
    return
  }

  // 3. Let originalURL be responses URL list[0].
  const originalURL = response.urlList[0]

  // 4. Let timingInfo be responses timing info.
  let timingInfo = response.timingInfo

  // 5. Let cacheState be responses cache state.
  let cacheState = response.cacheState

  // 6. If originalURLs scheme is not an HTTP(S) scheme, then return.
  if (!urlIsHttpHttpsScheme(originalURL)) {
    return
  }

  // 7. If timingInfo is null, then return.
  if (timingInfo === null) {
    return
  }

  // 8. If responses timing allow passed flag is not set, then:
  if (!response.timingAllowPassed) {
    //  1. Set timingInfo to a the result of creating an opaque timing info for timingInfo.
    timingInfo = createOpaqueTimingInfo({
      startTime: timingInfo.startTime
    })

    //  2. Set cacheState to the empty string.
    cacheState = ''
  }

  // 9. Set timingInfos end time to the coarsened shared current time
  // given globals relevant settings objects cross-origin isolated
  // capability.
  // TODO: given globals relevant settings objects cross-origin isolated
  // capability?
  timingInfo.endTime = coarsenedSharedCurrentTime()

  // 10. Set responses timing info to timingInfo.
  response.timingInfo = timingInfo

  // 11. Mark resource timing for timingInfo, originalURL, initiatorType,
  // global, and cacheState.
  markResourceTiming(
    timingInfo,
    originalURL,
    initiatorType,
    globalThis,
    cacheState
  )
}

// https://w3c.github.io/resource-timing/#dfn-mark-resource-timing
function markResourceTiming (timingInfo, originalURL, initiatorType, globalThis, cacheState) {
  if (nodeMajor > 18 || (nodeMajor === 18 && nodeMinor >= 2)) {
    performance.markResourceTiming(timingInfo, originalURL.href, initiatorType, globalThis, cacheState)
  }
}

// https://fetch.spec.whatwg.org/#abort-fetch
function abortFetch (p, request, responseObject, error) {
  // Note: AbortSignal.reason was added in node v17.2.0
  // which would give us an undefined error to reject with.
  // Remove this once node v16 is no longer supported.
  if (!error) {
    error = new DOMException('The operation was aborted.', 'AbortError')
  }

  // 1. Reject promise with error.
  p.reject(error)

  // 2. If requests body is not null and is readable, then cancel requests
  // body with error.
  if (request.body != null && isReadable(request.body?.stream)) {
    request.body.stream.cancel(error).catch((err) => {
      if (err.code === 'ERR_INVALID_STATE') {
        // Node bug?
        return
      }
      throw err
    })
  }

  // 3. If responseObject is null, then return.
  if (responseObject == null) {
    return
  }

  // 4. Let response be responseObjects response.
  const response = responseObject[kState]

  // 5. If responses body is not null and is readable, then error responses
  // body with error.
  if (response.body != null && isReadable(response.body?.stream)) {
    response.body.stream.cancel(error).catch((err) => {
      if (err.code === 'ERR_INVALID_STATE') {
        // Node bug?
        return
      }
      throw err
    })
  }
}

// https://fetch.spec.whatwg.org/#fetching
function fetching ({
  request,
  processRequestBodyChunkLength,
  processRequestEndOfBody,
  processResponse,
  processResponseEndOfBody,
  processResponseConsumeBody,
  useParallelQueue = false,
  dispatcher // undici
}) {
  // 1. Let taskDestination be null.
  let taskDestination = null

  // 2. Let crossOriginIsolatedCapability be false.
  let crossOriginIsolatedCapability = false

  // 3. If requests client is non-null, then:
  if (request.client != null) {
    // 1. Set taskDestination to requests clients global object.
    taskDestination = request.client.globalObject

    // 2. Set crossOriginIsolatedCapability to requests clients cross-origin
    // isolated capability.
    crossOriginIsolatedCapability =
      request.client.crossOriginIsolatedCapability
  }

  // 4. If useParallelQueue is true, then set taskDestination to the result of
  // starting a new parallel queue.
  // TODO

  // 5. Let timingInfo be a new fetch timing info whose start time and
  // post-redirect start time are the coarsened shared current time given
  // crossOriginIsolatedCapability.
  const currenTime = coarsenedSharedCurrentTime(crossOriginIsolatedCapability)
  const timingInfo = createOpaqueTimingInfo({
    startTime: currenTime
  })

  // 6. Let fetchParams be a new fetch params whose
  // request is request,
  // timing info is timingInfo,
  // process request body chunk length is processRequestBodyChunkLength,
  // process request end-of-body is processRequestEndOfBody,
  // process response is processResponse,
  // process response consume body is processResponseConsumeBody,
  // process response end-of-body is processResponseEndOfBody,
  // task destination is taskDestination,
  // and cross-origin isolated capability is crossOriginIsolatedCapability.
  const fetchParams = {
    controller: new Fetch(dispatcher),
    request,
    timingInfo,
    processRequestBodyChunkLength,
    processRequestEndOfBody,
    processResponse,
    processResponseConsumeBody,
    processResponseEndOfBody,
    taskDestination,
    crossOriginIsolatedCapability
  }

  // 7. If requests body is a byte sequence, then set requests body to
  //    requests body as a body.
  // NOTE: Since fetching is only called from fetch, body should already be
  // extracted.
  assert(!request.body || request.body.stream)

  // 8. If requests window is "client", then set requests window to requests
  // client, if requests clients global object is a Window object; otherwise
  // "no-window".
  if (request.window === 'client') {
    // TODO: What if request.client is null?
    request.window =
      request.client?.globalObject?.constructor?.name === 'Window'
        ? request.client
        : 'no-window'
  }

  // 9. If requests origin is "client", then set requests origin to requests
  // clients origin.
  if (request.origin === 'client') {
    // TODO: What if request.client is null?
    request.origin = request.client?.origin
  }

  // 10. If all of the following conditions are true:
  // TODO

  // 11. If requests policy container is "client", then:
  if (request.policyContainer === 'client') {
    // 1. If requests client is non-null, then set requests policy
    // container to a clone of requests clients policy container. [HTML]
    if (request.client != null) {
      request.policyContainer = clonePolicyContainer(
        request.client.policyContainer
      )
    } else {
      // 2. Otherwise, set requests policy container to a new policy
      // container.
      request.policyContainer = makePolicyContainer()
    }
  }

  // 12. If requests header list does not contain `Accept`, then:
  if (!request.headersList.contains('accept')) {
    // 1. Let value be `*/*`.
    const value = '*/*'

    // 2. A user agent should set value to the first matching statement, if
    // any, switching on requests destination:
    // "document"
    // "frame"
    // "iframe"
    // `text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8`
    // "image"
    // `image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5`
    // "style"
    // `text/css,*/*;q=0.1`
    // TODO

    // 3. Append `Accept`/value to requests header list.
    request.headersList.append('accept', value)
  }

  // 13. If requests header list does not contain `Accept-Language`, then
  // user agents should append `Accept-Language`/an appropriate value to
  // requests header list.
  if (!request.headersList.contains('accept-language')) {
    request.headersList.append('accept-language', '*')
  }

  // 14. If requests priority is null, then use requests initiator and
  // destination appropriately in setting requests priority to a
  // user-agent-defined object.
  if (request.priority === null) {
    // TODO
  }

  // 15. If request is a subresource request, then:
  if (subresourceSet.has(request.destination)) {
    // TODO
  }

  // 16. Run main fetch given fetchParams.
  mainFetch(fetchParams)
    .catch(err => {
      fetchParams.controller.terminate(err)
    })

  // 17. Return fetchParam's controller
  return fetchParams.controller
}

// https://fetch.spec.whatwg.org/#concept-main-fetch
async function mainFetch (fetchParams, recursive = false) {
  // 1. Let request be fetchParamss request.
  const request = fetchParams.request

  // 2. Let response be null.
  let response = null

  // 3. If requests local-URLs-only flag is set and requests current URL is
  // not local, then set response to a network error.
  if (request.localURLsOnly && !urlIsLocal(requestCurrentURL(request))) {
    response = makeNetworkError('local URLs only')
  }

  // 4. Run report Content Security Policy violations for request.
  // TODO

  // 5. Upgrade request to a potentially trustworthy URL, if appropriate.
  tryUpgradeRequestToAPotentiallyTrustworthyURL(request)

  // 6. If should request be blocked due to a bad port, should fetching request
  // be blocked as mixed content, or should request be blocked by Content
  // Security Policy returns blocked, then set response to a network error.
  if (requestBadPort(request) === 'blocked') {
    response = makeNetworkError('bad port')
  }
  // TODO: should fetching request be blocked as mixed content?
  // TODO: should request be blocked by Content Security Policy?

  // 7. If requests referrer policy is the empty string, then set requests
  // referrer policy to requests policy containers referrer policy.
  if (request.referrerPolicy === '') {
    request.referrerPolicy = request.policyContainer.referrerPolicy
  }

  // 8. If requests referrer is not "no-referrer", then set requests
  // referrer to the result of invoking determine requests referrer.
  if (request.referrer !== 'no-referrer') {
    request.referrer = determineRequestsReferrer(request)
  }

  // 9. Set requests current URLs scheme to "https" if all of the following
  // conditions are true:
  // - requests current URLs scheme is "http"
  // - requests current URLs host is a domain
  // - Matching requests current URLs host per Known HSTS Host Domain Name
  //   Matching results in either a superdomain match with an asserted
  //   includeSubDomains directive or a congruent match (with or without an
  //   asserted includeSubDomains directive). [HSTS]
  // TODO

  // 10. If recursive is false, then run the remaining steps in parallel.
  // TODO

  // 11. If response is null, then set response to the result of running
  // the steps corresponding to the first matching statement:
  if (response === null) {
    response = await (async () => {
      const currentURL = requestCurrentURL(request)

      if (
        // - requests current URLs origin is same origin with requests origin,
        //   and requests response tainting is "basic"
        (sameOrigin(currentURL, request.url) && request.responseTainting === 'basic') ||
        // requests current URLs scheme is "data"
        (currentURL.protocol === 'data:') ||
        // - requests mode is "navigate" or "websocket"
        (request.mode === 'navigate' || request.mode === 'websocket')
      ) {
        // 1. Set requests response tainting to "basic".
        request.responseTainting = 'basic'

        // 2. Return the result of running scheme fetch given fetchParams.
        return await schemeFetch(fetchParams)
      }

      // requests mode is "same-origin"
      if (request.mode === 'same-origin') {
        // 1. Return a network error.
        return makeNetworkError('request mode cannot be "same-origin"')
      }

      // requests mode is "no-cors"
      if (request.mode === 'no-cors') {
        // 1. If requests redirect mode is not "follow", then return a network
        // error.
        if (request.redirect !== 'follow') {
          return makeNetworkError(
            'redirect mode cannot be "follow" for "no-cors" request'
          )
        }

        // 2. Set requests response tainting to "opaque".
        request.responseTainting = 'opaque'

        // 3. Return the result of running scheme fetch given fetchParams.
        return await schemeFetch(fetchParams)
      }

      // requests current URLs scheme is not an HTTP(S) scheme
      if (!urlIsHttpHttpsScheme(requestCurrentURL(request))) {
        // Return a network error.
        return makeNetworkError('URL scheme must be a HTTP(S) scheme')
      }

      // - requests use-CORS-preflight flag is set
      // - requests unsafe-request flag is set and either requests method is
      //   not a CORS-safelisted method or CORS-unsafe request-header names with
      //   requests header list is not empty
      //    1. Set requests response tainting to "cors".
      //    2. Let corsWithPreflightResponse be the result of running HTTP fetch
      //    given fetchParams and true.
      //    3. If corsWithPreflightResponse is a network error, then clear cache
      //    entries using request.
      //    4. Return corsWithPreflightResponse.
      // TODO

      // Otherwise
      //    1. Set requests response tainting to "cors".
      request.responseTainting = 'cors'

      //    2. Return the result of running HTTP fetch given fetchParams.
      return await httpFetch(fetchParams)
    })()
  }

  // 12. If recursive is true, then return response.
  if (recursive) {
    return response
  }

  // 13. If response is not a network error and response is not a filtered
  // response, then:
  if (response.status !== 0 && !response.internalResponse) {
    // If requests response tainting is "cors", then:
    if (request.responseTainting === 'cors') {
      // 1. Let headerNames be the result of extracting header list values
      // given `Access-Control-Expose-Headers` and responses header list.
      // TODO
      // 2. If requests credentials mode is not "include" and headerNames
      // contains `*`, then set responses CORS-exposed header-name list to
      // all unique header names in responses header list.
      // TODO
      // 3. Otherwise, if headerNames is not null or failure, then set
      // responses CORS-exposed header-name list to headerNames.
      // TODO
    }

    // Set response to the following filtered response with response as its
    // internal response, depending on requests response tainting:
    if (request.responseTainting === 'basic') {
      response = filterResponse(response, 'basic')
    } else if (request.responseTainting === 'cors') {
      response = filterResponse(response, 'cors')
    } else if (request.responseTainting === 'opaque') {
      response = filterResponse(response, 'opaque')
    } else {
      assert(false)
    }
  }

  // 14. Let internalResponse be response, if response is a network error,
  // and responses internal response otherwise.
  let internalResponse =
    response.status === 0 ? response : response.internalResponse

  // 15. If internalResponses URL list is empty, then set it to a clone of
  // requests URL list.
  if (internalResponse.urlList.length === 0) {
    internalResponse.urlList.push(...request.urlList)
  }

  // 16. If requests timing allow failed flag is unset, then set
  // internalResponses timing allow passed flag.
  if (!request.timingAllowFailed) {
    response.timingAllowPassed = true
  }

  // 17. If response is not a network error and any of the following returns
  // blocked
  // - should internalResponse to request be blocked as mixed content
  // - should internalResponse to request be blocked by Content Security Policy
  // - should internalResponse to request be blocked due to its MIME type
  // - should internalResponse to request be blocked due to nosniff
  // TODO

  // 18. If responses type is "opaque", internalResponses status is 206,
  // internalResponses range-requested flag is set, and requests header
  // list does not contain `Range`, then set response and internalResponse
  // to a network error.
  if (
    response.type === 'opaque' &&
    internalResponse.status === 206 &&
    internalResponse.rangeRequested &&
    !request.headers.contains('range')
  ) {
    response = internalResponse = makeNetworkError()
  }

  // 19. If response is not a network error and either requests method is
  // `HEAD` or `CONNECT`, or internalResponses status is a null body status,
  // set internalResponses body to null and disregard any enqueuing toward
  // it (if any).
  if (
    response.status !== 0 &&
    (request.method === 'HEAD' ||
      request.method === 'CONNECT' ||
      nullBodyStatus.includes(internalResponse.status))
  ) {
    internalResponse.body = null
    fetchParams.controller.dump = true
  }

  // 20. If requests integrity metadata is not the empty string, then:
  if (request.integrity) {
    // 1. Let processBodyError be this step: run fetch finale given fetchParams
    // and a network error.
    const processBodyError = (reason) =>
      fetchFinale(fetchParams, makeNetworkError(reason))

    // 2. If requests response tainting is "opaque", or responses body is null,
    // then run processBodyError and abort these steps.
    if (request.responseTainting === 'opaque' || response.body == null) {
      processBodyError(response.error)
      return
    }

    // 3. Let processBody given bytes be these steps:
    const processBody = (bytes) => {
      // 1. If bytes do not match requests integrity metadata,
      // then run processBodyError and abort these steps. [SRI]
      if (!bytesMatch(bytes, request.integrity)) {
        processBodyError('integrity mismatch')
        return
      }

      // 2. Set responses body to bytes as a body.
      response.body = safelyExtractBody(bytes)[0]

      // 3. Run fetch finale given fetchParams and response.
      fetchFinale(fetchParams, response)
    }

    // 4. Fully read responses body given processBody and processBodyError.
    await fullyReadBody(response.body, processBody, processBodyError)
  } else {
    // 21. Otherwise, run fetch finale given fetchParams and response.
    fetchFinale(fetchParams, response)
  }
}

// https://fetch.spec.whatwg.org/#concept-scheme-fetch
// given a fetch params fetchParams
function schemeFetch (fetchParams) {
  // Note: since the connection is destroyed on redirect, which sets fetchParams to a
  // cancelled state, we do not want this condition to trigger *unless* there have been
  // no redirects. See https://github.com/nodejs/undici/issues/1776
  // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.
  if (isCancelled(fetchParams) && fetchParams.request.redirectCount === 0) {
    return Promise.resolve(makeAppropriateNetworkError(fetchParams))
  }

  // 2. Let request be fetchParamss request.
  const { request } = fetchParams

  const { protocol: scheme } = requestCurrentURL(request)

  // 3. Switch on requests current URLs scheme and run the associated steps:
  switch (scheme) {
    case 'about:': {
      // If requests current URLs path is the string "blank", then return a new response
      // whose status message is `OK`, header list is  (`Content-Type`, `text/html;charset=utf-8`) ,
      // and body is the empty byte sequence as a body.

      // Otherwise, return a network error.
      return Promise.resolve(makeNetworkError('about scheme is not supported'))
    }
    case 'blob:': {
      if (!resolveObjectURL) {
        resolveObjectURL = (__nccwpck_require__(181).resolveObjectURL)
      }

      // 1. Let blobURLEntry be requests current URLs blob URL entry.
      const blobURLEntry = requestCurrentURL(request)

      // https://github.com/web-platform-tests/wpt/blob/7b0ebaccc62b566a1965396e5be7bb2bc06f841f/FileAPI/url/resources/fetch-tests.js#L52-L56
      // Buffer.resolveObjectURL does not ignore URL queries.
      if (blobURLEntry.search.length !== 0) {
        return Promise.resolve(makeNetworkError('NetworkError when attempting to fetch resource.'))
      }

      const blobURLEntryObject = resolveObjectURL(blobURLEntry.toString())

      // 2. If requests method is not `GET`, blobURLEntry is null, or blobURLEntrys
      //    object is not a Blob object, then return a network error.
      if (request.method !== 'GET' || !isBlobLike(blobURLEntryObject)) {
        return Promise.resolve(makeNetworkError('invalid method'))
      }

      // 3. Let bodyWithType be the result of safely extracting blobURLEntrys object.
      const bodyWithType = safelyExtractBody(blobURLEntryObject)

      // 4. Let body be bodyWithTypes body.
      const body = bodyWithType[0]

      // 5. Let length be bodys length, serialized and isomorphic encoded.
      const length = isomorphicEncode(`${body.length}`)

      // 6. Let type be bodyWithTypes type if it is non-null; otherwise the empty byte sequence.
      const type = bodyWithType[1] ?? ''

      // 7. Return a new response whose status message is `OK`, header list is
      //     (`Content-Length`, length), (`Content-Type`, type) , and body is body.
      const response = makeResponse({
        statusText: 'OK',
        headersList: [
          ['content-length', { name: 'Content-Length', value: length }],
          ['content-type', { name: 'Content-Type', value: type }]
        ]
      })

      response.body = body

      return Promise.resolve(response)
    }
    case 'data:': {
      // 1. Let dataURLStruct be the result of running the
      //    data: URL processor on requests current URL.
      const currentURL = requestCurrentURL(request)
      const dataURLStruct = dataURLProcessor(currentURL)

      // 2. If dataURLStruct is failure, then return a
      //    network error.
      if (dataURLStruct === 'failure') {
        return Promise.resolve(makeNetworkError('failed to fetch the data URL'))
      }

      // 3. Let mimeType be dataURLStructs MIME type, serialized.
      const mimeType = serializeAMimeType(dataURLStruct.mimeType)

      // 4. Return a response whose status message is `OK`,
      //    header list is  (`Content-Type`, mimeType) ,
      //    and body is dataURLStructs body as a body.
      return Promise.resolve(makeResponse({
        statusText: 'OK',
        headersList: [
          ['content-type', { name: 'Content-Type', value: mimeType }]
        ],
        body: safelyExtractBody(dataURLStruct.body)[0]
      }))
    }
    case 'file:': {
      // For now, unfortunate as it is, file URLs are left as an exercise for the reader.
      // When in doubt, return a network error.
      return Promise.resolve(makeNetworkError('not implemented... yet...'))
    }
    case 'http:':
    case 'https:': {
      // Return the result of running HTTP fetch given fetchParams.

      return httpFetch(fetchParams)
        .catch((err) => makeNetworkError(err))
    }
    default: {
      return Promise.resolve(makeNetworkError('unknown scheme'))
    }
  }
}

// https://fetch.spec.whatwg.org/#finalize-response
function finalizeResponse (fetchParams, response) {
  // 1. Set fetchParamss requests done flag.
  fetchParams.request.done = true

  // 2, If fetchParamss process response done is not null, then queue a fetch
  // task to run fetchParamss process response done given response, with
  // fetchParamss task destination.
  if (fetchParams.processResponseDone != null) {
    queueMicrotask(() => fetchParams.processResponseDone(response))
  }
}

// https://fetch.spec.whatwg.org/#fetch-finale
function fetchFinale (fetchParams, response) {
  // 1. If response is a network error, then:
  if (response.type === 'error') {
    // 1. Set responses URL list to  fetchParamss requests URL list[0] .
    response.urlList = [fetchParams.request.urlList[0]]

    // 2. Set responses timing info to the result of creating an opaque timing
    // info for fetchParamss timing info.
    response.timingInfo = createOpaqueTimingInfo({
      startTime: fetchParams.timingInfo.startTime
    })
  }

  // 2. Let processResponseEndOfBody be the following steps:
  const processResponseEndOfBody = () => {
    // 1. Set fetchParamss requests done flag.
    fetchParams.request.done = true

    // If fetchParamss process response end-of-body is not null,
    // then queue a fetch task to run fetchParamss process response
    // end-of-body given response with fetchParamss task destination.
    if (fetchParams.processResponseEndOfBody != null) {
      queueMicrotask(() => fetchParams.processResponseEndOfBody(response))
    }
  }

  // 3. If fetchParamss process response is non-null, then queue a fetch task
  // to run fetchParamss process response given response, with fetchParamss
  // task destination.
  if (fetchParams.processResponse != null) {
    queueMicrotask(() => fetchParams.processResponse(response))
  }

  // 4. If responses body is null, then run processResponseEndOfBody.
  if (response.body == null) {
    processResponseEndOfBody()
  } else {
  // 5. Otherwise:

    // 1. Let transformStream be a new a TransformStream.

    // 2. Let identityTransformAlgorithm be an algorithm which, given chunk,
    // enqueues chunk in transformStream.
    const identityTransformAlgorithm = (chunk, controller) => {
      controller.enqueue(chunk)
    }

    // 3. Set up transformStream with transformAlgorithm set to identityTransformAlgorithm
    // and flushAlgorithm set to processResponseEndOfBody.
    const transformStream = new TransformStream({
      start () {},
      transform: identityTransformAlgorithm,
      flush: processResponseEndOfBody
    }, {
      size () {
        return 1
      }
    }, {
      size () {
        return 1
      }
    })

    // 4. Set responses body to the result of piping responses body through transformStream.
    response.body = { stream: response.body.stream.pipeThrough(transformStream) }
  }

  // 6. If fetchParamss process response consume body is non-null, then:
  if (fetchParams.processResponseConsumeBody != null) {
    // 1. Let processBody given nullOrBytes be this step: run fetchParamss
    // process response consume body given response and nullOrBytes.
    const processBody = (nullOrBytes) => fetchParams.processResponseConsumeBody(response, nullOrBytes)

    // 2. Let processBodyError be this step: run fetchParamss process
    // response consume body given response and failure.
    const processBodyError = (failure) => fetchParams.processResponseConsumeBody(response, failure)

    // 3. If responses body is null, then queue a fetch task to run processBody
    // given null, with fetchParamss task destination.
    if (response.body == null) {
      queueMicrotask(() => processBody(null))
    } else {
      // 4. Otherwise, fully read responses body given processBody, processBodyError,
      // and fetchParamss task destination.
      return fullyReadBody(response.body, processBody, processBodyError)
    }
    return Promise.resolve()
  }
}

// https://fetch.spec.whatwg.org/#http-fetch
async function httpFetch (fetchParams) {
  // 1. Let request be fetchParamss request.
  const request = fetchParams.request

  // 2. Let response be null.
  let response = null

  // 3. Let actualResponse be null.
  let actualResponse = null

  // 4. Let timingInfo be fetchParamss timing info.
  const timingInfo = fetchParams.timingInfo

  // 5. If requests service-workers mode is "all", then:
  if (request.serviceWorkers === 'all') {
    // TODO
  }

  // 6. If response is null, then:
  if (response === null) {
    // 1. If makeCORSPreflight is true and one of these conditions is true:
    // TODO

    // 2. If requests redirect mode is "follow", then set requests
    // service-workers mode to "none".
    if (request.redirect === 'follow') {
      request.serviceWorkers = 'none'
    }

    // 3. Set response and actualResponse to the result of running
    // HTTP-network-or-cache fetch given fetchParams.
    actualResponse = response = await httpNetworkOrCacheFetch(fetchParams)

    // 4. If requests response tainting is "cors" and a CORS check
    // for request and response returns failure, then return a network error.
    if (
      request.responseTainting === 'cors' &&
      corsCheck(request, response) === 'failure'
    ) {
      return makeNetworkError('cors failure')
    }

    // 5. If the TAO check for request and response returns failure, then set
    // requests timing allow failed flag.
    if (TAOCheck(request, response) === 'failure') {
      request.timingAllowFailed = true
    }
  }

  // 7. If either requests response tainting or responses type
  // is "opaque", and the cross-origin resource policy check with
  // requests origin, requests client, requests destination,
  // and actualResponse returns blocked, then return a network error.
  if (
    (request.responseTainting === 'opaque' || response.type === 'opaque') &&
    crossOriginResourcePolicyCheck(
      request.origin,
      request.client,
      request.destination,
      actualResponse
    ) === 'blocked'
  ) {
    return makeNetworkError('blocked')
  }

  // 8. If actualResponses status is a redirect status, then:
  if (redirectStatusSet.has(actualResponse.status)) {
    // 1. If actualResponses status is not 303, requests body is not null,
    // and the connection uses HTTP/2, then user agents may, and are even
    // encouraged to, transmit an RST_STREAM frame.
    // See, https://github.com/whatwg/fetch/issues/1288
    if (request.redirect !== 'manual') {
      fetchParams.controller.connection.destroy()
    }

    // 2. Switch on requests redirect mode:
    if (request.redirect === 'error') {
      // Set response to a network error.
      response = makeNetworkError('unexpected redirect')
    } else if (request.redirect === 'manual') {
      // Set response to an opaque-redirect filtered response whose internal
      // response is actualResponse.
      // NOTE(spec): On the web this would return an `opaqueredirect` response,
      // but that doesn't make sense server side.
      // See https://github.com/nodejs/undici/issues/1193.
      response = actualResponse
    } else if (request.redirect === 'follow') {
      // Set response to the result of running HTTP-redirect fetch given
      // fetchParams and response.
      response = await httpRedirectFetch(fetchParams, response)
    } else {
      assert(false)
    }
  }

  // 9. Set responses timing info to timingInfo.
  response.timingInfo = timingInfo

  // 10. Return response.
  return response
}

// https://fetch.spec.whatwg.org/#http-redirect-fetch
function httpRedirectFetch (fetchParams, response) {
  // 1. Let request be fetchParamss request.
  const request = fetchParams.request

  // 2. Let actualResponse be response, if response is not a filtered response,
  // and responses internal response otherwise.
  const actualResponse = response.internalResponse
    ? response.internalResponse
    : response

  // 3. Let locationURL be actualResponses location URL given requests current
  // URLs fragment.
  let locationURL

  try {
    locationURL = responseLocationURL(
      actualResponse,
      requestCurrentURL(request).hash
    )

    // 4. If locationURL is null, then return response.
    if (locationURL == null) {
      return response
    }
  } catch (err) {
    // 5. If locationURL is failure, then return a network error.
    return Promise.resolve(makeNetworkError(err))
  }

  // 6. If locationURLs scheme is not an HTTP(S) scheme, then return a network
  // error.
  if (!urlIsHttpHttpsScheme(locationURL)) {
    return Promise.resolve(makeNetworkError('URL scheme must be a HTTP(S) scheme'))
  }

  // 7. If requests redirect count is 20, then return a network error.
  if (request.redirectCount === 20) {
    return Promise.resolve(makeNetworkError('redirect count exceeded'))
  }

  // 8. Increase requests redirect count by 1.
  request.redirectCount += 1

  // 9. If requests mode is "cors", locationURL includes credentials, and
  // requests origin is not same origin with locationURLs origin, then return
  //  a network error.
  if (
    request.mode === 'cors' &&
    (locationURL.username || locationURL.password) &&
    !sameOrigin(request, locationURL)
  ) {
    return Promise.resolve(makeNetworkError('cross origin not allowed for request mode "cors"'))
  }

  // 10. If requests response tainting is "cors" and locationURL includes
  // credentials, then return a network error.
  if (
    request.responseTainting === 'cors' &&
    (locationURL.username || locationURL.password)
  ) {
    return Promise.resolve(makeNetworkError(
      'URL cannot contain credentials for request mode "cors"'
    ))
  }

  // 11. If actualResponses status is not 303, requests body is non-null,
  // and requests bodys source is null, then return a network error.
  if (
    actualResponse.status !== 303 &&
    request.body != null &&
    request.body.source == null
  ) {
    return Promise.resolve(makeNetworkError())
  }

  // 12. If one of the following is true
  // - actualResponses status is 301 or 302 and requests method is `POST`
  // - actualResponses status is 303 and requests method is not `GET` or `HEAD`
  if (
    ([301, 302].includes(actualResponse.status) && request.method === 'POST') ||
    (actualResponse.status === 303 &&
      !GET_OR_HEAD.includes(request.method))
  ) {
    // then:
    // 1. Set requests method to `GET` and requests body to null.
    request.method = 'GET'
    request.body = null

    // 2. For each headerName of request-body-header name, delete headerName from
    // requests header list.
    for (const headerName of requestBodyHeader) {
      request.headersList.delete(headerName)
    }
  }

  // 13. If requests current URLs origin is not same origin with locationURLs
  //     origin, then for each headerName of CORS non-wildcard request-header name,
  //     delete headerName from requests header list.
  if (!sameOrigin(requestCurrentURL(request), locationURL)) {
    // https://fetch.spec.whatwg.org/#cors-non-wildcard-request-header-name
    request.headersList.delete('authorization')

    // https://fetch.spec.whatwg.org/#authentication-entries
    request.headersList.delete('proxy-authorization', true)

    // "Cookie" and "Host" are forbidden request-headers, which undici doesn't implement.
    request.headersList.delete('cookie')
    request.headersList.delete('host')
  }

  // 14. If requests body is non-null, then set requests body to the first return
  // value of safely extracting requests bodys source.
  if (request.body != null) {
    assert(request.body.source != null)
    request.body = safelyExtractBody(request.body.source)[0]
  }

  // 15. Let timingInfo be fetchParamss timing info.
  const timingInfo = fetchParams.timingInfo

  // 16. Set timingInfos redirect end time and post-redirect start time to the
  // coarsened shared current time given fetchParamss cross-origin isolated
  // capability.
  timingInfo.redirectEndTime = timingInfo.postRedirectStartTime =
    coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability)

  // 17. If timingInfos redirect start time is 0, then set timingInfos
  //  redirect start time to timingInfos start time.
  if (timingInfo.redirectStartTime === 0) {
    timingInfo.redirectStartTime = timingInfo.startTime
  }

  // 18. Append locationURL to requests URL list.
  request.urlList.push(locationURL)

  // 19. Invoke set requests referrer policy on redirect on request and
  // actualResponse.
  setRequestReferrerPolicyOnRedirect(request, actualResponse)

  // 20. Return the result of running main fetch given fetchParams and true.
  return mainFetch(fetchParams, true)
}

// https://fetch.spec.whatwg.org/#http-network-or-cache-fetch
async function httpNetworkOrCacheFetch (
  fetchParams,
  isAuthenticationFetch = false,
  isNewConnectionFetch = false
) {
  // 1. Let request be fetchParamss request.
  const request = fetchParams.request

  // 2. Let httpFetchParams be null.
  let httpFetchParams = null

  // 3. Let httpRequest be null.
  let httpRequest = null

  // 4. Let response be null.
  let response = null

  // 5. Let storedResponse be null.
  // TODO: cache

  // 6. Let httpCache be null.
  const httpCache = null

  // 7. Let the revalidatingFlag be unset.
  const revalidatingFlag = false

  // 8. Run these steps, but abort when the ongoing fetch is terminated:

  //    1. If requests window is "no-window" and requests redirect mode is
  //    "error", then set httpFetchParams to fetchParams and httpRequest to
  //    request.
  if (request.window === 'no-window' && request.redirect === 'error') {
    httpFetchParams = fetchParams
    httpRequest = request
  } else {
    // Otherwise:

    // 1. Set httpRequest to a clone of request.
    httpRequest = makeRequest(request)

    // 2. Set httpFetchParams to a copy of fetchParams.
    httpFetchParams = { ...fetchParams }

    // 3. Set httpFetchParamss request to httpRequest.
    httpFetchParams.request = httpRequest
  }

  //    3. Let includeCredentials be true if one of
  const includeCredentials =
    request.credentials === 'include' ||
    (request.credentials === 'same-origin' &&
      request.responseTainting === 'basic')

  //    4. Let contentLength be httpRequests bodys length, if httpRequests
  //    body is non-null; otherwise null.
  const contentLength = httpRequest.body ? httpRequest.body.length : null

  //    5. Let contentLengthHeaderValue be null.
  let contentLengthHeaderValue = null

  //    6. If httpRequests body is null and httpRequests method is `POST` or
  //    `PUT`, then set contentLengthHeaderValue to `0`.
  if (
    httpRequest.body == null &&
    ['POST', 'PUT'].includes(httpRequest.method)
  ) {
    contentLengthHeaderValue = '0'
  }

  //    7. If contentLength is non-null, then set contentLengthHeaderValue to
  //    contentLength, serialized and isomorphic encoded.
  if (contentLength != null) {
    contentLengthHeaderValue = isomorphicEncode(`${contentLength}`)
  }

  //    8. If contentLengthHeaderValue is non-null, then append
  //    `Content-Length`/contentLengthHeaderValue to httpRequests header
  //    list.
  if (contentLengthHeaderValue != null) {
    httpRequest.headersList.append('content-length', contentLengthHeaderValue)
  }

  //    9. If contentLengthHeaderValue is non-null, then append (`Content-Length`,
  //    contentLengthHeaderValue) to httpRequests header list.

  //    10. If contentLength is non-null and httpRequests keepalive is true,
  //    then:
  if (contentLength != null && httpRequest.keepalive) {
    // NOTE: keepalive is a noop outside of browser context.
  }

  //    11. If httpRequests referrer is a URL, then append
  //    `Referer`/httpRequests referrer, serialized and isomorphic encoded,
  //     to httpRequests header list.
  if (httpRequest.referrer instanceof URL) {
    httpRequest.headersList.append('referer', isomorphicEncode(httpRequest.referrer.href))
  }

  //    12. Append a request `Origin` header for httpRequest.
  appendRequestOriginHeader(httpRequest)

  //    13. Append the Fetch metadata headers for httpRequest. [FETCH-METADATA]
  appendFetchMetadata(httpRequest)

  //    14. If httpRequests header list does not contain `User-Agent`, then
  //    user agents should append `User-Agent`/default `User-Agent` value to
  //    httpRequests header list.
  if (!httpRequest.headersList.contains('user-agent')) {
    httpRequest.headersList.append('user-agent', typeof esbuildDetection === 'undefined' ? 'undici' : 'node')
  }

  //    15. If httpRequests cache mode is "default" and httpRequests header
  //    list contains `If-Modified-Since`, `If-None-Match`,
  //    `If-Unmodified-Since`, `If-Match`, or `If-Range`, then set
  //    httpRequests cache mode to "no-store".
  if (
    httpRequest.cache === 'default' &&
    (httpRequest.headersList.contains('if-modified-since') ||
      httpRequest.headersList.contains('if-none-match') ||
      httpRequest.headersList.contains('if-unmodified-since') ||
      httpRequest.headersList.contains('if-match') ||
      httpRequest.headersList.contains('if-range'))
  ) {
    httpRequest.cache = 'no-store'
  }

  //    16. If httpRequests cache mode is "no-cache", httpRequests prevent
  //    no-cache cache-control header modification flag is unset, and
  //    httpRequests header list does not contain `Cache-Control`, then append
  //    `Cache-Control`/`max-age=0` to httpRequests header list.
  if (
    httpRequest.cache === 'no-cache' &&
    !httpRequest.preventNoCacheCacheControlHeaderModification &&
    !httpRequest.headersList.contains('cache-control')
  ) {
    httpRequest.headersList.append('cache-control', 'max-age=0')
  }

  //    17. If httpRequests cache mode is "no-store" or "reload", then:
  if (httpRequest.cache === 'no-store' || httpRequest.cache === 'reload') {
    // 1. If httpRequests header list does not contain `Pragma`, then append
    // `Pragma`/`no-cache` to httpRequests header list.
    if (!httpRequest.headersList.contains('pragma')) {
      httpRequest.headersList.append('pragma', 'no-cache')
    }

    // 2. If httpRequests header list does not contain `Cache-Control`,
    // then append `Cache-Control`/`no-cache` to httpRequests header list.
    if (!httpRequest.headersList.contains('cache-control')) {
      httpRequest.headersList.append('cache-control', 'no-cache')
    }
  }

  //    18. If httpRequests header list contains `Range`, then append
  //    `Accept-Encoding`/`identity` to httpRequests header list.
  if (httpRequest.headersList.contains('range')) {
    httpRequest.headersList.append('accept-encoding', 'identity')
  }

  //    19. Modify httpRequests header list per HTTP. Do not append a given
  //    header if httpRequests header list contains that headers name.
  //    TODO: https://github.com/whatwg/fetch/issues/1285#issuecomment-896560129
  if (!httpRequest.headersList.contains('accept-encoding')) {
    if (urlHasHttpsScheme(requestCurrentURL(httpRequest))) {
      httpRequest.headersList.append('accept-encoding', 'br, gzip, deflate')
    } else {
      httpRequest.headersList.append('accept-encoding', 'gzip, deflate')
    }
  }

  httpRequest.headersList.delete('host')

  //    20. If includeCredentials is true, then:
  if (includeCredentials) {
    // 1. If the user agent is not configured to block cookies for httpRequest
    // (see section 7 of [COOKIES]), then:
    // TODO: credentials
    // 2. If httpRequests header list does not contain `Authorization`, then:
    // TODO: credentials
  }

  //    21. If theres a proxy-authentication entry, use it as appropriate.
  //    TODO: proxy-authentication

  //    22. Set httpCache to the result of determining the HTTP cache
  //    partition, given httpRequest.
  //    TODO: cache

  //    23. If httpCache is null, then set httpRequests cache mode to
  //    "no-store".
  if (httpCache == null) {
    httpRequest.cache = 'no-store'
  }

  //    24. If httpRequests cache mode is neither "no-store" nor "reload",
  //    then:
  if (httpRequest.mode !== 'no-store' && httpRequest.mode !== 'reload') {
    // TODO: cache
  }

  // 9. If aborted, then return the appropriate network error for fetchParams.
  // TODO

  // 10. If response is null, then:
  if (response == null) {
    // 1. If httpRequests cache mode is "only-if-cached", then return a
    // network error.
    if (httpRequest.mode === 'only-if-cached') {
      return makeNetworkError('only if cached')
    }

    // 2. Let forwardResponse be the result of running HTTP-network fetch
    // given httpFetchParams, includeCredentials, and isNewConnectionFetch.
    const forwardResponse = await httpNetworkFetch(
      httpFetchParams,
      includeCredentials,
      isNewConnectionFetch
    )

    // 3. If httpRequests method is unsafe and forwardResponses status is
    // in the range 200 to 399, inclusive, invalidate appropriate stored
    // responses in httpCache, as per the "Invalidation" chapter of HTTP
    // Caching, and set storedResponse to null. [HTTP-CACHING]
    if (
      !safeMethodsSet.has(httpRequest.method) &&
      forwardResponse.status >= 200 &&
      forwardResponse.status <= 399
    ) {
      // TODO: cache
    }

    // 4. If the revalidatingFlag is set and forwardResponses status is 304,
    // then:
    if (revalidatingFlag && forwardResponse.status === 304) {
      // TODO: cache
    }

    // 5. If response is null, then:
    if (response == null) {
      // 1. Set response to forwardResponse.
      response = forwardResponse

      // 2. Store httpRequest and forwardResponse in httpCache, as per the
      // "Storing Responses in Caches" chapter of HTTP Caching. [HTTP-CACHING]
      // TODO: cache
    }
  }

  // 11. Set responses URL list to a clone of httpRequests URL list.
  response.urlList = [...httpRequest.urlList]

  // 12. If httpRequests header list contains `Range`, then set responses
  // range-requested flag.
  if (httpRequest.headersList.contains('range')) {
    response.rangeRequested = true
  }

  // 13. Set responses request-includes-credentials to includeCredentials.
  response.requestIncludesCredentials = includeCredentials

  // 14. If responses status is 401, httpRequests response tainting is not
  // "cors", includeCredentials is true, and requests window is an environment
  // settings object, then:
  // TODO

  // 15. If responses status is 407, then:
  if (response.status === 407) {
    // 1. If requests window is "no-window", then return a network error.
    if (request.window === 'no-window') {
      return makeNetworkError()
    }

    // 2. ???

    // 3. If fetchParams is canceled, then return the appropriate network error for fetchParams.
    if (isCancelled(fetchParams)) {
      return makeAppropriateNetworkError(fetchParams)
    }

    // 4. Prompt the end user as appropriate in requests window and store
    // the result as a proxy-authentication entry. [HTTP-AUTH]
    // TODO: Invoke some kind of callback?

    // 5. Set response to the result of running HTTP-network-or-cache fetch given
    // fetchParams.
    // TODO
    return makeNetworkError('proxy authentication required')
  }

  // 16. If all of the following are true
  if (
    // responses status is 421
    response.status === 421 &&
    // isNewConnectionFetch is false
    !isNewConnectionFetch &&
    // requests body is null, or requests body is non-null and requests bodys source is non-null
    (request.body == null || request.body.source != null)
  ) {
    // then:

    // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.
    if (isCancelled(fetchParams)) {
      return makeAppropriateNetworkError(fetchParams)
    }

    // 2. Set response to the result of running HTTP-network-or-cache
    // fetch given fetchParams, isAuthenticationFetch, and true.

    // TODO (spec): The spec doesn't specify this but we need to cancel
    // the active response before we can start a new one.
    // https://github.com/whatwg/fetch/issues/1293
    fetchParams.controller.connection.destroy()

    response = await httpNetworkOrCacheFetch(
      fetchParams,
      isAuthenticationFetch,
      true
    )
  }

  // 17. If isAuthenticationFetch is true, then create an authentication entry
  if (isAuthenticationFetch) {
    // TODO
  }

  // 18. Return response.
  return response
}

// https://fetch.spec.whatwg.org/#http-network-fetch
async function httpNetworkFetch (
  fetchParams,
  includeCredentials = false,
  forceNewConnection = false
) {
  assert(!fetchParams.controller.connection || fetchParams.controller.connection.destroyed)

  fetchParams.controller.connection = {
    abort: null,
    destroyed: false,
    destroy (err) {
      if (!this.destroyed) {
        this.destroyed = true
        this.abort?.(err ?? new DOMException('The operation was aborted.', 'AbortError'))
      }
    }
  }

  // 1. Let request be fetchParamss request.
  const request = fetchParams.request

  // 2. Let response be null.
  let response = null

  // 3. Let timingInfo be fetchParamss timing info.
  const timingInfo = fetchParams.timingInfo

  // 4. Let httpCache be the result of determining the HTTP cache partition,
  // given request.
  // TODO: cache
  const httpCache = null

  // 5. If httpCache is null, then set requests cache mode to "no-store".
  if (httpCache == null) {
    request.cache = 'no-store'
  }

  // 6. Let networkPartitionKey be the result of determining the network
  // partition key given request.
  // TODO

  // 7. Let newConnection be "yes" if forceNewConnection is true; otherwise
  // "no".
  const newConnection = forceNewConnection ? 'yes' : 'no' // eslint-disable-line no-unused-vars

  // 8. Switch on requests mode:
  if (request.mode === 'websocket') {
    // Let connection be the result of obtaining a WebSocket connection,
    // given requests current URL.
    // TODO
  } else {
    // Let connection be the result of obtaining a connection, given
    // networkPartitionKey, requests current URLs origin,
    // includeCredentials, and forceNewConnection.
    // TODO
  }

  // 9. Run these steps, but abort when the ongoing fetch is terminated:

  //    1. If connection is failure, then return a network error.

  //    2. Set timingInfos final connection timing info to the result of
  //    calling clamp and coarsen connection timing info with connections
  //    timing info, timingInfos post-redirect start time, and fetchParamss
  //    cross-origin isolated capability.

  //    3. If connection is not an HTTP/2 connection, requests body is non-null,
  //    and requests bodys source is null, then append (`Transfer-Encoding`,
  //    `chunked`) to requests header list.

  //    4. Set timingInfos final network-request start time to the coarsened
  //    shared current time given fetchParamss cross-origin isolated
  //    capability.

  //    5. Set response to the result of making an HTTP request over connection
  //    using request with the following caveats:

  //        - Follow the relevant requirements from HTTP. [HTTP] [HTTP-SEMANTICS]
  //        [HTTP-COND] [HTTP-CACHING] [HTTP-AUTH]

  //        - If requests body is non-null, and requests bodys source is null,
  //        then the user agent may have a buffer of up to 64 kibibytes and store
  //        a part of requests body in that buffer. If the user agent reads from
  //        requests body beyond that buffers size and the user agent needs to
  //        resend request, then instead return a network error.

  //        - Set timingInfos final network-response start time to the coarsened
  //        shared current time given fetchParamss cross-origin isolated capability,
  //        immediately after the user agents HTTP parser receives the first byte
  //        of the response (e.g., frame header bytes for HTTP/2 or response status
  //        line for HTTP/1.x).

  //        - Wait until all the headers are transmitted.

  //        - Any responses whose status is in the range 100 to 199, inclusive,
  //        and is not 101, are to be ignored, except for the purposes of setting
  //        timingInfos final network-response start time above.

  //    - If requests header list contains `Transfer-Encoding`/`chunked` and
  //    response is transferred via HTTP/1.0 or older, then return a network
  //    error.

  //    - If the HTTP request results in a TLS client certificate dialog, then:

  //        1. If requests window is an environment settings object, make the
  //        dialog available in requests window.

  //        2. Otherwise, return a network error.

  // To transmit requests body body, run these steps:
  let requestBody = null
  // 1. If body is null and fetchParamss process request end-of-body is
  // non-null, then queue a fetch task given fetchParamss process request
  // end-of-body and fetchParamss task destination.
  if (request.body == null && fetchParams.processRequestEndOfBody) {
    queueMicrotask(() => fetchParams.processRequestEndOfBody())
  } else if (request.body != null) {
    // 2. Otherwise, if body is non-null:

    //    1. Let processBodyChunk given bytes be these steps:
    const processBodyChunk = async function * (bytes) {
      // 1. If the ongoing fetch is terminated, then abort these steps.
      if (isCancelled(fetchParams)) {
        return
      }

      // 2. Run this step in parallel: transmit bytes.
      yield bytes

      // 3. If fetchParamss process request body is non-null, then run
      // fetchParamss process request body given bytess length.
      fetchParams.processRequestBodyChunkLength?.(bytes.byteLength)
    }

    // 2. Let processEndOfBody be these steps:
    const processEndOfBody = () => {
      // 1. If fetchParams is canceled, then abort these steps.
      if (isCancelled(fetchParams)) {
        return
      }

      // 2. If fetchParamss process request end-of-body is non-null,
      // then run fetchParamss process request end-of-body.
      if (fetchParams.processRequestEndOfBody) {
        fetchParams.processRequestEndOfBody()
      }
    }

    // 3. Let processBodyError given e be these steps:
    const processBodyError = (e) => {
      // 1. If fetchParams is canceled, then abort these steps.
      if (isCancelled(fetchParams)) {
        return
      }

      // 2. If e is an "AbortError" DOMException, then abort fetchParamss controller.
      if (e.name === 'AbortError') {
        fetchParams.controller.abort()
      } else {
        fetchParams.controller.terminate(e)
      }
    }

    // 4. Incrementally read requests body given processBodyChunk, processEndOfBody,
    // processBodyError, and fetchParamss task destination.
    requestBody = (async function * () {
      try {
        for await (const bytes of request.body.stream) {
          yield * processBodyChunk(bytes)
        }
        processEndOfBody()
      } catch (err) {
        processBodyError(err)
      }
    })()
  }

  try {
    // socket is only provided for websockets
    const { body, status, statusText, headersList, socket } = await dispatch({ body: requestBody })

    if (socket) {
      response = makeResponse({ status, statusText, headersList, socket })
    } else {
      const iterator = body[Symbol.asyncIterator]()
      fetchParams.controller.next = () => iterator.next()

      response = makeResponse({ status, statusText, headersList })
    }
  } catch (err) {
    // 10. If aborted, then:
    if (err.name === 'AbortError') {
      // 1. If connection uses HTTP/2, then transmit an RST_STREAM frame.
      fetchParams.controller.connection.destroy()

      // 2. Return the appropriate network error for fetchParams.
      return makeAppropriateNetworkError(fetchParams, err)
    }

    return makeNetworkError(err)
  }

  // 11. Let pullAlgorithm be an action that resumes the ongoing fetch
  // if it is suspended.
  const pullAlgorithm = () => {
    fetchParams.controller.resume()
  }

  // 12. Let cancelAlgorithm be an algorithm that aborts fetchParamss
  // controller with reason, given reason.
  const cancelAlgorithm = (reason) => {
    fetchParams.controller.abort(reason)
  }

  // 13. Let highWaterMark be a non-negative, non-NaN number, chosen by
  // the user agent.
  // TODO

  // 14. Let sizeAlgorithm be an algorithm that accepts a chunk object
  // and returns a non-negative, non-NaN, non-infinite number, chosen by the user agent.
  // TODO

  // 15. Let stream be a new ReadableStream.
  // 16. Set up stream with pullAlgorithm set to pullAlgorithm,
  // cancelAlgorithm set to cancelAlgorithm, highWaterMark set to
  // highWaterMark, and sizeAlgorithm set to sizeAlgorithm.
  if (!ReadableStream) {
    ReadableStream = (__nccwpck_require__(3774).ReadableStream)
  }

  const stream = new ReadableStream(
    {
      async start (controller) {
        fetchParams.controller.controller = controller
      },
      async pull (controller) {
        await pullAlgorithm(controller)
      },
      async cancel (reason) {
        await cancelAlgorithm(reason)
      }
    },
    {
      highWaterMark: 0,
      size () {
        return 1
      }
    }
  )

  // 17. Run these steps, but abort when the ongoing fetch is terminated:

  //    1. Set responses body to a new body whose stream is stream.
  response.body = { stream }

  //    2. If response is not a network error and requests cache mode is
  //    not "no-store", then update response in httpCache for request.
  //    TODO

  //    3. If includeCredentials is true and the user agent is not configured
  //    to block cookies for request (see section 7 of [COOKIES]), then run the
  //    "set-cookie-string" parsing algorithm (see section 5.2 of [COOKIES]) on
  //    the value of each header whose name is a byte-case-insensitive match for
  //    `Set-Cookie` in responses header list, if any, and requests current URL.
  //    TODO

  // 18. If aborted, then:
  // TODO

  // 19. Run these steps in parallel:

  //    1. Run these steps, but abort when fetchParams is canceled:
  fetchParams.controller.on('terminated', onAborted)
  fetchParams.controller.resume = async () => {
    // 1. While true
    while (true) {
      // 1-3. See onData...

      // 4. Set bytes to the result of handling content codings given
      // codings and bytes.
      let bytes
      let isFailure
      try {
        const { done, value } = await fetchParams.controller.next()

        if (isAborted(fetchParams)) {
          break
        }

        bytes = done ? undefined : value
      } catch (err) {
        if (fetchParams.controller.ended && !timingInfo.encodedBodySize) {
          // zlib doesn't like empty streams.
          bytes = undefined
        } else {
          bytes = err

          // err may be propagated from the result of calling readablestream.cancel,
          // which might not be an error. https://github.com/nodejs/undici/issues/2009
          isFailure = true
        }
      }

      if (bytes === undefined) {
        // 2. Otherwise, if the bytes transmission for responses message
        // body is done normally and stream is readable, then close
        // stream, finalize response for fetchParams and response, and
        // abort these in-parallel steps.
        readableStreamClose(fetchParams.controller.controller)

        finalizeResponse(fetchParams, response)

        return
      }

      // 5. Increase timingInfos decoded body size by bytess length.
      timingInfo.decodedBodySize += bytes?.byteLength ?? 0

      // 6. If bytes is failure, then terminate fetchParamss controller.
      if (isFailure) {
        fetchParams.controller.terminate(bytes)
        return
      }

      // 7. Enqueue a Uint8Array wrapping an ArrayBuffer containing bytes
      // into stream.
      fetchParams.controller.controller.enqueue(new Uint8Array(bytes))

      // 8. If stream is errored, then terminate the ongoing fetch.
      if (isErrored(stream)) {
        fetchParams.controller.terminate()
        return
      }

      // 9. If stream doesnt need more data ask the user agent to suspend
      // the ongoing fetch.
      if (!fetchParams.controller.controller.desiredSize) {
        return
      }
    }
  }

  //    2. If aborted, then:
  function onAborted (reason) {
    // 2. If fetchParams is aborted, then:
    if (isAborted(fetchParams)) {
      // 1. Set responses aborted flag.
      response.aborted = true

      // 2. If stream is readable, then error stream with the result of
      //    deserialize a serialized abort reason given fetchParamss
      //    controllers serialized abort reason and an
      //    implementation-defined realm.
      if (isReadable(stream)) {
        fetchParams.controller.controller.error(
          fetchParams.controller.serializedAbortReason
        )
      }
    } else {
      // 3. Otherwise, if stream is readable, error stream with a TypeError.
      if (isReadable(stream)) {
        fetchParams.controller.controller.error(new TypeError('terminated', {
          cause: isErrorLike(reason) ? reason : undefined
        }))
      }
    }

    // 4. If connection uses HTTP/2, then transmit an RST_STREAM frame.
    // 5. Otherwise, the user agent should close connection unless it would be bad for performance to do so.
    fetchParams.controller.connection.destroy()
  }

  // 20. Return response.
  return response

  async function dispatch ({ body }) {
    const url = requestCurrentURL(request)
    /** @type {import('../..').Agent} */
    const agent = fetchParams.controller.dispatcher

    return new Promise((resolve, reject) => agent.dispatch(
      {
        path: url.pathname + url.search,
        origin: url.origin,
        method: request.method,
        body: fetchParams.controller.dispatcher.isMockActive ? request.body && (request.body.source || request.body.stream) : body,
        headers: request.headersList.entries,
        maxRedirections: 0,
        upgrade: request.mode === 'websocket' ? 'websocket' : undefined
      },
      {
        body: null,
        abort: null,

        onConnect (abort) {
          // TODO (fix): Do we need connection here?
          const { connection } = fetchParams.controller

          if (connection.destroyed) {
            abort(new DOMException('The operation was aborted.', 'AbortError'))
          } else {
            fetchParams.controller.on('terminated', abort)
            this.abort = connection.abort = abort
          }
        },

        onHeaders (status, headersList, resume, statusText) {
          if (status < 200) {
            return
          }

          let codings = []
          let location = ''

          const headers = new Headers()

          // For H2, the headers are a plain JS object
          // We distinguish between them and iterate accordingly
          if (Array.isArray(headersList)) {
            for (let n = 0; n < headersList.length; n += 2) {
              const key = headersList[n + 0].toString('latin1')
              const val = headersList[n + 1].toString('latin1')
              if (key.toLowerCase() === 'content-encoding') {
                // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1
                // "All content-coding values are case-insensitive..."
                codings = val.toLowerCase().split(',').map((x) => x.trim())
              } else if (key.toLowerCase() === 'location') {
                location = val
              }

              headers[kHeadersList].append(key, val)
            }
          } else {
            const keys = Object.keys(headersList)
            for (const key of keys) {
              const val = headersList[key]
              if (key.toLowerCase() === 'content-encoding') {
                // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1
                // "All content-coding values are case-insensitive..."
                codings = val.toLowerCase().split(',').map((x) => x.trim()).reverse()
              } else if (key.toLowerCase() === 'location') {
                location = val
              }

              headers[kHeadersList].append(key, val)
            }
          }

          this.body = new Readable({ read: resume })

          const decoders = []

          const willFollow = request.redirect === 'follow' &&
            location &&
            redirectStatusSet.has(status)

          // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding
          if (request.method !== 'HEAD' && request.method !== 'CONNECT' && !nullBodyStatus.includes(status) && !willFollow) {
            for (const coding of codings) {
              // https://www.rfc-editor.org/rfc/rfc9112.html#section-7.2
              if (coding === 'x-gzip' || coding === 'gzip') {
                decoders.push(zlib.createGunzip({
                  // Be less strict when decoding compressed responses, since sometimes
                  // servers send slightly invalid responses that are still accepted
                  // by common browsers.
                  // Always using Z_SYNC_FLUSH is what cURL does.
                  flush: zlib.constants.Z_SYNC_FLUSH,
                  finishFlush: zlib.constants.Z_SYNC_FLUSH
                }))
              } else if (coding === 'deflate') {
                decoders.push(zlib.createInflate())
              } else if (coding === 'br') {
                decoders.push(zlib.createBrotliDecompress())
              } else {
                decoders.length = 0
                break
              }
            }
          }

          resolve({
            status,
            statusText,
            headersList: headers[kHeadersList],
            body: decoders.length
              ? pipeline(this.body, ...decoders, () => { })
              : this.body.on('error', () => {})
          })

          return true
        },

        onData (chunk) {
          if (fetchParams.controller.dump) {
            return
          }

          // 1. If one or more bytes have been transmitted from responses
          // message body, then:

          //  1. Let bytes be the transmitted bytes.
          const bytes = chunk

          //  2. Let codings be the result of extracting header list values
          //  given `Content-Encoding` and responses header list.
          //  See pullAlgorithm.

          //  3. Increase timingInfos encoded body size by bytess length.
          timingInfo.encodedBodySize += bytes.byteLength

          //  4. See pullAlgorithm...

          return this.body.push(bytes)
        },

        onComplete () {
          if (this.abort) {
            fetchParams.controller.off('terminated', this.abort)
          }

          fetchParams.controller.ended = true

          this.body.push(null)
        },

        onError (error) {
          if (this.abort) {
            fetchParams.controller.off('terminated', this.abort)
          }

          this.body?.destroy(error)

          fetchParams.controller.terminate(error)

          reject(error)
        },

        onUpgrade (status, headersList, socket) {
          if (status !== 101) {
            return
          }

          const headers = new Headers()

          for (let n = 0; n < headersList.length; n += 2) {
            const key = headersList[n + 0].toString('latin1')
            const val = headersList[n + 1].toString('latin1')

            headers[kHeadersList].append(key, val)
          }

          resolve({
            status,
            statusText: STATUS_CODES[status],
            headersList: headers[kHeadersList],
            socket
          })

          return true
        }
      }
    ))
  }
}

module.exports = {
  fetch,
  Fetch,
  fetching,
  finalizeAndReportTiming
}


/***/ }),

/***/ 5194:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";
/* globals AbortController */



const { extractBody, mixinBody, cloneBody } = __nccwpck_require__(8923)
const { Headers, fill: fillHeaders, HeadersList } = __nccwpck_require__(6349)
const { FinalizationRegistry } = __nccwpck_require__(3194)()
const util = __nccwpck_require__(3440)
const {
  isValidHTTPToken,
  sameOrigin,
  normalizeMethod,
  makePolicyContainer,
  normalizeMethodRecord
} = __nccwpck_require__(5523)
const {
  forbiddenMethodsSet,
  corsSafeListedMethodsSet,
  referrerPolicy,
  requestRedirect,
  requestMode,
  requestCredentials,
  requestCache,
  requestDuplex
} = __nccwpck_require__(7326)
const { kEnumerableProperty } = util
const { kHeaders, kSignal, kState, kGuard, kRealm } = __nccwpck_require__(9710)
const { webidl } = __nccwpck_require__(4222)
const { getGlobalOrigin } = __nccwpck_require__(5628)
const { URLSerializer } = __nccwpck_require__(4322)
const { kHeadersList, kConstruct } = __nccwpck_require__(6443)
const assert = __nccwpck_require__(2613)
const { getMaxListeners, setMaxListeners, getEventListeners, defaultMaxListeners } = __nccwpck_require__(4434)

let TransformStream = globalThis.TransformStream

const kAbortController = Symbol('abortController')

const requestFinalizer = new FinalizationRegistry(({ signal, abort }) => {
  signal.removeEventListener('abort', abort)
})

// https://fetch.spec.whatwg.org/#request-class
class Request {
  // https://fetch.spec.whatwg.org/#dom-request
  constructor (input, init = {}) {
    if (input === kConstruct) {
      return
    }

    webidl.argumentLengthCheck(arguments, 1, { header: 'Request constructor' })

    input = webidl.converters.RequestInfo(input)
    init = webidl.converters.RequestInit(init)

    // https://html.spec.whatwg.org/multipage/webappapis.html#environment-settings-object
    this[kRealm] = {
      settingsObject: {
        baseUrl: getGlobalOrigin(),
        get origin () {
          return this.baseUrl?.origin
        },
        policyContainer: makePolicyContainer()
      }
    }

    // 1. Let request be null.
    let request = null

    // 2. Let fallbackMode be null.
    let fallbackMode = null

    // 3. Let baseURL be thiss relevant settings objects API base URL.
    const baseUrl = this[kRealm].settingsObject.baseUrl

    // 4. Let signal be null.
    let signal = null

    // 5. If input is a string, then:
    if (typeof input === 'string') {
      // 1. Let parsedURL be the result of parsing input with baseURL.
      // 2. If parsedURL is failure, then throw a TypeError.
      let parsedURL
      try {
        parsedURL = new URL(input, baseUrl)
      } catch (err) {
        throw new TypeError('Failed to parse URL from ' + input, { cause: err })
      }

      // 3. If parsedURL includes credentials, then throw a TypeError.
      if (parsedURL.username || parsedURL.password) {
        throw new TypeError(
          'Request cannot be constructed from a URL that includes credentials: ' +
            input
        )
      }

      // 4. Set request to a new request whose URL is parsedURL.
      request = makeRequest({ urlList: [parsedURL] })

      // 5. Set fallbackMode to "cors".
      fallbackMode = 'cors'
    } else {
      // 6. Otherwise:

      // 7. Assert: input is a Request object.
      assert(input instanceof Request)

      // 8. Set request to inputs request.
      request = input[kState]

      // 9. Set signal to inputs signal.
      signal = input[kSignal]
    }

    // 7. Let origin be thiss relevant settings objects origin.
    const origin = this[kRealm].settingsObject.origin

    // 8. Let window be "client".
    let window = 'client'

    // 9. If requests window is an environment settings object and its origin
    // is same origin with origin, then set window to requests window.
    if (
      request.window?.constructor?.name === 'EnvironmentSettingsObject' &&
      sameOrigin(request.window, origin)
    ) {
      window = request.window
    }

    // 10. If init["window"] exists and is non-null, then throw a TypeError.
    if (init.window != null) {
      throw new TypeError(`'window' option '${window}' must be null`)
    }

    // 11. If init["window"] exists, then set window to "no-window".
    if ('window' in init) {
      window = 'no-window'
    }

    // 12. Set request to a new request with the following properties:
    request = makeRequest({
      // URL requests URL.
      // undici implementation note: this is set as the first item in request's urlList in makeRequest
      // method requests method.
      method: request.method,
      // header list A copy of requests header list.
      // undici implementation note: headersList is cloned in makeRequest
      headersList: request.headersList,
      // unsafe-request flag Set.
      unsafeRequest: request.unsafeRequest,
      // client Thiss relevant settings object.
      client: this[kRealm].settingsObject,
      // window window.
      window,
      // priority requests priority.
      priority: request.priority,
      // origin requests origin. The propagation of the origin is only significant for navigation requests
      // being handled by a service worker. In this scenario a request can have an origin that is different
      // from the current client.
      origin: request.origin,
      // referrer requests referrer.
      referrer: request.referrer,
      // referrer policy requests referrer policy.
      referrerPolicy: request.referrerPolicy,
      // mode requests mode.
      mode: request.mode,
      // credentials mode requests credentials mode.
      credentials: request.credentials,
      // cache mode requests cache mode.
      cache: request.cache,
      // redirect mode requests redirect mode.
      redirect: request.redirect,
      // integrity metadata requests integrity metadata.
      integrity: request.integrity,
      // keepalive requests keepalive.
      keepalive: request.keepalive,
      // reload-navigation flag requests reload-navigation flag.
      reloadNavigation: request.reloadNavigation,
      // history-navigation flag requests history-navigation flag.
      historyNavigation: request.historyNavigation,
      // URL list A clone of requests URL list.
      urlList: [...request.urlList]
    })

    const initHasKey = Object.keys(init).length !== 0

    // 13. If init is not empty, then:
    if (initHasKey) {
      // 1. If requests mode is "navigate", then set it to "same-origin".
      if (request.mode === 'navigate') {
        request.mode = 'same-origin'
      }

      // 2. Unset requests reload-navigation flag.
      request.reloadNavigation = false

      // 3. Unset requests history-navigation flag.
      request.historyNavigation = false

      // 4. Set requests origin to "client".
      request.origin = 'client'

      // 5. Set requests referrer to "client"
      request.referrer = 'client'

      // 6. Set requests referrer policy to the empty string.
      request.referrerPolicy = ''

      // 7. Set requests URL to requests current URL.
      request.url = request.urlList[request.urlList.length - 1]

      // 8. Set requests URL list to  requests URL .
      request.urlList = [request.url]
    }

    // 14. If init["referrer"] exists, then:
    if (init.referrer !== undefined) {
      // 1. Let referrer be init["referrer"].
      const referrer = init.referrer

      // 2. If referrer is the empty string, then set requests referrer to "no-referrer".
      if (referrer === '') {
        request.referrer = 'no-referrer'
      } else {
        // 1. Let parsedReferrer be the result of parsing referrer with
        // baseURL.
        // 2. If parsedReferrer is failure, then throw a TypeError.
        let parsedReferrer
        try {
          parsedReferrer = new URL(referrer, baseUrl)
        } catch (err) {
          throw new TypeError(`Referrer "${referrer}" is not a valid URL.`, { cause: err })
        }

        // 3. If one of the following is true
        // - parsedReferrers scheme is "about" and path is the string "client"
        // - parsedReferrers origin is not same origin with origin
        // then set requests referrer to "client".
        if (
          (parsedReferrer.protocol === 'about:' && parsedReferrer.hostname === 'client') ||
          (origin && !sameOrigin(parsedReferrer, this[kRealm].settingsObject.baseUrl))
        ) {
          request.referrer = 'client'
        } else {
          // 4. Otherwise, set requests referrer to parsedReferrer.
          request.referrer = parsedReferrer
        }
      }
    }

    // 15. If init["referrerPolicy"] exists, then set requests referrer policy
    // to it.
    if (init.referrerPolicy !== undefined) {
      request.referrerPolicy = init.referrerPolicy
    }

    // 16. Let mode be init["mode"] if it exists, and fallbackMode otherwise.
    let mode
    if (init.mode !== undefined) {
      mode = init.mode
    } else {
      mode = fallbackMode
    }

    // 17. If mode is "navigate", then throw a TypeError.
    if (mode === 'navigate') {
      throw webidl.errors.exception({
        header: 'Request constructor',
        message: 'invalid request mode navigate.'
      })
    }

    // 18. If mode is non-null, set requests mode to mode.
    if (mode != null) {
      request.mode = mode
    }

    // 19. If init["credentials"] exists, then set requests credentials mode
    // to it.
    if (init.credentials !== undefined) {
      request.credentials = init.credentials
    }

    // 18. If init["cache"] exists, then set requests cache mode to it.
    if (init.cache !== undefined) {
      request.cache = init.cache
    }

    // 21. If requests cache mode is "only-if-cached" and requests mode is
    // not "same-origin", then throw a TypeError.
    if (request.cache === 'only-if-cached' && request.mode !== 'same-origin') {
      throw new TypeError(
        "'only-if-cached' can be set only with 'same-origin' mode"
      )
    }

    // 22. If init["redirect"] exists, then set requests redirect mode to it.
    if (init.redirect !== undefined) {
      request.redirect = init.redirect
    }

    // 23. If init["integrity"] exists, then set requests integrity metadata to it.
    if (init.integrity != null) {
      request.integrity = String(init.integrity)
    }

    // 24. If init["keepalive"] exists, then set requests keepalive to it.
    if (init.keepalive !== undefined) {
      request.keepalive = Boolean(init.keepalive)
    }

    // 25. If init["method"] exists, then:
    if (init.method !== undefined) {
      // 1. Let method be init["method"].
      let method = init.method

      // 2. If method is not a method or method is a forbidden method, then
      // throw a TypeError.
      if (!isValidHTTPToken(method)) {
        throw new TypeError(`'${method}' is not a valid HTTP method.`)
      }

      if (forbiddenMethodsSet.has(method.toUpperCase())) {
        throw new TypeError(`'${method}' HTTP method is unsupported.`)
      }

      // 3. Normalize method.
      method = normalizeMethodRecord[method] ?? normalizeMethod(method)

      // 4. Set requests method to method.
      request.method = method
    }

    // 26. If init["signal"] exists, then set signal to it.
    if (init.signal !== undefined) {
      signal = init.signal
    }

    // 27. Set thiss request to request.
    this[kState] = request

    // 28. Set thiss signal to a new AbortSignal object with thiss relevant
    // Realm.
    // TODO: could this be simplified with AbortSignal.any
    // (https://dom.spec.whatwg.org/#dom-abortsignal-any)
    const ac = new AbortController()
    this[kSignal] = ac.signal
    this[kSignal][kRealm] = this[kRealm]

    // 29. If signal is not null, then make thiss signal follow signal.
    if (signal != null) {
      if (
        !signal ||
        typeof signal.aborted !== 'boolean' ||
        typeof signal.addEventListener !== 'function'
      ) {
        throw new TypeError(
          "Failed to construct 'Request': member signal is not of type AbortSignal."
        )
      }

      if (signal.aborted) {
        ac.abort(signal.reason)
      } else {
        // Keep a strong ref to ac while request object
        // is alive. This is needed to prevent AbortController
        // from being prematurely garbage collected.
        // See, https://github.com/nodejs/undici/issues/1926.
        this[kAbortController] = ac

        const acRef = new WeakRef(ac)
        const abort = function () {
          const ac = acRef.deref()
          if (ac !== undefined) {
            ac.abort(this.reason)
          }
        }

        // Third-party AbortControllers may not work with these.
        // See, https://github.com/nodejs/undici/pull/1910#issuecomment-1464495619.
        try {
          // If the max amount of listeners is equal to the default, increase it
          // This is only available in node >= v19.9.0
          if (typeof getMaxListeners === 'function' && getMaxListeners(signal) === defaultMaxListeners) {
            setMaxListeners(100, signal)
          } else if (getEventListeners(signal, 'abort').length >= defaultMaxListeners) {
            setMaxListeners(100, signal)
          }
        } catch {}

        util.addAbortListener(signal, abort)
        requestFinalizer.register(ac, { signal, abort })
      }
    }

    // 30. Set thiss headers to a new Headers object with thiss relevant
    // Realm, whose header list is requests header list and guard is
    // "request".
    this[kHeaders] = new Headers(kConstruct)
    this[kHeaders][kHeadersList] = request.headersList
    this[kHeaders][kGuard] = 'request'
    this[kHeaders][kRealm] = this[kRealm]

    // 31. If thiss requests mode is "no-cors", then:
    if (mode === 'no-cors') {
      // 1. If thiss requests method is not a CORS-safelisted method,
      // then throw a TypeError.
      if (!corsSafeListedMethodsSet.has(request.method)) {
        throw new TypeError(
          `'${request.method} is unsupported in no-cors mode.`
        )
      }

      // 2. Set thiss headerss guard to "request-no-cors".
      this[kHeaders][kGuard] = 'request-no-cors'
    }

    // 32. If init is not empty, then:
    if (initHasKey) {
      /** @type {HeadersList} */
      const headersList = this[kHeaders][kHeadersList]
      // 1. Let headers be a copy of thiss headers and its associated header
      // list.
      // 2. If init["headers"] exists, then set headers to init["headers"].
      const headers = init.headers !== undefined ? init.headers : new HeadersList(headersList)

      // 3. Empty thiss headerss header list.
      headersList.clear()

      // 4. If headers is a Headers object, then for each header in its header
      // list, append headers name/headers value to thiss headers.
      if (headers instanceof HeadersList) {
        for (const [key, val] of headers) {
          headersList.append(key, val)
        }
        // Note: Copy the `set-cookie` meta-data.
        headersList.cookies = headers.cookies
      } else {
        // 5. Otherwise, fill thiss headers with headers.
        fillHeaders(this[kHeaders], headers)
      }
    }

    // 33. Let inputBody be inputs requests body if input is a Request
    // object; otherwise null.
    const inputBody = input instanceof Request ? input[kState].body : null

    // 34. If either init["body"] exists and is non-null or inputBody is
    // non-null, and requests method is `GET` or `HEAD`, then throw a
    // TypeError.
    if (
      (init.body != null || inputBody != null) &&
      (request.method === 'GET' || request.method === 'HEAD')
    ) {
      throw new TypeError('Request with GET/HEAD method cannot have body.')
    }

    // 35. Let initBody be null.
    let initBody = null

    // 36. If init["body"] exists and is non-null, then:
    if (init.body != null) {
      // 1. Let Content-Type be null.
      // 2. Set initBody and Content-Type to the result of extracting
      // init["body"], with keepalive set to requests keepalive.
      const [extractedBody, contentType] = extractBody(
        init.body,
        request.keepalive
      )
      initBody = extractedBody

      // 3, If Content-Type is non-null and thiss headerss header list does
      // not contain `Content-Type`, then append `Content-Type`/Content-Type to
      // thiss headers.
      if (contentType && !this[kHeaders][kHeadersList].contains('content-type')) {
        this[kHeaders].append('content-type', contentType)
      }
    }

    // 37. Let inputOrInitBody be initBody if it is non-null; otherwise
    // inputBody.
    const inputOrInitBody = initBody ?? inputBody

    // 38. If inputOrInitBody is non-null and inputOrInitBodys source is
    // null, then:
    if (inputOrInitBody != null && inputOrInitBody.source == null) {
      // 1. If initBody is non-null and init["duplex"] does not exist,
      //    then throw a TypeError.
      if (initBody != null && init.duplex == null) {
        throw new TypeError('RequestInit: duplex option is required when sending a body.')
      }

      // 2. If thiss requests mode is neither "same-origin" nor "cors",
      // then throw a TypeError.
      if (request.mode !== 'same-origin' && request.mode !== 'cors') {
        throw new TypeError(
          'If request is made from ReadableStream, mode should be "same-origin" or "cors"'
        )
      }

      // 3. Set thiss requests use-CORS-preflight flag.
      request.useCORSPreflightFlag = true
    }

    // 39. Let finalBody be inputOrInitBody.
    let finalBody = inputOrInitBody

    // 40. If initBody is null and inputBody is non-null, then:
    if (initBody == null && inputBody != null) {
      // 1. If input is unusable, then throw a TypeError.
      if (util.isDisturbed(inputBody.stream) || inputBody.stream.locked) {
        throw new TypeError(
          'Cannot construct a Request with a Request object that has already been used.'
        )
      }

      // 2. Set finalBody to the result of creating a proxy for inputBody.
      if (!TransformStream) {
        TransformStream = (__nccwpck_require__(3774).TransformStream)
      }

      // https://streams.spec.whatwg.org/#readablestream-create-a-proxy
      const identityTransform = new TransformStream()
      inputBody.stream.pipeThrough(identityTransform)
      finalBody = {
        source: inputBody.source,
        length: inputBody.length,
        stream: identityTransform.readable
      }
    }

    // 41. Set thiss requests body to finalBody.
    this[kState].body = finalBody
  }

  // Returns requests HTTP method, which is "GET" by default.
  get method () {
    webidl.brandCheck(this, Request)

    // The method getter steps are to return thiss requests method.
    return this[kState].method
  }

  // Returns the URL of request as a string.
  get url () {
    webidl.brandCheck(this, Request)

    // The url getter steps are to return thiss requests URL, serialized.
    return URLSerializer(this[kState].url)
  }

  // Returns a Headers object consisting of the headers associated with request.
  // Note that headers added in the network layer by the user agent will not
  // be accounted for in this object, e.g., the "Host" header.
  get headers () {
    webidl.brandCheck(this, Request)

    // The headers getter steps are to return thiss headers.
    return this[kHeaders]
  }

  // Returns the kind of resource requested by request, e.g., "document"
  // or "script".
  get destination () {
    webidl.brandCheck(this, Request)

    // The destination getter are to return thiss requests destination.
    return this[kState].destination
  }

  // Returns the referrer of request. Its value can be a same-origin URL if
  // explicitly set in init, the empty string to indicate no referrer, and
  // "about:client" when defaulting to the globals default. This is used
  // during fetching to determine the value of the `Referer` header of the
  // request being made.
  get referrer () {
    webidl.brandCheck(this, Request)

    // 1. If thiss requests referrer is "no-referrer", then return the
    // empty string.
    if (this[kState].referrer === 'no-referrer') {
      return ''
    }

    // 2. If thiss requests referrer is "client", then return
    // "about:client".
    if (this[kState].referrer === 'client') {
      return 'about:client'
    }

    // Return thiss requests referrer, serialized.
    return this[kState].referrer.toString()
  }

  // Returns the referrer policy associated with request.
  // This is used during fetching to compute the value of the requests
  // referrer.
  get referrerPolicy () {
    webidl.brandCheck(this, Request)

    // The referrerPolicy getter steps are to return thiss requests referrer policy.
    return this[kState].referrerPolicy
  }

  // Returns the mode associated with request, which is a string indicating
  // whether the request will use CORS, or will be restricted to same-origin
  // URLs.
  get mode () {
    webidl.brandCheck(this, Request)

    // The mode getter steps are to return thiss requests mode.
    return this[kState].mode
  }

  // Returns the credentials mode associated with request,
  // which is a string indicating whether credentials will be sent with the
  // request always, never, or only when sent to a same-origin URL.
  get credentials () {
    // The credentials getter steps are to return thiss requests credentials mode.
    return this[kState].credentials
  }

  // Returns the cache mode associated with request,
  // which is a string indicating how the request will
  // interact with the browsers cache when fetching.
  get cache () {
    webidl.brandCheck(this, Request)

    // The cache getter steps are to return thiss requests cache mode.
    return this[kState].cache
  }

  // Returns the redirect mode associated with request,
  // which is a string indicating how redirects for the
  // request will be handled during fetching. A request
  // will follow redirects by default.
  get redirect () {
    webidl.brandCheck(this, Request)

    // The redirect getter steps are to return thiss requests redirect mode.
    return this[kState].redirect
  }

  // Returns requests subresource integrity metadata, which is a
  // cryptographic hash of the resource being fetched. Its value
  // consists of multiple hashes separated by whitespace. [SRI]
  get integrity () {
    webidl.brandCheck(this, Request)

    // The integrity getter steps are to return thiss requests integrity
    // metadata.
    return this[kState].integrity
  }

  // Returns a boolean indicating whether or not request can outlive the
  // global in which it was created.
  get keepalive () {
    webidl.brandCheck(this, Request)

    // The keepalive getter steps are to return thiss requests keepalive.
    return this[kState].keepalive
  }

  // Returns a boolean indicating whether or not request is for a reload
  // navigation.
  get isReloadNavigation () {
    webidl.brandCheck(this, Request)

    // The isReloadNavigation getter steps are to return true if thiss
    // requests reload-navigation flag is set; otherwise false.
    return this[kState].reloadNavigation
  }

  // Returns a boolean indicating whether or not request is for a history
  // navigation (a.k.a. back-foward navigation).
  get isHistoryNavigation () {
    webidl.brandCheck(this, Request)

    // The isHistoryNavigation getter steps are to return true if thiss requests
    // history-navigation flag is set; otherwise false.
    return this[kState].historyNavigation
  }

  // Returns the signal associated with request, which is an AbortSignal
  // object indicating whether or not request has been aborted, and its
  // abort event handler.
  get signal () {
    webidl.brandCheck(this, Request)

    // The signal getter steps are to return thiss signal.
    return this[kSignal]
  }

  get body () {
    webidl.brandCheck(this, Request)

    return this[kState].body ? this[kState].body.stream : null
  }

  get bodyUsed () {
    webidl.brandCheck(this, Request)

    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)
  }

  get duplex () {
    webidl.brandCheck(this, Request)

    return 'half'
  }

  // Returns a clone of request.
  clone () {
    webidl.brandCheck(this, Request)

    // 1. If this is unusable, then throw a TypeError.
    if (this.bodyUsed || this.body?.locked) {
      throw new TypeError('unusable')
    }

    // 2. Let clonedRequest be the result of cloning thiss request.
    const clonedRequest = cloneRequest(this[kState])

    // 3. Let clonedRequestObject be the result of creating a Request object,
    // given clonedRequest, thiss headerss guard, and thiss relevant Realm.
    const clonedRequestObject = new Request(kConstruct)
    clonedRequestObject[kState] = clonedRequest
    clonedRequestObject[kRealm] = this[kRealm]
    clonedRequestObject[kHeaders] = new Headers(kConstruct)
    clonedRequestObject[kHeaders][kHeadersList] = clonedRequest.headersList
    clonedRequestObject[kHeaders][kGuard] = this[kHeaders][kGuard]
    clonedRequestObject[kHeaders][kRealm] = this[kHeaders][kRealm]

    // 4. Make clonedRequestObjects signal follow thiss signal.
    const ac = new AbortController()
    if (this.signal.aborted) {
      ac.abort(this.signal.reason)
    } else {
      util.addAbortListener(
        this.signal,
        () => {
          ac.abort(this.signal.reason)
        }
      )
    }
    clonedRequestObject[kSignal] = ac.signal

    // 4. Return clonedRequestObject.
    return clonedRequestObject
  }
}

mixinBody(Request)

function makeRequest (init) {
  // https://fetch.spec.whatwg.org/#requests
  const request = {
    method: 'GET',
    localURLsOnly: false,
    unsafeRequest: false,
    body: null,
    client: null,
    reservedClient: null,
    replacesClientId: '',
    window: 'client',
    keepalive: false,
    serviceWorkers: 'all',
    initiator: '',
    destination: '',
    priority: null,
    origin: 'client',
    policyContainer: 'client',
    referrer: 'client',
    referrerPolicy: '',
    mode: 'no-cors',
    useCORSPreflightFlag: false,
    credentials: 'same-origin',
    useCredentials: false,
    cache: 'default',
    redirect: 'follow',
    integrity: '',
    cryptoGraphicsNonceMetadata: '',
    parserMetadata: '',
    reloadNavigation: false,
    historyNavigation: false,
    userActivation: false,
    taintedOrigin: false,
    redirectCount: 0,
    responseTainting: 'basic',
    preventNoCacheCacheControlHeaderModification: false,
    done: false,
    timingAllowFailed: false,
    ...init,
    headersList: init.headersList
      ? new HeadersList(init.headersList)
      : new HeadersList()
  }
  request.url = request.urlList[0]
  return request
}

// https://fetch.spec.whatwg.org/#concept-request-clone
function cloneRequest (request) {
  // To clone a request request, run these steps:

  // 1. Let newRequest be a copy of request, except for its body.
  const newRequest = makeRequest({ ...request, body: null })

  // 2. If requests body is non-null, set newRequests body to the
  // result of cloning requests body.
  if (request.body != null) {
    newRequest.body = cloneBody(request.body)
  }

  // 3. Return newRequest.
  return newRequest
}

Object.defineProperties(Request.prototype, {
  method: kEnumerableProperty,
  url: kEnumerableProperty,
  headers: kEnumerableProperty,
  redirect: kEnumerableProperty,
  clone: kEnumerableProperty,
  signal: kEnumerableProperty,
  duplex: kEnumerableProperty,
  destination: kEnumerableProperty,
  body: kEnumerableProperty,
  bodyUsed: kEnumerableProperty,
  isHistoryNavigation: kEnumerableProperty,
  isReloadNavigation: kEnumerableProperty,
  keepalive: kEnumerableProperty,
  integrity: kEnumerableProperty,
  cache: kEnumerableProperty,
  credentials: kEnumerableProperty,
  attribute: kEnumerableProperty,
  referrerPolicy: kEnumerableProperty,
  referrer: kEnumerableProperty,
  mode: kEnumerableProperty,
  [Symbol.toStringTag]: {
    value: 'Request',
    configurable: true
  }
})

webidl.converters.Request = webidl.interfaceConverter(
  Request
)

// https://fetch.spec.whatwg.org/#requestinfo
webidl.converters.RequestInfo = function (V) {
  if (typeof V === 'string') {
    return webidl.converters.USVString(V)
  }

  if (V instanceof Request) {
    return webidl.converters.Request(V)
  }

  return webidl.converters.USVString(V)
}

webidl.converters.AbortSignal = webidl.interfaceConverter(
  AbortSignal
)

// https://fetch.spec.whatwg.org/#requestinit
webidl.converters.RequestInit = webidl.dictionaryConverter([
  {
    key: 'method',
    converter: webidl.converters.ByteString
  },
  {
    key: 'headers',
    converter: webidl.converters.HeadersInit
  },
  {
    key: 'body',
    converter: webidl.nullableConverter(
      webidl.converters.BodyInit
    )
  },
  {
    key: 'referrer',
    converter: webidl.converters.USVString
  },
  {
    key: 'referrerPolicy',
    converter: webidl.converters.DOMString,
    // https://w3c.github.io/webappsec-referrer-policy/#referrer-policy
    allowedValues: referrerPolicy
  },
  {
    key: 'mode',
    converter: webidl.converters.DOMString,
    // https://fetch.spec.whatwg.org/#concept-request-mode
    allowedValues: requestMode
  },
  {
    key: 'credentials',
    converter: webidl.converters.DOMString,
    // https://fetch.spec.whatwg.org/#requestcredentials
    allowedValues: requestCredentials
  },
  {
    key: 'cache',
    converter: webidl.converters.DOMString,
    // https://fetch.spec.whatwg.org/#requestcache
    allowedValues: requestCache
  },
  {
    key: 'redirect',
    converter: webidl.converters.DOMString,
    // https://fetch.spec.whatwg.org/#requestredirect
    allowedValues: requestRedirect
  },
  {
    key: 'integrity',
    converter: webidl.converters.DOMString
  },
  {
    key: 'keepalive',
    converter: webidl.converters.boolean
  },
  {
    key: 'signal',
    converter: webidl.nullableConverter(
      (signal) => webidl.converters.AbortSignal(
        signal,
        { strict: false }
      )
    )
  },
  {
    key: 'window',
    converter: webidl.converters.any
  },
  {
    key: 'duplex',
    converter: webidl.converters.DOMString,
    allowedValues: requestDuplex
  }
])

module.exports = { Request, makeRequest }


/***/ }),

/***/ 8676:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { Headers, HeadersList, fill } = __nccwpck_require__(6349)
const { extractBody, cloneBody, mixinBody } = __nccwpck_require__(8923)
const util = __nccwpck_require__(3440)
const { kEnumerableProperty } = util
const {
  isValidReasonPhrase,
  isCancelled,
  isAborted,
  isBlobLike,
  serializeJavascriptValueToJSONString,
  isErrorLike,
  isomorphicEncode
} = __nccwpck_require__(5523)
const {
  redirectStatusSet,
  nullBodyStatus,
  DOMException
} = __nccwpck_require__(7326)
const { kState, kHeaders, kGuard, kRealm } = __nccwpck_require__(9710)
const { webidl } = __nccwpck_require__(4222)
const { FormData } = __nccwpck_require__(3073)
const { getGlobalOrigin } = __nccwpck_require__(5628)
const { URLSerializer } = __nccwpck_require__(4322)
const { kHeadersList, kConstruct } = __nccwpck_require__(6443)
const assert = __nccwpck_require__(2613)
const { types } = __nccwpck_require__(9023)

const ReadableStream = globalThis.ReadableStream || (__nccwpck_require__(3774).ReadableStream)
const textEncoder = new TextEncoder('utf-8')

// https://fetch.spec.whatwg.org/#response-class
class Response {
  // Creates network error Response.
  static error () {
    // TODO
    const relevantRealm = { settingsObject: {} }

    // The static error() method steps are to return the result of creating a
    // Response object, given a new network error, "immutable", and thiss
    // relevant Realm.
    const responseObject = new Response()
    responseObject[kState] = makeNetworkError()
    responseObject[kRealm] = relevantRealm
    responseObject[kHeaders][kHeadersList] = responseObject[kState].headersList
    responseObject[kHeaders][kGuard] = 'immutable'
    responseObject[kHeaders][kRealm] = relevantRealm
    return responseObject
  }

  // https://fetch.spec.whatwg.org/#dom-response-json
  static json (data, init = {}) {
    webidl.argumentLengthCheck(arguments, 1, { header: 'Response.json' })

    if (init !== null) {
      init = webidl.converters.ResponseInit(init)
    }

    // 1. Let bytes the result of running serialize a JavaScript value to JSON bytes on data.
    const bytes = textEncoder.encode(
      serializeJavascriptValueToJSONString(data)
    )

    // 2. Let body be the result of extracting bytes.
    const body = extractBody(bytes)

    // 3. Let responseObject be the result of creating a Response object, given a new response,
    //    "response", and thiss relevant Realm.
    const relevantRealm = { settingsObject: {} }
    const responseObject = new Response()
    responseObject[kRealm] = relevantRealm
    responseObject[kHeaders][kGuard] = 'response'
    responseObject[kHeaders][kRealm] = relevantRealm

    // 4. Perform initialize a response given responseObject, init, and (body, "application/json").
    initializeResponse(responseObject, init, { body: body[0], type: 'application/json' })

    // 5. Return responseObject.
    return responseObject
  }

  // Creates a redirect Response that redirects to url with status status.
  static redirect (url, status = 302) {
    const relevantRealm = { settingsObject: {} }

    webidl.argumentLengthCheck(arguments, 1, { header: 'Response.redirect' })

    url = webidl.converters.USVString(url)
    status = webidl.converters['unsigned short'](status)

    // 1. Let parsedURL be the result of parsing url with current settings
    // objects API base URL.
    // 2. If parsedURL is failure, then throw a TypeError.
    // TODO: base-URL?
    let parsedURL
    try {
      parsedURL = new URL(url, getGlobalOrigin())
    } catch (err) {
      throw Object.assign(new TypeError('Failed to parse URL from ' + url), {
        cause: err
      })
    }

    // 3. If status is not a redirect status, then throw a RangeError.
    if (!redirectStatusSet.has(status)) {
      throw new RangeError('Invalid status code ' + status)
    }

    // 4. Let responseObject be the result of creating a Response object,
    // given a new response, "immutable", and thiss relevant Realm.
    const responseObject = new Response()
    responseObject[kRealm] = relevantRealm
    responseObject[kHeaders][kGuard] = 'immutable'
    responseObject[kHeaders][kRealm] = relevantRealm

    // 5. Set responseObjects responses status to status.
    responseObject[kState].status = status

    // 6. Let value be parsedURL, serialized and isomorphic encoded.
    const value = isomorphicEncode(URLSerializer(parsedURL))

    // 7. Append `Location`/value to responseObjects responses header list.
    responseObject[kState].headersList.append('location', value)

    // 8. Return responseObject.
    return responseObject
  }

  // https://fetch.spec.whatwg.org/#dom-response
  constructor (body = null, init = {}) {
    if (body !== null) {
      body = webidl.converters.BodyInit(body)
    }

    init = webidl.converters.ResponseInit(init)

    // TODO
    this[kRealm] = { settingsObject: {} }

    // 1. Set thiss response to a new response.
    this[kState] = makeResponse({})

    // 2. Set thiss headers to a new Headers object with thiss relevant
    // Realm, whose header list is thiss responses header list and guard
    // is "response".
    this[kHeaders] = new Headers(kConstruct)
    this[kHeaders][kGuard] = 'response'
    this[kHeaders][kHeadersList] = this[kState].headersList
    this[kHeaders][kRealm] = this[kRealm]

    // 3. Let bodyWithType be null.
    let bodyWithType = null

    // 4. If body is non-null, then set bodyWithType to the result of extracting body.
    if (body != null) {
      const [extractedBody, type] = extractBody(body)
      bodyWithType = { body: extractedBody, type }
    }

    // 5. Perform initialize a response given this, init, and bodyWithType.
    initializeResponse(this, init, bodyWithType)
  }

  // Returns responses type, e.g., "cors".
  get type () {
    webidl.brandCheck(this, Response)

    // The type getter steps are to return thiss responses type.
    return this[kState].type
  }

  // Returns responses URL, if it has one; otherwise the empty string.
  get url () {
    webidl.brandCheck(this, Response)

    const urlList = this[kState].urlList

    // The url getter steps are to return the empty string if thiss
    // responses URL is null; otherwise thiss responses URL,
    // serialized with exclude fragment set to true.
    const url = urlList[urlList.length - 1] ?? null

    if (url === null) {
      return ''
    }

    return URLSerializer(url, true)
  }

  // Returns whether response was obtained through a redirect.
  get redirected () {
    webidl.brandCheck(this, Response)

    // The redirected getter steps are to return true if thiss responses URL
    // list has more than one item; otherwise false.
    return this[kState].urlList.length > 1
  }

  // Returns responses status.
  get status () {
    webidl.brandCheck(this, Response)

    // The status getter steps are to return thiss responses status.
    return this[kState].status
  }

  // Returns whether responses status is an ok status.
  get ok () {
    webidl.brandCheck(this, Response)

    // The ok getter steps are to return true if thiss responses status is an
    // ok status; otherwise false.
    return this[kState].status >= 200 && this[kState].status <= 299
  }

  // Returns responses status message.
  get statusText () {
    webidl.brandCheck(this, Response)

    // The statusText getter steps are to return thiss responses status
    // message.
    return this[kState].statusText
  }

  // Returns responses headers as Headers.
  get headers () {
    webidl.brandCheck(this, Response)

    // The headers getter steps are to return thiss headers.
    return this[kHeaders]
  }

  get body () {
    webidl.brandCheck(this, Response)

    return this[kState].body ? this[kState].body.stream : null
  }

  get bodyUsed () {
    webidl.brandCheck(this, Response)

    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)
  }

  // Returns a clone of response.
  clone () {
    webidl.brandCheck(this, Response)

    // 1. If this is unusable, then throw a TypeError.
    if (this.bodyUsed || (this.body && this.body.locked)) {
      throw webidl.errors.exception({
        header: 'Response.clone',
        message: 'Body has already been consumed.'
      })
    }

    // 2. Let clonedResponse be the result of cloning thiss response.
    const clonedResponse = cloneResponse(this[kState])

    // 3. Return the result of creating a Response object, given
    // clonedResponse, thiss headerss guard, and thiss relevant Realm.
    const clonedResponseObject = new Response()
    clonedResponseObject[kState] = clonedResponse
    clonedResponseObject[kRealm] = this[kRealm]
    clonedResponseObject[kHeaders][kHeadersList] = clonedResponse.headersList
    clonedResponseObject[kHeaders][kGuard] = this[kHeaders][kGuard]
    clonedResponseObject[kHeaders][kRealm] = this[kHeaders][kRealm]

    return clonedResponseObject
  }
}

mixinBody(Response)

Object.defineProperties(Response.prototype, {
  type: kEnumerableProperty,
  url: kEnumerableProperty,
  status: kEnumerableProperty,
  ok: kEnumerableProperty,
  redirected: kEnumerableProperty,
  statusText: kEnumerableProperty,
  headers: kEnumerableProperty,
  clone: kEnumerableProperty,
  body: kEnumerableProperty,
  bodyUsed: kEnumerableProperty,
  [Symbol.toStringTag]: {
    value: 'Response',
    configurable: true
  }
})

Object.defineProperties(Response, {
  json: kEnumerableProperty,
  redirect: kEnumerableProperty,
  error: kEnumerableProperty
})

// https://fetch.spec.whatwg.org/#concept-response-clone
function cloneResponse (response) {
  // To clone a response response, run these steps:

  // 1. If response is a filtered response, then return a new identical
  // filtered response whose internal response is a clone of responses
  // internal response.
  if (response.internalResponse) {
    return filterResponse(
      cloneResponse(response.internalResponse),
      response.type
    )
  }

  // 2. Let newResponse be a copy of response, except for its body.
  const newResponse = makeResponse({ ...response, body: null })

  // 3. If responses body is non-null, then set newResponses body to the
  // result of cloning responses body.
  if (response.body != null) {
    newResponse.body = cloneBody(response.body)
  }

  // 4. Return newResponse.
  return newResponse
}

function makeResponse (init) {
  return {
    aborted: false,
    rangeRequested: false,
    timingAllowPassed: false,
    requestIncludesCredentials: false,
    type: 'default',
    status: 200,
    timingInfo: null,
    cacheState: '',
    statusText: '',
    ...init,
    headersList: init.headersList
      ? new HeadersList(init.headersList)
      : new HeadersList(),
    urlList: init.urlList ? [...init.urlList] : []
  }
}

function makeNetworkError (reason) {
  const isError = isErrorLike(reason)
  return makeResponse({
    type: 'error',
    status: 0,
    error: isError
      ? reason
      : new Error(reason ? String(reason) : reason),
    aborted: reason && reason.name === 'AbortError'
  })
}

function makeFilteredResponse (response, state) {
  state = {
    internalResponse: response,
    ...state
  }

  return new Proxy(response, {
    get (target, p) {
      return p in state ? state[p] : target[p]
    },
    set (target, p, value) {
      assert(!(p in state))
      target[p] = value
      return true
    }
  })
}

// https://fetch.spec.whatwg.org/#concept-filtered-response
function filterResponse (response, type) {
  // Set response to the following filtered response with response as its
  // internal response, depending on requests response tainting:
  if (type === 'basic') {
    // A basic filtered response is a filtered response whose type is "basic"
    // and header list excludes any headers in internal responses header list
    // whose name is a forbidden response-header name.

    // Note: undici does not implement forbidden response-header names
    return makeFilteredResponse(response, {
      type: 'basic',
      headersList: response.headersList
    })
  } else if (type === 'cors') {
    // A CORS filtered response is a filtered response whose type is "cors"
    // and header list excludes any headers in internal responses header
    // list whose name is not a CORS-safelisted response-header name, given
    // internal responses CORS-exposed header-name list.

    // Note: undici does not implement CORS-safelisted response-header names
    return makeFilteredResponse(response, {
      type: 'cors',
      headersList: response.headersList
    })
  } else if (type === 'opaque') {
    // An opaque filtered response is a filtered response whose type is
    // "opaque", URL list is the empty list, status is 0, status message
    // is the empty byte sequence, header list is empty, and body is null.

    return makeFilteredResponse(response, {
      type: 'opaque',
      urlList: Object.freeze([]),
      status: 0,
      statusText: '',
      body: null
    })
  } else if (type === 'opaqueredirect') {
    // An opaque-redirect filtered response is a filtered response whose type
    // is "opaqueredirect", status is 0, status message is the empty byte
    // sequence, header list is empty, and body is null.

    return makeFilteredResponse(response, {
      type: 'opaqueredirect',
      status: 0,
      statusText: '',
      headersList: [],
      body: null
    })
  } else {
    assert(false)
  }
}

// https://fetch.spec.whatwg.org/#appropriate-network-error
function makeAppropriateNetworkError (fetchParams, err = null) {
  // 1. Assert: fetchParams is canceled.
  assert(isCancelled(fetchParams))

  // 2. Return an aborted network error if fetchParams is aborted;
  // otherwise return a network error.
  return isAborted(fetchParams)
    ? makeNetworkError(Object.assign(new DOMException('The operation was aborted.', 'AbortError'), { cause: err }))
    : makeNetworkError(Object.assign(new DOMException('Request was cancelled.'), { cause: err }))
}

// https://whatpr.org/fetch/1392.html#initialize-a-response
function initializeResponse (response, init, body) {
  // 1. If init["status"] is not in the range 200 to 599, inclusive, then
  //    throw a RangeError.
  if (init.status !== null && (init.status < 200 || init.status > 599)) {
    throw new RangeError('init["status"] must be in the range of 200 to 599, inclusive.')
  }

  // 2. If init["statusText"] does not match the reason-phrase token production,
  //    then throw a TypeError.
  if ('statusText' in init && init.statusText != null) {
    // See, https://datatracker.ietf.org/doc/html/rfc7230#section-3.1.2:
    //   reason-phrase  = *( HTAB / SP / VCHAR / obs-text )
    if (!isValidReasonPhrase(String(init.statusText))) {
      throw new TypeError('Invalid statusText')
    }
  }

  // 3. Set responses responses status to init["status"].
  if ('status' in init && init.status != null) {
    response[kState].status = init.status
  }

  // 4. Set responses responses status message to init["statusText"].
  if ('statusText' in init && init.statusText != null) {
    response[kState].statusText = init.statusText
  }

  // 5. If init["headers"] exists, then fill responses headers with init["headers"].
  if ('headers' in init && init.headers != null) {
    fill(response[kHeaders], init.headers)
  }

  // 6. If body was given, then:
  if (body) {
    // 1. If response's status is a null body status, then throw a TypeError.
    if (nullBodyStatus.includes(response.status)) {
      throw webidl.errors.exception({
        header: 'Response constructor',
        message: 'Invalid response status code ' + response.status
      })
    }

    // 2. Set response's body to body's body.
    response[kState].body = body.body

    // 3. If body's type is non-null and response's header list does not contain
    //    `Content-Type`, then append (`Content-Type`, body's type) to response's header list.
    if (body.type != null && !response[kState].headersList.contains('Content-Type')) {
      response[kState].headersList.append('content-type', body.type)
    }
  }
}

webidl.converters.ReadableStream = webidl.interfaceConverter(
  ReadableStream
)

webidl.converters.FormData = webidl.interfaceConverter(
  FormData
)

webidl.converters.URLSearchParams = webidl.interfaceConverter(
  URLSearchParams
)

// https://fetch.spec.whatwg.org/#typedefdef-xmlhttprequestbodyinit
webidl.converters.XMLHttpRequestBodyInit = function (V) {
  if (typeof V === 'string') {
    return webidl.converters.USVString(V)
  }

  if (isBlobLike(V)) {
    return webidl.converters.Blob(V, { strict: false })
  }

  if (types.isArrayBuffer(V) || types.isTypedArray(V) || types.isDataView(V)) {
    return webidl.converters.BufferSource(V)
  }

  if (util.isFormDataLike(V)) {
    return webidl.converters.FormData(V, { strict: false })
  }

  if (V instanceof URLSearchParams) {
    return webidl.converters.URLSearchParams(V)
  }

  return webidl.converters.DOMString(V)
}

// https://fetch.spec.whatwg.org/#bodyinit
webidl.converters.BodyInit = function (V) {
  if (V instanceof ReadableStream) {
    return webidl.converters.ReadableStream(V)
  }

  // Note: the spec doesn't include async iterables,
  // this is an undici extension.
  if (V?.[Symbol.asyncIterator]) {
    return V
  }

  return webidl.converters.XMLHttpRequestBodyInit(V)
}

webidl.converters.ResponseInit = webidl.dictionaryConverter([
  {
    key: 'status',
    converter: webidl.converters['unsigned short'],
    defaultValue: 200
  },
  {
    key: 'statusText',
    converter: webidl.converters.ByteString,
    defaultValue: ''
  },
  {
    key: 'headers',
    converter: webidl.converters.HeadersInit
  }
])

module.exports = {
  makeNetworkError,
  makeResponse,
  makeAppropriateNetworkError,
  filterResponse,
  Response,
  cloneResponse
}


/***/ }),

/***/ 9710:
/***/ ((module) => {

"use strict";


module.exports = {
  kUrl: Symbol('url'),
  kHeaders: Symbol('headers'),
  kSignal: Symbol('signal'),
  kState: Symbol('state'),
  kGuard: Symbol('guard'),
  kRealm: Symbol('realm')
}


/***/ }),

/***/ 5523:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { redirectStatusSet, referrerPolicySet: referrerPolicyTokens, badPortsSet } = __nccwpck_require__(7326)
const { getGlobalOrigin } = __nccwpck_require__(5628)
const { performance } = __nccwpck_require__(2987)
const { isBlobLike, toUSVString, ReadableStreamFrom } = __nccwpck_require__(3440)
const assert = __nccwpck_require__(2613)
const { isUint8Array } = __nccwpck_require__(8253)

let supportedHashes = []

// https://nodejs.org/api/crypto.html#determining-if-crypto-support-is-unavailable
/** @type {import('crypto')|undefined} */
let crypto

try {
  crypto = __nccwpck_require__(6982)
  const possibleRelevantHashes = ['sha256', 'sha384', 'sha512']
  supportedHashes = crypto.getHashes().filter((hash) => possibleRelevantHashes.includes(hash))
/* c8 ignore next 3 */
} catch {
}

function responseURL (response) {
  // https://fetch.spec.whatwg.org/#responses
  // A response has an associated URL. It is a pointer to the last URL
  // in responses URL list and null if responses URL list is empty.
  const urlList = response.urlList
  const length = urlList.length
  return length === 0 ? null : urlList[length - 1].toString()
}

// https://fetch.spec.whatwg.org/#concept-response-location-url
function responseLocationURL (response, requestFragment) {
  // 1. If responses status is not a redirect status, then return null.
  if (!redirectStatusSet.has(response.status)) {
    return null
  }

  // 2. Let location be the result of extracting header list values given
  // `Location` and responses header list.
  let location = response.headersList.get('location')

  // 3. If location is a header value, then set location to the result of
  //    parsing location with responses URL.
  if (location !== null && isValidHeaderValue(location)) {
    location = new URL(location, responseURL(response))
  }

  // 4. If location is a URL whose fragment is null, then set locations
  // fragment to requestFragment.
  if (location && !location.hash) {
    location.hash = requestFragment
  }

  // 5. Return location.
  return location
}

/** @returns {URL} */
function requestCurrentURL (request) {
  return request.urlList[request.urlList.length - 1]
}

function requestBadPort (request) {
  // 1. Let url be requests current URL.
  const url = requestCurrentURL(request)

  // 2. If urls scheme is an HTTP(S) scheme and urls port is a bad port,
  // then return blocked.
  if (urlIsHttpHttpsScheme(url) && badPortsSet.has(url.port)) {
    return 'blocked'
  }

  // 3. Return allowed.
  return 'allowed'
}

function isErrorLike (object) {
  return object instanceof Error || (
    object?.constructor?.name === 'Error' ||
    object?.constructor?.name === 'DOMException'
  )
}

// Check whether |statusText| is a ByteString and
// matches the Reason-Phrase token production.
// RFC 2616: https://tools.ietf.org/html/rfc2616
// RFC 7230: https://tools.ietf.org/html/rfc7230
// "reason-phrase = *( HTAB / SP / VCHAR / obs-text )"
// https://github.com/chromium/chromium/blob/94.0.4604.1/third_party/blink/renderer/core/fetch/response.cc#L116
function isValidReasonPhrase (statusText) {
  for (let i = 0; i < statusText.length; ++i) {
    const c = statusText.charCodeAt(i)
    if (
      !(
        (
          c === 0x09 || // HTAB
          (c >= 0x20 && c <= 0x7e) || // SP / VCHAR
          (c >= 0x80 && c <= 0xff)
        ) // obs-text
      )
    ) {
      return false
    }
  }
  return true
}

/**
 * @see https://tools.ietf.org/html/rfc7230#section-3.2.6
 * @param {number} c
 */
function isTokenCharCode (c) {
  switch (c) {
    case 0x22:
    case 0x28:
    case 0x29:
    case 0x2c:
    case 0x2f:
    case 0x3a:
    case 0x3b:
    case 0x3c:
    case 0x3d:
    case 0x3e:
    case 0x3f:
    case 0x40:
    case 0x5b:
    case 0x5c:
    case 0x5d:
    case 0x7b:
    case 0x7d:
      // DQUOTE and "(),/:;<=>?@[\]{}"
      return false
    default:
      // VCHAR %x21-7E
      return c >= 0x21 && c <= 0x7e
  }
}

/**
 * @param {string} characters
 */
function isValidHTTPToken (characters) {
  if (characters.length === 0) {
    return false
  }
  for (let i = 0; i < characters.length; ++i) {
    if (!isTokenCharCode(characters.charCodeAt(i))) {
      return false
    }
  }
  return true
}

/**
 * @see https://fetch.spec.whatwg.org/#header-name
 * @param {string} potentialValue
 */
function isValidHeaderName (potentialValue) {
  return isValidHTTPToken(potentialValue)
}

/**
 * @see https://fetch.spec.whatwg.org/#header-value
 * @param {string} potentialValue
 */
function isValidHeaderValue (potentialValue) {
  // - Has no leading or trailing HTTP tab or space bytes.
  // - Contains no 0x00 (NUL) or HTTP newline bytes.
  if (
    potentialValue.startsWith('\t') ||
    potentialValue.startsWith(' ') ||
    potentialValue.endsWith('\t') ||
    potentialValue.endsWith(' ')
  ) {
    return false
  }

  if (
    potentialValue.includes('\0') ||
    potentialValue.includes('\r') ||
    potentialValue.includes('\n')
  ) {
    return false
  }

  return true
}

// https://w3c.github.io/webappsec-referrer-policy/#set-requests-referrer-policy-on-redirect
function setRequestReferrerPolicyOnRedirect (request, actualResponse) {
  //  Given a request request and a response actualResponse, this algorithm
  //  updates requests referrer policy according to the Referrer-Policy
  //  header (if any) in actualResponse.

  // 1. Let policy be the result of executing  8.1 Parse a referrer policy
  // from a Referrer-Policy header on actualResponse.

  // 8.1 Parse a referrer policy from a Referrer-Policy header
  // 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy` and responses header list.
  const { headersList } = actualResponse
  // 2. Let policy be the empty string.
  // 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty string, then set policy to token.
  // 4. Return policy.
  const policyHeader = (headersList.get('referrer-policy') ?? '').split(',')

  // Note: As the referrer-policy can contain multiple policies
  // separated by comma, we need to loop through all of them
  // and pick the first valid one.
  // Ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#specify_a_fallback_policy
  let policy = ''
  if (policyHeader.length > 0) {
    // The right-most policy takes precedence.
    // The left-most policy is the fallback.
    for (let i = policyHeader.length; i !== 0; i--) {
      const token = policyHeader[i - 1].trim()
      if (referrerPolicyTokens.has(token)) {
        policy = token
        break
      }
    }
  }

  // 2. If policy is not the empty string, then set requests referrer policy to policy.
  if (policy !== '') {
    request.referrerPolicy = policy
  }
}

// https://fetch.spec.whatwg.org/#cross-origin-resource-policy-check
function crossOriginResourcePolicyCheck () {
  // TODO
  return 'allowed'
}

// https://fetch.spec.whatwg.org/#concept-cors-check
function corsCheck () {
  // TODO
  return 'success'
}

// https://fetch.spec.whatwg.org/#concept-tao-check
function TAOCheck () {
  // TODO
  return 'success'
}

function appendFetchMetadata (httpRequest) {
  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-dest-header
  //  TODO

  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-mode-header

  //  1. Assert: rs url is a potentially trustworthy URL.
  //  TODO

  //  2. Let header be a Structured Header whose value is a token.
  let header = null

  //  3. Set headers value to rs mode.
  header = httpRequest.mode

  //  4. Set a structured field value `Sec-Fetch-Mode`/header in rs header list.
  httpRequest.headersList.set('sec-fetch-mode', header)

  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-site-header
  //  TODO

  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-user-header
  //  TODO
}

// https://fetch.spec.whatwg.org/#append-a-request-origin-header
function appendRequestOriginHeader (request) {
  // 1. Let serializedOrigin be the result of byte-serializing a request origin with request.
  let serializedOrigin = request.origin

  // 2. If requests response tainting is "cors" or requests mode is "websocket", then append (`Origin`, serializedOrigin) to requests header list.
  if (request.responseTainting === 'cors' || request.mode === 'websocket') {
    if (serializedOrigin) {
      request.headersList.append('origin', serializedOrigin)
    }

  // 3. Otherwise, if requests method is neither `GET` nor `HEAD`, then:
  } else if (request.method !== 'GET' && request.method !== 'HEAD') {
    // 1. Switch on requests referrer policy:
    switch (request.referrerPolicy) {
      case 'no-referrer':
        // Set serializedOrigin to `null`.
        serializedOrigin = null
        break
      case 'no-referrer-when-downgrade':
      case 'strict-origin':
      case 'strict-origin-when-cross-origin':
        // If requests origin is a tuple origin, its scheme is "https", and requests current URLs scheme is not "https", then set serializedOrigin to `null`.
        if (request.origin && urlHasHttpsScheme(request.origin) && !urlHasHttpsScheme(requestCurrentURL(request))) {
          serializedOrigin = null
        }
        break
      case 'same-origin':
        // If requests origin is not same origin with requests current URLs origin, then set serializedOrigin to `null`.
        if (!sameOrigin(request, requestCurrentURL(request))) {
          serializedOrigin = null
        }
        break
      default:
        // Do nothing.
    }

    if (serializedOrigin) {
      // 2. Append (`Origin`, serializedOrigin) to requests header list.
      request.headersList.append('origin', serializedOrigin)
    }
  }
}

function coarsenedSharedCurrentTime (crossOriginIsolatedCapability) {
  // TODO
  return performance.now()
}

// https://fetch.spec.whatwg.org/#create-an-opaque-timing-info
function createOpaqueTimingInfo (timingInfo) {
  return {
    startTime: timingInfo.startTime ?? 0,
    redirectStartTime: 0,
    redirectEndTime: 0,
    postRedirectStartTime: timingInfo.startTime ?? 0,
    finalServiceWorkerStartTime: 0,
    finalNetworkResponseStartTime: 0,
    finalNetworkRequestStartTime: 0,
    endTime: 0,
    encodedBodySize: 0,
    decodedBodySize: 0,
    finalConnectionTimingInfo: null
  }
}

// https://html.spec.whatwg.org/multipage/origin.html#policy-container
function makePolicyContainer () {
  // Note: the fetch spec doesn't make use of embedder policy or CSP list
  return {
    referrerPolicy: 'strict-origin-when-cross-origin'
  }
}

// https://html.spec.whatwg.org/multipage/origin.html#clone-a-policy-container
function clonePolicyContainer (policyContainer) {
  return {
    referrerPolicy: policyContainer.referrerPolicy
  }
}

// https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer
function determineRequestsReferrer (request) {
  // 1. Let policy be request's referrer policy.
  const policy = request.referrerPolicy

  // Note: policy cannot (shouldn't) be null or an empty string.
  assert(policy)

  // 2. Let environment be requests client.

  let referrerSource = null

  // 3. Switch on requests referrer:
  if (request.referrer === 'client') {
    // Note: node isn't a browser and doesn't implement document/iframes,
    // so we bypass this step and replace it with our own.

    const globalOrigin = getGlobalOrigin()

    if (!globalOrigin || globalOrigin.origin === 'null') {
      return 'no-referrer'
    }

    // note: we need to clone it as it's mutated
    referrerSource = new URL(globalOrigin)
  } else if (request.referrer instanceof URL) {
    // Let referrerSource be requests referrer.
    referrerSource = request.referrer
  }

  // 4. Let requests referrerURL be the result of stripping referrerSource for
  //    use as a referrer.
  let referrerURL = stripURLForReferrer(referrerSource)

  // 5. Let referrerOrigin be the result of stripping referrerSource for use as
  //    a referrer, with the origin-only flag set to true.
  const referrerOrigin = stripURLForReferrer(referrerSource, true)

  // 6. If the result of serializing referrerURL is a string whose length is
  //    greater than 4096, set referrerURL to referrerOrigin.
  if (referrerURL.toString().length > 4096) {
    referrerURL = referrerOrigin
  }

  const areSameOrigin = sameOrigin(request, referrerURL)
  const isNonPotentiallyTrustWorthy = isURLPotentiallyTrustworthy(referrerURL) &&
    !isURLPotentiallyTrustworthy(request.url)

  // 8. Execute the switch statements corresponding to the value of policy:
  switch (policy) {
    case 'origin': return referrerOrigin != null ? referrerOrigin : stripURLForReferrer(referrerSource, true)
    case 'unsafe-url': return referrerURL
    case 'same-origin':
      return areSameOrigin ? referrerOrigin : 'no-referrer'
    case 'origin-when-cross-origin':
      return areSameOrigin ? referrerURL : referrerOrigin
    case 'strict-origin-when-cross-origin': {
      const currentURL = requestCurrentURL(request)

      // 1. If the origin of referrerURL and the origin of requests current
      //    URL are the same, then return referrerURL.
      if (sameOrigin(referrerURL, currentURL)) {
        return referrerURL
      }

      // 2. If referrerURL is a potentially trustworthy URL and requests
      //    current URL is not a potentially trustworthy URL, then return no
      //    referrer.
      if (isURLPotentiallyTrustworthy(referrerURL) && !isURLPotentiallyTrustworthy(currentURL)) {
        return 'no-referrer'
      }

      // 3. Return referrerOrigin.
      return referrerOrigin
    }
    case 'strict-origin': // eslint-disable-line
      /**
         * 1. If referrerURL is a potentially trustworthy URL and
         * requests current URL is not a potentially trustworthy URL,
         * then return no referrer.
         * 2. Return referrerOrigin
        */
    case 'no-referrer-when-downgrade': // eslint-disable-line
      /**
       * 1. If referrerURL is a potentially trustworthy URL and
       * requests current URL is not a potentially trustworthy URL,
       * then return no referrer.
       * 2. Return referrerOrigin
      */

    default: // eslint-disable-line
      return isNonPotentiallyTrustWorthy ? 'no-referrer' : referrerOrigin
  }
}

/**
 * @see https://w3c.github.io/webappsec-referrer-policy/#strip-url
 * @param {URL} url
 * @param {boolean|undefined} originOnly
 */
function stripURLForReferrer (url, originOnly) {
  // 1. Assert: url is a URL.
  assert(url instanceof URL)

  // 2. If urls scheme is a local scheme, then return no referrer.
  if (url.protocol === 'file:' || url.protocol === 'about:' || url.protocol === 'blank:') {
    return 'no-referrer'
  }

  // 3. Set urls username to the empty string.
  url.username = ''

  // 4. Set urls password to the empty string.
  url.password = ''

  // 5. Set urls fragment to null.
  url.hash = ''

  // 6. If the origin-only flag is true, then:
  if (originOnly) {
    // 1. Set urls path to  the empty string .
    url.pathname = ''

    // 2. Set urls query to null.
    url.search = ''
  }

  // 7. Return url.
  return url
}

function isURLPotentiallyTrustworthy (url) {
  if (!(url instanceof URL)) {
    return false
  }

  // If child of about, return true
  if (url.href === 'about:blank' || url.href === 'about:srcdoc') {
    return true
  }

  // If scheme is data, return true
  if (url.protocol === 'data:') return true

  // If file, return true
  if (url.protocol === 'file:') return true

  return isOriginPotentiallyTrustworthy(url.origin)

  function isOriginPotentiallyTrustworthy (origin) {
    // If origin is explicitly null, return false
    if (origin == null || origin === 'null') return false

    const originAsURL = new URL(origin)

    // If secure, return true
    if (originAsURL.protocol === 'https:' || originAsURL.protocol === 'wss:') {
      return true
    }

    // If localhost or variants, return true
    if (/^127(?:\.[0-9]+){0,2}\.[0-9]+$|^\[(?:0*:)*?:?0*1\]$/.test(originAsURL.hostname) ||
     (originAsURL.hostname === 'localhost' || originAsURL.hostname.includes('localhost.')) ||
     (originAsURL.hostname.endsWith('.localhost'))) {
      return true
    }

    // If any other, return false
    return false
  }
}

/**
 * @see https://w3c.github.io/webappsec-subresource-integrity/#does-response-match-metadatalist
 * @param {Uint8Array} bytes
 * @param {string} metadataList
 */
function bytesMatch (bytes, metadataList) {
  // If node is not built with OpenSSL support, we cannot check
  // a request's integrity, so allow it by default (the spec will
  // allow requests if an invalid hash is given, as precedence).
  /* istanbul ignore if: only if node is built with --without-ssl */
  if (crypto === undefined) {
    return true
  }

  // 1. Let parsedMetadata be the result of parsing metadataList.
  const parsedMetadata = parseMetadata(metadataList)

  // 2. If parsedMetadata is no metadata, return true.
  if (parsedMetadata === 'no metadata') {
    return true
  }

  // 3. If response is not eligible for integrity validation, return false.
  // TODO

  // 4. If parsedMetadata is the empty set, return true.
  if (parsedMetadata.length === 0) {
    return true
  }

  // 5. Let metadata be the result of getting the strongest
  //    metadata from parsedMetadata.
  const strongest = getStrongestMetadata(parsedMetadata)
  const metadata = filterMetadataListByAlgorithm(parsedMetadata, strongest)

  // 6. For each item in metadata:
  for (const item of metadata) {
    // 1. Let algorithm be the alg component of item.
    const algorithm = item.algo

    // 2. Let expectedValue be the val component of item.
    const expectedValue = item.hash

    // See https://github.com/web-platform-tests/wpt/commit/e4c5cc7a5e48093220528dfdd1c4012dc3837a0e
    // "be liberal with padding". This is annoying, and it's not even in the spec.

    // 3. Let actualValue be the result of applying algorithm to bytes.
    let actualValue = crypto.createHash(algorithm).update(bytes).digest('base64')

    if (actualValue[actualValue.length - 1] === '=') {
      if (actualValue[actualValue.length - 2] === '=') {
        actualValue = actualValue.slice(0, -2)
      } else {
        actualValue = actualValue.slice(0, -1)
      }
    }

    // 4. If actualValue is a case-sensitive match for expectedValue,
    //    return true.
    if (compareBase64Mixed(actualValue, expectedValue)) {
      return true
    }
  }

  // 7. Return false.
  return false
}

// https://w3c.github.io/webappsec-subresource-integrity/#grammardef-hash-with-options
// https://www.w3.org/TR/CSP2/#source-list-syntax
// https://www.rfc-editor.org/rfc/rfc5234#appendix-B.1
const parseHashWithOptions = /(?<algo>sha256|sha384|sha512)-((?<hash>[A-Za-z0-9+/]+|[A-Za-z0-9_-]+)={0,2}(?:\s|$)( +[!-~]*)?)?/i

/**
 * @see https://w3c.github.io/webappsec-subresource-integrity/#parse-metadata
 * @param {string} metadata
 */
function parseMetadata (metadata) {
  // 1. Let result be the empty set.
  /** @type {{ algo: string, hash: string }[]} */
  const result = []

  // 2. Let empty be equal to true.
  let empty = true

  // 3. For each token returned by splitting metadata on spaces:
  for (const token of metadata.split(' ')) {
    // 1. Set empty to false.
    empty = false

    // 2. Parse token as a hash-with-options.
    const parsedToken = parseHashWithOptions.exec(token)

    // 3. If token does not parse, continue to the next token.
    if (
      parsedToken === null ||
      parsedToken.groups === undefined ||
      parsedToken.groups.algo === undefined
    ) {
      // Note: Chromium blocks the request at this point, but Firefox
      // gives a warning that an invalid integrity was given. The
      // correct behavior is to ignore these, and subsequently not
      // check the integrity of the resource.
      continue
    }

    // 4. Let algorithm be the hash-algo component of token.
    const algorithm = parsedToken.groups.algo.toLowerCase()

    // 5. If algorithm is a hash function recognized by the user
    //    agent, add the parsed token to result.
    if (supportedHashes.includes(algorithm)) {
      result.push(parsedToken.groups)
    }
  }

  // 4. Return no metadata if empty is true, otherwise return result.
  if (empty === true) {
    return 'no metadata'
  }

  return result
}

/**
 * @param {{ algo: 'sha256' | 'sha384' | 'sha512' }[]} metadataList
 */
function getStrongestMetadata (metadataList) {
  // Let algorithm be the algo component of the first item in metadataList.
  // Can be sha256
  let algorithm = metadataList[0].algo
  // If the algorithm is sha512, then it is the strongest
  // and we can return immediately
  if (algorithm[3] === '5') {
    return algorithm
  }

  for (let i = 1; i < metadataList.length; ++i) {
    const metadata = metadataList[i]
    // If the algorithm is sha512, then it is the strongest
    // and we can break the loop immediately
    if (metadata.algo[3] === '5') {
      algorithm = 'sha512'
      break
    // If the algorithm is sha384, then a potential sha256 or sha384 is ignored
    } else if (algorithm[3] === '3') {
      continue
    // algorithm is sha256, check if algorithm is sha384 and if so, set it as
    // the strongest
    } else if (metadata.algo[3] === '3') {
      algorithm = 'sha384'
    }
  }
  return algorithm
}

function filterMetadataListByAlgorithm (metadataList, algorithm) {
  if (metadataList.length === 1) {
    return metadataList
  }

  let pos = 0
  for (let i = 0; i < metadataList.length; ++i) {
    if (metadataList[i].algo === algorithm) {
      metadataList[pos++] = metadataList[i]
    }
  }

  metadataList.length = pos

  return metadataList
}

/**
 * Compares two base64 strings, allowing for base64url
 * in the second string.
 *
* @param {string} actualValue always base64
 * @param {string} expectedValue base64 or base64url
 * @returns {boolean}
 */
function compareBase64Mixed (actualValue, expectedValue) {
  if (actualValue.length !== expectedValue.length) {
    return false
  }
  for (let i = 0; i < actualValue.length; ++i) {
    if (actualValue[i] !== expectedValue[i]) {
      if (
        (actualValue[i] === '+' && expectedValue[i] === '-') ||
        (actualValue[i] === '/' && expectedValue[i] === '_')
      ) {
        continue
      }
      return false
    }
  }

  return true
}

// https://w3c.github.io/webappsec-upgrade-insecure-requests/#upgrade-request
function tryUpgradeRequestToAPotentiallyTrustworthyURL (request) {
  // TODO
}

/**
 * @link {https://html.spec.whatwg.org/multipage/origin.html#same-origin}
 * @param {URL} A
 * @param {URL} B
 */
function sameOrigin (A, B) {
  // 1. If A and B are the same opaque origin, then return true.
  if (A.origin === B.origin && A.origin === 'null') {
    return true
  }

  // 2. If A and B are both tuple origins and their schemes,
  //    hosts, and port are identical, then return true.
  if (A.protocol === B.protocol && A.hostname === B.hostname && A.port === B.port) {
    return true
  }

  // 3. Return false.
  return false
}

function createDeferredPromise () {
  let res
  let rej
  const promise = new Promise((resolve, reject) => {
    res = resolve
    rej = reject
  })

  return { promise, resolve: res, reject: rej }
}

function isAborted (fetchParams) {
  return fetchParams.controller.state === 'aborted'
}

function isCancelled (fetchParams) {
  return fetchParams.controller.state === 'aborted' ||
    fetchParams.controller.state === 'terminated'
}

const normalizeMethodRecord = {
  delete: 'DELETE',
  DELETE: 'DELETE',
  get: 'GET',
  GET: 'GET',
  head: 'HEAD',
  HEAD: 'HEAD',
  options: 'OPTIONS',
  OPTIONS: 'OPTIONS',
  post: 'POST',
  POST: 'POST',
  put: 'PUT',
  PUT: 'PUT'
}

// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.
Object.setPrototypeOf(normalizeMethodRecord, null)

/**
 * @see https://fetch.spec.whatwg.org/#concept-method-normalize
 * @param {string} method
 */
function normalizeMethod (method) {
  return normalizeMethodRecord[method.toLowerCase()] ?? method
}

// https://infra.spec.whatwg.org/#serialize-a-javascript-value-to-a-json-string
function serializeJavascriptValueToJSONString (value) {
  // 1. Let result be ? Call(%JSON.stringify%, undefined,  value ).
  const result = JSON.stringify(value)

  // 2. If result is undefined, then throw a TypeError.
  if (result === undefined) {
    throw new TypeError('Value is not JSON serializable')
  }

  // 3. Assert: result is a string.
  assert(typeof result === 'string')

  // 4. Return result.
  return result
}

// https://tc39.es/ecma262/#sec-%25iteratorprototype%25-object
const esIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]()))

/**
 * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object
 * @param {() => unknown[]} iterator
 * @param {string} name name of the instance
 * @param {'key'|'value'|'key+value'} kind
 */
function makeIterator (iterator, name, kind) {
  const object = {
    index: 0,
    kind,
    target: iterator
  }

  const i = {
    next () {
      // 1. Let interface be the interface for which the iterator prototype object exists.

      // 2. Let thisValue be the this value.

      // 3. Let object be ? ToObject(thisValue).

      // 4. If object is a platform object, then perform a security
      //    check, passing:

      // 5. If object is not a default iterator object for interface,
      //    then throw a TypeError.
      if (Object.getPrototypeOf(this) !== i) {
        throw new TypeError(
          `'next' called on an object that does not implement interface ${name} Iterator.`
        )
      }

      // 6. Let index be objects index.
      // 7. Let kind be objects kind.
      // 8. Let values be objects target's value pairs to iterate over.
      const { index, kind, target } = object
      const values = target()

      // 9. Let len be the length of values.
      const len = values.length

      // 10. If index is greater than or equal to len, then return
      //     CreateIterResultObject(undefined, true).
      if (index >= len) {
        return { value: undefined, done: true }
      }

      // 11. Let pair be the entry in values at index index.
      const pair = values[index]

      // 12. Set objects index to index + 1.
      object.index = index + 1

      // 13. Return the iterator result for pair and kind.
      return iteratorResult(pair, kind)
    },
    // The class string of an iterator prototype object for a given interface is the
    // result of concatenating the identifier of the interface and the string " Iterator".
    [Symbol.toStringTag]: `${name} Iterator`
  }

  // The [[Prototype]] internal slot of an iterator prototype object must be %IteratorPrototype%.
  Object.setPrototypeOf(i, esIteratorPrototype)
  // esIteratorPrototype needs to be the prototype of i
  // which is the prototype of an empty object. Yes, it's confusing.
  return Object.setPrototypeOf({}, i)
}

// https://webidl.spec.whatwg.org/#iterator-result
function iteratorResult (pair, kind) {
  let result

  // 1. Let result be a value determined by the value of kind:
  switch (kind) {
    case 'key': {
      // 1. Let idlKey be pairs key.
      // 2. Let key be the result of converting idlKey to an
      //    ECMAScript value.
      // 3. result is key.
      result = pair[0]
      break
    }
    case 'value': {
      // 1. Let idlValue be pairs value.
      // 2. Let value be the result of converting idlValue to
      //    an ECMAScript value.
      // 3. result is value.
      result = pair[1]
      break
    }
    case 'key+value': {
      // 1. Let idlKey be pairs key.
      // 2. Let idlValue be pairs value.
      // 3. Let key be the result of converting idlKey to an
      //    ECMAScript value.
      // 4. Let value be the result of converting idlValue to
      //    an ECMAScript value.
      // 5. Let array be ! ArrayCreate(2).
      // 6. Call ! CreateDataProperty(array, "0", key).
      // 7. Call ! CreateDataProperty(array, "1", value).
      // 8. result is array.
      result = pair
      break
    }
  }

  // 2. Return CreateIterResultObject(result, false).
  return { value: result, done: false }
}

/**
 * @see https://fetch.spec.whatwg.org/#body-fully-read
 */
async function fullyReadBody (body, processBody, processBodyError) {
  // 1. If taskDestination is null, then set taskDestination to
  //    the result of starting a new parallel queue.

  // 2. Let successSteps given a byte sequence bytes be to queue a
  //    fetch task to run processBody given bytes, with taskDestination.
  const successSteps = processBody

  // 3. Let errorSteps be to queue a fetch task to run processBodyError,
  //    with taskDestination.
  const errorSteps = processBodyError

  // 4. Let reader be the result of getting a reader for bodys stream.
  //    If that threw an exception, then run errorSteps with that
  //    exception and return.
  let reader

  try {
    reader = body.stream.getReader()
  } catch (e) {
    errorSteps(e)
    return
  }

  // 5. Read all bytes from reader, given successSteps and errorSteps.
  try {
    const result = await readAllBytes(reader)
    successSteps(result)
  } catch (e) {
    errorSteps(e)
  }
}

/** @type {ReadableStream} */
let ReadableStream = globalThis.ReadableStream

function isReadableStreamLike (stream) {
  if (!ReadableStream) {
    ReadableStream = (__nccwpck_require__(3774).ReadableStream)
  }

  return stream instanceof ReadableStream || (
    stream[Symbol.toStringTag] === 'ReadableStream' &&
    typeof stream.tee === 'function'
  )
}

const MAXIMUM_ARGUMENT_LENGTH = 65535

/**
 * @see https://infra.spec.whatwg.org/#isomorphic-decode
 * @param {number[]|Uint8Array} input
 */
function isomorphicDecode (input) {
  // 1. To isomorphic decode a byte sequence input, return a string whose code point
  //    length is equal to inputs length and whose code points have the same values
  //    as the values of inputs bytes, in the same order.

  if (input.length < MAXIMUM_ARGUMENT_LENGTH) {
    return String.fromCharCode(...input)
  }

  return input.reduce((previous, current) => previous + String.fromCharCode(current), '')
}

/**
 * @param {ReadableStreamController<Uint8Array>} controller
 */
function readableStreamClose (controller) {
  try {
    controller.close()
  } catch (err) {
    // TODO: add comment explaining why this error occurs.
    if (!err.message.includes('Controller is already closed')) {
      throw err
    }
  }
}

/**
 * @see https://infra.spec.whatwg.org/#isomorphic-encode
 * @param {string} input
 */
function isomorphicEncode (input) {
  // 1. Assert: input contains no code points greater than U+00FF.
  for (let i = 0; i < input.length; i++) {
    assert(input.charCodeAt(i) <= 0xFF)
  }

  // 2. Return a byte sequence whose length is equal to inputs code
  //    point length and whose bytes have the same values as the
  //    values of inputs code points, in the same order
  return input
}

/**
 * @see https://streams.spec.whatwg.org/#readablestreamdefaultreader-read-all-bytes
 * @see https://streams.spec.whatwg.org/#read-loop
 * @param {ReadableStreamDefaultReader} reader
 */
async function readAllBytes (reader) {
  const bytes = []
  let byteLength = 0

  while (true) {
    const { done, value: chunk } = await reader.read()

    if (done) {
      // 1. Call successSteps with bytes.
      return Buffer.concat(bytes, byteLength)
    }

    // 1. If chunk is not a Uint8Array object, call failureSteps
    //    with a TypeError and abort these steps.
    if (!isUint8Array(chunk)) {
      throw new TypeError('Received non-Uint8Array chunk')
    }

    // 2. Append the bytes represented by chunk to bytes.
    bytes.push(chunk)
    byteLength += chunk.length

    // 3. Read-loop given reader, bytes, successSteps, and failureSteps.
  }
}

/**
 * @see https://fetch.spec.whatwg.org/#is-local
 * @param {URL} url
 */
function urlIsLocal (url) {
  assert('protocol' in url) // ensure it's a url object

  const protocol = url.protocol

  return protocol === 'about:' || protocol === 'blob:' || protocol === 'data:'
}

/**
 * @param {string|URL} url
 */
function urlHasHttpsScheme (url) {
  if (typeof url === 'string') {
    return url.startsWith('https:')
  }

  return url.protocol === 'https:'
}

/**
 * @see https://fetch.spec.whatwg.org/#http-scheme
 * @param {URL} url
 */
function urlIsHttpHttpsScheme (url) {
  assert('protocol' in url) // ensure it's a url object

  const protocol = url.protocol

  return protocol === 'http:' || protocol === 'https:'
}

/**
 * Fetch supports node >= 16.8.0, but Object.hasOwn was added in v16.9.0.
 */
const hasOwn = Object.hasOwn || ((dict, key) => Object.prototype.hasOwnProperty.call(dict, key))

module.exports = {
  isAborted,
  isCancelled,
  createDeferredPromise,
  ReadableStreamFrom,
  toUSVString,
  tryUpgradeRequestToAPotentiallyTrustworthyURL,
  coarsenedSharedCurrentTime,
  determineRequestsReferrer,
  makePolicyContainer,
  clonePolicyContainer,
  appendFetchMetadata,
  appendRequestOriginHeader,
  TAOCheck,
  corsCheck,
  crossOriginResourcePolicyCheck,
  createOpaqueTimingInfo,
  setRequestReferrerPolicyOnRedirect,
  isValidHTTPToken,
  requestBadPort,
  requestCurrentURL,
  responseURL,
  responseLocationURL,
  isBlobLike,
  isURLPotentiallyTrustworthy,
  isValidReasonPhrase,
  sameOrigin,
  normalizeMethod,
  serializeJavascriptValueToJSONString,
  makeIterator,
  isValidHeaderName,
  isValidHeaderValue,
  hasOwn,
  isErrorLike,
  fullyReadBody,
  bytesMatch,
  isReadableStreamLike,
  readableStreamClose,
  isomorphicEncode,
  isomorphicDecode,
  urlIsLocal,
  urlHasHttpsScheme,
  urlIsHttpHttpsScheme,
  readAllBytes,
  normalizeMethodRecord,
  parseMetadata
}


/***/ }),

/***/ 4222:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { types } = __nccwpck_require__(9023)
const { hasOwn, toUSVString } = __nccwpck_require__(5523)

/** @type {import('../../types/webidl').Webidl} */
const webidl = {}
webidl.converters = {}
webidl.util = {}
webidl.errors = {}

webidl.errors.exception = function (message) {
  return new TypeError(`${message.header}: ${message.message}`)
}

webidl.errors.conversionFailed = function (context) {
  const plural = context.types.length === 1 ? '' : ' one of'
  const message =
    `${context.argument} could not be converted to` +
    `${plural}: ${context.types.join(', ')}.`

  return webidl.errors.exception({
    header: context.prefix,
    message
  })
}

webidl.errors.invalidArgument = function (context) {
  return webidl.errors.exception({
    header: context.prefix,
    message: `"${context.value}" is an invalid ${context.type}.`
  })
}

// https://webidl.spec.whatwg.org/#implements
webidl.brandCheck = function (V, I, opts = undefined) {
  if (opts?.strict !== false && !(V instanceof I)) {
    throw new TypeError('Illegal invocation')
  } else {
    return V?.[Symbol.toStringTag] === I.prototype[Symbol.toStringTag]
  }
}

webidl.argumentLengthCheck = function ({ length }, min, ctx) {
  if (length < min) {
    throw webidl.errors.exception({
      message: `${min} argument${min !== 1 ? 's' : ''} required, ` +
               `but${length ? ' only' : ''} ${length} found.`,
      ...ctx
    })
  }
}

webidl.illegalConstructor = function () {
  throw webidl.errors.exception({
    header: 'TypeError',
    message: 'Illegal constructor'
  })
}

// https://tc39.es/ecma262/#sec-ecmascript-data-types-and-values
webidl.util.Type = function (V) {
  switch (typeof V) {
    case 'undefined': return 'Undefined'
    case 'boolean': return 'Boolean'
    case 'string': return 'String'
    case 'symbol': return 'Symbol'
    case 'number': return 'Number'
    case 'bigint': return 'BigInt'
    case 'function':
    case 'object': {
      if (V === null) {
        return 'Null'
      }

      return 'Object'
    }
  }
}

// https://webidl.spec.whatwg.org/#abstract-opdef-converttoint
webidl.util.ConvertToInt = function (V, bitLength, signedness, opts = {}) {
  let upperBound
  let lowerBound

  // 1. If bitLength is 64, then:
  if (bitLength === 64) {
    // 1. Let upperBound be 2^53  1.
    upperBound = Math.pow(2, 53) - 1

    // 2. If signedness is "unsigned", then let lowerBound be 0.
    if (signedness === 'unsigned') {
      lowerBound = 0
    } else {
      // 3. Otherwise let lowerBound be 2^53 + 1.
      lowerBound = Math.pow(-2, 53) + 1
    }
  } else if (signedness === 'unsigned') {
    // 2. Otherwise, if signedness is "unsigned", then:

    // 1. Let lowerBound be 0.
    lowerBound = 0

    // 2. Let upperBound be 2^bitLength  1.
    upperBound = Math.pow(2, bitLength) - 1
  } else {
    // 3. Otherwise:

    // 1. Let lowerBound be -2^bitLength  1.
    lowerBound = Math.pow(-2, bitLength) - 1

    // 2. Let upperBound be 2^bitLength  1  1.
    upperBound = Math.pow(2, bitLength - 1) - 1
  }

  // 4. Let x be ? ToNumber(V).
  let x = Number(V)

  // 5. If x is 0, then set x to +0.
  if (x === 0) {
    x = 0
  }

  // 6. If the conversion is to an IDL type associated
  //    with the [EnforceRange] extended attribute, then:
  if (opts.enforceRange === true) {
    // 1. If x is NaN, +, or , then throw a TypeError.
    if (
      Number.isNaN(x) ||
      x === Number.POSITIVE_INFINITY ||
      x === Number.NEGATIVE_INFINITY
    ) {
      throw webidl.errors.exception({
        header: 'Integer conversion',
        message: `Could not convert ${V} to an integer.`
      })
    }

    // 2. Set x to IntegerPart(x).
    x = webidl.util.IntegerPart(x)

    // 3. If x < lowerBound or x > upperBound, then
    //    throw a TypeError.
    if (x < lowerBound || x > upperBound) {
      throw webidl.errors.exception({
        header: 'Integer conversion',
        message: `Value must be between ${lowerBound}-${upperBound}, got ${x}.`
      })
    }

    // 4. Return x.
    return x
  }

  // 7. If x is not NaN and the conversion is to an IDL
  //    type associated with the [Clamp] extended
  //    attribute, then:
  if (!Number.isNaN(x) && opts.clamp === true) {
    // 1. Set x to min(max(x, lowerBound), upperBound).
    x = Math.min(Math.max(x, lowerBound), upperBound)

    // 2. Round x to the nearest integer, choosing the
    //    even integer if it lies halfway between two,
    //    and choosing +0 rather than 0.
    if (Math.floor(x) % 2 === 0) {
      x = Math.floor(x)
    } else {
      x = Math.ceil(x)
    }

    // 3. Return x.
    return x
  }

  // 8. If x is NaN, +0, +, or , then return +0.
  if (
    Number.isNaN(x) ||
    (x === 0 && Object.is(0, x)) ||
    x === Number.POSITIVE_INFINITY ||
    x === Number.NEGATIVE_INFINITY
  ) {
    return 0
  }

  // 9. Set x to IntegerPart(x).
  x = webidl.util.IntegerPart(x)

  // 10. Set x to x modulo 2^bitLength.
  x = x % Math.pow(2, bitLength)

  // 11. If signedness is "signed" and x  2^bitLength  1,
  //    then return x  2^bitLength.
  if (signedness === 'signed' && x >= Math.pow(2, bitLength) - 1) {
    return x - Math.pow(2, bitLength)
  }

  // 12. Otherwise, return x.
  return x
}

// https://webidl.spec.whatwg.org/#abstract-opdef-integerpart
webidl.util.IntegerPart = function (n) {
  // 1. Let r be floor(abs(n)).
  const r = Math.floor(Math.abs(n))

  // 2. If n < 0, then return -1  r.
  if (n < 0) {
    return -1 * r
  }

  // 3. Otherwise, return r.
  return r
}

// https://webidl.spec.whatwg.org/#es-sequence
webidl.sequenceConverter = function (converter) {
  return (V) => {
    // 1. If Type(V) is not Object, throw a TypeError.
    if (webidl.util.Type(V) !== 'Object') {
      throw webidl.errors.exception({
        header: 'Sequence',
        message: `Value of type ${webidl.util.Type(V)} is not an Object.`
      })
    }

    // 2. Let method be ? GetMethod(V, @@iterator).
    /** @type {Generator} */
    const method = V?.[Symbol.iterator]?.()
    const seq = []

    // 3. If method is undefined, throw a TypeError.
    if (
      method === undefined ||
      typeof method.next !== 'function'
    ) {
      throw webidl.errors.exception({
        header: 'Sequence',
        message: 'Object is not an iterator.'
      })
    }

    // https://webidl.spec.whatwg.org/#create-sequence-from-iterable
    while (true) {
      const { done, value } = method.next()

      if (done) {
        break
      }

      seq.push(converter(value))
    }

    return seq
  }
}

// https://webidl.spec.whatwg.org/#es-to-record
webidl.recordConverter = function (keyConverter, valueConverter) {
  return (O) => {
    // 1. If Type(O) is not Object, throw a TypeError.
    if (webidl.util.Type(O) !== 'Object') {
      throw webidl.errors.exception({
        header: 'Record',
        message: `Value of type ${webidl.util.Type(O)} is not an Object.`
      })
    }

    // 2. Let result be a new empty instance of record<K, V>.
    const result = {}

    if (!types.isProxy(O)) {
      // Object.keys only returns enumerable properties
      const keys = Object.keys(O)

      for (const key of keys) {
        // 1. Let typedKey be key converted to an IDL value of type K.
        const typedKey = keyConverter(key)

        // 2. Let value be ? Get(O, key).
        // 3. Let typedValue be value converted to an IDL value of type V.
        const typedValue = valueConverter(O[key])

        // 4. Set result[typedKey] to typedValue.
        result[typedKey] = typedValue
      }

      // 5. Return result.
      return result
    }

    // 3. Let keys be ? O.[[OwnPropertyKeys]]().
    const keys = Reflect.ownKeys(O)

    // 4. For each key of keys.
    for (const key of keys) {
      // 1. Let desc be ? O.[[GetOwnProperty]](key).
      const desc = Reflect.getOwnPropertyDescriptor(O, key)

      // 2. If desc is not undefined and desc.[[Enumerable]] is true:
      if (desc?.enumerable) {
        // 1. Let typedKey be key converted to an IDL value of type K.
        const typedKey = keyConverter(key)

        // 2. Let value be ? Get(O, key).
        // 3. Let typedValue be value converted to an IDL value of type V.
        const typedValue = valueConverter(O[key])

        // 4. Set result[typedKey] to typedValue.
        result[typedKey] = typedValue
      }
    }

    // 5. Return result.
    return result
  }
}

webidl.interfaceConverter = function (i) {
  return (V, opts = {}) => {
    if (opts.strict !== false && !(V instanceof i)) {
      throw webidl.errors.exception({
        header: i.name,
        message: `Expected ${V} to be an instance of ${i.name}.`
      })
    }

    return V
  }
}

webidl.dictionaryConverter = function (converters) {
  return (dictionary) => {
    const type = webidl.util.Type(dictionary)
    const dict = {}

    if (type === 'Null' || type === 'Undefined') {
      return dict
    } else if (type !== 'Object') {
      throw webidl.errors.exception({
        header: 'Dictionary',
        message: `Expected ${dictionary} to be one of: Null, Undefined, Object.`
      })
    }

    for (const options of converters) {
      const { key, defaultValue, required, converter } = options

      if (required === true) {
        if (!hasOwn(dictionary, key)) {
          throw webidl.errors.exception({
            header: 'Dictionary',
            message: `Missing required key "${key}".`
          })
        }
      }

      let value = dictionary[key]
      const hasDefault = hasOwn(options, 'defaultValue')

      // Only use defaultValue if value is undefined and
      // a defaultValue options was provided.
      if (hasDefault && value !== null) {
        value = value ?? defaultValue
      }

      // A key can be optional and have no default value.
      // When this happens, do not perform a conversion,
      // and do not assign the key a value.
      if (required || hasDefault || value !== undefined) {
        value = converter(value)

        if (
          options.allowedValues &&
          !options.allowedValues.includes(value)
        ) {
          throw webidl.errors.exception({
            header: 'Dictionary',
            message: `${value} is not an accepted type. Expected one of ${options.allowedValues.join(', ')}.`
          })
        }

        dict[key] = value
      }
    }

    return dict
  }
}

webidl.nullableConverter = function (converter) {
  return (V) => {
    if (V === null) {
      return V
    }

    return converter(V)
  }
}

// https://webidl.spec.whatwg.org/#es-DOMString
webidl.converters.DOMString = function (V, opts = {}) {
  // 1. If V is null and the conversion is to an IDL type
  //    associated with the [LegacyNullToEmptyString]
  //    extended attribute, then return the DOMString value
  //    that represents the empty string.
  if (V === null && opts.legacyNullToEmptyString) {
    return ''
  }

  // 2. Let x be ? ToString(V).
  if (typeof V === 'symbol') {
    throw new TypeError('Could not convert argument of type symbol to string.')
  }

  // 3. Return the IDL DOMString value that represents the
  //    same sequence of code units as the one the
  //    ECMAScript String value x represents.
  return String(V)
}

// https://webidl.spec.whatwg.org/#es-ByteString
webidl.converters.ByteString = function (V) {
  // 1. Let x be ? ToString(V).
  // Note: DOMString converter perform ? ToString(V)
  const x = webidl.converters.DOMString(V)

  // 2. If the value of any element of x is greater than
  //    255, then throw a TypeError.
  for (let index = 0; index < x.length; index++) {
    if (x.charCodeAt(index) > 255) {
      throw new TypeError(
        'Cannot convert argument to a ByteString because the character at ' +
        `index ${index} has a value of ${x.charCodeAt(index)} which is greater than 255.`
      )
    }
  }

  // 3. Return an IDL ByteString value whose length is the
  //    length of x, and where the value of each element is
  //    the value of the corresponding element of x.
  return x
}

// https://webidl.spec.whatwg.org/#es-USVString
webidl.converters.USVString = toUSVString

// https://webidl.spec.whatwg.org/#es-boolean
webidl.converters.boolean = function (V) {
  // 1. Let x be the result of computing ToBoolean(V).
  const x = Boolean(V)

  // 2. Return the IDL boolean value that is the one that represents
  //    the same truth value as the ECMAScript Boolean value x.
  return x
}

// https://webidl.spec.whatwg.org/#es-any
webidl.converters.any = function (V) {
  return V
}

// https://webidl.spec.whatwg.org/#es-long-long
webidl.converters['long long'] = function (V) {
  // 1. Let x be ? ConvertToInt(V, 64, "signed").
  const x = webidl.util.ConvertToInt(V, 64, 'signed')

  // 2. Return the IDL long long value that represents
  //    the same numeric value as x.
  return x
}

// https://webidl.spec.whatwg.org/#es-unsigned-long-long
webidl.converters['unsigned long long'] = function (V) {
  // 1. Let x be ? ConvertToInt(V, 64, "unsigned").
  const x = webidl.util.ConvertToInt(V, 64, 'unsigned')

  // 2. Return the IDL unsigned long long value that
  //    represents the same numeric value as x.
  return x
}

// https://webidl.spec.whatwg.org/#es-unsigned-long
webidl.converters['unsigned long'] = function (V) {
  // 1. Let x be ? ConvertToInt(V, 32, "unsigned").
  const x = webidl.util.ConvertToInt(V, 32, 'unsigned')

  // 2. Return the IDL unsigned long value that
  //    represents the same numeric value as x.
  return x
}

// https://webidl.spec.whatwg.org/#es-unsigned-short
webidl.converters['unsigned short'] = function (V, opts) {
  // 1. Let x be ? ConvertToInt(V, 16, "unsigned").
  const x = webidl.util.ConvertToInt(V, 16, 'unsigned', opts)

  // 2. Return the IDL unsigned short value that represents
  //    the same numeric value as x.
  return x
}

// https://webidl.spec.whatwg.org/#idl-ArrayBuffer
webidl.converters.ArrayBuffer = function (V, opts = {}) {
  // 1. If Type(V) is not Object, or V does not have an
  //    [[ArrayBufferData]] internal slot, then throw a
  //    TypeError.
  // see: https://tc39.es/ecma262/#sec-properties-of-the-arraybuffer-instances
  // see: https://tc39.es/ecma262/#sec-properties-of-the-sharedarraybuffer-instances
  if (
    webidl.util.Type(V) !== 'Object' ||
    !types.isAnyArrayBuffer(V)
  ) {
    throw webidl.errors.conversionFailed({
      prefix: `${V}`,
      argument: `${V}`,
      types: ['ArrayBuffer']
    })
  }

  // 2. If the conversion is not to an IDL type associated
  //    with the [AllowShared] extended attribute, and
  //    IsSharedArrayBuffer(V) is true, then throw a
  //    TypeError.
  if (opts.allowShared === false && types.isSharedArrayBuffer(V)) {
    throw webidl.errors.exception({
      header: 'ArrayBuffer',
      message: 'SharedArrayBuffer is not allowed.'
    })
  }

  // 3. If the conversion is not to an IDL type associated
  //    with the [AllowResizable] extended attribute, and
  //    IsResizableArrayBuffer(V) is true, then throw a
  //    TypeError.
  // Note: resizable ArrayBuffers are currently a proposal.

  // 4. Return the IDL ArrayBuffer value that is a
  //    reference to the same object as V.
  return V
}

webidl.converters.TypedArray = function (V, T, opts = {}) {
  // 1. Let T be the IDL type V is being converted to.

  // 2. If Type(V) is not Object, or V does not have a
  //    [[TypedArrayName]] internal slot with a value
  //    equal to Ts name, then throw a TypeError.
  if (
    webidl.util.Type(V) !== 'Object' ||
    !types.isTypedArray(V) ||
    V.constructor.name !== T.name
  ) {
    throw webidl.errors.conversionFailed({
      prefix: `${T.name}`,
      argument: `${V}`,
      types: [T.name]
    })
  }

  // 3. If the conversion is not to an IDL type associated
  //    with the [AllowShared] extended attribute, and
  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is
  //    true, then throw a TypeError.
  if (opts.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {
    throw webidl.errors.exception({
      header: 'ArrayBuffer',
      message: 'SharedArrayBuffer is not allowed.'
    })
  }

  // 4. If the conversion is not to an IDL type associated
  //    with the [AllowResizable] extended attribute, and
  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is
  //    true, then throw a TypeError.
  // Note: resizable array buffers are currently a proposal

  // 5. Return the IDL value of type T that is a reference
  //    to the same object as V.
  return V
}

webidl.converters.DataView = function (V, opts = {}) {
  // 1. If Type(V) is not Object, or V does not have a
  //    [[DataView]] internal slot, then throw a TypeError.
  if (webidl.util.Type(V) !== 'Object' || !types.isDataView(V)) {
    throw webidl.errors.exception({
      header: 'DataView',
      message: 'Object is not a DataView.'
    })
  }

  // 2. If the conversion is not to an IDL type associated
  //    with the [AllowShared] extended attribute, and
  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is true,
  //    then throw a TypeError.
  if (opts.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {
    throw webidl.errors.exception({
      header: 'ArrayBuffer',
      message: 'SharedArrayBuffer is not allowed.'
    })
  }

  // 3. If the conversion is not to an IDL type associated
  //    with the [AllowResizable] extended attribute, and
  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is
  //    true, then throw a TypeError.
  // Note: resizable ArrayBuffers are currently a proposal

  // 4. Return the IDL DataView value that is a reference
  //    to the same object as V.
  return V
}

// https://webidl.spec.whatwg.org/#BufferSource
webidl.converters.BufferSource = function (V, opts = {}) {
  if (types.isAnyArrayBuffer(V)) {
    return webidl.converters.ArrayBuffer(V, opts)
  }

  if (types.isTypedArray(V)) {
    return webidl.converters.TypedArray(V, V.constructor)
  }

  if (types.isDataView(V)) {
    return webidl.converters.DataView(V, opts)
  }

  throw new TypeError(`Could not convert ${V} to a BufferSource.`)
}

webidl.converters['sequence<ByteString>'] = webidl.sequenceConverter(
  webidl.converters.ByteString
)

webidl.converters['sequence<sequence<ByteString>>'] = webidl.sequenceConverter(
  webidl.converters['sequence<ByteString>']
)

webidl.converters['record<ByteString, ByteString>'] = webidl.recordConverter(
  webidl.converters.ByteString,
  webidl.converters.ByteString
)

module.exports = {
  webidl
}


/***/ }),

/***/ 396:
/***/ ((module) => {

"use strict";


/**
 * @see https://encoding.spec.whatwg.org/#concept-encoding-get
 * @param {string|undefined} label
 */
function getEncoding (label) {
  if (!label) {
    return 'failure'
  }

  // 1. Remove any leading and trailing ASCII whitespace from label.
  // 2. If label is an ASCII case-insensitive match for any of the
  //    labels listed in the table below, then return the
  //    corresponding encoding; otherwise return failure.
  switch (label.trim().toLowerCase()) {
    case 'unicode-1-1-utf-8':
    case 'unicode11utf8':
    case 'unicode20utf8':
    case 'utf-8':
    case 'utf8':
    case 'x-unicode20utf8':
      return 'UTF-8'
    case '866':
    case 'cp866':
    case 'csibm866':
    case 'ibm866':
      return 'IBM866'
    case 'csisolatin2':
    case 'iso-8859-2':
    case 'iso-ir-101':
    case 'iso8859-2':
    case 'iso88592':
    case 'iso_8859-2':
    case 'iso_8859-2:1987':
    case 'l2':
    case 'latin2':
      return 'ISO-8859-2'
    case 'csisolatin3':
    case 'iso-8859-3':
    case 'iso-ir-109':
    case 'iso8859-3':
    case 'iso88593':
    case 'iso_8859-3':
    case 'iso_8859-3:1988':
    case 'l3':
    case 'latin3':
      return 'ISO-8859-3'
    case 'csisolatin4':
    case 'iso-8859-4':
    case 'iso-ir-110':
    case 'iso8859-4':
    case 'iso88594':
    case 'iso_8859-4':
    case 'iso_8859-4:1988':
    case 'l4':
    case 'latin4':
      return 'ISO-8859-4'
    case 'csisolatincyrillic':
    case 'cyrillic':
    case 'iso-8859-5':
    case 'iso-ir-144':
    case 'iso8859-5':
    case 'iso88595':
    case 'iso_8859-5':
    case 'iso_8859-5:1988':
      return 'ISO-8859-5'
    case 'arabic':
    case 'asmo-708':
    case 'csiso88596e':
    case 'csiso88596i':
    case 'csisolatinarabic':
    case 'ecma-114':
    case 'iso-8859-6':
    case 'iso-8859-6-e':
    case 'iso-8859-6-i':
    case 'iso-ir-127':
    case 'iso8859-6':
    case 'iso88596':
    case 'iso_8859-6':
    case 'iso_8859-6:1987':
      return 'ISO-8859-6'
    case 'csisolatingreek':
    case 'ecma-118':
    case 'elot_928':
    case 'greek':
    case 'greek8':
    case 'iso-8859-7':
    case 'iso-ir-126':
    case 'iso8859-7':
    case 'iso88597':
    case 'iso_8859-7':
    case 'iso_8859-7:1987':
    case 'sun_eu_greek':
      return 'ISO-8859-7'
    case 'csiso88598e':
    case 'csisolatinhebrew':
    case 'hebrew':
    case 'iso-8859-8':
    case 'iso-8859-8-e':
    case 'iso-ir-138':
    case 'iso8859-8':
    case 'iso88598':
    case 'iso_8859-8':
    case 'iso_8859-8:1988':
    case 'visual':
      return 'ISO-8859-8'
    case 'csiso88598i':
    case 'iso-8859-8-i':
    case 'logical':
      return 'ISO-8859-8-I'
    case 'csisolatin6':
    case 'iso-8859-10':
    case 'iso-ir-157':
    case 'iso8859-10':
    case 'iso885910':
    case 'l6':
    case 'latin6':
      return 'ISO-8859-10'
    case 'iso-8859-13':
    case 'iso8859-13':
    case 'iso885913':
      return 'ISO-8859-13'
    case 'iso-8859-14':
    case 'iso8859-14':
    case 'iso885914':
      return 'ISO-8859-14'
    case 'csisolatin9':
    case 'iso-8859-15':
    case 'iso8859-15':
    case 'iso885915':
    case 'iso_8859-15':
    case 'l9':
      return 'ISO-8859-15'
    case 'iso-8859-16':
      return 'ISO-8859-16'
    case 'cskoi8r':
    case 'koi':
    case 'koi8':
    case 'koi8-r':
    case 'koi8_r':
      return 'KOI8-R'
    case 'koi8-ru':
    case 'koi8-u':
      return 'KOI8-U'
    case 'csmacintosh':
    case 'mac':
    case 'macintosh':
    case 'x-mac-roman':
      return 'macintosh'
    case 'iso-8859-11':
    case 'iso8859-11':
    case 'iso885911':
    case 'tis-620':
    case 'windows-874':
      return 'windows-874'
    case 'cp1250':
    case 'windows-1250':
    case 'x-cp1250':
      return 'windows-1250'
    case 'cp1251':
    case 'windows-1251':
    case 'x-cp1251':
      return 'windows-1251'
    case 'ansi_x3.4-1968':
    case 'ascii':
    case 'cp1252':
    case 'cp819':
    case 'csisolatin1':
    case 'ibm819':
    case 'iso-8859-1':
    case 'iso-ir-100':
    case 'iso8859-1':
    case 'iso88591':
    case 'iso_8859-1':
    case 'iso_8859-1:1987':
    case 'l1':
    case 'latin1':
    case 'us-ascii':
    case 'windows-1252':
    case 'x-cp1252':
      return 'windows-1252'
    case 'cp1253':
    case 'windows-1253':
    case 'x-cp1253':
      return 'windows-1253'
    case 'cp1254':
    case 'csisolatin5':
    case 'iso-8859-9':
    case 'iso-ir-148':
    case 'iso8859-9':
    case 'iso88599':
    case 'iso_8859-9':
    case 'iso_8859-9:1989':
    case 'l5':
    case 'latin5':
    case 'windows-1254':
    case 'x-cp1254':
      return 'windows-1254'
    case 'cp1255':
    case 'windows-1255':
    case 'x-cp1255':
      return 'windows-1255'
    case 'cp1256':
    case 'windows-1256':
    case 'x-cp1256':
      return 'windows-1256'
    case 'cp1257':
    case 'windows-1257':
    case 'x-cp1257':
      return 'windows-1257'
    case 'cp1258':
    case 'windows-1258':
    case 'x-cp1258':
      return 'windows-1258'
    case 'x-mac-cyrillic':
    case 'x-mac-ukrainian':
      return 'x-mac-cyrillic'
    case 'chinese':
    case 'csgb2312':
    case 'csiso58gb231280':
    case 'gb2312':
    case 'gb_2312':
    case 'gb_2312-80':
    case 'gbk':
    case 'iso-ir-58':
    case 'x-gbk':
      return 'GBK'
    case 'gb18030':
      return 'gb18030'
    case 'big5':
    case 'big5-hkscs':
    case 'cn-big5':
    case 'csbig5':
    case 'x-x-big5':
      return 'Big5'
    case 'cseucpkdfmtjapanese':
    case 'euc-jp':
    case 'x-euc-jp':
      return 'EUC-JP'
    case 'csiso2022jp':
    case 'iso-2022-jp':
      return 'ISO-2022-JP'
    case 'csshiftjis':
    case 'ms932':
    case 'ms_kanji':
    case 'shift-jis':
    case 'shift_jis':
    case 'sjis':
    case 'windows-31j':
    case 'x-sjis':
      return 'Shift_JIS'
    case 'cseuckr':
    case 'csksc56011987':
    case 'euc-kr':
    case 'iso-ir-149':
    case 'korean':
    case 'ks_c_5601-1987':
    case 'ks_c_5601-1989':
    case 'ksc5601':
    case 'ksc_5601':
    case 'windows-949':
      return 'EUC-KR'
    case 'csiso2022kr':
    case 'hz-gb-2312':
    case 'iso-2022-cn':
    case 'iso-2022-cn-ext':
    case 'iso-2022-kr':
    case 'replacement':
      return 'replacement'
    case 'unicodefffe':
    case 'utf-16be':
      return 'UTF-16BE'
    case 'csunicode':
    case 'iso-10646-ucs-2':
    case 'ucs-2':
    case 'unicode':
    case 'unicodefeff':
    case 'utf-16':
    case 'utf-16le':
      return 'UTF-16LE'
    case 'x-user-defined':
      return 'x-user-defined'
    default: return 'failure'
  }
}

module.exports = {
  getEncoding
}


/***/ }),

/***/ 2160:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const {
  staticPropertyDescriptors,
  readOperation,
  fireAProgressEvent
} = __nccwpck_require__(165)
const {
  kState,
  kError,
  kResult,
  kEvents,
  kAborted
} = __nccwpck_require__(6812)
const { webidl } = __nccwpck_require__(4222)
const { kEnumerableProperty } = __nccwpck_require__(3440)

class FileReader extends EventTarget {
  constructor () {
    super()

    this[kState] = 'empty'
    this[kResult] = null
    this[kError] = null
    this[kEvents] = {
      loadend: null,
      error: null,
      abort: null,
      load: null,
      progress: null,
      loadstart: null
    }
  }

  /**
   * @see https://w3c.github.io/FileAPI/#dfn-readAsArrayBuffer
   * @param {import('buffer').Blob} blob
   */
  readAsArrayBuffer (blob) {
    webidl.brandCheck(this, FileReader)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsArrayBuffer' })

    blob = webidl.converters.Blob(blob, { strict: false })

    // The readAsArrayBuffer(blob) method, when invoked,
    // must initiate a read operation for blob with ArrayBuffer.
    readOperation(this, blob, 'ArrayBuffer')
  }

  /**
   * @see https://w3c.github.io/FileAPI/#readAsBinaryString
   * @param {import('buffer').Blob} blob
   */
  readAsBinaryString (blob) {
    webidl.brandCheck(this, FileReader)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsBinaryString' })

    blob = webidl.converters.Blob(blob, { strict: false })

    // The readAsBinaryString(blob) method, when invoked,
    // must initiate a read operation for blob with BinaryString.
    readOperation(this, blob, 'BinaryString')
  }

  /**
   * @see https://w3c.github.io/FileAPI/#readAsDataText
   * @param {import('buffer').Blob} blob
   * @param {string?} encoding
   */
  readAsText (blob, encoding = undefined) {
    webidl.brandCheck(this, FileReader)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsText' })

    blob = webidl.converters.Blob(blob, { strict: false })

    if (encoding !== undefined) {
      encoding = webidl.converters.DOMString(encoding)
    }

    // The readAsText(blob, encoding) method, when invoked,
    // must initiate a read operation for blob with Text and encoding.
    readOperation(this, blob, 'Text', encoding)
  }

  /**
   * @see https://w3c.github.io/FileAPI/#dfn-readAsDataURL
   * @param {import('buffer').Blob} blob
   */
  readAsDataURL (blob) {
    webidl.brandCheck(this, FileReader)

    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsDataURL' })

    blob = webidl.converters.Blob(blob, { strict: false })

    // The readAsDataURL(blob) method, when invoked, must
    // initiate a read operation for blob with DataURL.
    readOperation(this, blob, 'DataURL')
  }

  /**
   * @see https://w3c.github.io/FileAPI/#dfn-abort
   */
  abort () {
    // 1. If this's state is "empty" or if this's state is
    //    "done" set this's result to null and terminate
    //    this algorithm.
    if (this[kState] === 'empty' || this[kState] === 'done') {
      this[kResult] = null
      return
    }

    // 2. If this's state is "loading" set this's state to
    //    "done" and set this's result to null.
    if (this[kState] === 'loading') {
      this[kState] = 'done'
      this[kResult] = null
    }

    // 3. If there are any tasks from this on the file reading
    //    task source in an affiliated task queue, then remove
    //    those tasks from that task queue.
    this[kAborted] = true

    // 4. Terminate the algorithm for the read method being processed.
    // TODO

    // 5. Fire a progress event called abort at this.
    fireAProgressEvent('abort', this)

    // 6. If this's state is not "loading", fire a progress
    //    event called loadend at this.
    if (this[kState] !== 'loading') {
      fireAProgressEvent('loadend', this)
    }
  }

  /**
   * @see https://w3c.github.io/FileAPI/#dom-filereader-readystate
   */
  get readyState () {
    webidl.brandCheck(this, FileReader)

    switch (this[kState]) {
      case 'empty': return this.EMPTY
      case 'loading': return this.LOADING
      case 'done': return this.DONE
    }
  }

  /**
   * @see https://w3c.github.io/FileAPI/#dom-filereader-result
   */
  get result () {
    webidl.brandCheck(this, FileReader)

    // The result attributes getter, when invoked, must return
    // this's result.
    return this[kResult]
  }

  /**
   * @see https://w3c.github.io/FileAPI/#dom-filereader-error
   */
  get error () {
    webidl.brandCheck(this, FileReader)

    // The error attributes getter, when invoked, must return
    // this's error.
    return this[kError]
  }

  get onloadend () {
    webidl.brandCheck(this, FileReader)

    return this[kEvents].loadend
  }

  set onloadend (fn) {
    webidl.brandCheck(this, FileReader)

    if (this[kEvents].loadend) {
      this.removeEventListener('loadend', this[kEvents].loadend)
    }

    if (typeof fn === 'function') {
      this[kEvents].loadend = fn
      this.addEventListener('loadend', fn)
    } else {
      this[kEvents].loadend = null
    }
  }

  get onerror () {
    webidl.brandCheck(this, FileReader)

    return this[kEvents].error
  }

  set onerror (fn) {
    webidl.brandCheck(this, FileReader)

    if (this[kEvents].error) {
      this.removeEventListener('error', this[kEvents].error)
    }

    if (typeof fn === 'function') {
      this[kEvents].error = fn
      this.addEventListener('error', fn)
    } else {
      this[kEvents].error = null
    }
  }

  get onloadstart () {
    webidl.brandCheck(this, FileReader)

    return this[kEvents].loadstart
  }

  set onloadstart (fn) {
    webidl.brandCheck(this, FileReader)

    if (this[kEvents].loadstart) {
      this.removeEventListener('loadstart', this[kEvents].loadstart)
    }

    if (typeof fn === 'function') {
      this[kEvents].loadstart = fn
      this.addEventListener('loadstart', fn)
    } else {
      this[kEvents].loadstart = null
    }
  }

  get onprogress () {
    webidl.brandCheck(this, FileReader)

    return this[kEvents].progress
  }

  set onprogress (fn) {
    webidl.brandCheck(this, FileReader)

    if (this[kEvents].progress) {
      this.removeEventListener('progress', this[kEvents].progress)
    }

    if (typeof fn === 'function') {
      this[kEvents].progress = fn
      this.addEventListener('progress', fn)
    } else {
      this[kEvents].progress = null
    }
  }

  get onload () {
    webidl.brandCheck(this, FileReader)

    return this[kEvents].load
  }

  set onload (fn) {
    webidl.brandCheck(this, FileReader)

    if (this[kEvents].load) {
      this.removeEventListener('load', this[kEvents].load)
    }

    if (typeof fn === 'function') {
      this[kEvents].load = fn
      this.addEventListener('load', fn)
    } else {
      this[kEvents].load = null
    }
  }

  get onabort () {
    webidl.brandCheck(this, FileReader)

    return this[kEvents].abort
  }

  set onabort (fn) {
    webidl.brandCheck(this, FileReader)

    if (this[kEvents].abort) {
      this.removeEventListener('abort', this[kEvents].abort)
    }

    if (typeof fn === 'function') {
      this[kEvents].abort = fn
      this.addEventListener('abort', fn)
    } else {
      this[kEvents].abort = null
    }
  }
}

// https://w3c.github.io/FileAPI/#dom-filereader-empty
FileReader.EMPTY = FileReader.prototype.EMPTY = 0
// https://w3c.github.io/FileAPI/#dom-filereader-loading
FileReader.LOADING = FileReader.prototype.LOADING = 1
// https://w3c.github.io/FileAPI/#dom-filereader-done
FileReader.DONE = FileReader.prototype.DONE = 2

Object.defineProperties(FileReader.prototype, {
  EMPTY: staticPropertyDescriptors,
  LOADING: staticPropertyDescriptors,
  DONE: staticPropertyDescriptors,
  readAsArrayBuffer: kEnumerableProperty,
  readAsBinaryString: kEnumerableProperty,
  readAsText: kEnumerableProperty,
  readAsDataURL: kEnumerableProperty,
  abort: kEnumerableProperty,
  readyState: kEnumerableProperty,
  result: kEnumerableProperty,
  error: kEnumerableProperty,
  onloadstart: kEnumerableProperty,
  onprogress: kEnumerableProperty,
  onload: kEnumerableProperty,
  onabort: kEnumerableProperty,
  onerror: kEnumerableProperty,
  onloadend: kEnumerableProperty,
  [Symbol.toStringTag]: {
    value: 'FileReader',
    writable: false,
    enumerable: false,
    configurable: true
  }
})

Object.defineProperties(FileReader, {
  EMPTY: staticPropertyDescriptors,
  LOADING: staticPropertyDescriptors,
  DONE: staticPropertyDescriptors
})

module.exports = {
  FileReader
}


/***/ }),

/***/ 5976:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { webidl } = __nccwpck_require__(4222)

const kState = Symbol('ProgressEvent state')

/**
 * @see https://xhr.spec.whatwg.org/#progressevent
 */
class ProgressEvent extends Event {
  constructor (type, eventInitDict = {}) {
    type = webidl.converters.DOMString(type)
    eventInitDict = webidl.converters.ProgressEventInit(eventInitDict ?? {})

    super(type, eventInitDict)

    this[kState] = {
      lengthComputable: eventInitDict.lengthComputable,
      loaded: eventInitDict.loaded,
      total: eventInitDict.total
    }
  }

  get lengthComputable () {
    webidl.brandCheck(this, ProgressEvent)

    return this[kState].lengthComputable
  }

  get loaded () {
    webidl.brandCheck(this, ProgressEvent)

    return this[kState].loaded
  }

  get total () {
    webidl.brandCheck(this, ProgressEvent)

    return this[kState].total
  }
}

webidl.converters.ProgressEventInit = webidl.dictionaryConverter([
  {
    key: 'lengthComputable',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'loaded',
    converter: webidl.converters['unsigned long long'],
    defaultValue: 0
  },
  {
    key: 'total',
    converter: webidl.converters['unsigned long long'],
    defaultValue: 0
  },
  {
    key: 'bubbles',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'cancelable',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'composed',
    converter: webidl.converters.boolean,
    defaultValue: false
  }
])

module.exports = {
  ProgressEvent
}


/***/ }),

/***/ 6812:
/***/ ((module) => {

"use strict";


module.exports = {
  kState: Symbol('FileReader state'),
  kResult: Symbol('FileReader result'),
  kError: Symbol('FileReader error'),
  kLastProgressEventFired: Symbol('FileReader last progress event fired timestamp'),
  kEvents: Symbol('FileReader events'),
  kAborted: Symbol('FileReader aborted')
}


/***/ }),

/***/ 165:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const {
  kState,
  kError,
  kResult,
  kAborted,
  kLastProgressEventFired
} = __nccwpck_require__(6812)
const { ProgressEvent } = __nccwpck_require__(5976)
const { getEncoding } = __nccwpck_require__(396)
const { DOMException } = __nccwpck_require__(7326)
const { serializeAMimeType, parseMIMEType } = __nccwpck_require__(4322)
const { types } = __nccwpck_require__(9023)
const { StringDecoder } = __nccwpck_require__(3193)
const { btoa } = __nccwpck_require__(181)

/** @type {PropertyDescriptor} */
const staticPropertyDescriptors = {
  enumerable: true,
  writable: false,
  configurable: false
}

/**
 * @see https://w3c.github.io/FileAPI/#readOperation
 * @param {import('./filereader').FileReader} fr
 * @param {import('buffer').Blob} blob
 * @param {string} type
 * @param {string?} encodingName
 */
function readOperation (fr, blob, type, encodingName) {
  // 1. If frs state is "loading", throw an InvalidStateError
  //    DOMException.
  if (fr[kState] === 'loading') {
    throw new DOMException('Invalid state', 'InvalidStateError')
  }

  // 2. Set frs state to "loading".
  fr[kState] = 'loading'

  // 3. Set frs result to null.
  fr[kResult] = null

  // 4. Set frs error to null.
  fr[kError] = null

  // 5. Let stream be the result of calling get stream on blob.
  /** @type {import('stream/web').ReadableStream} */
  const stream = blob.stream()

  // 6. Let reader be the result of getting a reader from stream.
  const reader = stream.getReader()

  // 7. Let bytes be an empty byte sequence.
  /** @type {Uint8Array[]} */
  const bytes = []

  // 8. Let chunkPromise be the result of reading a chunk from
  //    stream with reader.
  let chunkPromise = reader.read()

  // 9. Let isFirstChunk be true.
  let isFirstChunk = true

  // 10. In parallel, while true:
  // Note: "In parallel" just means non-blocking
  // Note 2: readOperation itself cannot be async as double
  // reading the body would then reject the promise, instead
  // of throwing an error.
  ;(async () => {
    while (!fr[kAborted]) {
      // 1. Wait for chunkPromise to be fulfilled or rejected.
      try {
        const { done, value } = await chunkPromise

        // 2. If chunkPromise is fulfilled, and isFirstChunk is
        //    true, queue a task to fire a progress event called
        //    loadstart at fr.
        if (isFirstChunk && !fr[kAborted]) {
          queueMicrotask(() => {
            fireAProgressEvent('loadstart', fr)
          })
        }

        // 3. Set isFirstChunk to false.
        isFirstChunk = false

        // 4. If chunkPromise is fulfilled with an object whose
        //    done property is false and whose value property is
        //    a Uint8Array object, run these steps:
        if (!done && types.isUint8Array(value)) {
          // 1. Let bs be the byte sequence represented by the
          //    Uint8Array object.

          // 2. Append bs to bytes.
          bytes.push(value)

          // 3. If roughly 50ms have passed since these steps
          //    were last invoked, queue a task to fire a
          //    progress event called progress at fr.
          if (
            (
              fr[kLastProgressEventFired] === undefined ||
              Date.now() - fr[kLastProgressEventFired] >= 50
            ) &&
            !fr[kAborted]
          ) {
            fr[kLastProgressEventFired] = Date.now()
            queueMicrotask(() => {
              fireAProgressEvent('progress', fr)
            })
          }

          // 4. Set chunkPromise to the result of reading a
          //    chunk from stream with reader.
          chunkPromise = reader.read()
        } else if (done) {
          // 5. Otherwise, if chunkPromise is fulfilled with an
          //    object whose done property is true, queue a task
          //    to run the following steps and abort this algorithm:
          queueMicrotask(() => {
            // 1. Set frs state to "done".
            fr[kState] = 'done'

            // 2. Let result be the result of package data given
            //    bytes, type, blobs type, and encodingName.
            try {
              const result = packageData(bytes, type, blob.type, encodingName)

              // 4. Else:

              if (fr[kAborted]) {
                return
              }

              // 1. Set frs result to result.
              fr[kResult] = result

              // 2. Fire a progress event called load at the fr.
              fireAProgressEvent('load', fr)
            } catch (error) {
              // 3. If package data threw an exception error:

              // 1. Set frs error to error.
              fr[kError] = error

              // 2. Fire a progress event called error at fr.
              fireAProgressEvent('error', fr)
            }

            // 5. If frs state is not "loading", fire a progress
            //    event called loadend at the fr.
            if (fr[kState] !== 'loading') {
              fireAProgressEvent('loadend', fr)
            }
          })

          break
        }
      } catch (error) {
        if (fr[kAborted]) {
          return
        }

        // 6. Otherwise, if chunkPromise is rejected with an
        //    error error, queue a task to run the following
        //    steps and abort this algorithm:
        queueMicrotask(() => {
          // 1. Set frs state to "done".
          fr[kState] = 'done'

          // 2. Set frs error to error.
          fr[kError] = error

          // 3. Fire a progress event called error at fr.
          fireAProgressEvent('error', fr)

          // 4. If frs state is not "loading", fire a progress
          //    event called loadend at fr.
          if (fr[kState] !== 'loading') {
            fireAProgressEvent('loadend', fr)
          }
        })

        break
      }
    }
  })()
}

/**
 * @see https://w3c.github.io/FileAPI/#fire-a-progress-event
 * @see https://dom.spec.whatwg.org/#concept-event-fire
 * @param {string} e The name of the event
 * @param {import('./filereader').FileReader} reader
 */
function fireAProgressEvent (e, reader) {
  // The progress event e does not bubble. e.bubbles must be false
  // The progress event e is NOT cancelable. e.cancelable must be false
  const event = new ProgressEvent(e, {
    bubbles: false,
    cancelable: false
  })

  reader.dispatchEvent(event)
}

/**
 * @see https://w3c.github.io/FileAPI/#blob-package-data
 * @param {Uint8Array[]} bytes
 * @param {string} type
 * @param {string?} mimeType
 * @param {string?} encodingName
 */
function packageData (bytes, type, mimeType, encodingName) {
  // 1. A Blob has an associated package data algorithm, given
  //    bytes, a type, a optional mimeType, and a optional
  //    encodingName, which switches on type and runs the
  //    associated steps:

  switch (type) {
    case 'DataURL': {
      // 1. Return bytes as a DataURL [RFC2397] subject to
      //    the considerations below:
      //  * Use mimeType as part of the Data URL if it is
      //    available in keeping with the Data URL
      //    specification [RFC2397].
      //  * If mimeType is not available return a Data URL
      //    without a media-type. [RFC2397].

      // https://datatracker.ietf.org/doc/html/rfc2397#section-3
      // dataurl    := "data:" [ mediatype ] [ ";base64" ] "," data
      // mediatype  := [ type "/" subtype ] *( ";" parameter )
      // data       := *urlchar
      // parameter  := attribute "=" value
      let dataURL = 'data:'

      const parsed = parseMIMEType(mimeType || 'application/octet-stream')

      if (parsed !== 'failure') {
        dataURL += serializeAMimeType(parsed)
      }

      dataURL += ';base64,'

      const decoder = new StringDecoder('latin1')

      for (const chunk of bytes) {
        dataURL += btoa(decoder.write(chunk))
      }

      dataURL += btoa(decoder.end())

      return dataURL
    }
    case 'Text': {
      // 1. Let encoding be failure
      let encoding = 'failure'

      // 2. If the encodingName is present, set encoding to the
      //    result of getting an encoding from encodingName.
      if (encodingName) {
        encoding = getEncoding(encodingName)
      }

      // 3. If encoding is failure, and mimeType is present:
      if (encoding === 'failure' && mimeType) {
        // 1. Let type be the result of parse a MIME type
        //    given mimeType.
        const type = parseMIMEType(mimeType)

        // 2. If type is not failure, set encoding to the result
        //    of getting an encoding from types parameters["charset"].
        if (type !== 'failure') {
          encoding = getEncoding(type.parameters.get('charset'))
        }
      }

      // 4. If encoding is failure, then set encoding to UTF-8.
      if (encoding === 'failure') {
        encoding = 'UTF-8'
      }

      // 5. Decode bytes using fallback encoding encoding, and
      //    return the result.
      return decode(bytes, encoding)
    }
    case 'ArrayBuffer': {
      // Return a new ArrayBuffer whose contents are bytes.
      const sequence = combineByteSequences(bytes)

      return sequence.buffer
    }
    case 'BinaryString': {
      // Return bytes as a binary string, in which every byte
      //  is represented by a code unit of equal value [0..255].
      let binaryString = ''

      const decoder = new StringDecoder('latin1')

      for (const chunk of bytes) {
        binaryString += decoder.write(chunk)
      }

      binaryString += decoder.end()

      return binaryString
    }
  }
}

/**
 * @see https://encoding.spec.whatwg.org/#decode
 * @param {Uint8Array[]} ioQueue
 * @param {string} encoding
 */
function decode (ioQueue, encoding) {
  const bytes = combineByteSequences(ioQueue)

  // 1. Let BOMEncoding be the result of BOM sniffing ioQueue.
  const BOMEncoding = BOMSniffing(bytes)

  let slice = 0

  // 2. If BOMEncoding is non-null:
  if (BOMEncoding !== null) {
    // 1. Set encoding to BOMEncoding.
    encoding = BOMEncoding

    // 2. Read three bytes from ioQueue, if BOMEncoding is
    //    UTF-8; otherwise read two bytes.
    //    (Do nothing with those bytes.)
    slice = BOMEncoding === 'UTF-8' ? 3 : 2
  }

  // 3. Process a queue with an instance of encodings
  //    decoder, ioQueue, output, and "replacement".

  // 4. Return output.

  const sliced = bytes.slice(slice)
  return new TextDecoder(encoding).decode(sliced)
}

/**
 * @see https://encoding.spec.whatwg.org/#bom-sniff
 * @param {Uint8Array} ioQueue
 */
function BOMSniffing (ioQueue) {
  // 1. Let BOM be the result of peeking 3 bytes from ioQueue,
  //    converted to a byte sequence.
  const [a, b, c] = ioQueue

  // 2. For each of the rows in the table below, starting with
  //    the first one and going down, if BOM starts with the
  //    bytes given in the first column, then return the
  //    encoding given in the cell in the second column of that
  //    row. Otherwise, return null.
  if (a === 0xEF && b === 0xBB && c === 0xBF) {
    return 'UTF-8'
  } else if (a === 0xFE && b === 0xFF) {
    return 'UTF-16BE'
  } else if (a === 0xFF && b === 0xFE) {
    return 'UTF-16LE'
  }

  return null
}

/**
 * @param {Uint8Array[]} sequences
 */
function combineByteSequences (sequences) {
  const size = sequences.reduce((a, b) => {
    return a + b.byteLength
  }, 0)

  let offset = 0

  return sequences.reduce((a, b) => {
    a.set(b, offset)
    offset += b.byteLength
    return a
  }, new Uint8Array(size))
}

module.exports = {
  staticPropertyDescriptors,
  readOperation,
  fireAProgressEvent
}


/***/ }),

/***/ 2581:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


// We include a version number for the Dispatcher API. In case of breaking changes,
// this version number must be increased to avoid conflicts.
const globalDispatcher = Symbol.for('undici.globalDispatcher.1')
const { InvalidArgumentError } = __nccwpck_require__(8707)
const Agent = __nccwpck_require__(9965)

if (getGlobalDispatcher() === undefined) {
  setGlobalDispatcher(new Agent())
}

function setGlobalDispatcher (agent) {
  if (!agent || typeof agent.dispatch !== 'function') {
    throw new InvalidArgumentError('Argument agent must implement Agent')
  }
  Object.defineProperty(globalThis, globalDispatcher, {
    value: agent,
    writable: true,
    enumerable: false,
    configurable: false
  })
}

function getGlobalDispatcher () {
  return globalThis[globalDispatcher]
}

module.exports = {
  setGlobalDispatcher,
  getGlobalDispatcher
}


/***/ }),

/***/ 8840:
/***/ ((module) => {

"use strict";


module.exports = class DecoratorHandler {
  constructor (handler) {
    this.handler = handler
  }

  onConnect (...args) {
    return this.handler.onConnect(...args)
  }

  onError (...args) {
    return this.handler.onError(...args)
  }

  onUpgrade (...args) {
    return this.handler.onUpgrade(...args)
  }

  onHeaders (...args) {
    return this.handler.onHeaders(...args)
  }

  onData (...args) {
    return this.handler.onData(...args)
  }

  onComplete (...args) {
    return this.handler.onComplete(...args)
  }

  onBodySent (...args) {
    return this.handler.onBodySent(...args)
  }
}


/***/ }),

/***/ 8299:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const util = __nccwpck_require__(3440)
const { kBodyUsed } = __nccwpck_require__(6443)
const assert = __nccwpck_require__(2613)
const { InvalidArgumentError } = __nccwpck_require__(8707)
const EE = __nccwpck_require__(4434)

const redirectableStatusCodes = [300, 301, 302, 303, 307, 308]

const kBody = Symbol('body')

class BodyAsyncIterable {
  constructor (body) {
    this[kBody] = body
    this[kBodyUsed] = false
  }

  async * [Symbol.asyncIterator] () {
    assert(!this[kBodyUsed], 'disturbed')
    this[kBodyUsed] = true
    yield * this[kBody]
  }
}

class RedirectHandler {
  constructor (dispatch, maxRedirections, opts, handler) {
    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {
      throw new InvalidArgumentError('maxRedirections must be a positive number')
    }

    util.validateHandler(handler, opts.method, opts.upgrade)

    this.dispatch = dispatch
    this.location = null
    this.abort = null
    this.opts = { ...opts, maxRedirections: 0 } // opts must be a copy
    this.maxRedirections = maxRedirections
    this.handler = handler
    this.history = []

    if (util.isStream(this.opts.body)) {
      // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp
      // so that it can be dispatched again?
      // TODO (fix): Do we need 100-expect support to provide a way to do this properly?
      if (util.bodyLength(this.opts.body) === 0) {
        this.opts.body
          .on('data', function () {
            assert(false)
          })
      }

      if (typeof this.opts.body.readableDidRead !== 'boolean') {
        this.opts.body[kBodyUsed] = false
        EE.prototype.on.call(this.opts.body, 'data', function () {
          this[kBodyUsed] = true
        })
      }
    } else if (this.opts.body && typeof this.opts.body.pipeTo === 'function') {
      // TODO (fix): We can't access ReadableStream internal state
      // to determine whether or not it has been disturbed. This is just
      // a workaround.
      this.opts.body = new BodyAsyncIterable(this.opts.body)
    } else if (
      this.opts.body &&
      typeof this.opts.body !== 'string' &&
      !ArrayBuffer.isView(this.opts.body) &&
      util.isIterable(this.opts.body)
    ) {
      // TODO: Should we allow re-using iterable if !this.opts.idempotent
      // or through some other flag?
      this.opts.body = new BodyAsyncIterable(this.opts.body)
    }
  }

  onConnect (abort) {
    this.abort = abort
    this.handler.onConnect(abort, { history: this.history })
  }

  onUpgrade (statusCode, headers, socket) {
    this.handler.onUpgrade(statusCode, headers, socket)
  }

  onError (error) {
    this.handler.onError(error)
  }

  onHeaders (statusCode, headers, resume, statusText) {
    this.location = this.history.length >= this.maxRedirections || util.isDisturbed(this.opts.body)
      ? null
      : parseLocation(statusCode, headers)

    if (this.opts.origin) {
      this.history.push(new URL(this.opts.path, this.opts.origin))
    }

    if (!this.location) {
      return this.handler.onHeaders(statusCode, headers, resume, statusText)
    }

    const { origin, pathname, search } = util.parseURL(new URL(this.location, this.opts.origin && new URL(this.opts.path, this.opts.origin)))
    const path = search ? `${pathname}${search}` : pathname

    // Remove headers referring to the original URL.
    // By default it is Host only, unless it's a 303 (see below), which removes also all Content-* headers.
    // https://tools.ietf.org/html/rfc7231#section-6.4
    this.opts.headers = cleanRequestHeaders(this.opts.headers, statusCode === 303, this.opts.origin !== origin)
    this.opts.path = path
    this.opts.origin = origin
    this.opts.maxRedirections = 0
    this.opts.query = null

    // https://tools.ietf.org/html/rfc7231#section-6.4.4
    // In case of HTTP 303, always replace method to be either HEAD or GET
    if (statusCode === 303 && this.opts.method !== 'HEAD') {
      this.opts.method = 'GET'
      this.opts.body = null
    }
  }

  onData (chunk) {
    if (this.location) {
      /*
        https://tools.ietf.org/html/rfc7231#section-6.4

        TLDR: undici always ignores 3xx response bodies.

        Redirection is used to serve the requested resource from another URL, so it is assumes that
        no body is generated (and thus can be ignored). Even though generating a body is not prohibited.

        For status 301, 302, 303, 307 and 308 (the latter from RFC 7238), the specs mention that the body usually
        (which means it's optional and not mandated) contain just an hyperlink to the value of
        the Location response header, so the body can be ignored safely.

        For status 300, which is "Multiple Choices", the spec mentions both generating a Location
        response header AND a response body with the other possible location to follow.
        Since the spec explicitily chooses not to specify a format for such body and leave it to
        servers and browsers implementors, we ignore the body as there is no specified way to eventually parse it.
      */
    } else {
      return this.handler.onData(chunk)
    }
  }

  onComplete (trailers) {
    if (this.location) {
      /*
        https://tools.ietf.org/html/rfc7231#section-6.4

        TLDR: undici always ignores 3xx response trailers as they are not expected in case of redirections
        and neither are useful if present.

        See comment on onData method above for more detailed informations.
      */

      this.location = null
      this.abort = null

      this.dispatch(this.opts, this)
    } else {
      this.handler.onComplete(trailers)
    }
  }

  onBodySent (chunk) {
    if (this.handler.onBodySent) {
      this.handler.onBodySent(chunk)
    }
  }
}

function parseLocation (statusCode, headers) {
  if (redirectableStatusCodes.indexOf(statusCode) === -1) {
    return null
  }

  for (let i = 0; i < headers.length; i += 2) {
    if (headers[i].toString().toLowerCase() === 'location') {
      return headers[i + 1]
    }
  }
}

// https://tools.ietf.org/html/rfc7231#section-6.4.4
function shouldRemoveHeader (header, removeContent, unknownOrigin) {
  if (header.length === 4) {
    return util.headerNameToString(header) === 'host'
  }
  if (removeContent && util.headerNameToString(header).startsWith('content-')) {
    return true
  }
  if (unknownOrigin && (header.length === 13 || header.length === 6 || header.length === 19)) {
    const name = util.headerNameToString(header)
    return name === 'authorization' || name === 'cookie' || name === 'proxy-authorization'
  }
  return false
}

// https://tools.ietf.org/html/rfc7231#section-6.4
function cleanRequestHeaders (headers, removeContent, unknownOrigin) {
  const ret = []
  if (Array.isArray(headers)) {
    for (let i = 0; i < headers.length; i += 2) {
      if (!shouldRemoveHeader(headers[i], removeContent, unknownOrigin)) {
        ret.push(headers[i], headers[i + 1])
      }
    }
  } else if (headers && typeof headers === 'object') {
    for (const key of Object.keys(headers)) {
      if (!shouldRemoveHeader(key, removeContent, unknownOrigin)) {
        ret.push(key, headers[key])
      }
    }
  } else {
    assert(headers == null, 'headers must be an object or an array')
  }
  return ret
}

module.exports = RedirectHandler


/***/ }),

/***/ 3573:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

const assert = __nccwpck_require__(2613)

const { kRetryHandlerDefaultRetry } = __nccwpck_require__(6443)
const { RequestRetryError } = __nccwpck_require__(8707)
const { isDisturbed, parseHeaders, parseRangeHeader } = __nccwpck_require__(3440)

function calculateRetryAfterHeader (retryAfter) {
  const current = Date.now()
  const diff = new Date(retryAfter).getTime() - current

  return diff
}

class RetryHandler {
  constructor (opts, handlers) {
    const { retryOptions, ...dispatchOpts } = opts
    const {
      // Retry scoped
      retry: retryFn,
      maxRetries,
      maxTimeout,
      minTimeout,
      timeoutFactor,
      // Response scoped
      methods,
      errorCodes,
      retryAfter,
      statusCodes
    } = retryOptions ?? {}

    this.dispatch = handlers.dispatch
    this.handler = handlers.handler
    this.opts = dispatchOpts
    this.abort = null
    this.aborted = false
    this.retryOpts = {
      retry: retryFn ?? RetryHandler[kRetryHandlerDefaultRetry],
      retryAfter: retryAfter ?? true,
      maxTimeout: maxTimeout ?? 30 * 1000, // 30s,
      timeout: minTimeout ?? 500, // .5s
      timeoutFactor: timeoutFactor ?? 2,
      maxRetries: maxRetries ?? 5,
      // What errors we should retry
      methods: methods ?? ['GET', 'HEAD', 'OPTIONS', 'PUT', 'DELETE', 'TRACE'],
      // Indicates which errors to retry
      statusCodes: statusCodes ?? [500, 502, 503, 504, 429],
      // List of errors to retry
      errorCodes: errorCodes ?? [
        'ECONNRESET',
        'ECONNREFUSED',
        'ENOTFOUND',
        'ENETDOWN',
        'ENETUNREACH',
        'EHOSTDOWN',
        'EHOSTUNREACH',
        'EPIPE'
      ]
    }

    this.retryCount = 0
    this.start = 0
    this.end = null
    this.etag = null
    this.resume = null

    // Handle possible onConnect duplication
    this.handler.onConnect(reason => {
      this.aborted = true
      if (this.abort) {
        this.abort(reason)
      } else {
        this.reason = reason
      }
    })
  }

  onRequestSent () {
    if (this.handler.onRequestSent) {
      this.handler.onRequestSent()
    }
  }

  onUpgrade (statusCode, headers, socket) {
    if (this.handler.onUpgrade) {
      this.handler.onUpgrade(statusCode, headers, socket)
    }
  }

  onConnect (abort) {
    if (this.aborted) {
      abort(this.reason)
    } else {
      this.abort = abort
    }
  }

  onBodySent (chunk) {
    if (this.handler.onBodySent) return this.handler.onBodySent(chunk)
  }

  static [kRetryHandlerDefaultRetry] (err, { state, opts }, cb) {
    const { statusCode, code, headers } = err
    const { method, retryOptions } = opts
    const {
      maxRetries,
      timeout,
      maxTimeout,
      timeoutFactor,
      statusCodes,
      errorCodes,
      methods
    } = retryOptions
    let { counter, currentTimeout } = state

    currentTimeout =
      currentTimeout != null && currentTimeout > 0 ? currentTimeout : timeout

    // Any code that is not a Undici's originated and allowed to retry
    if (
      code &&
      code !== 'UND_ERR_REQ_RETRY' &&
      code !== 'UND_ERR_SOCKET' &&
      !errorCodes.includes(code)
    ) {
      cb(err)
      return
    }

    // If a set of method are provided and the current method is not in the list
    if (Array.isArray(methods) && !methods.includes(method)) {
      cb(err)
      return
    }

    // If a set of status code are provided and the current status code is not in the list
    if (
      statusCode != null &&
      Array.isArray(statusCodes) &&
      !statusCodes.includes(statusCode)
    ) {
      cb(err)
      return
    }

    // If we reached the max number of retries
    if (counter > maxRetries) {
      cb(err)
      return
    }

    let retryAfterHeader = headers != null && headers['retry-after']
    if (retryAfterHeader) {
      retryAfterHeader = Number(retryAfterHeader)
      retryAfterHeader = isNaN(retryAfterHeader)
        ? calculateRetryAfterHeader(retryAfterHeader)
        : retryAfterHeader * 1e3 // Retry-After is in seconds
    }

    const retryTimeout =
      retryAfterHeader > 0
        ? Math.min(retryAfterHeader, maxTimeout)
        : Math.min(currentTimeout * timeoutFactor ** counter, maxTimeout)

    state.currentTimeout = retryTimeout

    setTimeout(() => cb(null), retryTimeout)
  }

  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
    const headers = parseHeaders(rawHeaders)

    this.retryCount += 1

    if (statusCode >= 300) {
      this.abort(
        new RequestRetryError('Request failed', statusCode, {
          headers,
          count: this.retryCount
        })
      )
      return false
    }

    // Checkpoint for resume from where we left it
    if (this.resume != null) {
      this.resume = null

      if (statusCode !== 206) {
        return true
      }

      const contentRange = parseRangeHeader(headers['content-range'])
      // If no content range
      if (!contentRange) {
        this.abort(
          new RequestRetryError('Content-Range mismatch', statusCode, {
            headers,
            count: this.retryCount
          })
        )
        return false
      }

      // Let's start with a weak etag check
      if (this.etag != null && this.etag !== headers.etag) {
        this.abort(
          new RequestRetryError('ETag mismatch', statusCode, {
            headers,
            count: this.retryCount
          })
        )
        return false
      }

      const { start, size, end = size } = contentRange

      assert(this.start === start, 'content-range mismatch')
      assert(this.end == null || this.end === end, 'content-range mismatch')

      this.resume = resume
      return true
    }

    if (this.end == null) {
      if (statusCode === 206) {
        // First time we receive 206
        const range = parseRangeHeader(headers['content-range'])

        if (range == null) {
          return this.handler.onHeaders(
            statusCode,
            rawHeaders,
            resume,
            statusMessage
          )
        }

        const { start, size, end = size } = range

        assert(
          start != null && Number.isFinite(start) && this.start !== start,
          'content-range mismatch'
        )
        assert(Number.isFinite(start))
        assert(
          end != null && Number.isFinite(end) && this.end !== end,
          'invalid content-length'
        )

        this.start = start
        this.end = end
      }

      // We make our best to checkpoint the body for further range headers
      if (this.end == null) {
        const contentLength = headers['content-length']
        this.end = contentLength != null ? Number(contentLength) : null
      }

      assert(Number.isFinite(this.start))
      assert(
        this.end == null || Number.isFinite(this.end),
        'invalid content-length'
      )

      this.resume = resume
      this.etag = headers.etag != null ? headers.etag : null

      return this.handler.onHeaders(
        statusCode,
        rawHeaders,
        resume,
        statusMessage
      )
    }

    const err = new RequestRetryError('Request failed', statusCode, {
      headers,
      count: this.retryCount
    })

    this.abort(err)

    return false
  }

  onData (chunk) {
    this.start += chunk.length

    return this.handler.onData(chunk)
  }

  onComplete (rawTrailers) {
    this.retryCount = 0
    return this.handler.onComplete(rawTrailers)
  }

  onError (err) {
    if (this.aborted || isDisturbed(this.opts.body)) {
      return this.handler.onError(err)
    }

    this.retryOpts.retry(
      err,
      {
        state: { counter: this.retryCount++, currentTimeout: this.retryAfter },
        opts: { retryOptions: this.retryOpts, ...this.opts }
      },
      onRetry.bind(this)
    )

    function onRetry (err) {
      if (err != null || this.aborted || isDisturbed(this.opts.body)) {
        return this.handler.onError(err)
      }

      if (this.start !== 0) {
        this.opts = {
          ...this.opts,
          headers: {
            ...this.opts.headers,
            range: `bytes=${this.start}-${this.end ?? ''}`
          }
        }
      }

      try {
        this.dispatch(this.opts, this)
      } catch (err) {
        this.handler.onError(err)
      }
    }
  }
}

module.exports = RetryHandler


/***/ }),

/***/ 4415:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const RedirectHandler = __nccwpck_require__(8299)

function createRedirectInterceptor ({ maxRedirections: defaultMaxRedirections }) {
  return (dispatch) => {
    return function Intercept (opts, handler) {
      const { maxRedirections = defaultMaxRedirections } = opts

      if (!maxRedirections) {
        return dispatch(opts, handler)
      }

      const redirectHandler = new RedirectHandler(dispatch, maxRedirections, opts, handler)
      opts = { ...opts, maxRedirections: 0 } // Stop sub dispatcher from also redirecting.
      return dispatch(opts, redirectHandler)
    }
  }
}

module.exports = createRedirectInterceptor


/***/ }),

/***/ 2824:
/***/ ((__unused_webpack_module, exports, __nccwpck_require__) => {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.SPECIAL_HEADERS = exports.HEADER_STATE = exports.MINOR = exports.MAJOR = exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS = exports.TOKEN = exports.STRICT_TOKEN = exports.HEX = exports.URL_CHAR = exports.STRICT_URL_CHAR = exports.USERINFO_CHARS = exports.MARK = exports.ALPHANUM = exports.NUM = exports.HEX_MAP = exports.NUM_MAP = exports.ALPHA = exports.FINISH = exports.H_METHOD_MAP = exports.METHOD_MAP = exports.METHODS_RTSP = exports.METHODS_ICE = exports.METHODS_HTTP = exports.METHODS = exports.LENIENT_FLAGS = exports.FLAGS = exports.TYPE = exports.ERROR = void 0;
const utils_1 = __nccwpck_require__(172);
// C headers
var ERROR;
(function (ERROR) {
    ERROR[ERROR["OK"] = 0] = "OK";
    ERROR[ERROR["INTERNAL"] = 1] = "INTERNAL";
    ERROR[ERROR["STRICT"] = 2] = "STRICT";
    ERROR[ERROR["LF_EXPECTED"] = 3] = "LF_EXPECTED";
    ERROR[ERROR["UNEXPECTED_CONTENT_LENGTH"] = 4] = "UNEXPECTED_CONTENT_LENGTH";
    ERROR[ERROR["CLOSED_CONNECTION"] = 5] = "CLOSED_CONNECTION";
    ERROR[ERROR["INVALID_METHOD"] = 6] = "INVALID_METHOD";
    ERROR[ERROR["INVALID_URL"] = 7] = "INVALID_URL";
    ERROR[ERROR["INVALID_CONSTANT"] = 8] = "INVALID_CONSTANT";
    ERROR[ERROR["INVALID_VERSION"] = 9] = "INVALID_VERSION";
    ERROR[ERROR["INVALID_HEADER_TOKEN"] = 10] = "INVALID_HEADER_TOKEN";
    ERROR[ERROR["INVALID_CONTENT_LENGTH"] = 11] = "INVALID_CONTENT_LENGTH";
    ERROR[ERROR["INVALID_CHUNK_SIZE"] = 12] = "INVALID_CHUNK_SIZE";
    ERROR[ERROR["INVALID_STATUS"] = 13] = "INVALID_STATUS";
    ERROR[ERROR["INVALID_EOF_STATE"] = 14] = "INVALID_EOF_STATE";
    ERROR[ERROR["INVALID_TRANSFER_ENCODING"] = 15] = "INVALID_TRANSFER_ENCODING";
    ERROR[ERROR["CB_MESSAGE_BEGIN"] = 16] = "CB_MESSAGE_BEGIN";
    ERROR[ERROR["CB_HEADERS_COMPLETE"] = 17] = "CB_HEADERS_COMPLETE";
    ERROR[ERROR["CB_MESSAGE_COMPLETE"] = 18] = "CB_MESSAGE_COMPLETE";
    ERROR[ERROR["CB_CHUNK_HEADER"] = 19] = "CB_CHUNK_HEADER";
    ERROR[ERROR["CB_CHUNK_COMPLETE"] = 20] = "CB_CHUNK_COMPLETE";
    ERROR[ERROR["PAUSED"] = 21] = "PAUSED";
    ERROR[ERROR["PAUSED_UPGRADE"] = 22] = "PAUSED_UPGRADE";
    ERROR[ERROR["PAUSED_H2_UPGRADE"] = 23] = "PAUSED_H2_UPGRADE";
    ERROR[ERROR["USER"] = 24] = "USER";
})(ERROR = exports.ERROR || (exports.ERROR = {}));
var TYPE;
(function (TYPE) {
    TYPE[TYPE["BOTH"] = 0] = "BOTH";
    TYPE[TYPE["REQUEST"] = 1] = "REQUEST";
    TYPE[TYPE["RESPONSE"] = 2] = "RESPONSE";
})(TYPE = exports.TYPE || (exports.TYPE = {}));
var FLAGS;
(function (FLAGS) {
    FLAGS[FLAGS["CONNECTION_KEEP_ALIVE"] = 1] = "CONNECTION_KEEP_ALIVE";
    FLAGS[FLAGS["CONNECTION_CLOSE"] = 2] = "CONNECTION_CLOSE";
    FLAGS[FLAGS["CONNECTION_UPGRADE"] = 4] = "CONNECTION_UPGRADE";
    FLAGS[FLAGS["CHUNKED"] = 8] = "CHUNKED";
    FLAGS[FLAGS["UPGRADE"] = 16] = "UPGRADE";
    FLAGS[FLAGS["CONTENT_LENGTH"] = 32] = "CONTENT_LENGTH";
    FLAGS[FLAGS["SKIPBODY"] = 64] = "SKIPBODY";
    FLAGS[FLAGS["TRAILING"] = 128] = "TRAILING";
    // 1 << 8 is unused
    FLAGS[FLAGS["TRANSFER_ENCODING"] = 512] = "TRANSFER_ENCODING";
})(FLAGS = exports.FLAGS || (exports.FLAGS = {}));
var LENIENT_FLAGS;
(function (LENIENT_FLAGS) {
    LENIENT_FLAGS[LENIENT_FLAGS["HEADERS"] = 1] = "HEADERS";
    LENIENT_FLAGS[LENIENT_FLAGS["CHUNKED_LENGTH"] = 2] = "CHUNKED_LENGTH";
    LENIENT_FLAGS[LENIENT_FLAGS["KEEP_ALIVE"] = 4] = "KEEP_ALIVE";
})(LENIENT_FLAGS = exports.LENIENT_FLAGS || (exports.LENIENT_FLAGS = {}));
var METHODS;
(function (METHODS) {
    METHODS[METHODS["DELETE"] = 0] = "DELETE";
    METHODS[METHODS["GET"] = 1] = "GET";
    METHODS[METHODS["HEAD"] = 2] = "HEAD";
    METHODS[METHODS["POST"] = 3] = "POST";
    METHODS[METHODS["PUT"] = 4] = "PUT";
    /* pathological */
    METHODS[METHODS["CONNECT"] = 5] = "CONNECT";
    METHODS[METHODS["OPTIONS"] = 6] = "OPTIONS";
    METHODS[METHODS["TRACE"] = 7] = "TRACE";
    /* WebDAV */
    METHODS[METHODS["COPY"] = 8] = "COPY";
    METHODS[METHODS["LOCK"] = 9] = "LOCK";
    METHODS[METHODS["MKCOL"] = 10] = "MKCOL";
    METHODS[METHODS["MOVE"] = 11] = "MOVE";
    METHODS[METHODS["PROPFIND"] = 12] = "PROPFIND";
    METHODS[METHODS["PROPPATCH"] = 13] = "PROPPATCH";
    METHODS[METHODS["SEARCH"] = 14] = "SEARCH";
    METHODS[METHODS["UNLOCK"] = 15] = "UNLOCK";
    METHODS[METHODS["BIND"] = 16] = "BIND";
    METHODS[METHODS["REBIND"] = 17] = "REBIND";
    METHODS[METHODS["UNBIND"] = 18] = "UNBIND";
    METHODS[METHODS["ACL"] = 19] = "ACL";
    /* subversion */
    METHODS[METHODS["REPORT"] = 20] = "REPORT";
    METHODS[METHODS["MKACTIVITY"] = 21] = "MKACTIVITY";
    METHODS[METHODS["CHECKOUT"] = 22] = "CHECKOUT";
    METHODS[METHODS["MERGE"] = 23] = "MERGE";
    /* upnp */
    METHODS[METHODS["M-SEARCH"] = 24] = "M-SEARCH";
    METHODS[METHODS["NOTIFY"] = 25] = "NOTIFY";
    METHODS[METHODS["SUBSCRIBE"] = 26] = "SUBSCRIBE";
    METHODS[METHODS["UNSUBSCRIBE"] = 27] = "UNSUBSCRIBE";
    /* RFC-5789 */
    METHODS[METHODS["PATCH"] = 28] = "PATCH";
    METHODS[METHODS["PURGE"] = 29] = "PURGE";
    /* CalDAV */
    METHODS[METHODS["MKCALENDAR"] = 30] = "MKCALENDAR";
    /* RFC-2068, section 19.6.1.2 */
    METHODS[METHODS["LINK"] = 31] = "LINK";
    METHODS[METHODS["UNLINK"] = 32] = "UNLINK";
    /* icecast */
    METHODS[METHODS["SOURCE"] = 33] = "SOURCE";
    /* RFC-7540, section 11.6 */
    METHODS[METHODS["PRI"] = 34] = "PRI";
    /* RFC-2326 RTSP */
    METHODS[METHODS["DESCRIBE"] = 35] = "DESCRIBE";
    METHODS[METHODS["ANNOUNCE"] = 36] = "ANNOUNCE";
    METHODS[METHODS["SETUP"] = 37] = "SETUP";
    METHODS[METHODS["PLAY"] = 38] = "PLAY";
    METHODS[METHODS["PAUSE"] = 39] = "PAUSE";
    METHODS[METHODS["TEARDOWN"] = 40] = "TEARDOWN";
    METHODS[METHODS["GET_PARAMETER"] = 41] = "GET_PARAMETER";
    METHODS[METHODS["SET_PARAMETER"] = 42] = "SET_PARAMETER";
    METHODS[METHODS["REDIRECT"] = 43] = "REDIRECT";
    METHODS[METHODS["RECORD"] = 44] = "RECORD";
    /* RAOP */
    METHODS[METHODS["FLUSH"] = 45] = "FLUSH";
})(METHODS = exports.METHODS || (exports.METHODS = {}));
exports.METHODS_HTTP = [
    METHODS.DELETE,
    METHODS.GET,
    METHODS.HEAD,
    METHODS.POST,
    METHODS.PUT,
    METHODS.CONNECT,
    METHODS.OPTIONS,
    METHODS.TRACE,
    METHODS.COPY,
    METHODS.LOCK,
    METHODS.MKCOL,
    METHODS.MOVE,
    METHODS.PROPFIND,
    METHODS.PROPPATCH,
    METHODS.SEARCH,
    METHODS.UNLOCK,
    METHODS.BIND,
    METHODS.REBIND,
    METHODS.UNBIND,
    METHODS.ACL,
    METHODS.REPORT,
    METHODS.MKACTIVITY,
    METHODS.CHECKOUT,
    METHODS.MERGE,
    METHODS['M-SEARCH'],
    METHODS.NOTIFY,
    METHODS.SUBSCRIBE,
    METHODS.UNSUBSCRIBE,
    METHODS.PATCH,
    METHODS.PURGE,
    METHODS.MKCALENDAR,
    METHODS.LINK,
    METHODS.UNLINK,
    METHODS.PRI,
    // TODO(indutny): should we allow it with HTTP?
    METHODS.SOURCE,
];
exports.METHODS_ICE = [
    METHODS.SOURCE,
];
exports.METHODS_RTSP = [
    METHODS.OPTIONS,
    METHODS.DESCRIBE,
    METHODS.ANNOUNCE,
    METHODS.SETUP,
    METHODS.PLAY,
    METHODS.PAUSE,
    METHODS.TEARDOWN,
    METHODS.GET_PARAMETER,
    METHODS.SET_PARAMETER,
    METHODS.REDIRECT,
    METHODS.RECORD,
    METHODS.FLUSH,
    // For AirPlay
    METHODS.GET,
    METHODS.POST,
];
exports.METHOD_MAP = utils_1.enumToMap(METHODS);
exports.H_METHOD_MAP = {};
Object.keys(exports.METHOD_MAP).forEach((key) => {
    if (/^H/.test(key)) {
        exports.H_METHOD_MAP[key] = exports.METHOD_MAP[key];
    }
});
var FINISH;
(function (FINISH) {
    FINISH[FINISH["SAFE"] = 0] = "SAFE";
    FINISH[FINISH["SAFE_WITH_CB"] = 1] = "SAFE_WITH_CB";
    FINISH[FINISH["UNSAFE"] = 2] = "UNSAFE";
})(FINISH = exports.FINISH || (exports.FINISH = {}));
exports.ALPHA = [];
for (let i = 'A'.charCodeAt(0); i <= 'Z'.charCodeAt(0); i++) {
    // Upper case
    exports.ALPHA.push(String.fromCharCode(i));
    // Lower case
    exports.ALPHA.push(String.fromCharCode(i + 0x20));
}
exports.NUM_MAP = {
    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,
    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,
};
exports.HEX_MAP = {
    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,
    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,
    A: 0XA, B: 0XB, C: 0XC, D: 0XD, E: 0XE, F: 0XF,
    a: 0xa, b: 0xb, c: 0xc, d: 0xd, e: 0xe, f: 0xf,
};
exports.NUM = [
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
];
exports.ALPHANUM = exports.ALPHA.concat(exports.NUM);
exports.MARK = ['-', '_', '.', '!', '~', '*', '\'', '(', ')'];
exports.USERINFO_CHARS = exports.ALPHANUM
    .concat(exports.MARK)
    .concat(['%', ';', ':', '&', '=', '+', '$', ',']);
// TODO(indutny): use RFC
exports.STRICT_URL_CHAR = [
    '!', '"', '$', '%', '&', '\'',
    '(', ')', '*', '+', ',', '-', '.', '/',
    ':', ';', '<', '=', '>',
    '@', '[', '\\', ']', '^', '_',
    '`',
    '{', '|', '}', '~',
].concat(exports.ALPHANUM);
exports.URL_CHAR = exports.STRICT_URL_CHAR
    .concat(['\t', '\f']);
// All characters with 0x80 bit set to 1
for (let i = 0x80; i <= 0xff; i++) {
    exports.URL_CHAR.push(i);
}
exports.HEX = exports.NUM.concat(['a', 'b', 'c', 'd', 'e', 'f', 'A', 'B', 'C', 'D', 'E', 'F']);
/* Tokens as defined by rfc 2616. Also lowercases them.
 *        token       = 1*<any CHAR except CTLs or separators>
 *     separators     = "(" | ")" | "<" | ">" | "@"
 *                    | "," | ";" | ":" | "\" | <">
 *                    | "/" | "[" | "]" | "?" | "="
 *                    | "{" | "}" | SP | HT
 */
exports.STRICT_TOKEN = [
    '!', '#', '$', '%', '&', '\'',
    '*', '+', '-', '.',
    '^', '_', '`',
    '|', '~',
].concat(exports.ALPHANUM);
exports.TOKEN = exports.STRICT_TOKEN.concat([' ']);
/*
 * Verify that a char is a valid visible (printable) US-ASCII
 * character or %x80-FF
 */
exports.HEADER_CHARS = ['\t'];
for (let i = 32; i <= 255; i++) {
    if (i !== 127) {
        exports.HEADER_CHARS.push(i);
    }
}
// ',' = \x44
exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS.filter((c) => c !== 44);
exports.MAJOR = exports.NUM_MAP;
exports.MINOR = exports.MAJOR;
var HEADER_STATE;
(function (HEADER_STATE) {
    HEADER_STATE[HEADER_STATE["GENERAL"] = 0] = "GENERAL";
    HEADER_STATE[HEADER_STATE["CONNECTION"] = 1] = "CONNECTION";
    HEADER_STATE[HEADER_STATE["CONTENT_LENGTH"] = 2] = "CONTENT_LENGTH";
    HEADER_STATE[HEADER_STATE["TRANSFER_ENCODING"] = 3] = "TRANSFER_ENCODING";
    HEADER_STATE[HEADER_STATE["UPGRADE"] = 4] = "UPGRADE";
    HEADER_STATE[HEADER_STATE["CONNECTION_KEEP_ALIVE"] = 5] = "CONNECTION_KEEP_ALIVE";
    HEADER_STATE[HEADER_STATE["CONNECTION_CLOSE"] = 6] = "CONNECTION_CLOSE";
    HEADER_STATE[HEADER_STATE["CONNECTION_UPGRADE"] = 7] = "CONNECTION_UPGRADE";
    HEADER_STATE[HEADER_STATE["TRANSFER_ENCODING_CHUNKED"] = 8] = "TRANSFER_ENCODING_CHUNKED";
})(HEADER_STATE = exports.HEADER_STATE || (exports.HEADER_STATE = {}));
exports.SPECIAL_HEADERS = {
    'connection': HEADER_STATE.CONNECTION,
    'content-length': HEADER_STATE.CONTENT_LENGTH,
    'proxy-connection': HEADER_STATE.CONNECTION,
    'transfer-encoding': HEADER_STATE.TRANSFER_ENCODING,
    'upgrade': HEADER_STATE.UPGRADE,
};
//# sourceMappingURL=constants.js.map

/***/ }),

/***/ 3870:
/***/ ((module) => {

module.exports = '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'


/***/ }),

/***/ 3434:
/***/ ((module) => {

module.exports = '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'


/***/ }),

/***/ 172:
/***/ ((__unused_webpack_module, exports) => {

"use strict";

Object.defineProperty(exports, "__esModule", ({ value: true }));
exports.enumToMap = void 0;
function enumToMap(obj) {
    const res = {};
    Object.keys(obj).forEach((key) => {
        const value = obj[key];
        if (typeof value === 'number') {
            res[key] = value;
        }
    });
    return res;
}
exports.enumToMap = enumToMap;
//# sourceMappingURL=utils.js.map

/***/ }),

/***/ 7501:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { kClients } = __nccwpck_require__(6443)
const Agent = __nccwpck_require__(9965)
const {
  kAgent,
  kMockAgentSet,
  kMockAgentGet,
  kDispatches,
  kIsMockActive,
  kNetConnect,
  kGetNetConnect,
  kOptions,
  kFactory
} = __nccwpck_require__(1117)
const MockClient = __nccwpck_require__(7365)
const MockPool = __nccwpck_require__(4004)
const { matchValue, buildMockOptions } = __nccwpck_require__(3397)
const { InvalidArgumentError, UndiciError } = __nccwpck_require__(8707)
const Dispatcher = __nccwpck_require__(992)
const Pluralizer = __nccwpck_require__(1529)
const PendingInterceptorsFormatter = __nccwpck_require__(6142)

class FakeWeakRef {
  constructor (value) {
    this.value = value
  }

  deref () {
    return this.value
  }
}

class MockAgent extends Dispatcher {
  constructor (opts) {
    super(opts)

    this[kNetConnect] = true
    this[kIsMockActive] = true

    // Instantiate Agent and encapsulate
    if ((opts && opts.agent && typeof opts.agent.dispatch !== 'function')) {
      throw new InvalidArgumentError('Argument opts.agent must implement Agent')
    }
    const agent = opts && opts.agent ? opts.agent : new Agent(opts)
    this[kAgent] = agent

    this[kClients] = agent[kClients]
    this[kOptions] = buildMockOptions(opts)
  }

  get (origin) {
    let dispatcher = this[kMockAgentGet](origin)

    if (!dispatcher) {
      dispatcher = this[kFactory](origin)
      this[kMockAgentSet](origin, dispatcher)
    }
    return dispatcher
  }

  dispatch (opts, handler) {
    // Call MockAgent.get to perform additional setup before dispatching as normal
    this.get(opts.origin)
    return this[kAgent].dispatch(opts, handler)
  }

  async close () {
    await this[kAgent].close()
    this[kClients].clear()
  }

  deactivate () {
    this[kIsMockActive] = false
  }

  activate () {
    this[kIsMockActive] = true
  }

  enableNetConnect (matcher) {
    if (typeof matcher === 'string' || typeof matcher === 'function' || matcher instanceof RegExp) {
      if (Array.isArray(this[kNetConnect])) {
        this[kNetConnect].push(matcher)
      } else {
        this[kNetConnect] = [matcher]
      }
    } else if (typeof matcher === 'undefined') {
      this[kNetConnect] = true
    } else {
      throw new InvalidArgumentError('Unsupported matcher. Must be one of String|Function|RegExp.')
    }
  }

  disableNetConnect () {
    this[kNetConnect] = false
  }

  // This is required to bypass issues caused by using global symbols - see:
  // https://github.com/nodejs/undici/issues/1447
  get isMockActive () {
    return this[kIsMockActive]
  }

  [kMockAgentSet] (origin, dispatcher) {
    this[kClients].set(origin, new FakeWeakRef(dispatcher))
  }

  [kFactory] (origin) {
    const mockOptions = Object.assign({ agent: this }, this[kOptions])
    return this[kOptions] && this[kOptions].connections === 1
      ? new MockClient(origin, mockOptions)
      : new MockPool(origin, mockOptions)
  }

  [kMockAgentGet] (origin) {
    // First check if we can immediately find it
    const ref = this[kClients].get(origin)
    if (ref) {
      return ref.deref()
    }

    // If the origin is not a string create a dummy parent pool and return to user
    if (typeof origin !== 'string') {
      const dispatcher = this[kFactory]('http://localhost:9999')
      this[kMockAgentSet](origin, dispatcher)
      return dispatcher
    }

    // If we match, create a pool and assign the same dispatches
    for (const [keyMatcher, nonExplicitRef] of Array.from(this[kClients])) {
      const nonExplicitDispatcher = nonExplicitRef.deref()
      if (nonExplicitDispatcher && typeof keyMatcher !== 'string' && matchValue(keyMatcher, origin)) {
        const dispatcher = this[kFactory](origin)
        this[kMockAgentSet](origin, dispatcher)
        dispatcher[kDispatches] = nonExplicitDispatcher[kDispatches]
        return dispatcher
      }
    }
  }

  [kGetNetConnect] () {
    return this[kNetConnect]
  }

  pendingInterceptors () {
    const mockAgentClients = this[kClients]

    return Array.from(mockAgentClients.entries())
      .flatMap(([origin, scope]) => scope.deref()[kDispatches].map(dispatch => ({ ...dispatch, origin })))
      .filter(({ pending }) => pending)
  }

  assertNoPendingInterceptors ({ pendingInterceptorsFormatter = new PendingInterceptorsFormatter() } = {}) {
    const pending = this.pendingInterceptors()

    if (pending.length === 0) {
      return
    }

    const pluralizer = new Pluralizer('interceptor', 'interceptors').pluralize(pending.length)

    throw new UndiciError(`
${pluralizer.count} ${pluralizer.noun} ${pluralizer.is} pending:

${pendingInterceptorsFormatter.format(pending)}
`.trim())
  }
}

module.exports = MockAgent


/***/ }),

/***/ 7365:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { promisify } = __nccwpck_require__(9023)
const Client = __nccwpck_require__(6197)
const { buildMockDispatch } = __nccwpck_require__(3397)
const {
  kDispatches,
  kMockAgent,
  kClose,
  kOriginalClose,
  kOrigin,
  kOriginalDispatch,
  kConnected
} = __nccwpck_require__(1117)
const { MockInterceptor } = __nccwpck_require__(1511)
const Symbols = __nccwpck_require__(6443)
const { InvalidArgumentError } = __nccwpck_require__(8707)

/**
 * MockClient provides an API that extends the Client to influence the mockDispatches.
 */
class MockClient extends Client {
  constructor (origin, opts) {
    super(origin, opts)

    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {
      throw new InvalidArgumentError('Argument opts.agent must implement Agent')
    }

    this[kMockAgent] = opts.agent
    this[kOrigin] = origin
    this[kDispatches] = []
    this[kConnected] = 1
    this[kOriginalDispatch] = this.dispatch
    this[kOriginalClose] = this.close.bind(this)

    this.dispatch = buildMockDispatch.call(this)
    this.close = this[kClose]
  }

  get [Symbols.kConnected] () {
    return this[kConnected]
  }

  /**
   * Sets up the base interceptor for mocking replies from undici.
   */
  intercept (opts) {
    return new MockInterceptor(opts, this[kDispatches])
  }

  async [kClose] () {
    await promisify(this[kOriginalClose])()
    this[kConnected] = 0
    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])
  }
}

module.exports = MockClient


/***/ }),

/***/ 2429:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { UndiciError } = __nccwpck_require__(8707)

class MockNotMatchedError extends UndiciError {
  constructor (message) {
    super(message)
    Error.captureStackTrace(this, MockNotMatchedError)
    this.name = 'MockNotMatchedError'
    this.message = message || 'The request does not match any registered mock dispatches'
    this.code = 'UND_MOCK_ERR_MOCK_NOT_MATCHED'
  }
}

module.exports = {
  MockNotMatchedError
}


/***/ }),

/***/ 1511:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { getResponseData, buildKey, addMockDispatch } = __nccwpck_require__(3397)
const {
  kDispatches,
  kDispatchKey,
  kDefaultHeaders,
  kDefaultTrailers,
  kContentLength,
  kMockDispatch
} = __nccwpck_require__(1117)
const { InvalidArgumentError } = __nccwpck_require__(8707)
const { buildURL } = __nccwpck_require__(3440)

/**
 * Defines the scope API for an interceptor reply
 */
class MockScope {
  constructor (mockDispatch) {
    this[kMockDispatch] = mockDispatch
  }

  /**
   * Delay a reply by a set amount in ms.
   */
  delay (waitInMs) {
    if (typeof waitInMs !== 'number' || !Number.isInteger(waitInMs) || waitInMs <= 0) {
      throw new InvalidArgumentError('waitInMs must be a valid integer > 0')
    }

    this[kMockDispatch].delay = waitInMs
    return this
  }

  /**
   * For a defined reply, never mark as consumed.
   */
  persist () {
    this[kMockDispatch].persist = true
    return this
  }

  /**
   * Allow one to define a reply for a set amount of matching requests.
   */
  times (repeatTimes) {
    if (typeof repeatTimes !== 'number' || !Number.isInteger(repeatTimes) || repeatTimes <= 0) {
      throw new InvalidArgumentError('repeatTimes must be a valid integer > 0')
    }

    this[kMockDispatch].times = repeatTimes
    return this
  }
}

/**
 * Defines an interceptor for a Mock
 */
class MockInterceptor {
  constructor (opts, mockDispatches) {
    if (typeof opts !== 'object') {
      throw new InvalidArgumentError('opts must be an object')
    }
    if (typeof opts.path === 'undefined') {
      throw new InvalidArgumentError('opts.path must be defined')
    }
    if (typeof opts.method === 'undefined') {
      opts.method = 'GET'
    }
    // See https://github.com/nodejs/undici/issues/1245
    // As per RFC 3986, clients are not supposed to send URI
    // fragments to servers when they retrieve a document,
    if (typeof opts.path === 'string') {
      if (opts.query) {
        opts.path = buildURL(opts.path, opts.query)
      } else {
        // Matches https://github.com/nodejs/undici/blob/main/lib/fetch/index.js#L1811
        const parsedURL = new URL(opts.path, 'data://')
        opts.path = parsedURL.pathname + parsedURL.search
      }
    }
    if (typeof opts.method === 'string') {
      opts.method = opts.method.toUpperCase()
    }

    this[kDispatchKey] = buildKey(opts)
    this[kDispatches] = mockDispatches
    this[kDefaultHeaders] = {}
    this[kDefaultTrailers] = {}
    this[kContentLength] = false
  }

  createMockScopeDispatchData (statusCode, data, responseOptions = {}) {
    const responseData = getResponseData(data)
    const contentLength = this[kContentLength] ? { 'content-length': responseData.length } : {}
    const headers = { ...this[kDefaultHeaders], ...contentLength, ...responseOptions.headers }
    const trailers = { ...this[kDefaultTrailers], ...responseOptions.trailers }

    return { statusCode, data, headers, trailers }
  }

  validateReplyParameters (statusCode, data, responseOptions) {
    if (typeof statusCode === 'undefined') {
      throw new InvalidArgumentError('statusCode must be defined')
    }
    if (typeof data === 'undefined') {
      throw new InvalidArgumentError('data must be defined')
    }
    if (typeof responseOptions !== 'object') {
      throw new InvalidArgumentError('responseOptions must be an object')
    }
  }

  /**
   * Mock an undici request with a defined reply.
   */
  reply (replyData) {
    // Values of reply aren't available right now as they
    // can only be available when the reply callback is invoked.
    if (typeof replyData === 'function') {
      // We'll first wrap the provided callback in another function,
      // this function will properly resolve the data from the callback
      // when invoked.
      const wrappedDefaultsCallback = (opts) => {
        // Our reply options callback contains the parameter for statusCode, data and options.
        const resolvedData = replyData(opts)

        // Check if it is in the right format
        if (typeof resolvedData !== 'object') {
          throw new InvalidArgumentError('reply options callback must return an object')
        }

        const { statusCode, data = '', responseOptions = {} } = resolvedData
        this.validateReplyParameters(statusCode, data, responseOptions)
        // Since the values can be obtained immediately we return them
        // from this higher order function that will be resolved later.
        return {
          ...this.createMockScopeDispatchData(statusCode, data, responseOptions)
        }
      }

      // Add usual dispatch data, but this time set the data parameter to function that will eventually provide data.
      const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], wrappedDefaultsCallback)
      return new MockScope(newMockDispatch)
    }

    // We can have either one or three parameters, if we get here,
    // we should have 1-3 parameters. So we spread the arguments of
    // this function to obtain the parameters, since replyData will always
    // just be the statusCode.
    const [statusCode, data = '', responseOptions = {}] = [...arguments]
    this.validateReplyParameters(statusCode, data, responseOptions)

    // Send in-already provided data like usual
    const dispatchData = this.createMockScopeDispatchData(statusCode, data, responseOptions)
    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], dispatchData)
    return new MockScope(newMockDispatch)
  }

  /**
   * Mock an undici request with a defined error.
   */
  replyWithError (error) {
    if (typeof error === 'undefined') {
      throw new InvalidArgumentError('error must be defined')
    }

    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], { error })
    return new MockScope(newMockDispatch)
  }

  /**
   * Set default reply headers on the interceptor for subsequent replies
   */
  defaultReplyHeaders (headers) {
    if (typeof headers === 'undefined') {
      throw new InvalidArgumentError('headers must be defined')
    }

    this[kDefaultHeaders] = headers
    return this
  }

  /**
   * Set default reply trailers on the interceptor for subsequent replies
   */
  defaultReplyTrailers (trailers) {
    if (typeof trailers === 'undefined') {
      throw new InvalidArgumentError('trailers must be defined')
    }

    this[kDefaultTrailers] = trailers
    return this
  }

  /**
   * Set reply content length header for replies on the interceptor
   */
  replyContentLength () {
    this[kContentLength] = true
    return this
  }
}

module.exports.MockInterceptor = MockInterceptor
module.exports.MockScope = MockScope


/***/ }),

/***/ 4004:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { promisify } = __nccwpck_require__(9023)
const Pool = __nccwpck_require__(5076)
const { buildMockDispatch } = __nccwpck_require__(3397)
const {
  kDispatches,
  kMockAgent,
  kClose,
  kOriginalClose,
  kOrigin,
  kOriginalDispatch,
  kConnected
} = __nccwpck_require__(1117)
const { MockInterceptor } = __nccwpck_require__(1511)
const Symbols = __nccwpck_require__(6443)
const { InvalidArgumentError } = __nccwpck_require__(8707)

/**
 * MockPool provides an API that extends the Pool to influence the mockDispatches.
 */
class MockPool extends Pool {
  constructor (origin, opts) {
    super(origin, opts)

    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {
      throw new InvalidArgumentError('Argument opts.agent must implement Agent')
    }

    this[kMockAgent] = opts.agent
    this[kOrigin] = origin
    this[kDispatches] = []
    this[kConnected] = 1
    this[kOriginalDispatch] = this.dispatch
    this[kOriginalClose] = this.close.bind(this)

    this.dispatch = buildMockDispatch.call(this)
    this.close = this[kClose]
  }

  get [Symbols.kConnected] () {
    return this[kConnected]
  }

  /**
   * Sets up the base interceptor for mocking replies from undici.
   */
  intercept (opts) {
    return new MockInterceptor(opts, this[kDispatches])
  }

  async [kClose] () {
    await promisify(this[kOriginalClose])()
    this[kConnected] = 0
    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])
  }
}

module.exports = MockPool


/***/ }),

/***/ 1117:
/***/ ((module) => {

"use strict";


module.exports = {
  kAgent: Symbol('agent'),
  kOptions: Symbol('options'),
  kFactory: Symbol('factory'),
  kDispatches: Symbol('dispatches'),
  kDispatchKey: Symbol('dispatch key'),
  kDefaultHeaders: Symbol('default headers'),
  kDefaultTrailers: Symbol('default trailers'),
  kContentLength: Symbol('content length'),
  kMockAgent: Symbol('mock agent'),
  kMockAgentSet: Symbol('mock agent set'),
  kMockAgentGet: Symbol('mock agent get'),
  kMockDispatch: Symbol('mock dispatch'),
  kClose: Symbol('close'),
  kOriginalClose: Symbol('original agent close'),
  kOrigin: Symbol('origin'),
  kIsMockActive: Symbol('is mock active'),
  kNetConnect: Symbol('net connect'),
  kGetNetConnect: Symbol('get net connect'),
  kConnected: Symbol('connected')
}


/***/ }),

/***/ 3397:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { MockNotMatchedError } = __nccwpck_require__(2429)
const {
  kDispatches,
  kMockAgent,
  kOriginalDispatch,
  kOrigin,
  kGetNetConnect
} = __nccwpck_require__(1117)
const { buildURL, nop } = __nccwpck_require__(3440)
const { STATUS_CODES } = __nccwpck_require__(8611)
const {
  types: {
    isPromise
  }
} = __nccwpck_require__(9023)

function matchValue (match, value) {
  if (typeof match === 'string') {
    return match === value
  }
  if (match instanceof RegExp) {
    return match.test(value)
  }
  if (typeof match === 'function') {
    return match(value) === true
  }
  return false
}

function lowerCaseEntries (headers) {
  return Object.fromEntries(
    Object.entries(headers).map(([headerName, headerValue]) => {
      return [headerName.toLocaleLowerCase(), headerValue]
    })
  )
}

/**
 * @param {import('../../index').Headers|string[]|Record<string, string>} headers
 * @param {string} key
 */
function getHeaderByName (headers, key) {
  if (Array.isArray(headers)) {
    for (let i = 0; i < headers.length; i += 2) {
      if (headers[i].toLocaleLowerCase() === key.toLocaleLowerCase()) {
        return headers[i + 1]
      }
    }

    return undefined
  } else if (typeof headers.get === 'function') {
    return headers.get(key)
  } else {
    return lowerCaseEntries(headers)[key.toLocaleLowerCase()]
  }
}

/** @param {string[]} headers */
function buildHeadersFromArray (headers) { // fetch HeadersList
  const clone = headers.slice()
  const entries = []
  for (let index = 0; index < clone.length; index += 2) {
    entries.push([clone[index], clone[index + 1]])
  }
  return Object.fromEntries(entries)
}

function matchHeaders (mockDispatch, headers) {
  if (typeof mockDispatch.headers === 'function') {
    if (Array.isArray(headers)) { // fetch HeadersList
      headers = buildHeadersFromArray(headers)
    }
    return mockDispatch.headers(headers ? lowerCaseEntries(headers) : {})
  }
  if (typeof mockDispatch.headers === 'undefined') {
    return true
  }
  if (typeof headers !== 'object' || typeof mockDispatch.headers !== 'object') {
    return false
  }

  for (const [matchHeaderName, matchHeaderValue] of Object.entries(mockDispatch.headers)) {
    const headerValue = getHeaderByName(headers, matchHeaderName)

    if (!matchValue(matchHeaderValue, headerValue)) {
      return false
    }
  }
  return true
}

function safeUrl (path) {
  if (typeof path !== 'string') {
    return path
  }

  const pathSegments = path.split('?')

  if (pathSegments.length !== 2) {
    return path
  }

  const qp = new URLSearchParams(pathSegments.pop())
  qp.sort()
  return [...pathSegments, qp.toString()].join('?')
}

function matchKey (mockDispatch, { path, method, body, headers }) {
  const pathMatch = matchValue(mockDispatch.path, path)
  const methodMatch = matchValue(mockDispatch.method, method)
  const bodyMatch = typeof mockDispatch.body !== 'undefined' ? matchValue(mockDispatch.body, body) : true
  const headersMatch = matchHeaders(mockDispatch, headers)
  return pathMatch && methodMatch && bodyMatch && headersMatch
}

function getResponseData (data) {
  if (Buffer.isBuffer(data)) {
    return data
  } else if (typeof data === 'object') {
    return JSON.stringify(data)
  } else {
    return data.toString()
  }
}

function getMockDispatch (mockDispatches, key) {
  const basePath = key.query ? buildURL(key.path, key.query) : key.path
  const resolvedPath = typeof basePath === 'string' ? safeUrl(basePath) : basePath

  // Match path
  let matchedMockDispatches = mockDispatches.filter(({ consumed }) => !consumed).filter(({ path }) => matchValue(safeUrl(path), resolvedPath))
  if (matchedMockDispatches.length === 0) {
    throw new MockNotMatchedError(`Mock dispatch not matched for path '${resolvedPath}'`)
  }

  // Match method
  matchedMockDispatches = matchedMockDispatches.filter(({ method }) => matchValue(method, key.method))
  if (matchedMockDispatches.length === 0) {
    throw new MockNotMatchedError(`Mock dispatch not matched for method '${key.method}'`)
  }

  // Match body
  matchedMockDispatches = matchedMockDispatches.filter(({ body }) => typeof body !== 'undefined' ? matchValue(body, key.body) : true)
  if (matchedMockDispatches.length === 0) {
    throw new MockNotMatchedError(`Mock dispatch not matched for body '${key.body}'`)
  }

  // Match headers
  matchedMockDispatches = matchedMockDispatches.filter((mockDispatch) => matchHeaders(mockDispatch, key.headers))
  if (matchedMockDispatches.length === 0) {
    throw new MockNotMatchedError(`Mock dispatch not matched for headers '${typeof key.headers === 'object' ? JSON.stringify(key.headers) : key.headers}'`)
  }

  return matchedMockDispatches[0]
}

function addMockDispatch (mockDispatches, key, data) {
  const baseData = { timesInvoked: 0, times: 1, persist: false, consumed: false }
  const replyData = typeof data === 'function' ? { callback: data } : { ...data }
  const newMockDispatch = { ...baseData, ...key, pending: true, data: { error: null, ...replyData } }
  mockDispatches.push(newMockDispatch)
  return newMockDispatch
}

function deleteMockDispatch (mockDispatches, key) {
  const index = mockDispatches.findIndex(dispatch => {
    if (!dispatch.consumed) {
      return false
    }
    return matchKey(dispatch, key)
  })
  if (index !== -1) {
    mockDispatches.splice(index, 1)
  }
}

function buildKey (opts) {
  const { path, method, body, headers, query } = opts
  return {
    path,
    method,
    body,
    headers,
    query
  }
}

function generateKeyValues (data) {
  return Object.entries(data).reduce((keyValuePairs, [key, value]) => [
    ...keyValuePairs,
    Buffer.from(`${key}`),
    Array.isArray(value) ? value.map(x => Buffer.from(`${x}`)) : Buffer.from(`${value}`)
  ], [])
}

/**
 * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
 * @param {number} statusCode
 */
function getStatusText (statusCode) {
  return STATUS_CODES[statusCode] || 'unknown'
}

async function getResponse (body) {
  const buffers = []
  for await (const data of body) {
    buffers.push(data)
  }
  return Buffer.concat(buffers).toString('utf8')
}

/**
 * Mock dispatch function used to simulate undici dispatches
 */
function mockDispatch (opts, handler) {
  // Get mock dispatch from built key
  const key = buildKey(opts)
  const mockDispatch = getMockDispatch(this[kDispatches], key)

  mockDispatch.timesInvoked++

  // Here's where we resolve a callback if a callback is present for the dispatch data.
  if (mockDispatch.data.callback) {
    mockDispatch.data = { ...mockDispatch.data, ...mockDispatch.data.callback(opts) }
  }

  // Parse mockDispatch data
  const { data: { statusCode, data, headers, trailers, error }, delay, persist } = mockDispatch
  const { timesInvoked, times } = mockDispatch

  // If it's used up and not persistent, mark as consumed
  mockDispatch.consumed = !persist && timesInvoked >= times
  mockDispatch.pending = timesInvoked < times

  // If specified, trigger dispatch error
  if (error !== null) {
    deleteMockDispatch(this[kDispatches], key)
    handler.onError(error)
    return true
  }

  // Handle the request with a delay if necessary
  if (typeof delay === 'number' && delay > 0) {
    setTimeout(() => {
      handleReply(this[kDispatches])
    }, delay)
  } else {
    handleReply(this[kDispatches])
  }

  function handleReply (mockDispatches, _data = data) {
    // fetch's HeadersList is a 1D string array
    const optsHeaders = Array.isArray(opts.headers)
      ? buildHeadersFromArray(opts.headers)
      : opts.headers
    const body = typeof _data === 'function'
      ? _data({ ...opts, headers: optsHeaders })
      : _data

    // util.types.isPromise is likely needed for jest.
    if (isPromise(body)) {
      // If handleReply is asynchronous, throwing an error
      // in the callback will reject the promise, rather than
      // synchronously throw the error, which breaks some tests.
      // Rather, we wait for the callback to resolve if it is a
      // promise, and then re-run handleReply with the new body.
      body.then((newData) => handleReply(mockDispatches, newData))
      return
    }

    const responseData = getResponseData(body)
    const responseHeaders = generateKeyValues(headers)
    const responseTrailers = generateKeyValues(trailers)

    handler.abort = nop
    handler.onHeaders(statusCode, responseHeaders, resume, getStatusText(statusCode))
    handler.onData(Buffer.from(responseData))
    handler.onComplete(responseTrailers)
    deleteMockDispatch(mockDispatches, key)
  }

  function resume () {}

  return true
}

function buildMockDispatch () {
  const agent = this[kMockAgent]
  const origin = this[kOrigin]
  const originalDispatch = this[kOriginalDispatch]

  return function dispatch (opts, handler) {
    if (agent.isMockActive) {
      try {
        mockDispatch.call(this, opts, handler)
      } catch (error) {
        if (error instanceof MockNotMatchedError) {
          const netConnect = agent[kGetNetConnect]()
          if (netConnect === false) {
            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect disabled)`)
          }
          if (checkNetConnect(netConnect, origin)) {
            originalDispatch.call(this, opts, handler)
          } else {
            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect is not enabled for this origin)`)
          }
        } else {
          throw error
        }
      }
    } else {
      originalDispatch.call(this, opts, handler)
    }
  }
}

function checkNetConnect (netConnect, origin) {
  const url = new URL(origin)
  if (netConnect === true) {
    return true
  } else if (Array.isArray(netConnect) && netConnect.some((matcher) => matchValue(matcher, url.host))) {
    return true
  }
  return false
}

function buildMockOptions (opts) {
  if (opts) {
    const { agent, ...mockOptions } = opts
    return mockOptions
  }
}

module.exports = {
  getResponseData,
  getMockDispatch,
  addMockDispatch,
  deleteMockDispatch,
  buildKey,
  generateKeyValues,
  matchValue,
  getResponse,
  getStatusText,
  mockDispatch,
  buildMockDispatch,
  checkNetConnect,
  buildMockOptions,
  getHeaderByName
}


/***/ }),

/***/ 6142:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { Transform } = __nccwpck_require__(2203)
const { Console } = __nccwpck_require__(4236)

/**
 * Gets the output of `console.table()` as a string.
 */
module.exports = class PendingInterceptorsFormatter {
  constructor ({ disableColors } = {}) {
    this.transform = new Transform({
      transform (chunk, _enc, cb) {
        cb(null, chunk)
      }
    })

    this.logger = new Console({
      stdout: this.transform,
      inspectOptions: {
        colors: !disableColors && !process.env.CI
      }
    })
  }

  format (pendingInterceptors) {
    const withPrettyHeaders = pendingInterceptors.map(
      ({ method, path, data: { statusCode }, persist, times, timesInvoked, origin }) => ({
        Method: method,
        Origin: origin,
        Path: path,
        'Status code': statusCode,
        Persistent: persist ? '' : '',
        Invocations: timesInvoked,
        Remaining: persist ? Infinity : times - timesInvoked
      }))

    this.logger.table(withPrettyHeaders)
    return this.transform.read().toString()
  }
}


/***/ }),

/***/ 1529:
/***/ ((module) => {

"use strict";


const singulars = {
  pronoun: 'it',
  is: 'is',
  was: 'was',
  this: 'this'
}

const plurals = {
  pronoun: 'they',
  is: 'are',
  was: 'were',
  this: 'these'
}

module.exports = class Pluralizer {
  constructor (singular, plural) {
    this.singular = singular
    this.plural = plural
  }

  pluralize (count) {
    const one = count === 1
    const keys = one ? singulars : plurals
    const noun = one ? this.singular : this.plural
    return { ...keys, count, noun }
  }
}


/***/ }),

/***/ 4869:
/***/ ((module) => {

"use strict";
/* eslint-disable */



// Extracted from node/lib/internal/fixed_queue.js

// Currently optimal queue size, tested on V8 6.0 - 6.6. Must be power of two.
const kSize = 2048;
const kMask = kSize - 1;

// The FixedQueue is implemented as a singly-linked list of fixed-size
// circular buffers. It looks something like this:
//
//  head                                                       tail
//    |                                                          |
//    v                                                          v
// +-----------+ <-----\       +-----------+ <------\         +-----------+
// |  [null]   |        \----- |   next    |         \------- |   next    |
// +-----------+               +-----------+                  +-----------+
// |   item    | <-- bottom    |   item    | <-- bottom       |  [empty]  |
// |   item    |               |   item    |                  |  [empty]  |
// |   item    |               |   item    |                  |  [empty]  |
// |   item    |               |   item    |                  |  [empty]  |
// |   item    |               |   item    |       bottom --> |   item    |
// |   item    |               |   item    |                  |   item    |
// |    ...    |               |    ...    |                  |    ...    |
// |   item    |               |   item    |                  |   item    |
// |   item    |               |   item    |                  |   item    |
// |  [empty]  | <-- top       |   item    |                  |   item    |
// |  [empty]  |               |   item    |                  |   item    |
// |  [empty]  |               |  [empty]  | <-- top  top --> |  [empty]  |
// +-----------+               +-----------+                  +-----------+
//
// Or, if there is only one circular buffer, it looks something
// like either of these:
//
//  head   tail                                 head   tail
//    |     |                                     |     |
//    v     v                                     v     v
// +-----------+                               +-----------+
// |  [null]   |                               |  [null]   |
// +-----------+                               +-----------+
// |  [empty]  |                               |   item    |
// |  [empty]  |                               |   item    |
// |   item    | <-- bottom            top --> |  [empty]  |
// |   item    |                               |  [empty]  |
// |  [empty]  | <-- top            bottom --> |   item    |
// |  [empty]  |                               |   item    |
// +-----------+                               +-----------+
//
// Adding a value means moving `top` forward by one, removing means
// moving `bottom` forward by one. After reaching the end, the queue
// wraps around.
//
// When `top === bottom` the current queue is empty and when
// `top + 1 === bottom` it's full. This wastes a single space of storage
// but allows much quicker checks.

class FixedCircularBuffer {
  constructor() {
    this.bottom = 0;
    this.top = 0;
    this.list = new Array(kSize);
    this.next = null;
  }

  isEmpty() {
    return this.top === this.bottom;
  }

  isFull() {
    return ((this.top + 1) & kMask) === this.bottom;
  }

  push(data) {
    this.list[this.top] = data;
    this.top = (this.top + 1) & kMask;
  }

  shift() {
    const nextItem = this.list[this.bottom];
    if (nextItem === undefined)
      return null;
    this.list[this.bottom] = undefined;
    this.bottom = (this.bottom + 1) & kMask;
    return nextItem;
  }
}

module.exports = class FixedQueue {
  constructor() {
    this.head = this.tail = new FixedCircularBuffer();
  }

  isEmpty() {
    return this.head.isEmpty();
  }

  push(data) {
    if (this.head.isFull()) {
      // Head is full: Creates a new queue, sets the old queue's `.next` to it,
      // and sets it as the new main queue.
      this.head = this.head.next = new FixedCircularBuffer();
    }
    this.head.push(data);
  }

  shift() {
    const tail = this.tail;
    const next = tail.shift();
    if (tail.isEmpty() && tail.next !== null) {
      // If there is another queue, it forms the new tail.
      this.tail = tail.next;
    }
    return next;
  }
};


/***/ }),

/***/ 8640:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const DispatcherBase = __nccwpck_require__(1)
const FixedQueue = __nccwpck_require__(4869)
const { kConnected, kSize, kRunning, kPending, kQueued, kBusy, kFree, kUrl, kClose, kDestroy, kDispatch } = __nccwpck_require__(6443)
const PoolStats = __nccwpck_require__(4622)

const kClients = Symbol('clients')
const kNeedDrain = Symbol('needDrain')
const kQueue = Symbol('queue')
const kClosedResolve = Symbol('closed resolve')
const kOnDrain = Symbol('onDrain')
const kOnConnect = Symbol('onConnect')
const kOnDisconnect = Symbol('onDisconnect')
const kOnConnectionError = Symbol('onConnectionError')
const kGetDispatcher = Symbol('get dispatcher')
const kAddClient = Symbol('add client')
const kRemoveClient = Symbol('remove client')
const kStats = Symbol('stats')

class PoolBase extends DispatcherBase {
  constructor () {
    super()

    this[kQueue] = new FixedQueue()
    this[kClients] = []
    this[kQueued] = 0

    const pool = this

    this[kOnDrain] = function onDrain (origin, targets) {
      const queue = pool[kQueue]

      let needDrain = false

      while (!needDrain) {
        const item = queue.shift()
        if (!item) {
          break
        }
        pool[kQueued]--
        needDrain = !this.dispatch(item.opts, item.handler)
      }

      this[kNeedDrain] = needDrain

      if (!this[kNeedDrain] && pool[kNeedDrain]) {
        pool[kNeedDrain] = false
        pool.emit('drain', origin, [pool, ...targets])
      }

      if (pool[kClosedResolve] && queue.isEmpty()) {
        Promise
          .all(pool[kClients].map(c => c.close()))
          .then(pool[kClosedResolve])
      }
    }

    this[kOnConnect] = (origin, targets) => {
      pool.emit('connect', origin, [pool, ...targets])
    }

    this[kOnDisconnect] = (origin, targets, err) => {
      pool.emit('disconnect', origin, [pool, ...targets], err)
    }

    this[kOnConnectionError] = (origin, targets, err) => {
      pool.emit('connectionError', origin, [pool, ...targets], err)
    }

    this[kStats] = new PoolStats(this)
  }

  get [kBusy] () {
    return this[kNeedDrain]
  }

  get [kConnected] () {
    return this[kClients].filter(client => client[kConnected]).length
  }

  get [kFree] () {
    return this[kClients].filter(client => client[kConnected] && !client[kNeedDrain]).length
  }

  get [kPending] () {
    let ret = this[kQueued]
    for (const { [kPending]: pending } of this[kClients]) {
      ret += pending
    }
    return ret
  }

  get [kRunning] () {
    let ret = 0
    for (const { [kRunning]: running } of this[kClients]) {
      ret += running
    }
    return ret
  }

  get [kSize] () {
    let ret = this[kQueued]
    for (const { [kSize]: size } of this[kClients]) {
      ret += size
    }
    return ret
  }

  get stats () {
    return this[kStats]
  }

  async [kClose] () {
    if (this[kQueue].isEmpty()) {
      return Promise.all(this[kClients].map(c => c.close()))
    } else {
      return new Promise((resolve) => {
        this[kClosedResolve] = resolve
      })
    }
  }

  async [kDestroy] (err) {
    while (true) {
      const item = this[kQueue].shift()
      if (!item) {
        break
      }
      item.handler.onError(err)
    }

    return Promise.all(this[kClients].map(c => c.destroy(err)))
  }

  [kDispatch] (opts, handler) {
    const dispatcher = this[kGetDispatcher]()

    if (!dispatcher) {
      this[kNeedDrain] = true
      this[kQueue].push({ opts, handler })
      this[kQueued]++
    } else if (!dispatcher.dispatch(opts, handler)) {
      dispatcher[kNeedDrain] = true
      this[kNeedDrain] = !this[kGetDispatcher]()
    }

    return !this[kNeedDrain]
  }

  [kAddClient] (client) {
    client
      .on('drain', this[kOnDrain])
      .on('connect', this[kOnConnect])
      .on('disconnect', this[kOnDisconnect])
      .on('connectionError', this[kOnConnectionError])

    this[kClients].push(client)

    if (this[kNeedDrain]) {
      process.nextTick(() => {
        if (this[kNeedDrain]) {
          this[kOnDrain](client[kUrl], [this, client])
        }
      })
    }

    return this
  }

  [kRemoveClient] (client) {
    client.close(() => {
      const idx = this[kClients].indexOf(client)
      if (idx !== -1) {
        this[kClients].splice(idx, 1)
      }
    })

    this[kNeedDrain] = this[kClients].some(dispatcher => (
      !dispatcher[kNeedDrain] &&
      dispatcher.closed !== true &&
      dispatcher.destroyed !== true
    ))
  }
}

module.exports = {
  PoolBase,
  kClients,
  kNeedDrain,
  kAddClient,
  kRemoveClient,
  kGetDispatcher
}


/***/ }),

/***/ 4622:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

const { kFree, kConnected, kPending, kQueued, kRunning, kSize } = __nccwpck_require__(6443)
const kPool = Symbol('pool')

class PoolStats {
  constructor (pool) {
    this[kPool] = pool
  }

  get connected () {
    return this[kPool][kConnected]
  }

  get free () {
    return this[kPool][kFree]
  }

  get pending () {
    return this[kPool][kPending]
  }

  get queued () {
    return this[kPool][kQueued]
  }

  get running () {
    return this[kPool][kRunning]
  }

  get size () {
    return this[kPool][kSize]
  }
}

module.exports = PoolStats


/***/ }),

/***/ 5076:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const {
  PoolBase,
  kClients,
  kNeedDrain,
  kAddClient,
  kGetDispatcher
} = __nccwpck_require__(8640)
const Client = __nccwpck_require__(6197)
const {
  InvalidArgumentError
} = __nccwpck_require__(8707)
const util = __nccwpck_require__(3440)
const { kUrl, kInterceptors } = __nccwpck_require__(6443)
const buildConnector = __nccwpck_require__(9136)

const kOptions = Symbol('options')
const kConnections = Symbol('connections')
const kFactory = Symbol('factory')

function defaultFactory (origin, opts) {
  return new Client(origin, opts)
}

class Pool extends PoolBase {
  constructor (origin, {
    connections,
    factory = defaultFactory,
    connect,
    connectTimeout,
    tls,
    maxCachedSessions,
    socketPath,
    autoSelectFamily,
    autoSelectFamilyAttemptTimeout,
    allowH2,
    ...options
  } = {}) {
    super()

    if (connections != null && (!Number.isFinite(connections) || connections < 0)) {
      throw new InvalidArgumentError('invalid connections')
    }

    if (typeof factory !== 'function') {
      throw new InvalidArgumentError('factory must be a function.')
    }

    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {
      throw new InvalidArgumentError('connect must be a function or an object')
    }

    if (typeof connect !== 'function') {
      connect = buildConnector({
        ...tls,
        maxCachedSessions,
        allowH2,
        socketPath,
        timeout: connectTimeout,
        ...(util.nodeHasAutoSelectFamily && autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),
        ...connect
      })
    }

    this[kInterceptors] = options.interceptors && options.interceptors.Pool && Array.isArray(options.interceptors.Pool)
      ? options.interceptors.Pool
      : []
    this[kConnections] = connections || null
    this[kUrl] = util.parseOrigin(origin)
    this[kOptions] = { ...util.deepClone(options), connect, allowH2 }
    this[kOptions].interceptors = options.interceptors
      ? { ...options.interceptors }
      : undefined
    this[kFactory] = factory

    this.on('connectionError', (origin, targets, error) => {
      // If a connection error occurs, we remove the client from the pool,
      // and emit a connectionError event. They will not be re-used.
      // Fixes https://github.com/nodejs/undici/issues/3895
      for (const target of targets) {
        // Do not use kRemoveClient here, as it will close the client,
        // but the client cannot be closed in this state.
        const idx = this[kClients].indexOf(target)
        if (idx !== -1) {
          this[kClients].splice(idx, 1)
        }
      }
    })
  }

  [kGetDispatcher] () {
    let dispatcher = this[kClients].find(dispatcher => !dispatcher[kNeedDrain])

    if (dispatcher) {
      return dispatcher
    }

    if (!this[kConnections] || this[kClients].length < this[kConnections]) {
      dispatcher = this[kFactory](this[kUrl], this[kOptions])
      this[kAddClient](dispatcher)
    }

    return dispatcher
  }
}

module.exports = Pool


/***/ }),

/***/ 2720:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { kProxy, kClose, kDestroy, kInterceptors } = __nccwpck_require__(6443)
const { URL } = __nccwpck_require__(7016)
const Agent = __nccwpck_require__(9965)
const Pool = __nccwpck_require__(5076)
const DispatcherBase = __nccwpck_require__(1)
const { InvalidArgumentError, RequestAbortedError } = __nccwpck_require__(8707)
const buildConnector = __nccwpck_require__(9136)

const kAgent = Symbol('proxy agent')
const kClient = Symbol('proxy client')
const kProxyHeaders = Symbol('proxy headers')
const kRequestTls = Symbol('request tls settings')
const kProxyTls = Symbol('proxy tls settings')
const kConnectEndpoint = Symbol('connect endpoint function')

function defaultProtocolPort (protocol) {
  return protocol === 'https:' ? 443 : 80
}

function buildProxyOptions (opts) {
  if (typeof opts === 'string') {
    opts = { uri: opts }
  }

  if (!opts || !opts.uri) {
    throw new InvalidArgumentError('Proxy opts.uri is mandatory')
  }

  return {
    uri: opts.uri,
    protocol: opts.protocol || 'https'
  }
}

function defaultFactory (origin, opts) {
  return new Pool(origin, opts)
}

class ProxyAgent extends DispatcherBase {
  constructor (opts) {
    super(opts)
    this[kProxy] = buildProxyOptions(opts)
    this[kAgent] = new Agent(opts)
    this[kInterceptors] = opts.interceptors && opts.interceptors.ProxyAgent && Array.isArray(opts.interceptors.ProxyAgent)
      ? opts.interceptors.ProxyAgent
      : []

    if (typeof opts === 'string') {
      opts = { uri: opts }
    }

    if (!opts || !opts.uri) {
      throw new InvalidArgumentError('Proxy opts.uri is mandatory')
    }

    const { clientFactory = defaultFactory } = opts

    if (typeof clientFactory !== 'function') {
      throw new InvalidArgumentError('Proxy opts.clientFactory must be a function.')
    }

    this[kRequestTls] = opts.requestTls
    this[kProxyTls] = opts.proxyTls
    this[kProxyHeaders] = opts.headers || {}

    const resolvedUrl = new URL(opts.uri)
    const { origin, port, host, username, password } = resolvedUrl

    if (opts.auth && opts.token) {
      throw new InvalidArgumentError('opts.auth cannot be used in combination with opts.token')
    } else if (opts.auth) {
      /* @deprecated in favour of opts.token */
      this[kProxyHeaders]['proxy-authorization'] = `Basic ${opts.auth}`
    } else if (opts.token) {
      this[kProxyHeaders]['proxy-authorization'] = opts.token
    } else if (username && password) {
      this[kProxyHeaders]['proxy-authorization'] = `Basic ${Buffer.from(`${decodeURIComponent(username)}:${decodeURIComponent(password)}`).toString('base64')}`
    }

    const connect = buildConnector({ ...opts.proxyTls })
    this[kConnectEndpoint] = buildConnector({ ...opts.requestTls })
    this[kClient] = clientFactory(resolvedUrl, { connect })
    this[kAgent] = new Agent({
      ...opts,
      connect: async (opts, callback) => {
        let requestedHost = opts.host
        if (!opts.port) {
          requestedHost += `:${defaultProtocolPort(opts.protocol)}`
        }
        try {
          const { socket, statusCode } = await this[kClient].connect({
            origin,
            port,
            path: requestedHost,
            signal: opts.signal,
            headers: {
              ...this[kProxyHeaders],
              host
            }
          })
          if (statusCode !== 200) {
            socket.on('error', () => {}).destroy()
            callback(new RequestAbortedError(`Proxy response (${statusCode}) !== 200 when HTTP Tunneling`))
          }
          if (opts.protocol !== 'https:') {
            callback(null, socket)
            return
          }
          let servername
          if (this[kRequestTls]) {
            servername = this[kRequestTls].servername
          } else {
            servername = opts.servername
          }
          this[kConnectEndpoint]({ ...opts, servername, httpSocket: socket }, callback)
        } catch (err) {
          callback(err)
        }
      }
    })
  }

  dispatch (opts, handler) {
    const { host } = new URL(opts.origin)
    const headers = buildHeaders(opts.headers)
    throwIfProxyAuthIsSent(headers)
    return this[kAgent].dispatch(
      {
        ...opts,
        headers: {
          ...headers,
          host
        }
      },
      handler
    )
  }

  async [kClose] () {
    await this[kAgent].close()
    await this[kClient].close()
  }

  async [kDestroy] () {
    await this[kAgent].destroy()
    await this[kClient].destroy()
  }
}

/**
 * @param {string[] | Record<string, string>} headers
 * @returns {Record<string, string>}
 */
function buildHeaders (headers) {
  // When using undici.fetch, the headers list is stored
  // as an array.
  if (Array.isArray(headers)) {
    /** @type {Record<string, string>} */
    const headersPair = {}

    for (let i = 0; i < headers.length; i += 2) {
      headersPair[headers[i]] = headers[i + 1]
    }

    return headersPair
  }

  return headers
}

/**
 * @param {Record<string, string>} headers
 *
 * Previous versions of ProxyAgent suggests the Proxy-Authorization in request headers
 * Nevertheless, it was changed and to avoid a security vulnerability by end users
 * this check was created.
 * It should be removed in the next major version for performance reasons
 */
function throwIfProxyAuthIsSent (headers) {
  const existProxyAuth = headers && Object.keys(headers)
    .find((key) => key.toLowerCase() === 'proxy-authorization')
  if (existProxyAuth) {
    throw new InvalidArgumentError('Proxy-Authorization should be sent in ProxyAgent constructor')
  }
}

module.exports = ProxyAgent


/***/ }),

/***/ 8804:
/***/ ((module) => {

"use strict";


let fastNow = Date.now()
let fastNowTimeout

const fastTimers = []

function onTimeout () {
  fastNow = Date.now()

  let len = fastTimers.length
  let idx = 0
  while (idx < len) {
    const timer = fastTimers[idx]

    if (timer.state === 0) {
      timer.state = fastNow + timer.delay
    } else if (timer.state > 0 && fastNow >= timer.state) {
      timer.state = -1
      timer.callback(timer.opaque)
    }

    if (timer.state === -1) {
      timer.state = -2
      if (idx !== len - 1) {
        fastTimers[idx] = fastTimers.pop()
      } else {
        fastTimers.pop()
      }
      len -= 1
    } else {
      idx += 1
    }
  }

  if (fastTimers.length > 0) {
    refreshTimeout()
  }
}

function refreshTimeout () {
  if (fastNowTimeout && fastNowTimeout.refresh) {
    fastNowTimeout.refresh()
  } else {
    clearTimeout(fastNowTimeout)
    fastNowTimeout = setTimeout(onTimeout, 1e3)
    if (fastNowTimeout.unref) {
      fastNowTimeout.unref()
    }
  }
}

class Timeout {
  constructor (callback, delay, opaque) {
    this.callback = callback
    this.delay = delay
    this.opaque = opaque

    //  -2 not in timer list
    //  -1 in timer list but inactive
    //   0 in timer list waiting for time
    // > 0 in timer list waiting for time to expire
    this.state = -2

    this.refresh()
  }

  refresh () {
    if (this.state === -2) {
      fastTimers.push(this)
      if (!fastNowTimeout || fastTimers.length === 1) {
        refreshTimeout()
      }
    }

    this.state = 0
  }

  clear () {
    this.state = -1
  }
}

module.exports = {
  setTimeout (callback, delay, opaque) {
    return delay < 1e3
      ? setTimeout(callback, delay, opaque)
      : new Timeout(callback, delay, opaque)
  },
  clearTimeout (timeout) {
    if (timeout instanceof Timeout) {
      timeout.clear()
    } else {
      clearTimeout(timeout)
    }
  }
}


/***/ }),

/***/ 8550:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const diagnosticsChannel = __nccwpck_require__(1637)
const { uid, states } = __nccwpck_require__(5913)
const {
  kReadyState,
  kSentClose,
  kByteParser,
  kReceivedClose
} = __nccwpck_require__(2933)
const { fireEvent, failWebsocketConnection } = __nccwpck_require__(3574)
const { CloseEvent } = __nccwpck_require__(6255)
const { makeRequest } = __nccwpck_require__(5194)
const { fetching } = __nccwpck_require__(2315)
const { Headers } = __nccwpck_require__(6349)
const { getGlobalDispatcher } = __nccwpck_require__(2581)
const { kHeadersList } = __nccwpck_require__(6443)

const channels = {}
channels.open = diagnosticsChannel.channel('undici:websocket:open')
channels.close = diagnosticsChannel.channel('undici:websocket:close')
channels.socketError = diagnosticsChannel.channel('undici:websocket:socket_error')

/** @type {import('crypto')} */
let crypto
try {
  crypto = __nccwpck_require__(6982)
} catch {

}

/**
 * @see https://websockets.spec.whatwg.org/#concept-websocket-establish
 * @param {URL} url
 * @param {string|string[]} protocols
 * @param {import('./websocket').WebSocket} ws
 * @param {(response: any) => void} onEstablish
 * @param {Partial<import('../../types/websocket').WebSocketInit>} options
 */
function establishWebSocketConnection (url, protocols, ws, onEstablish, options) {
  // 1. Let requestURL be a copy of url, with its scheme set to "http", if urls
  //    scheme is "ws", and to "https" otherwise.
  const requestURL = url

  requestURL.protocol = url.protocol === 'ws:' ? 'http:' : 'https:'

  // 2. Let request be a new request, whose URL is requestURL, client is client,
  //    service-workers mode is "none", referrer is "no-referrer", mode is
  //    "websocket", credentials mode is "include", cache mode is "no-store" ,
  //    and redirect mode is "error".
  const request = makeRequest({
    urlList: [requestURL],
    serviceWorkers: 'none',
    referrer: 'no-referrer',
    mode: 'websocket',
    credentials: 'include',
    cache: 'no-store',
    redirect: 'error'
  })

  // Note: undici extension, allow setting custom headers.
  if (options.headers) {
    const headersList = new Headers(options.headers)[kHeadersList]

    request.headersList = headersList
  }

  // 3. Append (`Upgrade`, `websocket`) to requests header list.
  // 4. Append (`Connection`, `Upgrade`) to requests header list.
  // Note: both of these are handled by undici currently.
  // https://github.com/nodejs/undici/blob/68c269c4144c446f3f1220951338daef4a6b5ec4/lib/client.js#L1397

  // 5. Let keyValue be a nonce consisting of a randomly selected
  //    16-byte value that has been forgiving-base64-encoded and
  //    isomorphic encoded.
  const keyValue = crypto.randomBytes(16).toString('base64')

  // 6. Append (`Sec-WebSocket-Key`, keyValue) to requests
  //    header list.
  request.headersList.append('sec-websocket-key', keyValue)

  // 7. Append (`Sec-WebSocket-Version`, `13`) to requests
  //    header list.
  request.headersList.append('sec-websocket-version', '13')

  // 8. For each protocol in protocols, combine
  //    (`Sec-WebSocket-Protocol`, protocol) in requests header
  //    list.
  for (const protocol of protocols) {
    request.headersList.append('sec-websocket-protocol', protocol)
  }

  // 9. Let permessageDeflate be a user-agent defined
  //    "permessage-deflate" extension header value.
  // https://github.com/mozilla/gecko-dev/blob/ce78234f5e653a5d3916813ff990f053510227bc/netwerk/protocol/websocket/WebSocketChannel.cpp#L2673
  // TODO: enable once permessage-deflate is supported
  const permessageDeflate = '' // 'permessage-deflate; 15'

  // 10. Append (`Sec-WebSocket-Extensions`, permessageDeflate) to
  //     requests header list.
  // request.headersList.append('sec-websocket-extensions', permessageDeflate)

  // 11. Fetch request with useParallelQueue set to true, and
  //     processResponse given response being these steps:
  const controller = fetching({
    request,
    useParallelQueue: true,
    dispatcher: options.dispatcher ?? getGlobalDispatcher(),
    processResponse (response) {
      // 1. If response is a network error or its status is not 101,
      //    fail the WebSocket connection.
      if (response.type === 'error' || response.status !== 101) {
        failWebsocketConnection(ws, 'Received network error or non-101 status code.')
        return
      }

      // 2. If protocols is not the empty list and extracting header
      //    list values given `Sec-WebSocket-Protocol` and responses
      //    header list results in null, failure, or the empty byte
      //    sequence, then fail the WebSocket connection.
      if (protocols.length !== 0 && !response.headersList.get('Sec-WebSocket-Protocol')) {
        failWebsocketConnection(ws, 'Server did not respond with sent protocols.')
        return
      }

      // 3. Follow the requirements stated step 2 to step 6, inclusive,
      //    of the last set of steps in section 4.1 of The WebSocket
      //    Protocol to validate response. This either results in fail
      //    the WebSocket connection or the WebSocket connection is
      //    established.

      // 2. If the response lacks an |Upgrade| header field or the |Upgrade|
      //    header field contains a value that is not an ASCII case-
      //    insensitive match for the value "websocket", the client MUST
      //    _Fail the WebSocket Connection_.
      if (response.headersList.get('Upgrade')?.toLowerCase() !== 'websocket') {
        failWebsocketConnection(ws, 'Server did not set Upgrade header to "websocket".')
        return
      }

      // 3. If the response lacks a |Connection| header field or the
      //    |Connection| header field doesn't contain a token that is an
      //    ASCII case-insensitive match for the value "Upgrade", the client
      //    MUST _Fail the WebSocket Connection_.
      if (response.headersList.get('Connection')?.toLowerCase() !== 'upgrade') {
        failWebsocketConnection(ws, 'Server did not set Connection header to "upgrade".')
        return
      }

      // 4. If the response lacks a |Sec-WebSocket-Accept| header field or
      //    the |Sec-WebSocket-Accept| contains a value other than the
      //    base64-encoded SHA-1 of the concatenation of the |Sec-WebSocket-
      //    Key| (as a string, not base64-decoded) with the string "258EAFA5-
      //    E914-47DA-95CA-C5AB0DC85B11" but ignoring any leading and
      //    trailing whitespace, the client MUST _Fail the WebSocket
      //    Connection_.
      const secWSAccept = response.headersList.get('Sec-WebSocket-Accept')
      const digest = crypto.createHash('sha1').update(keyValue + uid).digest('base64')
      if (secWSAccept !== digest) {
        failWebsocketConnection(ws, 'Incorrect hash received in Sec-WebSocket-Accept header.')
        return
      }

      // 5. If the response includes a |Sec-WebSocket-Extensions| header
      //    field and this header field indicates the use of an extension
      //    that was not present in the client's handshake (the server has
      //    indicated an extension not requested by the client), the client
      //    MUST _Fail the WebSocket Connection_.  (The parsing of this
      //    header field to determine which extensions are requested is
      //    discussed in Section 9.1.)
      const secExtension = response.headersList.get('Sec-WebSocket-Extensions')

      if (secExtension !== null && secExtension !== permessageDeflate) {
        failWebsocketConnection(ws, 'Received different permessage-deflate than the one set.')
        return
      }

      // 6. If the response includes a |Sec-WebSocket-Protocol| header field
      //    and this header field indicates the use of a subprotocol that was
      //    not present in the client's handshake (the server has indicated a
      //    subprotocol not requested by the client), the client MUST _Fail
      //    the WebSocket Connection_.
      const secProtocol = response.headersList.get('Sec-WebSocket-Protocol')

      if (secProtocol !== null && secProtocol !== request.headersList.get('Sec-WebSocket-Protocol')) {
        failWebsocketConnection(ws, 'Protocol was not set in the opening handshake.')
        return
      }

      response.socket.on('data', onSocketData)
      response.socket.on('close', onSocketClose)
      response.socket.on('error', onSocketError)

      if (channels.open.hasSubscribers) {
        channels.open.publish({
          address: response.socket.address(),
          protocol: secProtocol,
          extensions: secExtension
        })
      }

      onEstablish(response)
    }
  })

  return controller
}

/**
 * @param {Buffer} chunk
 */
function onSocketData (chunk) {
  if (!this.ws[kByteParser].write(chunk)) {
    this.pause()
  }
}

/**
 * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol
 * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.4
 */
function onSocketClose () {
  const { ws } = this

  // If the TCP connection was closed after the
  // WebSocket closing handshake was completed, the WebSocket connection
  // is said to have been closed _cleanly_.
  const wasClean = ws[kSentClose] && ws[kReceivedClose]

  let code = 1005
  let reason = ''

  const result = ws[kByteParser].closingInfo

  if (result) {
    code = result.code ?? 1005
    reason = result.reason
  } else if (!ws[kSentClose]) {
    // If _The WebSocket
    // Connection is Closed_ and no Close control frame was received by the
    // endpoint (such as could occur if the underlying transport connection
    // is lost), _The WebSocket Connection Close Code_ is considered to be
    // 1006.
    code = 1006
  }

  // 1. Change the ready state to CLOSED (3).
  ws[kReadyState] = states.CLOSED

  // 2. If the user agent was required to fail the WebSocket
  //    connection, or if the WebSocket connection was closed
  //    after being flagged as full, fire an event named error
  //    at the WebSocket object.
  // TODO

  // 3. Fire an event named close at the WebSocket object,
  //    using CloseEvent, with the wasClean attribute
  //    initialized to true if the connection closed cleanly
  //    and false otherwise, the code attribute initialized to
  //    the WebSocket connection close code, and the reason
  //    attribute initialized to the result of applying UTF-8
  //    decode without BOM to the WebSocket connection close
  //    reason.
  fireEvent('close', ws, CloseEvent, {
    wasClean, code, reason
  })

  if (channels.close.hasSubscribers) {
    channels.close.publish({
      websocket: ws,
      code,
      reason
    })
  }
}

function onSocketError (error) {
  const { ws } = this

  ws[kReadyState] = states.CLOSING

  if (channels.socketError.hasSubscribers) {
    channels.socketError.publish(error)
  }

  this.destroy()
}

module.exports = {
  establishWebSocketConnection
}


/***/ }),

/***/ 5913:
/***/ ((module) => {

"use strict";


// This is a Globally Unique Identifier unique used
// to validate that the endpoint accepts websocket
// connections.
// See https://www.rfc-editor.org/rfc/rfc6455.html#section-1.3
const uid = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'

/** @type {PropertyDescriptor} */
const staticPropertyDescriptors = {
  enumerable: true,
  writable: false,
  configurable: false
}

const states = {
  CONNECTING: 0,
  OPEN: 1,
  CLOSING: 2,
  CLOSED: 3
}

const opcodes = {
  CONTINUATION: 0x0,
  TEXT: 0x1,
  BINARY: 0x2,
  CLOSE: 0x8,
  PING: 0x9,
  PONG: 0xA
}

const maxUnsigned16Bit = 2 ** 16 - 1 // 65535

const parserStates = {
  INFO: 0,
  PAYLOADLENGTH_16: 2,
  PAYLOADLENGTH_64: 3,
  READ_DATA: 4
}

const emptyBuffer = Buffer.allocUnsafe(0)

module.exports = {
  uid,
  staticPropertyDescriptors,
  states,
  opcodes,
  maxUnsigned16Bit,
  parserStates,
  emptyBuffer
}


/***/ }),

/***/ 6255:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { webidl } = __nccwpck_require__(4222)
const { kEnumerableProperty } = __nccwpck_require__(3440)
const { MessagePort } = __nccwpck_require__(8167)

/**
 * @see https://html.spec.whatwg.org/multipage/comms.html#messageevent
 */
class MessageEvent extends Event {
  #eventInit

  constructor (type, eventInitDict = {}) {
    webidl.argumentLengthCheck(arguments, 1, { header: 'MessageEvent constructor' })

    type = webidl.converters.DOMString(type)
    eventInitDict = webidl.converters.MessageEventInit(eventInitDict)

    super(type, eventInitDict)

    this.#eventInit = eventInitDict
  }

  get data () {
    webidl.brandCheck(this, MessageEvent)

    return this.#eventInit.data
  }

  get origin () {
    webidl.brandCheck(this, MessageEvent)

    return this.#eventInit.origin
  }

  get lastEventId () {
    webidl.brandCheck(this, MessageEvent)

    return this.#eventInit.lastEventId
  }

  get source () {
    webidl.brandCheck(this, MessageEvent)

    return this.#eventInit.source
  }

  get ports () {
    webidl.brandCheck(this, MessageEvent)

    if (!Object.isFrozen(this.#eventInit.ports)) {
      Object.freeze(this.#eventInit.ports)
    }

    return this.#eventInit.ports
  }

  initMessageEvent (
    type,
    bubbles = false,
    cancelable = false,
    data = null,
    origin = '',
    lastEventId = '',
    source = null,
    ports = []
  ) {
    webidl.brandCheck(this, MessageEvent)

    webidl.argumentLengthCheck(arguments, 1, { header: 'MessageEvent.initMessageEvent' })

    return new MessageEvent(type, {
      bubbles, cancelable, data, origin, lastEventId, source, ports
    })
  }
}

/**
 * @see https://websockets.spec.whatwg.org/#the-closeevent-interface
 */
class CloseEvent extends Event {
  #eventInit

  constructor (type, eventInitDict = {}) {
    webidl.argumentLengthCheck(arguments, 1, { header: 'CloseEvent constructor' })

    type = webidl.converters.DOMString(type)
    eventInitDict = webidl.converters.CloseEventInit(eventInitDict)

    super(type, eventInitDict)

    this.#eventInit = eventInitDict
  }

  get wasClean () {
    webidl.brandCheck(this, CloseEvent)

    return this.#eventInit.wasClean
  }

  get code () {
    webidl.brandCheck(this, CloseEvent)

    return this.#eventInit.code
  }

  get reason () {
    webidl.brandCheck(this, CloseEvent)

    return this.#eventInit.reason
  }
}

// https://html.spec.whatwg.org/multipage/webappapis.html#the-errorevent-interface
class ErrorEvent extends Event {
  #eventInit

  constructor (type, eventInitDict) {
    webidl.argumentLengthCheck(arguments, 1, { header: 'ErrorEvent constructor' })

    super(type, eventInitDict)

    type = webidl.converters.DOMString(type)
    eventInitDict = webidl.converters.ErrorEventInit(eventInitDict ?? {})

    this.#eventInit = eventInitDict
  }

  get message () {
    webidl.brandCheck(this, ErrorEvent)

    return this.#eventInit.message
  }

  get filename () {
    webidl.brandCheck(this, ErrorEvent)

    return this.#eventInit.filename
  }

  get lineno () {
    webidl.brandCheck(this, ErrorEvent)

    return this.#eventInit.lineno
  }

  get colno () {
    webidl.brandCheck(this, ErrorEvent)

    return this.#eventInit.colno
  }

  get error () {
    webidl.brandCheck(this, ErrorEvent)

    return this.#eventInit.error
  }
}

Object.defineProperties(MessageEvent.prototype, {
  [Symbol.toStringTag]: {
    value: 'MessageEvent',
    configurable: true
  },
  data: kEnumerableProperty,
  origin: kEnumerableProperty,
  lastEventId: kEnumerableProperty,
  source: kEnumerableProperty,
  ports: kEnumerableProperty,
  initMessageEvent: kEnumerableProperty
})

Object.defineProperties(CloseEvent.prototype, {
  [Symbol.toStringTag]: {
    value: 'CloseEvent',
    configurable: true
  },
  reason: kEnumerableProperty,
  code: kEnumerableProperty,
  wasClean: kEnumerableProperty
})

Object.defineProperties(ErrorEvent.prototype, {
  [Symbol.toStringTag]: {
    value: 'ErrorEvent',
    configurable: true
  },
  message: kEnumerableProperty,
  filename: kEnumerableProperty,
  lineno: kEnumerableProperty,
  colno: kEnumerableProperty,
  error: kEnumerableProperty
})

webidl.converters.MessagePort = webidl.interfaceConverter(MessagePort)

webidl.converters['sequence<MessagePort>'] = webidl.sequenceConverter(
  webidl.converters.MessagePort
)

const eventInit = [
  {
    key: 'bubbles',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'cancelable',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'composed',
    converter: webidl.converters.boolean,
    defaultValue: false
  }
]

webidl.converters.MessageEventInit = webidl.dictionaryConverter([
  ...eventInit,
  {
    key: 'data',
    converter: webidl.converters.any,
    defaultValue: null
  },
  {
    key: 'origin',
    converter: webidl.converters.USVString,
    defaultValue: ''
  },
  {
    key: 'lastEventId',
    converter: webidl.converters.DOMString,
    defaultValue: ''
  },
  {
    key: 'source',
    // Node doesn't implement WindowProxy or ServiceWorker, so the only
    // valid value for source is a MessagePort.
    converter: webidl.nullableConverter(webidl.converters.MessagePort),
    defaultValue: null
  },
  {
    key: 'ports',
    converter: webidl.converters['sequence<MessagePort>'],
    get defaultValue () {
      return []
    }
  }
])

webidl.converters.CloseEventInit = webidl.dictionaryConverter([
  ...eventInit,
  {
    key: 'wasClean',
    converter: webidl.converters.boolean,
    defaultValue: false
  },
  {
    key: 'code',
    converter: webidl.converters['unsigned short'],
    defaultValue: 0
  },
  {
    key: 'reason',
    converter: webidl.converters.USVString,
    defaultValue: ''
  }
])

webidl.converters.ErrorEventInit = webidl.dictionaryConverter([
  ...eventInit,
  {
    key: 'message',
    converter: webidl.converters.DOMString,
    defaultValue: ''
  },
  {
    key: 'filename',
    converter: webidl.converters.USVString,
    defaultValue: ''
  },
  {
    key: 'lineno',
    converter: webidl.converters['unsigned long'],
    defaultValue: 0
  },
  {
    key: 'colno',
    converter: webidl.converters['unsigned long'],
    defaultValue: 0
  },
  {
    key: 'error',
    converter: webidl.converters.any
  }
])

module.exports = {
  MessageEvent,
  CloseEvent,
  ErrorEvent
}


/***/ }),

/***/ 1237:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { maxUnsigned16Bit } = __nccwpck_require__(5913)

/** @type {import('crypto')} */
let crypto
try {
  crypto = __nccwpck_require__(6982)
} catch {

}

class WebsocketFrameSend {
  /**
   * @param {Buffer|undefined} data
   */
  constructor (data) {
    this.frameData = data
    this.maskKey = crypto.randomBytes(4)
  }

  createFrame (opcode) {
    const bodyLength = this.frameData?.byteLength ?? 0

    /** @type {number} */
    let payloadLength = bodyLength // 0-125
    let offset = 6

    if (bodyLength > maxUnsigned16Bit) {
      offset += 8 // payload length is next 8 bytes
      payloadLength = 127
    } else if (bodyLength > 125) {
      offset += 2 // payload length is next 2 bytes
      payloadLength = 126
    }

    const buffer = Buffer.allocUnsafe(bodyLength + offset)

    // Clear first 2 bytes, everything else is overwritten
    buffer[0] = buffer[1] = 0
    buffer[0] |= 0x80 // FIN
    buffer[0] = (buffer[0] & 0xF0) + opcode // opcode

    /*! ws. MIT License. Einar Otto Stangvik <einaros@gmail.com> */
    buffer[offset - 4] = this.maskKey[0]
    buffer[offset - 3] = this.maskKey[1]
    buffer[offset - 2] = this.maskKey[2]
    buffer[offset - 1] = this.maskKey[3]

    buffer[1] = payloadLength

    if (payloadLength === 126) {
      buffer.writeUInt16BE(bodyLength, 2)
    } else if (payloadLength === 127) {
      // Clear extended payload length
      buffer[2] = buffer[3] = 0
      buffer.writeUIntBE(bodyLength, 4, 6)
    }

    buffer[1] |= 0x80 // MASK

    // mask body
    for (let i = 0; i < bodyLength; i++) {
      buffer[offset + i] = this.frameData[i] ^ this.maskKey[i % 4]
    }

    return buffer
  }
}

module.exports = {
  WebsocketFrameSend
}


/***/ }),

/***/ 3171:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { Writable } = __nccwpck_require__(2203)
const diagnosticsChannel = __nccwpck_require__(1637)
const { parserStates, opcodes, states, emptyBuffer } = __nccwpck_require__(5913)
const { kReadyState, kSentClose, kResponse, kReceivedClose } = __nccwpck_require__(2933)
const { isValidStatusCode, failWebsocketConnection, websocketMessageReceived } = __nccwpck_require__(3574)
const { WebsocketFrameSend } = __nccwpck_require__(1237)

// This code was influenced by ws released under the MIT license.
// Copyright (c) 2011 Einar Otto Stangvik <einaros@gmail.com>
// Copyright (c) 2013 Arnout Kazemier and contributors
// Copyright (c) 2016 Luigi Pinca and contributors

const channels = {}
channels.ping = diagnosticsChannel.channel('undici:websocket:ping')
channels.pong = diagnosticsChannel.channel('undici:websocket:pong')

class ByteParser extends Writable {
  #buffers = []
  #byteOffset = 0

  #state = parserStates.INFO

  #info = {}
  #fragments = []

  constructor (ws) {
    super()

    this.ws = ws
  }

  /**
   * @param {Buffer} chunk
   * @param {() => void} callback
   */
  _write (chunk, _, callback) {
    this.#buffers.push(chunk)
    this.#byteOffset += chunk.length

    this.run(callback)
  }

  /**
   * Runs whenever a new chunk is received.
   * Callback is called whenever there are no more chunks buffering,
   * or not enough bytes are buffered to parse.
   */
  run (callback) {
    while (true) {
      if (this.#state === parserStates.INFO) {
        // If there aren't enough bytes to parse the payload length, etc.
        if (this.#byteOffset < 2) {
          return callback()
        }

        const buffer = this.consume(2)

        this.#info.fin = (buffer[0] & 0x80) !== 0
        this.#info.opcode = buffer[0] & 0x0F

        // If we receive a fragmented message, we use the type of the first
        // frame to parse the full message as binary/text, when it's terminated
        this.#info.originalOpcode ??= this.#info.opcode

        this.#info.fragmented = !this.#info.fin && this.#info.opcode !== opcodes.CONTINUATION

        if (this.#info.fragmented && this.#info.opcode !== opcodes.BINARY && this.#info.opcode !== opcodes.TEXT) {
          // Only text and binary frames can be fragmented
          failWebsocketConnection(this.ws, 'Invalid frame type was fragmented.')
          return
        }

        const payloadLength = buffer[1] & 0x7F

        if (payloadLength <= 125) {
          this.#info.payloadLength = payloadLength
          this.#state = parserStates.READ_DATA
        } else if (payloadLength === 126) {
          this.#state = parserStates.PAYLOADLENGTH_16
        } else if (payloadLength === 127) {
          this.#state = parserStates.PAYLOADLENGTH_64
        }

        if (this.#info.fragmented && payloadLength > 125) {
          // A fragmented frame can't be fragmented itself
          failWebsocketConnection(this.ws, 'Fragmented frame exceeded 125 bytes.')
          return
        } else if (
          (this.#info.opcode === opcodes.PING ||
            this.#info.opcode === opcodes.PONG ||
            this.#info.opcode === opcodes.CLOSE) &&
          payloadLength > 125
        ) {
          // Control frames can have a payload length of 125 bytes MAX
          failWebsocketConnection(this.ws, 'Payload length for control frame exceeded 125 bytes.')
          return
        } else if (this.#info.opcode === opcodes.CLOSE) {
          if (payloadLength === 1) {
            failWebsocketConnection(this.ws, 'Received close frame with a 1-byte body.')
            return
          }

          const body = this.consume(payloadLength)

          this.#info.closeInfo = this.parseCloseBody(false, body)

          if (!this.ws[kSentClose]) {
            // If an endpoint receives a Close frame and did not previously send a
            // Close frame, the endpoint MUST send a Close frame in response.  (When
            // sending a Close frame in response, the endpoint typically echos the
            // status code it received.)
            const body = Buffer.allocUnsafe(2)
            body.writeUInt16BE(this.#info.closeInfo.code, 0)
            const closeFrame = new WebsocketFrameSend(body)

            this.ws[kResponse].socket.write(
              closeFrame.createFrame(opcodes.CLOSE),
              (err) => {
                if (!err) {
                  this.ws[kSentClose] = true
                }
              }
            )
          }

          // Upon either sending or receiving a Close control frame, it is said
          // that _The WebSocket Closing Handshake is Started_ and that the
          // WebSocket connection is in the CLOSING state.
          this.ws[kReadyState] = states.CLOSING
          this.ws[kReceivedClose] = true

          this.end()

          return
        } else if (this.#info.opcode === opcodes.PING) {
          // Upon receipt of a Ping frame, an endpoint MUST send a Pong frame in
          // response, unless it already received a Close frame.
          // A Pong frame sent in response to a Ping frame must have identical
          // "Application data"

          const body = this.consume(payloadLength)

          if (!this.ws[kReceivedClose]) {
            const frame = new WebsocketFrameSend(body)

            this.ws[kResponse].socket.write(frame.createFrame(opcodes.PONG))

            if (channels.ping.hasSubscribers) {
              channels.ping.publish({
                payload: body
              })
            }
          }

          this.#state = parserStates.INFO

          if (this.#byteOffset > 0) {
            continue
          } else {
            callback()
            return
          }
        } else if (this.#info.opcode === opcodes.PONG) {
          // A Pong frame MAY be sent unsolicited.  This serves as a
          // unidirectional heartbeat.  A response to an unsolicited Pong frame is
          // not expected.

          const body = this.consume(payloadLength)

          if (channels.pong.hasSubscribers) {
            channels.pong.publish({
              payload: body
            })
          }

          if (this.#byteOffset > 0) {
            continue
          } else {
            callback()
            return
          }
        }
      } else if (this.#state === parserStates.PAYLOADLENGTH_16) {
        if (this.#byteOffset < 2) {
          return callback()
        }

        const buffer = this.consume(2)

        this.#info.payloadLength = buffer.readUInt16BE(0)
        this.#state = parserStates.READ_DATA
      } else if (this.#state === parserStates.PAYLOADLENGTH_64) {
        if (this.#byteOffset < 8) {
          return callback()
        }

        const buffer = this.consume(8)
        const upper = buffer.readUInt32BE(0)

        // 2^31 is the maxinimum bytes an arraybuffer can contain
        // on 32-bit systems. Although, on 64-bit systems, this is
        // 2^53-1 bytes.
        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length
        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/common/globals.h;drc=1946212ac0100668f14eb9e2843bdd846e510a1e;bpv=1;bpt=1;l=1275
        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-array-buffer.h;l=34;drc=1946212ac0100668f14eb9e2843bdd846e510a1e
        if (upper > 2 ** 31 - 1) {
          failWebsocketConnection(this.ws, 'Received payload length > 2^31 bytes.')
          return
        }

        const lower = buffer.readUInt32BE(4)

        this.#info.payloadLength = (upper << 8) + lower
        this.#state = parserStates.READ_DATA
      } else if (this.#state === parserStates.READ_DATA) {
        if (this.#byteOffset < this.#info.payloadLength) {
          // If there is still more data in this chunk that needs to be read
          return callback()
        } else if (this.#byteOffset >= this.#info.payloadLength) {
          // If the server sent multiple frames in a single chunk

          const body = this.consume(this.#info.payloadLength)

          this.#fragments.push(body)

          // If the frame is unfragmented, or a fragmented frame was terminated,
          // a message was received
          if (!this.#info.fragmented || (this.#info.fin && this.#info.opcode === opcodes.CONTINUATION)) {
            const fullMessage = Buffer.concat(this.#fragments)

            websocketMessageReceived(this.ws, this.#info.originalOpcode, fullMessage)

            this.#info = {}
            this.#fragments.length = 0
          }

          this.#state = parserStates.INFO
        }
      }

      if (this.#byteOffset > 0) {
        continue
      } else {
        callback()
        break
      }
    }
  }

  /**
   * Take n bytes from the buffered Buffers
   * @param {number} n
   * @returns {Buffer|null}
   */
  consume (n) {
    if (n > this.#byteOffset) {
      return null
    } else if (n === 0) {
      return emptyBuffer
    }

    if (this.#buffers[0].length === n) {
      this.#byteOffset -= this.#buffers[0].length
      return this.#buffers.shift()
    }

    const buffer = Buffer.allocUnsafe(n)
    let offset = 0

    while (offset !== n) {
      const next = this.#buffers[0]
      const { length } = next

      if (length + offset === n) {
        buffer.set(this.#buffers.shift(), offset)
        break
      } else if (length + offset > n) {
        buffer.set(next.subarray(0, n - offset), offset)
        this.#buffers[0] = next.subarray(n - offset)
        break
      } else {
        buffer.set(this.#buffers.shift(), offset)
        offset += next.length
      }
    }

    this.#byteOffset -= n

    return buffer
  }

  parseCloseBody (onlyCode, data) {
    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.5
    /** @type {number|undefined} */
    let code

    if (data.length >= 2) {
      // _The WebSocket Connection Close Code_ is
      // defined as the status code (Section 7.4) contained in the first Close
      // control frame received by the application
      code = data.readUInt16BE(0)
    }

    if (onlyCode) {
      if (!isValidStatusCode(code)) {
        return null
      }

      return { code }
    }

    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.6
    /** @type {Buffer} */
    let reason = data.subarray(2)

    // Remove BOM
    if (reason[0] === 0xEF && reason[1] === 0xBB && reason[2] === 0xBF) {
      reason = reason.subarray(3)
    }

    if (code !== undefined && !isValidStatusCode(code)) {
      return null
    }

    try {
      // TODO: optimize this
      reason = new TextDecoder('utf-8', { fatal: true }).decode(reason)
    } catch {
      return null
    }

    return { code, reason }
  }

  get closingInfo () {
    return this.#info.closeInfo
  }
}

module.exports = {
  ByteParser
}


/***/ }),

/***/ 2933:
/***/ ((module) => {

"use strict";


module.exports = {
  kWebSocketURL: Symbol('url'),
  kReadyState: Symbol('ready state'),
  kController: Symbol('controller'),
  kResponse: Symbol('response'),
  kBinaryType: Symbol('binary type'),
  kSentClose: Symbol('sent close'),
  kReceivedClose: Symbol('received close'),
  kByteParser: Symbol('byte parser')
}


/***/ }),

/***/ 3574:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { kReadyState, kController, kResponse, kBinaryType, kWebSocketURL } = __nccwpck_require__(2933)
const { states, opcodes } = __nccwpck_require__(5913)
const { MessageEvent, ErrorEvent } = __nccwpck_require__(6255)

/* globals Blob */

/**
 * @param {import('./websocket').WebSocket} ws
 */
function isEstablished (ws) {
  // If the server's response is validated as provided for above, it is
  // said that _The WebSocket Connection is Established_ and that the
  // WebSocket Connection is in the OPEN state.
  return ws[kReadyState] === states.OPEN
}

/**
 * @param {import('./websocket').WebSocket} ws
 */
function isClosing (ws) {
  // Upon either sending or receiving a Close control frame, it is said
  // that _The WebSocket Closing Handshake is Started_ and that the
  // WebSocket connection is in the CLOSING state.
  return ws[kReadyState] === states.CLOSING
}

/**
 * @param {import('./websocket').WebSocket} ws
 */
function isClosed (ws) {
  return ws[kReadyState] === states.CLOSED
}

/**
 * @see https://dom.spec.whatwg.org/#concept-event-fire
 * @param {string} e
 * @param {EventTarget} target
 * @param {EventInit | undefined} eventInitDict
 */
function fireEvent (e, target, eventConstructor = Event, eventInitDict) {
  // 1. If eventConstructor is not given, then let eventConstructor be Event.

  // 2. Let event be the result of creating an event given eventConstructor,
  //    in the relevant realm of target.
  // 3. Initialize events type attribute to e.
  const event = new eventConstructor(e, eventInitDict) // eslint-disable-line new-cap

  // 4. Initialize any other IDL attributes of event as described in the
  //    invocation of this algorithm.

  // 5. Return the result of dispatching event at target, with legacy target
  //    override flag set if set.
  target.dispatchEvent(event)
}

/**
 * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol
 * @param {import('./websocket').WebSocket} ws
 * @param {number} type Opcode
 * @param {Buffer} data application data
 */
function websocketMessageReceived (ws, type, data) {
  // 1. If ready state is not OPEN (1), then return.
  if (ws[kReadyState] !== states.OPEN) {
    return
  }

  // 2. Let dataForEvent be determined by switching on type and binary type:
  let dataForEvent

  if (type === opcodes.TEXT) {
    // -> type indicates that the data is Text
    //      a new DOMString containing data
    try {
      dataForEvent = new TextDecoder('utf-8', { fatal: true }).decode(data)
    } catch {
      failWebsocketConnection(ws, 'Received invalid UTF-8 in text frame.')
      return
    }
  } else if (type === opcodes.BINARY) {
    if (ws[kBinaryType] === 'blob') {
      // -> type indicates that the data is Binary and binary type is "blob"
      //      a new Blob object, created in the relevant Realm of the WebSocket
      //      object, that represents data as its raw data
      dataForEvent = new Blob([data])
    } else {
      // -> type indicates that the data is Binary and binary type is "arraybuffer"
      //      a new ArrayBuffer object, created in the relevant Realm of the
      //      WebSocket object, whose contents are data
      dataForEvent = new Uint8Array(data).buffer
    }
  }

  // 3. Fire an event named message at the WebSocket object, using MessageEvent,
  //    with the origin attribute initialized to the serialization of the WebSocket
  //    objects url's origin, and the data attribute initialized to dataForEvent.
  fireEvent('message', ws, MessageEvent, {
    origin: ws[kWebSocketURL].origin,
    data: dataForEvent
  })
}

/**
 * @see https://datatracker.ietf.org/doc/html/rfc6455
 * @see https://datatracker.ietf.org/doc/html/rfc2616
 * @see https://bugs.chromium.org/p/chromium/issues/detail?id=398407
 * @param {string} protocol
 */
function isValidSubprotocol (protocol) {
  // If present, this value indicates one
  // or more comma-separated subprotocol the client wishes to speak,
  // ordered by preference.  The elements that comprise this value
  // MUST be non-empty strings with characters in the range U+0021 to
  // U+007E not including separator characters as defined in
  // [RFC2616] and MUST all be unique strings.
  if (protocol.length === 0) {
    return false
  }

  for (const char of protocol) {
    const code = char.charCodeAt(0)

    if (
      code < 0x21 ||
      code > 0x7E ||
      char === '(' ||
      char === ')' ||
      char === '<' ||
      char === '>' ||
      char === '@' ||
      char === ',' ||
      char === ';' ||
      char === ':' ||
      char === '\\' ||
      char === '"' ||
      char === '/' ||
      char === '[' ||
      char === ']' ||
      char === '?' ||
      char === '=' ||
      char === '{' ||
      char === '}' ||
      code === 32 || // SP
      code === 9 // HT
    ) {
      return false
    }
  }

  return true
}

/**
 * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7-4
 * @param {number} code
 */
function isValidStatusCode (code) {
  if (code >= 1000 && code < 1015) {
    return (
      code !== 1004 && // reserved
      code !== 1005 && // "MUST NOT be set as a status code"
      code !== 1006 // "MUST NOT be set as a status code"
    )
  }

  return code >= 3000 && code <= 4999
}

/**
 * @param {import('./websocket').WebSocket} ws
 * @param {string|undefined} reason
 */
function failWebsocketConnection (ws, reason) {
  const { [kController]: controller, [kResponse]: response } = ws

  controller.abort()

  if (response?.socket && !response.socket.destroyed) {
    response.socket.destroy()
  }

  if (reason) {
    fireEvent('error', ws, ErrorEvent, {
      error: new Error(reason)
    })
  }
}

module.exports = {
  isEstablished,
  isClosing,
  isClosed,
  fireEvent,
  isValidSubprotocol,
  isValidStatusCode,
  failWebsocketConnection,
  websocketMessageReceived
}


/***/ }),

/***/ 5171:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const { webidl } = __nccwpck_require__(4222)
const { DOMException } = __nccwpck_require__(7326)
const { URLSerializer } = __nccwpck_require__(4322)
const { getGlobalOrigin } = __nccwpck_require__(5628)
const { staticPropertyDescriptors, states, opcodes, emptyBuffer } = __nccwpck_require__(5913)
const {
  kWebSocketURL,
  kReadyState,
  kController,
  kBinaryType,
  kResponse,
  kSentClose,
  kByteParser
} = __nccwpck_require__(2933)
const { isEstablished, isClosing, isValidSubprotocol, failWebsocketConnection, fireEvent } = __nccwpck_require__(3574)
const { establishWebSocketConnection } = __nccwpck_require__(8550)
const { WebsocketFrameSend } = __nccwpck_require__(1237)
const { ByteParser } = __nccwpck_require__(3171)
const { kEnumerableProperty, isBlobLike } = __nccwpck_require__(3440)
const { getGlobalDispatcher } = __nccwpck_require__(2581)
const { types } = __nccwpck_require__(9023)

let experimentalWarned = false

// https://websockets.spec.whatwg.org/#interface-definition
class WebSocket extends EventTarget {
  #events = {
    open: null,
    error: null,
    close: null,
    message: null
  }

  #bufferedAmount = 0
  #protocol = ''
  #extensions = ''

  /**
   * @param {string} url
   * @param {string|string[]} protocols
   */
  constructor (url, protocols = []) {
    super()

    webidl.argumentLengthCheck(arguments, 1, { header: 'WebSocket constructor' })

    if (!experimentalWarned) {
      experimentalWarned = true
      process.emitWarning('WebSockets are experimental, expect them to change at any time.', {
        code: 'UNDICI-WS'
      })
    }

    const options = webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'](protocols)

    url = webidl.converters.USVString(url)
    protocols = options.protocols

    // 1. Let baseURL be this's relevant settings object's API base URL.
    const baseURL = getGlobalOrigin()

    // 1. Let urlRecord be the result of applying the URL parser to url with baseURL.
    let urlRecord

    try {
      urlRecord = new URL(url, baseURL)
    } catch (e) {
      // 3. If urlRecord is failure, then throw a "SyntaxError" DOMException.
      throw new DOMException(e, 'SyntaxError')
    }

    // 4. If urlRecords scheme is "http", then set urlRecords scheme to "ws".
    if (urlRecord.protocol === 'http:') {
      urlRecord.protocol = 'ws:'
    } else if (urlRecord.protocol === 'https:') {
      // 5. Otherwise, if urlRecords scheme is "https", set urlRecords scheme to "wss".
      urlRecord.protocol = 'wss:'
    }

    // 6. If urlRecords scheme is not "ws" or "wss", then throw a "SyntaxError" DOMException.
    if (urlRecord.protocol !== 'ws:' && urlRecord.protocol !== 'wss:') {
      throw new DOMException(
        `Expected a ws: or wss: protocol, got ${urlRecord.protocol}`,
        'SyntaxError'
      )
    }

    // 7. If urlRecords fragment is non-null, then throw a "SyntaxError"
    //    DOMException.
    if (urlRecord.hash || urlRecord.href.endsWith('#')) {
      throw new DOMException('Got fragment', 'SyntaxError')
    }

    // 8. If protocols is a string, set protocols to a sequence consisting
    //    of just that string.
    if (typeof protocols === 'string') {
      protocols = [protocols]
    }

    // 9. If any of the values in protocols occur more than once or otherwise
    //    fail to match the requirements for elements that comprise the value
    //    of `Sec-WebSocket-Protocol` fields as defined by The WebSocket
    //    protocol, then throw a "SyntaxError" DOMException.
    if (protocols.length !== new Set(protocols.map(p => p.toLowerCase())).size) {
      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')
    }

    if (protocols.length > 0 && !protocols.every(p => isValidSubprotocol(p))) {
      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')
    }

    // 10. Set this's url to urlRecord.
    this[kWebSocketURL] = new URL(urlRecord.href)

    // 11. Let client be this's relevant settings object.

    // 12. Run this step in parallel:

    //    1. Establish a WebSocket connection given urlRecord, protocols,
    //       and client.
    this[kController] = establishWebSocketConnection(
      urlRecord,
      protocols,
      this,
      (response) => this.#onConnectionEstablished(response),
      options
    )

    // Each WebSocket object has an associated ready state, which is a
    // number representing the state of the connection. Initially it must
    // be CONNECTING (0).
    this[kReadyState] = WebSocket.CONNECTING

    // The extensions attribute must initially return the empty string.

    // The protocol attribute must initially return the empty string.

    // Each WebSocket object has an associated binary type, which is a
    // BinaryType. Initially it must be "blob".
    this[kBinaryType] = 'blob'
  }

  /**
   * @see https://websockets.spec.whatwg.org/#dom-websocket-close
   * @param {number|undefined} code
   * @param {string|undefined} reason
   */
  close (code = undefined, reason = undefined) {
    webidl.brandCheck(this, WebSocket)

    if (code !== undefined) {
      code = webidl.converters['unsigned short'](code, { clamp: true })
    }

    if (reason !== undefined) {
      reason = webidl.converters.USVString(reason)
    }

    // 1. If code is present, but is neither an integer equal to 1000 nor an
    //    integer in the range 3000 to 4999, inclusive, throw an
    //    "InvalidAccessError" DOMException.
    if (code !== undefined) {
      if (code !== 1000 && (code < 3000 || code > 4999)) {
        throw new DOMException('invalid code', 'InvalidAccessError')
      }
    }

    let reasonByteLength = 0

    // 2. If reason is present, then run these substeps:
    if (reason !== undefined) {
      // 1. Let reasonBytes be the result of encoding reason.
      // 2. If reasonBytes is longer than 123 bytes, then throw a
      //    "SyntaxError" DOMException.
      reasonByteLength = Buffer.byteLength(reason)

      if (reasonByteLength > 123) {
        throw new DOMException(
          `Reason must be less than 123 bytes; received ${reasonByteLength}`,
          'SyntaxError'
        )
      }
    }

    // 3. Run the first matching steps from the following list:
    if (this[kReadyState] === WebSocket.CLOSING || this[kReadyState] === WebSocket.CLOSED) {
      // If this's ready state is CLOSING (2) or CLOSED (3)
      // Do nothing.
    } else if (!isEstablished(this)) {
      // If the WebSocket connection is not yet established
      // Fail the WebSocket connection and set this's ready state
      // to CLOSING (2).
      failWebsocketConnection(this, 'Connection was closed before it was established.')
      this[kReadyState] = WebSocket.CLOSING
    } else if (!isClosing(this)) {
      // If the WebSocket closing handshake has not yet been started
      // Start the WebSocket closing handshake and set this's ready
      // state to CLOSING (2).
      // - If neither code nor reason is present, the WebSocket Close
      //   message must not have a body.
      // - If code is present, then the status code to use in the
      //   WebSocket Close message must be the integer given by code.
      // - If reason is also present, then reasonBytes must be
      //   provided in the Close message after the status code.

      const frame = new WebsocketFrameSend()

      // If neither code nor reason is present, the WebSocket Close
      // message must not have a body.

      // If code is present, then the status code to use in the
      // WebSocket Close message must be the integer given by code.
      if (code !== undefined && reason === undefined) {
        frame.frameData = Buffer.allocUnsafe(2)
        frame.frameData.writeUInt16BE(code, 0)
      } else if (code !== undefined && reason !== undefined) {
        // If reason is also present, then reasonBytes must be
        // provided in the Close message after the status code.
        frame.frameData = Buffer.allocUnsafe(2 + reasonByteLength)
        frame.frameData.writeUInt16BE(code, 0)
        // the body MAY contain UTF-8-encoded data with value /reason/
        frame.frameData.write(reason, 2, 'utf-8')
      } else {
        frame.frameData = emptyBuffer
      }

      /** @type {import('stream').Duplex} */
      const socket = this[kResponse].socket

      socket.write(frame.createFrame(opcodes.CLOSE), (err) => {
        if (!err) {
          this[kSentClose] = true
        }
      })

      // Upon either sending or receiving a Close control frame, it is said
      // that _The WebSocket Closing Handshake is Started_ and that the
      // WebSocket connection is in the CLOSING state.
      this[kReadyState] = states.CLOSING
    } else {
      // Otherwise
      // Set this's ready state to CLOSING (2).
      this[kReadyState] = WebSocket.CLOSING
    }
  }

  /**
   * @see https://websockets.spec.whatwg.org/#dom-websocket-send
   * @param {NodeJS.TypedArray|ArrayBuffer|Blob|string} data
   */
  send (data) {
    webidl.brandCheck(this, WebSocket)

    webidl.argumentLengthCheck(arguments, 1, { header: 'WebSocket.send' })

    data = webidl.converters.WebSocketSendData(data)

    // 1. If this's ready state is CONNECTING, then throw an
    //    "InvalidStateError" DOMException.
    if (this[kReadyState] === WebSocket.CONNECTING) {
      throw new DOMException('Sent before connected.', 'InvalidStateError')
    }

    // 2. Run the appropriate set of steps from the following list:
    // https://datatracker.ietf.org/doc/html/rfc6455#section-6.1
    // https://datatracker.ietf.org/doc/html/rfc6455#section-5.2

    if (!isEstablished(this) || isClosing(this)) {
      return
    }

    /** @type {import('stream').Duplex} */
    const socket = this[kResponse].socket

    // If data is a string
    if (typeof data === 'string') {
      // If the WebSocket connection is established and the WebSocket
      // closing handshake has not yet started, then the user agent
      // must send a WebSocket Message comprised of the data argument
      // using a text frame opcode; if the data cannot be sent, e.g.
      // because it would need to be buffered but the buffer is full,
      // the user agent must flag the WebSocket as full and then close
      // the WebSocket connection. Any invocation of this method with a
      // string argument that does not throw an exception must increase
      // the bufferedAmount attribute by the number of bytes needed to
      // express the argument as UTF-8.

      const value = Buffer.from(data)
      const frame = new WebsocketFrameSend(value)
      const buffer = frame.createFrame(opcodes.TEXT)

      this.#bufferedAmount += value.byteLength
      socket.write(buffer, () => {
        this.#bufferedAmount -= value.byteLength
      })
    } else if (types.isArrayBuffer(data)) {
      // If the WebSocket connection is established, and the WebSocket
      // closing handshake has not yet started, then the user agent must
      // send a WebSocket Message comprised of data using a binary frame
      // opcode; if the data cannot be sent, e.g. because it would need
      // to be buffered but the buffer is full, the user agent must flag
      // the WebSocket as full and then close the WebSocket connection.
      // The data to be sent is the data stored in the buffer described
      // by the ArrayBuffer object. Any invocation of this method with an
      // ArrayBuffer argument that does not throw an exception must
      // increase the bufferedAmount attribute by the length of the
      // ArrayBuffer in bytes.

      const value = Buffer.from(data)
      const frame = new WebsocketFrameSend(value)
      const buffer = frame.createFrame(opcodes.BINARY)

      this.#bufferedAmount += value.byteLength
      socket.write(buffer, () => {
        this.#bufferedAmount -= value.byteLength
      })
    } else if (ArrayBuffer.isView(data)) {
      // If the WebSocket connection is established, and the WebSocket
      // closing handshake has not yet started, then the user agent must
      // send a WebSocket Message comprised of data using a binary frame
      // opcode; if the data cannot be sent, e.g. because it would need to
      // be buffered but the buffer is full, the user agent must flag the
      // WebSocket as full and then close the WebSocket connection. The
      // data to be sent is the data stored in the section of the buffer
      // described by the ArrayBuffer object that data references. Any
      // invocation of this method with this kind of argument that does
      // not throw an exception must increase the bufferedAmount attribute
      // by the length of datas buffer in bytes.

      const ab = Buffer.from(data, data.byteOffset, data.byteLength)

      const frame = new WebsocketFrameSend(ab)
      const buffer = frame.createFrame(opcodes.BINARY)

      this.#bufferedAmount += ab.byteLength
      socket.write(buffer, () => {
        this.#bufferedAmount -= ab.byteLength
      })
    } else if (isBlobLike(data)) {
      // If the WebSocket connection is established, and the WebSocket
      // closing handshake has not yet started, then the user agent must
      // send a WebSocket Message comprised of data using a binary frame
      // opcode; if the data cannot be sent, e.g. because it would need to
      // be buffered but the buffer is full, the user agent must flag the
      // WebSocket as full and then close the WebSocket connection. The data
      // to be sent is the raw data represented by the Blob object. Any
      // invocation of this method with a Blob argument that does not throw
      // an exception must increase the bufferedAmount attribute by the size
      // of the Blob objects raw data, in bytes.

      const frame = new WebsocketFrameSend()

      data.arrayBuffer().then((ab) => {
        const value = Buffer.from(ab)
        frame.frameData = value
        const buffer = frame.createFrame(opcodes.BINARY)

        this.#bufferedAmount += value.byteLength
        socket.write(buffer, () => {
          this.#bufferedAmount -= value.byteLength
        })
      })
    }
  }

  get readyState () {
    webidl.brandCheck(this, WebSocket)

    // The readyState getter steps are to return this's ready state.
    return this[kReadyState]
  }

  get bufferedAmount () {
    webidl.brandCheck(this, WebSocket)

    return this.#bufferedAmount
  }

  get url () {
    webidl.brandCheck(this, WebSocket)

    // The url getter steps are to return this's url, serialized.
    return URLSerializer(this[kWebSocketURL])
  }

  get extensions () {
    webidl.brandCheck(this, WebSocket)

    return this.#extensions
  }

  get protocol () {
    webidl.brandCheck(this, WebSocket)

    return this.#protocol
  }

  get onopen () {
    webidl.brandCheck(this, WebSocket)

    return this.#events.open
  }

  set onopen (fn) {
    webidl.brandCheck(this, WebSocket)

    if (this.#events.open) {
      this.removeEventListener('open', this.#events.open)
    }

    if (typeof fn === 'function') {
      this.#events.open = fn
      this.addEventListener('open', fn)
    } else {
      this.#events.open = null
    }
  }

  get onerror () {
    webidl.brandCheck(this, WebSocket)

    return this.#events.error
  }

  set onerror (fn) {
    webidl.brandCheck(this, WebSocket)

    if (this.#events.error) {
      this.removeEventListener('error', this.#events.error)
    }

    if (typeof fn === 'function') {
      this.#events.error = fn
      this.addEventListener('error', fn)
    } else {
      this.#events.error = null
    }
  }

  get onclose () {
    webidl.brandCheck(this, WebSocket)

    return this.#events.close
  }

  set onclose (fn) {
    webidl.brandCheck(this, WebSocket)

    if (this.#events.close) {
      this.removeEventListener('close', this.#events.close)
    }

    if (typeof fn === 'function') {
      this.#events.close = fn
      this.addEventListener('close', fn)
    } else {
      this.#events.close = null
    }
  }

  get onmessage () {
    webidl.brandCheck(this, WebSocket)

    return this.#events.message
  }

  set onmessage (fn) {
    webidl.brandCheck(this, WebSocket)

    if (this.#events.message) {
      this.removeEventListener('message', this.#events.message)
    }

    if (typeof fn === 'function') {
      this.#events.message = fn
      this.addEventListener('message', fn)
    } else {
      this.#events.message = null
    }
  }

  get binaryType () {
    webidl.brandCheck(this, WebSocket)

    return this[kBinaryType]
  }

  set binaryType (type) {
    webidl.brandCheck(this, WebSocket)

    if (type !== 'blob' && type !== 'arraybuffer') {
      this[kBinaryType] = 'blob'
    } else {
      this[kBinaryType] = type
    }
  }

  /**
   * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol
   */
  #onConnectionEstablished (response) {
    // processResponse is called when the "responses header list has been received and initialized."
    // once this happens, the connection is open
    this[kResponse] = response

    const parser = new ByteParser(this)
    parser.on('drain', function onParserDrain () {
      this.ws[kResponse].socket.resume()
    })

    response.socket.ws = this
    this[kByteParser] = parser

    // 1. Change the ready state to OPEN (1).
    this[kReadyState] = states.OPEN

    // 2. Change the extensions attributes value to the extensions in use, if
    //    it is not the null value.
    // https://datatracker.ietf.org/doc/html/rfc6455#section-9.1
    const extensions = response.headersList.get('sec-websocket-extensions')

    if (extensions !== null) {
      this.#extensions = extensions
    }

    // 3. Change the protocol attributes value to the subprotocol in use, if
    //    it is not the null value.
    // https://datatracker.ietf.org/doc/html/rfc6455#section-1.9
    const protocol = response.headersList.get('sec-websocket-protocol')

    if (protocol !== null) {
      this.#protocol = protocol
    }

    // 4. Fire an event named open at the WebSocket object.
    fireEvent('open', this)
  }
}

// https://websockets.spec.whatwg.org/#dom-websocket-connecting
WebSocket.CONNECTING = WebSocket.prototype.CONNECTING = states.CONNECTING
// https://websockets.spec.whatwg.org/#dom-websocket-open
WebSocket.OPEN = WebSocket.prototype.OPEN = states.OPEN
// https://websockets.spec.whatwg.org/#dom-websocket-closing
WebSocket.CLOSING = WebSocket.prototype.CLOSING = states.CLOSING
// https://websockets.spec.whatwg.org/#dom-websocket-closed
WebSocket.CLOSED = WebSocket.prototype.CLOSED = states.CLOSED

Object.defineProperties(WebSocket.prototype, {
  CONNECTING: staticPropertyDescriptors,
  OPEN: staticPropertyDescriptors,
  CLOSING: staticPropertyDescriptors,
  CLOSED: staticPropertyDescriptors,
  url: kEnumerableProperty,
  readyState: kEnumerableProperty,
  bufferedAmount: kEnumerableProperty,
  onopen: kEnumerableProperty,
  onerror: kEnumerableProperty,
  onclose: kEnumerableProperty,
  close: kEnumerableProperty,
  onmessage: kEnumerableProperty,
  binaryType: kEnumerableProperty,
  send: kEnumerableProperty,
  extensions: kEnumerableProperty,
  protocol: kEnumerableProperty,
  [Symbol.toStringTag]: {
    value: 'WebSocket',
    writable: false,
    enumerable: false,
    configurable: true
  }
})

Object.defineProperties(WebSocket, {
  CONNECTING: staticPropertyDescriptors,
  OPEN: staticPropertyDescriptors,
  CLOSING: staticPropertyDescriptors,
  CLOSED: staticPropertyDescriptors
})

webidl.converters['sequence<DOMString>'] = webidl.sequenceConverter(
  webidl.converters.DOMString
)

webidl.converters['DOMString or sequence<DOMString>'] = function (V) {
  if (webidl.util.Type(V) === 'Object' && Symbol.iterator in V) {
    return webidl.converters['sequence<DOMString>'](V)
  }

  return webidl.converters.DOMString(V)
}

// This implements the propsal made in https://github.com/whatwg/websockets/issues/42
webidl.converters.WebSocketInit = webidl.dictionaryConverter([
  {
    key: 'protocols',
    converter: webidl.converters['DOMString or sequence<DOMString>'],
    get defaultValue () {
      return []
    }
  },
  {
    key: 'dispatcher',
    converter: (V) => V,
    get defaultValue () {
      return getGlobalDispatcher()
    }
  },
  {
    key: 'headers',
    converter: webidl.nullableConverter(webidl.converters.HeadersInit)
  }
])

webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'] = function (V) {
  if (webidl.util.Type(V) === 'Object' && !(Symbol.iterator in V)) {
    return webidl.converters.WebSocketInit(V)
  }

  return { protocols: webidl.converters['DOMString or sequence<DOMString>'](V) }
}

webidl.converters.WebSocketSendData = function (V) {
  if (webidl.util.Type(V) === 'Object') {
    if (isBlobLike(V)) {
      return webidl.converters.Blob(V, { strict: false })
    }

    if (ArrayBuffer.isView(V) || types.isAnyArrayBuffer(V)) {
      return webidl.converters.BufferSource(V)
    }
  }

  return webidl.converters.USVString(V)
}

module.exports = {
  WebSocket
}


/***/ }),

/***/ 3843:
/***/ ((__unused_webpack_module, exports) => {

"use strict";


Object.defineProperty(exports, "__esModule", ({ value: true }));

function getUserAgent() {
  if (typeof navigator === "object" && "userAgent" in navigator) {
    return navigator.userAgent;
  }

  if (typeof process === "object" && process.version !== undefined) {
    return `Node.js/${process.version.substr(1)} (${process.platform}; ${process.arch})`;
  }

  return "<environment undetectable>";
}

exports.getUserAgent = getUserAgent;
//# sourceMappingURL=index.js.map


/***/ }),

/***/ 8264:
/***/ ((module) => {

// Returns a wrapper function that returns a wrapped callback
// The wrapper function should do some stuff, and return a
// presumably different callback function.
// This makes sure that own properties are retained, so that
// decorations and such are not lost along the way.
module.exports = wrappy
function wrappy (fn, cb) {
  if (fn && cb) return wrappy(fn)(cb)

  if (typeof fn !== 'function')
    throw new TypeError('need wrapper function')

  Object.keys(fn).forEach(function (k) {
    wrapper[k] = fn[k]
  })

  return wrapper

  function wrapper() {
    var args = new Array(arguments.length)
    for (var i = 0; i < args.length; i++) {
      args[i] = arguments[i]
    }
    var ret = fn.apply(this, args)
    var cb = args[args.length-1]
    if (typeof ret === 'function' && ret !== cb) {
      Object.keys(cb).forEach(function (k) {
        ret[k] = cb[k]
      })
    }
    return ret
  }
}


/***/ }),

/***/ 2613:
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ 290:
/***/ ((module) => {

"use strict";
module.exports = require("async_hooks");

/***/ }),

/***/ 181:
/***/ ((module) => {

"use strict";
module.exports = require("buffer");

/***/ }),

/***/ 5317:
/***/ ((module) => {

"use strict";
module.exports = require("child_process");

/***/ }),

/***/ 4236:
/***/ ((module) => {

"use strict";
module.exports = require("console");

/***/ }),

/***/ 6982:
/***/ ((module) => {

"use strict";
module.exports = require("crypto");

/***/ }),

/***/ 1637:
/***/ ((module) => {

"use strict";
module.exports = require("diagnostics_channel");

/***/ }),

/***/ 4434:
/***/ ((module) => {

"use strict";
module.exports = require("events");

/***/ }),

/***/ 9896:
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ 8611:
/***/ ((module) => {

"use strict";
module.exports = require("http");

/***/ }),

/***/ 5675:
/***/ ((module) => {

"use strict";
module.exports = require("http2");

/***/ }),

/***/ 5692:
/***/ ((module) => {

"use strict";
module.exports = require("https");

/***/ }),

/***/ 9278:
/***/ ((module) => {

"use strict";
module.exports = require("net");

/***/ }),

/***/ 7598:
/***/ ((module) => {

"use strict";
module.exports = require("node:crypto");

/***/ }),

/***/ 8474:
/***/ ((module) => {

"use strict";
module.exports = require("node:events");

/***/ }),

/***/ 7075:
/***/ ((module) => {

"use strict";
module.exports = require("node:stream");

/***/ }),

/***/ 7975:
/***/ ((module) => {

"use strict";
module.exports = require("node:util");

/***/ }),

/***/ 857:
/***/ ((module) => {

"use strict";
module.exports = require("os");

/***/ }),

/***/ 6928:
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ 2987:
/***/ ((module) => {

"use strict";
module.exports = require("perf_hooks");

/***/ }),

/***/ 3480:
/***/ ((module) => {

"use strict";
module.exports = require("querystring");

/***/ }),

/***/ 2203:
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ 3774:
/***/ ((module) => {

"use strict";
module.exports = require("stream/web");

/***/ }),

/***/ 3193:
/***/ ((module) => {

"use strict";
module.exports = require("string_decoder");

/***/ }),

/***/ 3557:
/***/ ((module) => {

"use strict";
module.exports = require("timers");

/***/ }),

/***/ 4756:
/***/ ((module) => {

"use strict";
module.exports = require("tls");

/***/ }),

/***/ 7016:
/***/ ((module) => {

"use strict";
module.exports = require("url");

/***/ }),

/***/ 9023:
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ }),

/***/ 8253:
/***/ ((module) => {

"use strict";
module.exports = require("util/types");

/***/ }),

/***/ 8167:
/***/ ((module) => {

"use strict";
module.exports = require("worker_threads");

/***/ }),

/***/ 3106:
/***/ ((module) => {

"use strict";
module.exports = require("zlib");

/***/ }),

/***/ 7182:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const WritableStream = (__nccwpck_require__(7075).Writable)
const inherits = (__nccwpck_require__(7975).inherits)

const StreamSearch = __nccwpck_require__(4136)

const PartStream = __nccwpck_require__(612)
const HeaderParser = __nccwpck_require__(2271)

const DASH = 45
const B_ONEDASH = Buffer.from('-')
const B_CRLF = Buffer.from('\r\n')
const EMPTY_FN = function () {}

function Dicer (cfg) {
  if (!(this instanceof Dicer)) { return new Dicer(cfg) }
  WritableStream.call(this, cfg)

  if (!cfg || (!cfg.headerFirst && typeof cfg.boundary !== 'string')) { throw new TypeError('Boundary required') }

  if (typeof cfg.boundary === 'string') { this.setBoundary(cfg.boundary) } else { this._bparser = undefined }

  this._headerFirst = cfg.headerFirst

  this._dashes = 0
  this._parts = 0
  this._finished = false
  this._realFinish = false
  this._isPreamble = true
  this._justMatched = false
  this._firstWrite = true
  this._inHeader = true
  this._part = undefined
  this._cb = undefined
  this._ignoreData = false
  this._partOpts = { highWaterMark: cfg.partHwm }
  this._pause = false

  const self = this
  this._hparser = new HeaderParser(cfg)
  this._hparser.on('header', function (header) {
    self._inHeader = false
    self._part.emit('header', header)
  })
}
inherits(Dicer, WritableStream)

Dicer.prototype.emit = function (ev) {
  if (ev === 'finish' && !this._realFinish) {
    if (!this._finished) {
      const self = this
      process.nextTick(function () {
        self.emit('error', new Error('Unexpected end of multipart data'))
        if (self._part && !self._ignoreData) {
          const type = (self._isPreamble ? 'Preamble' : 'Part')
          self._part.emit('error', new Error(type + ' terminated early due to unexpected end of multipart data'))
          self._part.push(null)
          process.nextTick(function () {
            self._realFinish = true
            self.emit('finish')
            self._realFinish = false
          })
          return
        }
        self._realFinish = true
        self.emit('finish')
        self._realFinish = false
      })
    }
  } else { WritableStream.prototype.emit.apply(this, arguments) }
}

Dicer.prototype._write = function (data, encoding, cb) {
  // ignore unexpected data (e.g. extra trailer data after finished)
  if (!this._hparser && !this._bparser) { return cb() }

  if (this._headerFirst && this._isPreamble) {
    if (!this._part) {
      this._part = new PartStream(this._partOpts)
      if (this.listenerCount('preamble') !== 0) { this.emit('preamble', this._part) } else { this._ignore() }
    }
    const r = this._hparser.push(data)
    if (!this._inHeader && r !== undefined && r < data.length) { data = data.slice(r) } else { return cb() }
  }

  // allows for "easier" testing
  if (this._firstWrite) {
    this._bparser.push(B_CRLF)
    this._firstWrite = false
  }

  this._bparser.push(data)

  if (this._pause) { this._cb = cb } else { cb() }
}

Dicer.prototype.reset = function () {
  this._part = undefined
  this._bparser = undefined
  this._hparser = undefined
}

Dicer.prototype.setBoundary = function (boundary) {
  const self = this
  this._bparser = new StreamSearch('\r\n--' + boundary)
  this._bparser.on('info', function (isMatch, data, start, end) {
    self._oninfo(isMatch, data, start, end)
  })
}

Dicer.prototype._ignore = function () {
  if (this._part && !this._ignoreData) {
    this._ignoreData = true
    this._part.on('error', EMPTY_FN)
    // we must perform some kind of read on the stream even though we are
    // ignoring the data, otherwise node's Readable stream will not emit 'end'
    // after pushing null to the stream
    this._part.resume()
  }
}

Dicer.prototype._oninfo = function (isMatch, data, start, end) {
  let buf; const self = this; let i = 0; let r; let shouldWriteMore = true

  if (!this._part && this._justMatched && data) {
    while (this._dashes < 2 && (start + i) < end) {
      if (data[start + i] === DASH) {
        ++i
        ++this._dashes
      } else {
        if (this._dashes) { buf = B_ONEDASH }
        this._dashes = 0
        break
      }
    }
    if (this._dashes === 2) {
      if ((start + i) < end && this.listenerCount('trailer') !== 0) { this.emit('trailer', data.slice(start + i, end)) }
      this.reset()
      this._finished = true
      // no more parts will be added
      if (self._parts === 0) {
        self._realFinish = true
        self.emit('finish')
        self._realFinish = false
      }
    }
    if (this._dashes) { return }
  }
  if (this._justMatched) { this._justMatched = false }
  if (!this._part) {
    this._part = new PartStream(this._partOpts)
    this._part._read = function (n) {
      self._unpause()
    }
    if (this._isPreamble && this.listenerCount('preamble') !== 0) {
      this.emit('preamble', this._part)
    } else if (this._isPreamble !== true && this.listenerCount('part') !== 0) {
      this.emit('part', this._part)
    } else {
      this._ignore()
    }
    if (!this._isPreamble) { this._inHeader = true }
  }
  if (data && start < end && !this._ignoreData) {
    if (this._isPreamble || !this._inHeader) {
      if (buf) { shouldWriteMore = this._part.push(buf) }
      shouldWriteMore = this._part.push(data.slice(start, end))
      if (!shouldWriteMore) { this._pause = true }
    } else if (!this._isPreamble && this._inHeader) {
      if (buf) { this._hparser.push(buf) }
      r = this._hparser.push(data.slice(start, end))
      if (!this._inHeader && r !== undefined && r < end) { this._oninfo(false, data, start + r, end) }
    }
  }
  if (isMatch) {
    this._hparser.reset()
    if (this._isPreamble) { this._isPreamble = false } else {
      if (start !== end) {
        ++this._parts
        this._part.on('end', function () {
          if (--self._parts === 0) {
            if (self._finished) {
              self._realFinish = true
              self.emit('finish')
              self._realFinish = false
            } else {
              self._unpause()
            }
          }
        })
      }
    }
    this._part.push(null)
    this._part = undefined
    this._ignoreData = false
    this._justMatched = true
    this._dashes = 0
  }
}

Dicer.prototype._unpause = function () {
  if (!this._pause) { return }

  this._pause = false
  if (this._cb) {
    const cb = this._cb
    this._cb = undefined
    cb()
  }
}

module.exports = Dicer


/***/ }),

/***/ 2271:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const EventEmitter = (__nccwpck_require__(8474).EventEmitter)
const inherits = (__nccwpck_require__(7975).inherits)
const getLimit = __nccwpck_require__(2393)

const StreamSearch = __nccwpck_require__(4136)

const B_DCRLF = Buffer.from('\r\n\r\n')
const RE_CRLF = /\r\n/g
const RE_HDR = /^([^:]+):[ \t]?([\x00-\xFF]+)?$/ // eslint-disable-line no-control-regex

function HeaderParser (cfg) {
  EventEmitter.call(this)

  cfg = cfg || {}
  const self = this
  this.nread = 0
  this.maxed = false
  this.npairs = 0
  this.maxHeaderPairs = getLimit(cfg, 'maxHeaderPairs', 2000)
  this.maxHeaderSize = getLimit(cfg, 'maxHeaderSize', 80 * 1024)
  this.buffer = ''
  this.header = {}
  this.finished = false
  this.ss = new StreamSearch(B_DCRLF)
  this.ss.on('info', function (isMatch, data, start, end) {
    if (data && !self.maxed) {
      if (self.nread + end - start >= self.maxHeaderSize) {
        end = self.maxHeaderSize - self.nread + start
        self.nread = self.maxHeaderSize
        self.maxed = true
      } else { self.nread += (end - start) }

      self.buffer += data.toString('binary', start, end)
    }
    if (isMatch) { self._finish() }
  })
}
inherits(HeaderParser, EventEmitter)

HeaderParser.prototype.push = function (data) {
  const r = this.ss.push(data)
  if (this.finished) { return r }
}

HeaderParser.prototype.reset = function () {
  this.finished = false
  this.buffer = ''
  this.header = {}
  this.ss.reset()
}

HeaderParser.prototype._finish = function () {
  if (this.buffer) { this._parseHeader() }
  this.ss.matches = this.ss.maxMatches
  const header = this.header
  this.header = {}
  this.buffer = ''
  this.finished = true
  this.nread = this.npairs = 0
  this.maxed = false
  this.emit('header', header)
}

HeaderParser.prototype._parseHeader = function () {
  if (this.npairs === this.maxHeaderPairs) { return }

  const lines = this.buffer.split(RE_CRLF)
  const len = lines.length
  let m, h

  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var
    if (lines[i].length === 0) { continue }
    if (lines[i][0] === '\t' || lines[i][0] === ' ') {
      // folded header content
      // RFC2822 says to just remove the CRLF and not the whitespace following
      // it, so we follow the RFC and include the leading whitespace ...
      if (h) {
        this.header[h][this.header[h].length - 1] += lines[i]
        continue
      }
    }

    const posColon = lines[i].indexOf(':')
    if (
      posColon === -1 ||
      posColon === 0
    ) {
      return
    }
    m = RE_HDR.exec(lines[i])
    h = m[1].toLowerCase()
    this.header[h] = this.header[h] || []
    this.header[h].push((m[2] || ''))
    if (++this.npairs === this.maxHeaderPairs) { break }
  }
}

module.exports = HeaderParser


/***/ }),

/***/ 612:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const inherits = (__nccwpck_require__(7975).inherits)
const ReadableStream = (__nccwpck_require__(7075).Readable)

function PartStream (opts) {
  ReadableStream.call(this, opts)
}
inherits(PartStream, ReadableStream)

PartStream.prototype._read = function (n) {}

module.exports = PartStream


/***/ }),

/***/ 4136:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


/**
 * Copyright Brian White. All rights reserved.
 *
 * @see https://github.com/mscdex/streamsearch
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to
 * deal in the Software without restriction, including without limitation the
 * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 * sell copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 *
 * Based heavily on the Streaming Boyer-Moore-Horspool C++ implementation
 * by Hongli Lai at: https://github.com/FooBarWidget/boyer-moore-horspool
 */
const EventEmitter = (__nccwpck_require__(8474).EventEmitter)
const inherits = (__nccwpck_require__(7975).inherits)

function SBMH (needle) {
  if (typeof needle === 'string') {
    needle = Buffer.from(needle)
  }

  if (!Buffer.isBuffer(needle)) {
    throw new TypeError('The needle has to be a String or a Buffer.')
  }

  const needleLength = needle.length

  if (needleLength === 0) {
    throw new Error('The needle cannot be an empty String/Buffer.')
  }

  if (needleLength > 256) {
    throw new Error('The needle cannot have a length bigger than 256.')
  }

  this.maxMatches = Infinity
  this.matches = 0

  this._occ = new Array(256)
    .fill(needleLength) // Initialize occurrence table.
  this._lookbehind_size = 0
  this._needle = needle
  this._bufpos = 0

  this._lookbehind = Buffer.alloc(needleLength)

  // Populate occurrence table with analysis of the needle,
  // ignoring last letter.
  for (var i = 0; i < needleLength - 1; ++i) { // eslint-disable-line no-var
    this._occ[needle[i]] = needleLength - 1 - i
  }
}
inherits(SBMH, EventEmitter)

SBMH.prototype.reset = function () {
  this._lookbehind_size = 0
  this.matches = 0
  this._bufpos = 0
}

SBMH.prototype.push = function (chunk, pos) {
  if (!Buffer.isBuffer(chunk)) {
    chunk = Buffer.from(chunk, 'binary')
  }
  const chlen = chunk.length
  this._bufpos = pos || 0
  let r
  while (r !== chlen && this.matches < this.maxMatches) { r = this._sbmh_feed(chunk) }
  return r
}

SBMH.prototype._sbmh_feed = function (data) {
  const len = data.length
  const needle = this._needle
  const needleLength = needle.length
  const lastNeedleChar = needle[needleLength - 1]

  // Positive: points to a position in `data`
  //           pos == 3 points to data[3]
  // Negative: points to a position in the lookbehind buffer
  //           pos == -2 points to lookbehind[lookbehind_size - 2]
  let pos = -this._lookbehind_size
  let ch

  if (pos < 0) {
    // Lookbehind buffer is not empty. Perform Boyer-Moore-Horspool
    // search with character lookup code that considers both the
    // lookbehind buffer and the current round's haystack data.
    //
    // Loop until
    //   there is a match.
    // or until
    //   we've moved past the position that requires the
    //   lookbehind buffer. In this case we switch to the
    //   optimized loop.
    // or until
    //   the character to look at lies outside the haystack.
    while (pos < 0 && pos <= len - needleLength) {
      ch = this._sbmh_lookup_char(data, pos + needleLength - 1)

      if (
        ch === lastNeedleChar &&
        this._sbmh_memcmp(data, pos, needleLength - 1)
      ) {
        this._lookbehind_size = 0
        ++this.matches
        this.emit('info', true)

        return (this._bufpos = pos + needleLength)
      }
      pos += this._occ[ch]
    }

    // No match.

    if (pos < 0) {
      // There's too few data for Boyer-Moore-Horspool to run,
      // so let's use a different algorithm to skip as much as
      // we can.
      // Forward pos until
      //   the trailing part of lookbehind + data
      //   looks like the beginning of the needle
      // or until
      //   pos == 0
      while (pos < 0 && !this._sbmh_memcmp(data, pos, len - pos)) { ++pos }
    }

    if (pos >= 0) {
      // Discard lookbehind buffer.
      this.emit('info', false, this._lookbehind, 0, this._lookbehind_size)
      this._lookbehind_size = 0
    } else {
      // Cut off part of the lookbehind buffer that has
      // been processed and append the entire haystack
      // into it.
      const bytesToCutOff = this._lookbehind_size + pos
      if (bytesToCutOff > 0) {
        // The cut off data is guaranteed not to contain the needle.
        this.emit('info', false, this._lookbehind, 0, bytesToCutOff)
      }

      this._lookbehind.copy(this._lookbehind, 0, bytesToCutOff,
        this._lookbehind_size - bytesToCutOff)
      this._lookbehind_size -= bytesToCutOff

      data.copy(this._lookbehind, this._lookbehind_size)
      this._lookbehind_size += len

      this._bufpos = len
      return len
    }
  }

  pos += (pos >= 0) * this._bufpos

  // Lookbehind buffer is now empty. We only need to check if the
  // needle is in the haystack.
  if (data.indexOf(needle, pos) !== -1) {
    pos = data.indexOf(needle, pos)
    ++this.matches
    if (pos > 0) { this.emit('info', true, data, this._bufpos, pos) } else { this.emit('info', true) }

    return (this._bufpos = pos + needleLength)
  } else {
    pos = len - needleLength
  }

  // There was no match. If there's trailing haystack data that we cannot
  // match yet using the Boyer-Moore-Horspool algorithm (because the trailing
  // data is less than the needle size) then match using a modified
  // algorithm that starts matching from the beginning instead of the end.
  // Whatever trailing data is left after running this algorithm is added to
  // the lookbehind buffer.
  while (
    pos < len &&
    (
      data[pos] !== needle[0] ||
      (
        (Buffer.compare(
          data.subarray(pos, pos + len - pos),
          needle.subarray(0, len - pos)
        ) !== 0)
      )
    )
  ) {
    ++pos
  }
  if (pos < len) {
    data.copy(this._lookbehind, 0, pos, pos + (len - pos))
    this._lookbehind_size = len - pos
  }

  // Everything until pos is guaranteed not to contain needle data.
  if (pos > 0) { this.emit('info', false, data, this._bufpos, pos < len ? pos : len) }

  this._bufpos = len
  return len
}

SBMH.prototype._sbmh_lookup_char = function (data, pos) {
  return (pos < 0)
    ? this._lookbehind[this._lookbehind_size + pos]
    : data[pos]
}

SBMH.prototype._sbmh_memcmp = function (data, pos, len) {
  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var
    if (this._sbmh_lookup_char(data, pos + i) !== this._needle[i]) { return false }
  }
  return true
}

module.exports = SBMH


/***/ }),

/***/ 9581:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const WritableStream = (__nccwpck_require__(7075).Writable)
const { inherits } = __nccwpck_require__(7975)
const Dicer = __nccwpck_require__(7182)

const MultipartParser = __nccwpck_require__(1192)
const UrlencodedParser = __nccwpck_require__(855)
const parseParams = __nccwpck_require__(8929)

function Busboy (opts) {
  if (!(this instanceof Busboy)) { return new Busboy(opts) }

  if (typeof opts !== 'object') {
    throw new TypeError('Busboy expected an options-Object.')
  }
  if (typeof opts.headers !== 'object') {
    throw new TypeError('Busboy expected an options-Object with headers-attribute.')
  }
  if (typeof opts.headers['content-type'] !== 'string') {
    throw new TypeError('Missing Content-Type-header.')
  }

  const {
    headers,
    ...streamOptions
  } = opts

  this.opts = {
    autoDestroy: false,
    ...streamOptions
  }
  WritableStream.call(this, this.opts)

  this._done = false
  this._parser = this.getParserByHeaders(headers)
  this._finished = false
}
inherits(Busboy, WritableStream)

Busboy.prototype.emit = function (ev) {
  if (ev === 'finish') {
    if (!this._done) {
      this._parser?.end()
      return
    } else if (this._finished) {
      return
    }
    this._finished = true
  }
  WritableStream.prototype.emit.apply(this, arguments)
}

Busboy.prototype.getParserByHeaders = function (headers) {
  const parsed = parseParams(headers['content-type'])

  const cfg = {
    defCharset: this.opts.defCharset,
    fileHwm: this.opts.fileHwm,
    headers,
    highWaterMark: this.opts.highWaterMark,
    isPartAFile: this.opts.isPartAFile,
    limits: this.opts.limits,
    parsedConType: parsed,
    preservePath: this.opts.preservePath
  }

  if (MultipartParser.detect.test(parsed[0])) {
    return new MultipartParser(this, cfg)
  }
  if (UrlencodedParser.detect.test(parsed[0])) {
    return new UrlencodedParser(this, cfg)
  }
  throw new Error('Unsupported Content-Type.')
}

Busboy.prototype._write = function (chunk, encoding, cb) {
  this._parser.write(chunk, cb)
}

module.exports = Busboy
module.exports["default"] = Busboy
module.exports.Busboy = Busboy

module.exports.Dicer = Dicer


/***/ }),

/***/ 1192:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


// TODO:
//  * support 1 nested multipart level
//    (see second multipart example here:
//     http://www.w3.org/TR/html401/interact/forms.html#didx-multipartform-data)
//  * support limits.fieldNameSize
//     -- this will require modifications to utils.parseParams

const { Readable } = __nccwpck_require__(7075)
const { inherits } = __nccwpck_require__(7975)

const Dicer = __nccwpck_require__(7182)

const parseParams = __nccwpck_require__(8929)
const decodeText = __nccwpck_require__(2747)
const basename = __nccwpck_require__(692)
const getLimit = __nccwpck_require__(2393)

const RE_BOUNDARY = /^boundary$/i
const RE_FIELD = /^form-data$/i
const RE_CHARSET = /^charset$/i
const RE_FILENAME = /^filename$/i
const RE_NAME = /^name$/i

Multipart.detect = /^multipart\/form-data/i
function Multipart (boy, cfg) {
  let i
  let len
  const self = this
  let boundary
  const limits = cfg.limits
  const isPartAFile = cfg.isPartAFile || ((fieldName, contentType, fileName) => (contentType === 'application/octet-stream' || fileName !== undefined))
  const parsedConType = cfg.parsedConType || []
  const defCharset = cfg.defCharset || 'utf8'
  const preservePath = cfg.preservePath
  const fileOpts = { highWaterMark: cfg.fileHwm }

  for (i = 0, len = parsedConType.length; i < len; ++i) {
    if (Array.isArray(parsedConType[i]) &&
      RE_BOUNDARY.test(parsedConType[i][0])) {
      boundary = parsedConType[i][1]
      break
    }
  }

  function checkFinished () {
    if (nends === 0 && finished && !boy._done) {
      finished = false
      self.end()
    }
  }

  if (typeof boundary !== 'string') { throw new Error('Multipart: Boundary not found') }

  const fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)
  const fileSizeLimit = getLimit(limits, 'fileSize', Infinity)
  const filesLimit = getLimit(limits, 'files', Infinity)
  const fieldsLimit = getLimit(limits, 'fields', Infinity)
  const partsLimit = getLimit(limits, 'parts', Infinity)
  const headerPairsLimit = getLimit(limits, 'headerPairs', 2000)
  const headerSizeLimit = getLimit(limits, 'headerSize', 80 * 1024)

  let nfiles = 0
  let nfields = 0
  let nends = 0
  let curFile
  let curField
  let finished = false

  this._needDrain = false
  this._pause = false
  this._cb = undefined
  this._nparts = 0
  this._boy = boy

  const parserCfg = {
    boundary,
    maxHeaderPairs: headerPairsLimit,
    maxHeaderSize: headerSizeLimit,
    partHwm: fileOpts.highWaterMark,
    highWaterMark: cfg.highWaterMark
  }

  this.parser = new Dicer(parserCfg)
  this.parser.on('drain', function () {
    self._needDrain = false
    if (self._cb && !self._pause) {
      const cb = self._cb
      self._cb = undefined
      cb()
    }
  }).on('part', function onPart (part) {
    if (++self._nparts > partsLimit) {
      self.parser.removeListener('part', onPart)
      self.parser.on('part', skipPart)
      boy.hitPartsLimit = true
      boy.emit('partsLimit')
      return skipPart(part)
    }

    // hack because streams2 _always_ doesn't emit 'end' until nextTick, so let
    // us emit 'end' early since we know the part has ended if we are already
    // seeing the next part
    if (curField) {
      const field = curField
      field.emit('end')
      field.removeAllListeners('end')
    }

    part.on('header', function (header) {
      let contype
      let fieldname
      let parsed
      let charset
      let encoding
      let filename
      let nsize = 0

      if (header['content-type']) {
        parsed = parseParams(header['content-type'][0])
        if (parsed[0]) {
          contype = parsed[0].toLowerCase()
          for (i = 0, len = parsed.length; i < len; ++i) {
            if (RE_CHARSET.test(parsed[i][0])) {
              charset = parsed[i][1].toLowerCase()
              break
            }
          }
        }
      }

      if (contype === undefined) { contype = 'text/plain' }
      if (charset === undefined) { charset = defCharset }

      if (header['content-disposition']) {
        parsed = parseParams(header['content-disposition'][0])
        if (!RE_FIELD.test(parsed[0])) { return skipPart(part) }
        for (i = 0, len = parsed.length; i < len; ++i) {
          if (RE_NAME.test(parsed[i][0])) {
            fieldname = parsed[i][1]
          } else if (RE_FILENAME.test(parsed[i][0])) {
            filename = parsed[i][1]
            if (!preservePath) { filename = basename(filename) }
          }
        }
      } else { return skipPart(part) }

      if (header['content-transfer-encoding']) { encoding = header['content-transfer-encoding'][0].toLowerCase() } else { encoding = '7bit' }

      let onData,
        onEnd

      if (isPartAFile(fieldname, contype, filename)) {
        // file/binary field
        if (nfiles === filesLimit) {
          if (!boy.hitFilesLimit) {
            boy.hitFilesLimit = true
            boy.emit('filesLimit')
          }
          return skipPart(part)
        }

        ++nfiles

        if (boy.listenerCount('file') === 0) {
          self.parser._ignore()
          return
        }

        ++nends
        const file = new FileStream(fileOpts)
        curFile = file
        file.on('end', function () {
          --nends
          self._pause = false
          checkFinished()
          if (self._cb && !self._needDrain) {
            const cb = self._cb
            self._cb = undefined
            cb()
          }
        })
        file._read = function (n) {
          if (!self._pause) { return }
          self._pause = false
          if (self._cb && !self._needDrain) {
            const cb = self._cb
            self._cb = undefined
            cb()
          }
        }
        boy.emit('file', fieldname, file, filename, encoding, contype)

        onData = function (data) {
          if ((nsize += data.length) > fileSizeLimit) {
            const extralen = fileSizeLimit - nsize + data.length
            if (extralen > 0) { file.push(data.slice(0, extralen)) }
            file.truncated = true
            file.bytesRead = fileSizeLimit
            part.removeAllListeners('data')
            file.emit('limit')
            return
          } else if (!file.push(data)) { self._pause = true }

          file.bytesRead = nsize
        }

        onEnd = function () {
          curFile = undefined
          file.push(null)
        }
      } else {
        // non-file field
        if (nfields === fieldsLimit) {
          if (!boy.hitFieldsLimit) {
            boy.hitFieldsLimit = true
            boy.emit('fieldsLimit')
          }
          return skipPart(part)
        }

        ++nfields
        ++nends
        let buffer = ''
        let truncated = false
        curField = part

        onData = function (data) {
          if ((nsize += data.length) > fieldSizeLimit) {
            const extralen = (fieldSizeLimit - (nsize - data.length))
            buffer += data.toString('binary', 0, extralen)
            truncated = true
            part.removeAllListeners('data')
          } else { buffer += data.toString('binary') }
        }

        onEnd = function () {
          curField = undefined
          if (buffer.length) { buffer = decodeText(buffer, 'binary', charset) }
          boy.emit('field', fieldname, buffer, false, truncated, encoding, contype)
          --nends
          checkFinished()
        }
      }

      /* As of node@2efe4ab761666 (v0.10.29+/v0.11.14+), busboy had become
         broken. Streams2/streams3 is a huge black box of confusion, but
         somehow overriding the sync state seems to fix things again (and still
         seems to work for previous node versions).
      */
      part._readableState.sync = false

      part.on('data', onData)
      part.on('end', onEnd)
    }).on('error', function (err) {
      if (curFile) { curFile.emit('error', err) }
    })
  }).on('error', function (err) {
    boy.emit('error', err)
  }).on('finish', function () {
    finished = true
    checkFinished()
  })
}

Multipart.prototype.write = function (chunk, cb) {
  const r = this.parser.write(chunk)
  if (r && !this._pause) {
    cb()
  } else {
    this._needDrain = !r
    this._cb = cb
  }
}

Multipart.prototype.end = function () {
  const self = this

  if (self.parser.writable) {
    self.parser.end()
  } else if (!self._boy._done) {
    process.nextTick(function () {
      self._boy._done = true
      self._boy.emit('finish')
    })
  }
}

function skipPart (part) {
  part.resume()
}

function FileStream (opts) {
  Readable.call(this, opts)

  this.bytesRead = 0

  this.truncated = false
}

inherits(FileStream, Readable)

FileStream.prototype._read = function (n) {}

module.exports = Multipart


/***/ }),

/***/ 855:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";


const Decoder = __nccwpck_require__(1496)
const decodeText = __nccwpck_require__(2747)
const getLimit = __nccwpck_require__(2393)

const RE_CHARSET = /^charset$/i

UrlEncoded.detect = /^application\/x-www-form-urlencoded/i
function UrlEncoded (boy, cfg) {
  const limits = cfg.limits
  const parsedConType = cfg.parsedConType
  this.boy = boy

  this.fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)
  this.fieldNameSizeLimit = getLimit(limits, 'fieldNameSize', 100)
  this.fieldsLimit = getLimit(limits, 'fields', Infinity)

  let charset
  for (var i = 0, len = parsedConType.length; i < len; ++i) { // eslint-disable-line no-var
    if (Array.isArray(parsedConType[i]) &&
        RE_CHARSET.test(parsedConType[i][0])) {
      charset = parsedConType[i][1].toLowerCase()
      break
    }
  }

  if (charset === undefined) { charset = cfg.defCharset || 'utf8' }

  this.decoder = new Decoder()
  this.charset = charset
  this._fields = 0
  this._state = 'key'
  this._checkingBytes = true
  this._bytesKey = 0
  this._bytesVal = 0
  this._key = ''
  this._val = ''
  this._keyTrunc = false
  this._valTrunc = false
  this._hitLimit = false
}

UrlEncoded.prototype.write = function (data, cb) {
  if (this._fields === this.fieldsLimit) {
    if (!this.boy.hitFieldsLimit) {
      this.boy.hitFieldsLimit = true
      this.boy.emit('fieldsLimit')
    }
    return cb()
  }

  let idxeq; let idxamp; let i; let p = 0; const len = data.length

  while (p < len) {
    if (this._state === 'key') {
      idxeq = idxamp = undefined
      for (i = p; i < len; ++i) {
        if (!this._checkingBytes) { ++p }
        if (data[i] === 0x3D/* = */) {
          idxeq = i
          break
        } else if (data[i] === 0x26/* & */) {
          idxamp = i
          break
        }
        if (this._checkingBytes && this._bytesKey === this.fieldNameSizeLimit) {
          this._hitLimit = true
          break
        } else if (this._checkingBytes) { ++this._bytesKey }
      }

      if (idxeq !== undefined) {
        // key with assignment
        if (idxeq > p) { this._key += this.decoder.write(data.toString('binary', p, idxeq)) }
        this._state = 'val'

        this._hitLimit = false
        this._checkingBytes = true
        this._val = ''
        this._bytesVal = 0
        this._valTrunc = false
        this.decoder.reset()

        p = idxeq + 1
      } else if (idxamp !== undefined) {
        // key with no assignment
        ++this._fields
        let key; const keyTrunc = this._keyTrunc
        if (idxamp > p) { key = (this._key += this.decoder.write(data.toString('binary', p, idxamp))) } else { key = this._key }

        this._hitLimit = false
        this._checkingBytes = true
        this._key = ''
        this._bytesKey = 0
        this._keyTrunc = false
        this.decoder.reset()

        if (key.length) {
          this.boy.emit('field', decodeText(key, 'binary', this.charset),
            '',
            keyTrunc,
            false)
        }

        p = idxamp + 1
        if (this._fields === this.fieldsLimit) { return cb() }
      } else if (this._hitLimit) {
        // we may not have hit the actual limit if there are encoded bytes...
        if (i > p) { this._key += this.decoder.write(data.toString('binary', p, i)) }
        p = i
        if ((this._bytesKey = this._key.length) === this.fieldNameSizeLimit) {
          // yep, we actually did hit the limit
          this._checkingBytes = false
          this._keyTrunc = true
        }
      } else {
        if (p < len) { this._key += this.decoder.write(data.toString('binary', p)) }
        p = len
      }
    } else {
      idxamp = undefined
      for (i = p; i < len; ++i) {
        if (!this._checkingBytes) { ++p }
        if (data[i] === 0x26/* & */) {
          idxamp = i
          break
        }
        if (this._checkingBytes && this._bytesVal === this.fieldSizeLimit) {
          this._hitLimit = true
          break
        } else if (this._checkingBytes) { ++this._bytesVal }
      }

      if (idxamp !== undefined) {
        ++this._fields
        if (idxamp > p) { this._val += this.decoder.write(data.toString('binary', p, idxamp)) }
        this.boy.emit('field', decodeText(this._key, 'binary', this.charset),
          decodeText(this._val, 'binary', this.charset),
          this._keyTrunc,
          this._valTrunc)
        this._state = 'key'

        this._hitLimit = false
        this._checkingBytes = true
        this._key = ''
        this._bytesKey = 0
        this._keyTrunc = false
        this.decoder.reset()

        p = idxamp + 1
        if (this._fields === this.fieldsLimit) { return cb() }
      } else if (this._hitLimit) {
        // we may not have hit the actual limit if there are encoded bytes...
        if (i > p) { this._val += this.decoder.write(data.toString('binary', p, i)) }
        p = i
        if ((this._val === '' && this.fieldSizeLimit === 0) ||
            (this._bytesVal = this._val.length) === this.fieldSizeLimit) {
          // yep, we actually did hit the limit
          this._checkingBytes = false
          this._valTrunc = true
        }
      } else {
        if (p < len) { this._val += this.decoder.write(data.toString('binary', p)) }
        p = len
      }
    }
  }
  cb()
}

UrlEncoded.prototype.end = function () {
  if (this.boy._done) { return }

  if (this._state === 'key' && this._key.length > 0) {
    this.boy.emit('field', decodeText(this._key, 'binary', this.charset),
      '',
      this._keyTrunc,
      false)
  } else if (this._state === 'val') {
    this.boy.emit('field', decodeText(this._key, 'binary', this.charset),
      decodeText(this._val, 'binary', this.charset),
      this._keyTrunc,
      this._valTrunc)
  }
  this.boy._done = true
  this.boy.emit('finish')
}

module.exports = UrlEncoded


/***/ }),

/***/ 1496:
/***/ ((module) => {

"use strict";


const RE_PLUS = /\+/g

const HEX = [
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
  0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
]

function Decoder () {
  this.buffer = undefined
}
Decoder.prototype.write = function (str) {
  // Replace '+' with ' ' before decoding
  str = str.replace(RE_PLUS, ' ')
  let res = ''
  let i = 0; let p = 0; const len = str.length
  for (; i < len; ++i) {
    if (this.buffer !== undefined) {
      if (!HEX[str.charCodeAt(i)]) {
        res += '%' + this.buffer
        this.buffer = undefined
        --i // retry character
      } else {
        this.buffer += str[i]
        ++p
        if (this.buffer.length === 2) {
          res += String.fromCharCode(parseInt(this.buffer, 16))
          this.buffer = undefined
        }
      }
    } else if (str[i] === '%') {
      if (i > p) {
        res += str.substring(p, i)
        p = i
      }
      this.buffer = ''
      ++p
    }
  }
  if (p < len && this.buffer === undefined) { res += str.substring(p) }
  return res
}
Decoder.prototype.reset = function () {
  this.buffer = undefined
}

module.exports = Decoder


/***/ }),

/***/ 692:
/***/ ((module) => {

"use strict";


module.exports = function basename (path) {
  if (typeof path !== 'string') { return '' }
  for (var i = path.length - 1; i >= 0; --i) { // eslint-disable-line no-var
    switch (path.charCodeAt(i)) {
      case 0x2F: // '/'
      case 0x5C: // '\'
        path = path.slice(i + 1)
        return (path === '..' || path === '.' ? '' : path)
    }
  }
  return (path === '..' || path === '.' ? '' : path)
}


/***/ }),

/***/ 2747:
/***/ (function(module) {

"use strict";


// Node has always utf-8
const utf8Decoder = new TextDecoder('utf-8')
const textDecoders = new Map([
  ['utf-8', utf8Decoder],
  ['utf8', utf8Decoder]
])

function getDecoder (charset) {
  let lc
  while (true) {
    switch (charset) {
      case 'utf-8':
      case 'utf8':
        return decoders.utf8
      case 'latin1':
      case 'ascii': // TODO: Make these a separate, strict decoder?
      case 'us-ascii':
      case 'iso-8859-1':
      case 'iso8859-1':
      case 'iso88591':
      case 'iso_8859-1':
      case 'windows-1252':
      case 'iso_8859-1:1987':
      case 'cp1252':
      case 'x-cp1252':
        return decoders.latin1
      case 'utf16le':
      case 'utf-16le':
      case 'ucs2':
      case 'ucs-2':
        return decoders.utf16le
      case 'base64':
        return decoders.base64
      default:
        if (lc === undefined) {
          lc = true
          charset = charset.toLowerCase()
          continue
        }
        return decoders.other.bind(charset)
    }
  }
}

const decoders = {
  utf8: (data, sourceEncoding) => {
    if (data.length === 0) {
      return ''
    }
    if (typeof data === 'string') {
      data = Buffer.from(data, sourceEncoding)
    }
    return data.utf8Slice(0, data.length)
  },

  latin1: (data, sourceEncoding) => {
    if (data.length === 0) {
      return ''
    }
    if (typeof data === 'string') {
      return data
    }
    return data.latin1Slice(0, data.length)
  },

  utf16le: (data, sourceEncoding) => {
    if (data.length === 0) {
      return ''
    }
    if (typeof data === 'string') {
      data = Buffer.from(data, sourceEncoding)
    }
    return data.ucs2Slice(0, data.length)
  },

  base64: (data, sourceEncoding) => {
    if (data.length === 0) {
      return ''
    }
    if (typeof data === 'string') {
      data = Buffer.from(data, sourceEncoding)
    }
    return data.base64Slice(0, data.length)
  },

  other: (data, sourceEncoding) => {
    if (data.length === 0) {
      return ''
    }
    if (typeof data === 'string') {
      data = Buffer.from(data, sourceEncoding)
    }

    if (textDecoders.has(this.toString())) {
      try {
        return textDecoders.get(this).decode(data)
      } catch {}
    }
    return typeof data === 'string'
      ? data
      : data.toString()
  }
}

function decodeText (text, sourceEncoding, destEncoding) {
  if (text) {
    return getDecoder(destEncoding)(text, sourceEncoding)
  }
  return text
}

module.exports = decodeText


/***/ }),

/***/ 2393:
/***/ ((module) => {

"use strict";


module.exports = function getLimit (limits, name, defaultLimit) {
  if (
    !limits ||
    limits[name] === undefined ||
    limits[name] === null
  ) { return defaultLimit }

  if (
    typeof limits[name] !== 'number' ||
    isNaN(limits[name])
  ) { throw new TypeError('Limit ' + name + ' is not a valid number') }

  return limits[name]
}


/***/ }),

/***/ 8929:
/***/ ((module, __unused_webpack_exports, __nccwpck_require__) => {

"use strict";
/* eslint-disable object-property-newline */


const decodeText = __nccwpck_require__(2747)

const RE_ENCODED = /%[a-fA-F0-9][a-fA-F0-9]/g

const EncodedLookup = {
  '%00': '\x00', '%01': '\x01', '%02': '\x02', '%03': '\x03', '%04': '\x04',
  '%05': '\x05', '%06': '\x06', '%07': '\x07', '%08': '\x08', '%09': '\x09',
  '%0a': '\x0a', '%0A': '\x0a', '%0b': '\x0b', '%0B': '\x0b', '%0c': '\x0c',
  '%0C': '\x0c', '%0d': '\x0d', '%0D': '\x0d', '%0e': '\x0e', '%0E': '\x0e',
  '%0f': '\x0f', '%0F': '\x0f', '%10': '\x10', '%11': '\x11', '%12': '\x12',
  '%13': '\x13', '%14': '\x14', '%15': '\x15', '%16': '\x16', '%17': '\x17',
  '%18': '\x18', '%19': '\x19', '%1a': '\x1a', '%1A': '\x1a', '%1b': '\x1b',
  '%1B': '\x1b', '%1c': '\x1c', '%1C': '\x1c', '%1d': '\x1d', '%1D': '\x1d',
  '%1e': '\x1e', '%1E': '\x1e', '%1f': '\x1f', '%1F': '\x1f', '%20': '\x20',
  '%21': '\x21', '%22': '\x22', '%23': '\x23', '%24': '\x24', '%25': '\x25',
  '%26': '\x26', '%27': '\x27', '%28': '\x28', '%29': '\x29', '%2a': '\x2a',
  '%2A': '\x2a', '%2b': '\x2b', '%2B': '\x2b', '%2c': '\x2c', '%2C': '\x2c',
  '%2d': '\x2d', '%2D': '\x2d', '%2e': '\x2e', '%2E': '\x2e', '%2f': '\x2f',
  '%2F': '\x2f', '%30': '\x30', '%31': '\x31', '%32': '\x32', '%33': '\x33',
  '%34': '\x34', '%35': '\x35', '%36': '\x36', '%37': '\x37', '%38': '\x38',
  '%39': '\x39', '%3a': '\x3a', '%3A': '\x3a', '%3b': '\x3b', '%3B': '\x3b',
  '%3c': '\x3c', '%3C': '\x3c', '%3d': '\x3d', '%3D': '\x3d', '%3e': '\x3e',
  '%3E': '\x3e', '%3f': '\x3f', '%3F': '\x3f', '%40': '\x40', '%41': '\x41',
  '%42': '\x42', '%43': '\x43', '%44': '\x44', '%45': '\x45', '%46': '\x46',
  '%47': '\x47', '%48': '\x48', '%49': '\x49', '%4a': '\x4a', '%4A': '\x4a',
  '%4b': '\x4b', '%4B': '\x4b', '%4c': '\x4c', '%4C': '\x4c', '%4d': '\x4d',
  '%4D': '\x4d', '%4e': '\x4e', '%4E': '\x4e', '%4f': '\x4f', '%4F': '\x4f',
  '%50': '\x50', '%51': '\x51', '%52': '\x52', '%53': '\x53', '%54': '\x54',
  '%55': '\x55', '%56': '\x56', '%57': '\x57', '%58': '\x58', '%59': '\x59',
  '%5a': '\x5a', '%5A': '\x5a', '%5b': '\x5b', '%5B': '\x5b', '%5c': '\x5c',
  '%5C': '\x5c', '%5d': '\x5d', '%5D': '\x5d', '%5e': '\x5e', '%5E': '\x5e',
  '%5f': '\x5f', '%5F': '\x5f', '%60': '\x60', '%61': '\x61', '%62': '\x62',
  '%63': '\x63', '%64': '\x64', '%65': '\x65', '%66': '\x66', '%67': '\x67',
  '%68': '\x68', '%69': '\x69', '%6a': '\x6a', '%6A': '\x6a', '%6b': '\x6b',
  '%6B': '\x6b', '%6c': '\x6c', '%6C': '\x6c', '%6d': '\x6d', '%6D': '\x6d',
  '%6e': '\x6e', '%6E': '\x6e', '%6f': '\x6f', '%6F': '\x6f', '%70': '\x70',
  '%71': '\x71', '%72': '\x72', '%73': '\x73', '%74': '\x74', '%75': '\x75',
  '%76': '\x76', '%77': '\x77', '%78': '\x78', '%79': '\x79', '%7a': '\x7a',
  '%7A': '\x7a', '%7b': '\x7b', '%7B': '\x7b', '%7c': '\x7c', '%7C': '\x7c',
  '%7d': '\x7d', '%7D': '\x7d', '%7e': '\x7e', '%7E': '\x7e', '%7f': '\x7f',
  '%7F': '\x7f', '%80': '\x80', '%81': '\x81', '%82': '\x82', '%83': '\x83',
  '%84': '\x84', '%85': '\x85', '%86': '\x86', '%87': '\x87', '%88': '\x88',
  '%89': '\x89', '%8a': '\x8a', '%8A': '\x8a', '%8b': '\x8b', '%8B': '\x8b',
  '%8c': '\x8c', '%8C': '\x8c', '%8d': '\x8d', '%8D': '\x8d', '%8e': '\x8e',
  '%8E': '\x8e', '%8f': '\x8f', '%8F': '\x8f', '%90': '\x90', '%91': '\x91',
  '%92': '\x92', '%93': '\x93', '%94': '\x94', '%95': '\x95', '%96': '\x96',
  '%97': '\x97', '%98': '\x98', '%99': '\x99', '%9a': '\x9a', '%9A': '\x9a',
  '%9b': '\x9b', '%9B': '\x9b', '%9c': '\x9c', '%9C': '\x9c', '%9d': '\x9d',
  '%9D': '\x9d', '%9e': '\x9e', '%9E': '\x9e', '%9f': '\x9f', '%9F': '\x9f',
  '%a0': '\xa0', '%A0': '\xa0', '%a1': '\xa1', '%A1': '\xa1', '%a2': '\xa2',
  '%A2': '\xa2', '%a3': '\xa3', '%A3': '\xa3', '%a4': '\xa4', '%A4': '\xa4',
  '%a5': '\xa5', '%A5': '\xa5', '%a6': '\xa6', '%A6': '\xa6', '%a7': '\xa7',
  '%A7': '\xa7', '%a8': '\xa8', '%A8': '\xa8', '%a9': '\xa9', '%A9': '\xa9',
  '%aa': '\xaa', '%Aa': '\xaa', '%aA': '\xaa', '%AA': '\xaa', '%ab': '\xab',
  '%Ab': '\xab', '%aB': '\xab', '%AB': '\xab', '%ac': '\xac', '%Ac': '\xac',
  '%aC': '\xac', '%AC': '\xac', '%ad': '\xad', '%Ad': '\xad', '%aD': '\xad',
  '%AD': '\xad', '%ae': '\xae', '%Ae': '\xae', '%aE': '\xae', '%AE': '\xae',
  '%af': '\xaf', '%Af': '\xaf', '%aF': '\xaf', '%AF': '\xaf', '%b0': '\xb0',
  '%B0': '\xb0', '%b1': '\xb1', '%B1': '\xb1', '%b2': '\xb2', '%B2': '\xb2',
  '%b3': '\xb3', '%B3': '\xb3', '%b4': '\xb4', '%B4': '\xb4', '%b5': '\xb5',
  '%B5': '\xb5', '%b6': '\xb6', '%B6': '\xb6', '%b7': '\xb7', '%B7': '\xb7',
  '%b8': '\xb8', '%B8': '\xb8', '%b9': '\xb9', '%B9': '\xb9', '%ba': '\xba',
  '%Ba': '\xba', '%bA': '\xba', '%BA': '\xba', '%bb': '\xbb', '%Bb': '\xbb',
  '%bB': '\xbb', '%BB': '\xbb', '%bc': '\xbc', '%Bc': '\xbc', '%bC': '\xbc',
  '%BC': '\xbc', '%bd': '\xbd', '%Bd': '\xbd', '%bD': '\xbd', '%BD': '\xbd',
  '%be': '\xbe', '%Be': '\xbe', '%bE': '\xbe', '%BE': '\xbe', '%bf': '\xbf',
  '%Bf': '\xbf', '%bF': '\xbf', '%BF': '\xbf', '%c0': '\xc0', '%C0': '\xc0',
  '%c1': '\xc1', '%C1': '\xc1', '%c2': '\xc2', '%C2': '\xc2', '%c3': '\xc3',
  '%C3': '\xc3', '%c4': '\xc4', '%C4': '\xc4', '%c5': '\xc5', '%C5': '\xc5',
  '%c6': '\xc6', '%C6': '\xc6', '%c7': '\xc7', '%C7': '\xc7', '%c8': '\xc8',
  '%C8': '\xc8', '%c9': '\xc9', '%C9': '\xc9', '%ca': '\xca', '%Ca': '\xca',
  '%cA': '\xca', '%CA': '\xca', '%cb': '\xcb', '%Cb': '\xcb', '%cB': '\xcb',
  '%CB': '\xcb', '%cc': '\xcc', '%Cc': '\xcc', '%cC': '\xcc', '%CC': '\xcc',
  '%cd': '\xcd', '%Cd': '\xcd', '%cD': '\xcd', '%CD': '\xcd', '%ce': '\xce',
  '%Ce': '\xce', '%cE': '\xce', '%CE': '\xce', '%cf': '\xcf', '%Cf': '\xcf',
  '%cF': '\xcf', '%CF': '\xcf', '%d0': '\xd0', '%D0': '\xd0', '%d1': '\xd1',
  '%D1': '\xd1', '%d2': '\xd2', '%D2': '\xd2', '%d3': '\xd3', '%D3': '\xd3',
  '%d4': '\xd4', '%D4': '\xd4', '%d5': '\xd5', '%D5': '\xd5', '%d6': '\xd6',
  '%D6': '\xd6', '%d7': '\xd7', '%D7': '\xd7', '%d8': '\xd8', '%D8': '\xd8',
  '%d9': '\xd9', '%D9': '\xd9', '%da': '\xda', '%Da': '\xda', '%dA': '\xda',
  '%DA': '\xda', '%db': '\xdb', '%Db': '\xdb', '%dB': '\xdb', '%DB': '\xdb',
  '%dc': '\xdc', '%Dc': '\xdc', '%dC': '\xdc', '%DC': '\xdc', '%dd': '\xdd',
  '%Dd': '\xdd', '%dD': '\xdd', '%DD': '\xdd', '%de': '\xde', '%De': '\xde',
  '%dE': '\xde', '%DE': '\xde', '%df': '\xdf', '%Df': '\xdf', '%dF': '\xdf',
  '%DF': '\xdf', '%e0': '\xe0', '%E0': '\xe0', '%e1': '\xe1', '%E1': '\xe1',
  '%e2': '\xe2', '%E2': '\xe2', '%e3': '\xe3', '%E3': '\xe3', '%e4': '\xe4',
  '%E4': '\xe4', '%e5': '\xe5', '%E5': '\xe5', '%e6': '\xe6', '%E6': '\xe6',
  '%e7': '\xe7', '%E7': '\xe7', '%e8': '\xe8', '%E8': '\xe8', '%e9': '\xe9',
  '%E9': '\xe9', '%ea': '\xea', '%Ea': '\xea', '%eA': '\xea', '%EA': '\xea',
  '%eb': '\xeb', '%Eb': '\xeb', '%eB': '\xeb', '%EB': '\xeb', '%ec': '\xec',
  '%Ec': '\xec', '%eC': '\xec', '%EC': '\xec', '%ed': '\xed', '%Ed': '\xed',
  '%eD': '\xed', '%ED': '\xed', '%ee': '\xee', '%Ee': '\xee', '%eE': '\xee',
  '%EE': '\xee', '%ef': '\xef', '%Ef': '\xef', '%eF': '\xef', '%EF': '\xef',
  '%f0': '\xf0', '%F0': '\xf0', '%f1': '\xf1', '%F1': '\xf1', '%f2': '\xf2',
  '%F2': '\xf2', '%f3': '\xf3', '%F3': '\xf3', '%f4': '\xf4', '%F4': '\xf4',
  '%f5': '\xf5', '%F5': '\xf5', '%f6': '\xf6', '%F6': '\xf6', '%f7': '\xf7',
  '%F7': '\xf7', '%f8': '\xf8', '%F8': '\xf8', '%f9': '\xf9', '%F9': '\xf9',
  '%fa': '\xfa', '%Fa': '\xfa', '%fA': '\xfa', '%FA': '\xfa', '%fb': '\xfb',
  '%Fb': '\xfb', '%fB': '\xfb', '%FB': '\xfb', '%fc': '\xfc', '%Fc': '\xfc',
  '%fC': '\xfc', '%FC': '\xfc', '%fd': '\xfd', '%Fd': '\xfd', '%fD': '\xfd',
  '%FD': '\xfd', '%fe': '\xfe', '%Fe': '\xfe', '%fE': '\xfe', '%FE': '\xfe',
  '%ff': '\xff', '%Ff': '\xff', '%fF': '\xff', '%FF': '\xff'
}

function encodedReplacer (match) {
  return EncodedLookup[match]
}

const STATE_KEY = 0
const STATE_VALUE = 1
const STATE_CHARSET = 2
const STATE_LANG = 3

function parseParams (str) {
  const res = []
  let state = STATE_KEY
  let charset = ''
  let inquote = false
  let escaping = false
  let p = 0
  let tmp = ''
  const len = str.length

  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var
    const char = str[i]
    if (char === '\\' && inquote) {
      if (escaping) { escaping = false } else {
        escaping = true
        continue
      }
    } else if (char === '"') {
      if (!escaping) {
        if (inquote) {
          inquote = false
          state = STATE_KEY
        } else { inquote = true }
        continue
      } else { escaping = false }
    } else {
      if (escaping && inquote) { tmp += '\\' }
      escaping = false
      if ((state === STATE_CHARSET || state === STATE_LANG) && char === "'") {
        if (state === STATE_CHARSET) {
          state = STATE_LANG
          charset = tmp.substring(1)
        } else { state = STATE_VALUE }
        tmp = ''
        continue
      } else if (state === STATE_KEY &&
        (char === '*' || char === '=') &&
        res.length) {
        state = char === '*'
          ? STATE_CHARSET
          : STATE_VALUE
        res[p] = [tmp, undefined]
        tmp = ''
        continue
      } else if (!inquote && char === ';') {
        state = STATE_KEY
        if (charset) {
          if (tmp.length) {
            tmp = decodeText(tmp.replace(RE_ENCODED, encodedReplacer),
              'binary',
              charset)
          }
          charset = ''
        } else if (tmp.length) {
          tmp = decodeText(tmp, 'binary', 'utf8')
        }
        if (res[p] === undefined) { res[p] = tmp } else { res[p][1] = tmp }
        tmp = ''
        ++p
        continue
      } else if (!inquote && (char === ' ' || char === '\t')) { continue }
    }
    tmp += char
  }
  if (charset && tmp.length) {
    tmp = decodeText(tmp.replace(RE_ENCODED, encodedReplacer),
      'binary',
      charset)
  } else if (tmp) {
    tmp = decodeText(tmp, 'binary', 'utf8')
  }

  if (res[p] === undefined) {
    if (tmp) { res[p] = tmp }
  } else { res[p][1] = tmp }

  return res
}

module.exports = parseParams


/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __nccwpck_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		var threw = true;
/******/ 		try {
/******/ 			__webpack_modules__[moduleId].call(module.exports, module, module.exports, __nccwpck_require__);
/******/ 			threw = false;
/******/ 		} finally {
/******/ 			if(threw) delete __webpack_module_cache__[moduleId];
/******/ 		}
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat */
/******/ 	
/******/ 	if (typeof __nccwpck_require__ !== 'undefined') __nccwpck_require__.ab = __dirname + "/";
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
const core = __nccwpck_require__(7484);
const github = __nccwpck_require__(3228);
const { getChangedPaths } = __nccwpck_require__(2924);

async function run() {
    try {
        const baseRef = core.getInput('base-ref') ||
            process.env.GITHUB_BASE_REF ||     // present on PR events
            github.context.payload?.repository?.default_branch ||
            'master';
        const affectedDirs = await getChangedPaths(baseRef);

        core.info('Affected directories: ' + affectedDirs.join(', '));
        core.setOutput('affected-dirs', affectedDirs.join(' '));
    } catch (error) {
        core.setFailed(error.message);
    }
}

run();

module.exports = __webpack_exports__;
/******/ })()
;
````

## File: .github/actions/test/action.yml
````yaml
name: Detect Changed Paths
description: Identify directories with changes and output them for use in workflows.
runs:
  using: node20
  main: dist/index.js
inputs:
  base-ref:
    description: The base reference to compare changes against.
    required: false
    default: 'origin/master'
  token:
    description: GitHub token for authentication.
    required: true
outputs:
  affected-dirs:
    description: A newline-separated list of affected directories.
````

## File: .github/actions/test/getChangedPaths.js
````javascript
const github = require('@actions/github');
const core = require('@actions/core');

async function getChangedPaths(baseRef = 'origin/master') {
    try {
        core.info(`executing getChangedPaths`);
        const token = core.getInput('token', { required: true });
        const octokit = github.getOctokit(token);
        const context = github.context;

        const { data: compare } = await octokit.rest.repos.compareCommits({
            owner: context.repo.owner,
            repo: context.repo.repo,
            base: baseRef,
            head: context.sha,
        });

        const directories = new Set();

        compare.files.forEach(file => {
            const dir = file.filename.split('/')[0];
            if (dir && dir !== '.github' && dir !== '.gitignore' && dir !== 'README.md') {
                directories.add(dir)
            };
        });

        return Array.from(directories);
    } catch (error) {
        core.error(`Error getting changed paths: ${error.message}`);
        return [];
    }
}

module.exports = { getChangedPaths };
````

## File: .github/actions/test/index.js
````javascript
const core = require('@actions/core');
const github = require('@actions/github');
const { getChangedPaths } = require('./getChangedPaths');

async function run() {
    try {
        const baseRef = core.getInput('base-ref') ||
            process.env.GITHUB_BASE_REF ||     // present on PR events
            github.context.payload?.repository?.default_branch ||
            'master';
        const affectedDirs = await getChangedPaths(baseRef);

        core.info('Affected directories: ' + affectedDirs.join(', '));
        core.setOutput('affected-dirs', affectedDirs.join(' '));
    } catch (error) {
        core.setFailed(error.message);
    }
}

run();
````

## File: .github/actions/test/package.json
````json
{
    "name": "detect-changed-paths",
    "version": "1.0.0",
    "private": true,
    "main": "index.js",
    "dependencies": {
        "@actions/core": "^1.10.0",
        "@actions/github": "^6.0.0"
    },
    "devDependencies": {
        "@vercel/ncc": "^0.38.3"
    },
    "scripts": {
        "build": "ncc build index.js -o dist"
    }
}
````

## File: .github/ISSUE_TEMPLATE/bug_report.md
````markdown
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: ''
assignees: ''

---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Browser [e.g. chrome, safari]
 - Version [e.g. 22]

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Additional context**
Add any other context about the problem here.
````

## File: .github/ISSUE_TEMPLATE/feature_request.md
````markdown
---
name: Feature request
about: Suggest an idea for this project
title: ''
labels: ''
assignees: ''

---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
````

## File: .github/workflows/checks.yml
````yaml
name: checks

on:
  pull_request:
    branches:
      - master
  deployment_status:

jobs:
  run-checks:
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22.13.0'
          cache: 'npm'
          cache-dependency-path: 'package-lock.json'

      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
          npm config set progress false
          npm config set loglevel error

      - name: Clean install
        run: |
          echo "Cleaning up any existing node_modules..."
          rm -rf node_modules package-lock.json
          echo "Installing all dependencies from the root..."
          # Skip nx wrapper postinstall to prevent hanging
          NX_WRAPPER_SKIP_INSTALL=true npm install --no-fund --no-audit --prefer-offline
        timeout-minutes: 10
        env:
          NX_WRAPPER_SKIP_INSTALL: true

      - name: Initialize Nx
        run: |
          echo "Manually initializing nx installation..."
          npx nx --version
        timeout-minutes: 5
      - name: Setup environment variables
        run: |
          cp packages/agents/vickie-bennie/.env.sample packages/agents/vickie-bennie/.env
          cp packages/foundry-tracing-foundations/.env.sample packages/foundry-tracing-foundations/.env
        timeout-minutes: 5

      - name: Build Affected Projects
        run: |
          echo "Building affected projects..."
          npx nx affected --target=build --base=origin/${{ github.base_ref }} --parallel=3

      - name: Run Tests on Affected Projects
        run: |
          echo "Running tests for affected projects..."
          npx nx affected --target=test --base=origin/${{ github.base_ref }} --parallel=3
        env:
          BASE_URL: ${{ github.event.deployment_status.environment_url || 'http://localhost:3000' }}
          GITLAB_HOST: https://gitlabhubdev.chemli.app
          GITLAB_ROOT_TOKEN: ${{secrets.GITLAB_ROOT_TOKEN}}
          OPENAI_API_KEY: ${{secrets.OPENAI_API_KEY}}
          BLOB_READ_WRITE_TOKEN: ${{secrets.BLOB_READ_WRITE_TOKEN}}
          KV_REST_API_READ_ONLY_TOKEN: ${{secrets.KV_REST_API_READ_ONLY_TOKEN}}
          KV_REST_API_TOKEN: ${{secrets.KV_REST_API_TOKEN}}
          KV_REST_API_URL: ${{secrets.KV_REST_API_URL}}
          KV_URL: ${{secrets.KV_URL}}
          GSUITE_SERVICE_ACCOUNT: ${{secrets.GSUITE_SERVICE_ACCOUNT}}
````

## File: .github/CODE_OF_CONDUCT.md
````markdown
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to innovate and find novel solutions to problems. We value merit and winning. We don't consider sexuality, what you look like, where you come from, or any immutable characteristic members possess. We do not believe in brining your whole self to work. Members wil bring their professional self to this community and extend professional courtesy and respect to everyone.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and honest, accepting constructive feedback. We do not condone ruinous empathy and obnoxious aggression.
* Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience
* Collaborating together to solve real problems that have a real positive impact on the world

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.
````

## File: .github/CODEOWNERS
````
# All code paths (everything in the repo, recursive)
* @doriansmiley
````

## File: .github/CONTRIBUTING.md
````markdown
### Contributing

* Fork repo
* Review open issues
* Pick one that is unassigned and has the label "Help Wanted"
* Create your code
* Build/modify the required test(s)
* `npm run test`
* `npm run lint`
* Submit your PR. Make sure you fill out a good description and a link to the issue. Empty PR descriptions or missing issue links will result in PR closure.
````

## File: .github/dependabot.yml
````yaml
version: 2

updates:
  #  GitHubActions (workflow steps) 
  - package-ecosystem: "github-actions"
    directory: "/"                # scans .github/workflows
    schedule:
      interval: "weekly"

  #  Local action in .github/actions/test 
  - package-ecosystem: "npm"
    directory: "/.github/actions/test"
    schedule:
      interval: "daily"

  #  foundrytracingfoundations package 
  - package-ecosystem: "npm"
    directory: "/foundry-tracing-foundations"
    schedule:
      interval: "daily"

  #  helloworld package 
  - package-ecosystem: "npm"
    directory: "/hello-world"
    schedule:
      interval: "daily"

  #  xreasonnode package 
  - package-ecosystem: "npm"
    directory: "/x-reason-node"
    schedule:
      interval: "daily"
````

## File: .github/PULL_REQUEST_TEMPLATE.md
````markdown
# What is the purpose of this change?
<!--
What functionality does this introduce or what feature does this fix? How and why?
Please link to a GitHub issue if applicable
-->

<!-- You can erase any parts of this template not applicable to your Pull Request. -->

* [ ] Have you written unit tests, as applicable?
* [ ] Have you run build and linter steps locally to ensure you fix your code before iterating on the PR?
* [ ] Have you run the tests locally, as applicable, and ensured they pass before issuing this PR?
````

## File: .nx/nxw.js
````javascript
"use strict";
// This file should be committed to your repository! It wraps Nx and ensures
// that your local installation matches nx.json.
// See: https://nx.dev/recipes/installation/install-non-javascript for more info.




Object.defineProperty(exports, "__esModule", { value: true });
const fs = require('fs');
const path = require('path');
const cp = require('child_process');
const installationPath = path.join(__dirname, 'installation', 'package.json');
function matchesCurrentNxInstall(currentInstallation, nxJsonInstallation) {
    if (!currentInstallation.devDependencies ||
        !Object.keys(currentInstallation.devDependencies).length) {
        return false;
    }
    try {
        if (currentInstallation.devDependencies['nx'] !==
            nxJsonInstallation.version ||
            require(path.join(path.dirname(installationPath), 'node_modules', 'nx', 'package.json')).version !== nxJsonInstallation.version) {
            return false;
        }
        for (const [plugin, desiredVersion] of Object.entries(nxJsonInstallation.plugins || {})) {
            if (currentInstallation.devDependencies[plugin] !== desiredVersion) {
                return false;
            }
        }
        return true;
    }
    catch {
        return false;
    }
}
function ensureDir(p) {
    if (!fs.existsSync(p)) {
        fs.mkdirSync(p, { recursive: true });
    }
}
function getCurrentInstallation() {
    try {
        return require(installationPath);
    }
    catch {
        return {
            name: 'nx-installation',
            version: '0.0.0',
            devDependencies: {},
        };
    }
}
function performInstallation(currentInstallation, nxJson) {
    fs.writeFileSync(installationPath, JSON.stringify({
        name: 'nx-installation',
        devDependencies: {
            nx: nxJson.installation.version,
            ...nxJson.installation.plugins,
        },
    }));
    try {
        cp.execSync('npm i', {
            cwd: path.dirname(installationPath),
            stdio: 'inherit',
            windowsHide: false,
        });
    }
    catch (e) {
        // revert possible changes to the current installation
        fs.writeFileSync(installationPath, JSON.stringify(currentInstallation));
        // rethrow
        throw e;
    }
}
function ensureUpToDateInstallation() {
    const nxJsonPath = path.join(__dirname, '..', 'nx.json');
    let nxJson;
    try {
        nxJson = require(nxJsonPath);
        if (!nxJson.installation) {
            console.error('[NX]: The "installation" entry in the "nx.json" file is required when running the nx wrapper. See https://nx.dev/recipes/installation/install-non-javascript');
            process.exit(1);
        }
    }
    catch {
        console.error('[NX]: The "nx.json" file is required when running the nx wrapper. See https://nx.dev/recipes/installation/install-non-javascript');
        process.exit(1);
    }
    try {
        ensureDir(path.join(__dirname, 'installation'));
        const currentInstallation = getCurrentInstallation();
        if (!matchesCurrentNxInstall(currentInstallation, nxJson.installation)) {
            performInstallation(currentInstallation, nxJson);
        }
    }
    catch (e) {
        const messageLines = [
            '[NX]: Nx wrapper failed to synchronize installation.',
        ];
        if (e instanceof Error) {
            messageLines.push('');
            messageLines.push(e.message);
            messageLines.push(e.stack);
        }
        else {
            messageLines.push(e.toString());
        }
        console.error(messageLines.join('\n'));
        process.exit(1);
    }
}
if (!process.env.NX_WRAPPER_SKIP_INSTALL) {
    ensureUpToDateInstallation();
}

require('./installation/node_modules/nx/bin/nx');
````

## File: apps/agents/public/circleLogo-big.svg
````
<svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 408 408"><defs><style>.cls-1{fill:#7dcb87;}.cls-2,.cls-3{fill:#fff;}.cls-3{fill-rule:evenodd;}</style></defs><circle class="cls-1" cx="204" cy="204" r="204"/><path class="cls-2" d="M62.59,150.88A156.5,156.5,0,0,1,348.92,132a2.75,2.75,0,0,0,0,.81h0a89.11,89.11,0,0,0-19.58,8.57C291.8,89.92,226,60.87,158,93.19a122.4,122.4,0,1,0,103.87,221.3c7.51-3.51,9.06,16.32,15.83,10.85a122.83,122.83,0,0,0,18.53-17.14l31.58-1.14A156.56,156.56,0,0,1,62.59,150.88Z"/><path class="cls-3" d="M125.17,335.46c64.39,45.29,108.21,12.4,147.86,3.83,31.42-6.85,63.73-37.37,75.89-53,1.8-2.28,11.92-12.4.49-14.6-6.93-1.31-16.32,9.46-33.13,20.81S286,310.41,251,315.47c-7.67,1.14-26.52,1.3-29-8.16-1.79-7,9.22-14.94,18.61-22.69,23-19.09,8.16-46.51-.82-33.21-12.89,19.67-18.44,17.71-42.92,33.46a103.28,103.28,0,0,0-32.64,32.64C149.25,342.72,99,304.45,125,336Zm148.68-29.22a121.49,121.49,0,0,0,19.58-5.87c6.78-11.59,13.63-23.75,11.18-26.36s-12.89-1.38-22.68,18.85a110.64,110.64,0,0,1-8.16,13.38Zm22.36-7a134.29,134.29,0,0,0,19.42-10.69l7.1-4.74c5.3-8.89,9.38-16.72,7.51-18.76-3.27-3.68-12.73-1.88-23.26,18a121.12,121.12,0,0,1-10.77,16.32Zm-40.8,10.2c6-.82,11.18-1.72,16.32-2.7,5.95-10.2,11.67-20.56,9.46-22.84s-11.58-1.31-20.56,17.05a85.55,85.55,0,0,1-4.81,8.16Z"/></svg>
````

## File: apps/agents/specs/index.spec.tsx
````typescript
import React from 'react';
import { render } from '@testing-library/react';
import Page from '../src/app/page';

describe('Page', () => {
  it('should render successfully', () => {
    const { baseElement } = render(<Page />);
    expect(baseElement).toBeTruthy();
  });
});
````

## File: apps/agents/src/app/api/communications/route.ts
````typescript
export const runtime = 'nodejs';

import { NextRequest, NextResponse } from 'next/server';
import { TYPES, CommsDao } from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';
import { uuidv4 } from '@codestrap/developer-foundations-utils';
import { withRequestContext } from '@codestrap/developer-foundations-utils/src/lib/asyncLocalStorage';

export async function OPTIONS() {
  return new NextResponse(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization, x-foundry-access-token',
    },
  });
}

export async function GET(req: NextRequest) {
  try {
    const searchParams = req.nextUrl.searchParams;
    const token = req.headers.get('x-foundry-access-token');

    const id = searchParams.get('id');

    if (!id) {
      return NextResponse.json({
        response_type: 'ephemeral',
        text: ' Missing required id param.',
      });
    }

    return withRequestContext({ token, requestId: uuidv4() }, async () => {
      const commsDao = container.get<CommsDao>(TYPES.CommsDao);
      const result = await commsDao.read(id);

      return NextResponse.json(result);
    });
  } catch (err) {
    console.error('Error reading communications object:', err);
    return new NextResponse('Internal error', { status: 500 });
  }
}
````

## File: apps/agents/src/app/api/energy/read/route.ts
````typescript
export const runtime = 'nodejs';

import { NextRequest, NextResponse } from 'next/server';
import { EnergyService, TYPES } from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

export async function OPTIONS() {
  return new NextResponse(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    },
  });
}

export async function POST(req: NextRequest) {
  try {
    const eiaService = container.get<EnergyService>(TYPES.EnergyService);

    const {
      scenarioPrices = [5, 6, 7, 8],
      caGallonsYear = 13.4e9,
      caGdp = 4.1e12,
      caShareUsGdp = 0.14,
    } = await safeJson(req);

    // Validate minimal sanity on inputs (keep it lightweight, no extra deps)
    if (
      !Array.isArray(scenarioPrices) ||
      !scenarioPrices.every((n) => typeof n === 'number')
    ) {
      return badRequest('scenarioPrices must be an array of numbers.');
    }
    if (typeof caGallonsYear !== 'number' || caGallonsYear <= 0) {
      return badRequest('caGallonsYear must be a positive number.');
    }
    if (typeof caGdp !== 'number' || caGdp <= 0) {
      return badRequest('caGdp must be a positive number.');
    }
    if (
      typeof caShareUsGdp !== 'number' ||
      caShareUsGdp <= 0 ||
      caShareUsGdp > 1
    ) {
      return badRequest('caShareUsGdp must be a number between 0 and 1.');
    }

    const results = await eiaService.read(
      scenarioPrices,
      caGallonsYear,
      caGdp,
      caShareUsGdp
    );

    return NextResponse.json(results, {
      status: 200,
      headers: corsHeaders(),
    });
  } catch (err) {
    console.error('energy/read error:', err);
    return NextResponse.json(
      { error: (err as Error)?.message ?? 'Internal error' },
      { status: 500, headers: corsHeaders() }
    );
  }
}

/** Helpers */

async function safeJson(req: NextRequest) {
  try {
    if (req.headers.get('content-type')?.includes('application/json')) {
      return await req.json();
    }
    // Support x-www-form-urlencoded if you want parity with your template
    const text = await req.text();
    try {
      return JSON.parse(text);
    } catch {
      // fallback to URLSearchParams
      const params = new URLSearchParams(text);
      return Object.fromEntries(params.entries());
    }
  } catch {
    return {};
  }
}

function badRequest(message: string) {
  return NextResponse.json(
    { error: message },
    { status: 400, headers: corsHeaders() }
  );
}

function corsHeaders() {
  return {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
    'Access-Control-Allow-Headers': 'Content-Type, Authorization',
  };
}
````

## File: apps/agents/src/app/api/energy/vega/route.ts
````typescript
export const runtime = 'nodejs';

import { NextRequest, NextResponse } from 'next/server';
import { EnergyService, TYPES } from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

export async function OPTIONS() {
  return new NextResponse(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    },
  });
}

export async function POST(req: NextRequest) {
  try {
    const eiaService = container.get<EnergyService>(TYPES.EnergyService);

    const {
      scenarioPrices = [5, 6, 7, 8],
      caGallonsYear = 13.4e9,
      caGdp = 4.1e12,
      caShareUsGdp = 0.14,
    } = await safeJson(req);

    if (
      !Array.isArray(scenarioPrices) ||
      !scenarioPrices.every((n) => typeof n === 'number')
    ) {
      return badRequest('scenarioPrices must be an array of numbers.');
    }
    if (typeof caGallonsYear !== 'number' || caGallonsYear <= 0) {
      return badRequest('caGallonsYear must be a positive number.');
    }
    if (typeof caGdp !== 'number' || caGdp <= 0) {
      return badRequest('caGdp must be a positive number.');
    }
    if (
      typeof caShareUsGdp !== 'number' ||
      caShareUsGdp <= 0 ||
      caShareUsGdp > 1
    ) {
      return badRequest('caShareUsGdp must be a number between 0 and 1.');
    }

    const results = await eiaService.read(
      scenarioPrices,
      caGallonsYear,
      caGdp,
      caShareUsGdp
    );

    const spec = eiaService.getVegaChartData(results);

    return NextResponse.json(spec, {
      status: 200,
      headers: corsHeaders(),
    });
  } catch (err) {
    console.error('energy/read error:', err);
    return NextResponse.json(
      { error: (err as Error)?.message ?? 'Internal error' },
      { status: 500, headers: corsHeaders() }
    );
  }
}

/** Helpers */

async function safeJson(req: NextRequest) {
  try {
    if (req.headers.get('content-type')?.includes('application/json')) {
      return await req.json();
    }
    const text = await req.text();
    try {
      return JSON.parse(text);
    } catch {
      const params = new URLSearchParams(text);
      return Object.fromEntries(params.entries());
    }
  } catch {
    return {};
  }
}

function badRequest(message: string) {
  return NextResponse.json(
    { error: message },
    { status: 400, headers: corsHeaders() }
  );
}

function corsHeaders() {
  return {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
    'Access-Control-Allow-Headers': 'Content-Type, Authorization',
  };
}
````

## File: apps/agents/src/app/api/machines/route.ts
````typescript
export const runtime = 'nodejs';

import { NextRequest, NextResponse } from 'next/server';
import { TYPES, MachineDao } from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';
import { uuidv4 } from '@codestrap/developer-foundations-utils';
import { withRequestContext } from '@codestrap/developer-foundations-utils/src/lib/asyncLocalStorage';

export async function OPTIONS() {
  return new NextResponse(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization, x-foundry-access-token',
    },
  });
}

export async function GET(req: NextRequest) {
  try {
    const searchParams = req.nextUrl.searchParams;
    const token = req.headers.get('x-foundry-access-token');

    const id = searchParams.get('id');

    if (!id) {
      return NextResponse.json({
        response_type: 'ephemeral',
        text: ' Missing required id param.',
      });
    }

    console.log(`calling machineDao.read with id ${id}`);

    return withRequestContext({ token, requestId: uuidv4() }, async () => {
      const machineDao = container.get<MachineDao>(TYPES.MachineDao);
      const result = await machineDao.read(id);

      return NextResponse.json(result);
    });
  } catch (err) {
    console.error('Error reading machine object:', (err as Error).stack);
    return new NextResponse('Internal error', { status: 500 });
  }
}
````

## File: apps/agents/src/app/api/slack/route.ts
````typescript
import { NextRequest, NextResponse } from 'next/server';
import crypto from 'crypto';
import { Vickie } from '@codestrap/developer-foundations-agents-vickie-bennie';

const SLACK_BOT_TOKEN = process.env.SLACK_BOT_TOKEN!;
const SIGNING_SECRET = process.env.SLACK_SIGNING_SECRET!;

export async function OPTIONS() {
  return new NextResponse(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    },
  });
}

function verifySlackSignature(req: NextRequest, body: string): boolean {
  const timestamp = req.headers.get('x-slack-request-timestamp');
  const signature = req.headers.get('x-slack-signature');
  if (!timestamp || !signature) return false;

  const fiveMinutesAgo = Math.floor(Date.now() / 1000) - 60 * 5;
  if (parseInt(timestamp) < fiveMinutesAgo) return false;

  const sigBase = `v0:${timestamp}:${body}`;
  const hmac = crypto.createHmac('sha256', SIGNING_SECRET);
  hmac.update(sigBase);
  const mySig = `v0=${hmac.digest('hex')}`;

  return crypto.timingSafeEqual(Buffer.from(mySig), Buffer.from(signature));
}

export async function POST(req: NextRequest) {
  const bodyText = await req.text();

  if (!verifySlackSignature(req, bodyText)) {
    return new NextResponse('Invalid signature', { status: 401 });
  }

  const params = new URLSearchParams(bodyText);
  const threadTs = params.get('thread_ts');
  const userId = params.get('user_id');
  const text = params.get('text');
  const channelId = params.get('channel_id');
  const command = params.get('command');

  if (!channelId || !userId || !text || !command) {
    return NextResponse.json({
      response_type: 'ephemeral',
      text: ' Missing required data.',
    });
  }

  try {
    // Post command acknowledgment to channel (and get ts for a new thread if needed)
    const initialPostRes = await fetch(
      'https://slack.com/api/chat.postMessage',
      {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${SLACK_BOT_TOKEN}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          channel: channelId,
          text: ` <@${userId}> used \`${command} ${text}\``,
        }),
      }
    );

    const initialPostData = await initialPostRes.json();
    const threadRootTs = threadTs || initialPostData.ts;

    if (!initialPostData.ok) {
      throw new Error(`Slack postMessage failed: ${initialPostData.error}`);
    }

    const vickie = new Vickie();
    const result = await vickie.askVickie(text, userId);

    // Post Foundry result as threaded reply
    const replyRes = await fetch('https://slack.com/api/chat.postMessage', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${SLACK_BOT_TOKEN}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        channel: channelId,
        thread_ts: threadRootTs,
        mrkdwn: true,
        text: ` <@${userId}>,\n${result.message}`,
      }),
    });

    const replyData = await replyRes.json();

    if (!replyData.ok) {
      throw new Error(`Slack reply failed: ${replyData.error}`);
    }

    return new NextResponse('Message posted to thread.', { status: 200 });
  } catch (err) {
    console.error('Error handling slash command:', err);
    return new NextResponse('Internal error', { status: 500 });
  }
}
````

## File: apps/agents/src/app/api/vickie/route.ts
````typescript
export const runtime = 'nodejs';

import { NextRequest, NextResponse } from 'next/server';
import { Vickie } from '@codestrap/developer-foundations-agents-vickie-bennie';
import { User } from '@osdk/foundry.admin';
import { uuidv4 } from '@codestrap/developer-foundations-utils';
import { withRequestContext } from '@codestrap/developer-foundations-utils/src/lib/asyncLocalStorage';

export async function OPTIONS() {
  return new NextResponse(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET,POST,OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization, x-foundry-access-token',
    },
  });
}

export async function POST(req: NextRequest) {
  try {
    const bodyText = await req.text();
    const token = req.headers.get('x-foundry-access-token');

    const params = new URLSearchParams(bodyText);
    const threadId = params.get('threadId') || undefined;
    const user = (params.get('user')) ? JSON.parse(params.get('user')!) as User : undefined;
    const userId = user?.id;
    const text = params.get('query') || undefined;
    const action = params.get('action');
    const plan = params.get('plan') || undefined;
    const executionId = params.get('executionId') || undefined;
    const forward: boolean =
      params.get('forward') === null ? true : params.get('forward') === 'true';
    const inputs = params.get('inputs') || undefined;

    if (!action) {
      return NextResponse.json({
        response_type: 'ephemeral',
        text: ' Missing required action param.',
      });
    }

    return withRequestContext({ token, user, requestId: uuidv4() }, async () => {
      const vickie = new Vickie();

      switch (action) {
        case 'askVickie':
          if (!text || !userId) {
            return NextResponse.json({
              response_type: 'ephemeral',
              text: ' Missing required text and userId params.',
            });
          }
          // fire and forget as to not timeout, short polling should be used in the client
          await vickie.askVickie(text, userId, threadId);
        // eslint-disable-next-line no-fallthrough
        case 'getTaskList':
          if (!text || !userId) {
            return NextResponse.json({
              response_type: 'ephemeral',
              text: ' Missing required text and userId params.',
            });
          }

          // fire and forget as to not timeout, short polling should be used in the client
          await vickie.createComsTasksList(text, userId, threadId);
        // eslint-disable-next-line no-fallthrough
        case 'executeTaskList':
          // fire and forget as to not timeout, short polling should be used in the client
          await vickie.getNextState(plan, forward, executionId, inputs, 'coms');
      }

      return NextResponse.json({
        status: 200,
        message: 'I am executing the request in the background.',
        executionId,
        threadId,
      });
    });
  } catch (err) {
    console.error('Error executing vickie:', err);
    return new NextResponse('Internal error', { status: 500 });
  }
}
````

## File: apps/agents/src/app/components/agents/foundryClientPublic.ts
````typescript
import { createClient } from '@osdk/client';
import { User, Users } from '@osdk/foundry.admin';
import { createPublicOauthClient } from '@osdk/oauth';
import { FoundryClient, Token } from '@codestrap/developer-foundations-types';

// this is a utility method to manage usage of the Foundry Client and ensure we only get a singleton
// files in the palantir services package can't use the container to get the foundry client, nor should they really
// They are in the same package
let client: FoundryClient | undefined = undefined;

export function getFoundryClient(): FoundryClient {
  if (!client) {
    client = createFoundryClient();
  }

  return client;
}

function createFoundryClient(): FoundryClient {
  // log ENV vars
  console.log('Environment variable keys:');
  Object.keys(process.env).forEach((key) => {
    if (key.indexOf('NEXT_PUBLIC_') >= 0) {
      console.log(`- ${key}`);
    }
  });

  if (!process.env['NEXT_PUBLIC_OSDK_CLIENT_ID']
    || !process.env['NEXT_PUBLIC_REDIRECT_URL']
    || !process.env['NEXT_PUBLIC_FOUNDRY_STACK_URL']
    || !process.env['NEXT_PUBLIC_ONTOLOGY_RID']
  ) {
    throw new Error(
      'missing required env vars: NEXT_PUBLIC_OSDK_CLIENT_ID, NEXT_PUBLIC_REDIRECT_URL, NEXT_PUBLIC_FOUNDRY_STACK_URL, NEXT_PUBLIC_ONTOLOGY_RID'
    );
  }

  // setup the OSDK
  const clientId: string = process.env['NEXT_PUBLIC_OSDK_CLIENT_ID'];
  const url: string = process.env['NEXT_PUBLIC_FOUNDRY_STACK_URL'];
  const ontologyRid: string = process.env['NEXT_PUBLIC_ONTOLOGY_RID'];
  const redirectUrl: string = window.location.href.split('?')[0];
  const scopes: string[] = [
    'api:use-ontologies-read',
    'api:use-ontologies-write',
    'api:use-admin-read',
    'api:use-connectivity-read',
    'api:use-connectivity-execute',
    'api:use-orchestration-read',
    'api:use-mediasets-read',
    'api:use-mediasets-write'
  ];
  //                                   client_id, url,redirectUrl, useHistory, loginPage, postLoginPage, scopes
  const auth = createPublicOauthClient(clientId, url, redirectUrl, true, redirectUrl, redirectUrl, scopes);
  const client = createClient(url, ontologyRid, auth);

  const getUser = async () => {
    const user: User = await Users.getCurrent(client);

    return user;
  };

  let token: Token | undefined;
  let tokenExpire: Date | undefined;
  let pendingRequest: Promise<Token> | undefined;

  auth.addEventListener('signIn', (evt) => {
    token = evt.detail; // Token
    tokenExpire = new Date(token.expires_at);
  });

  auth.addEventListener('signOut', (evt) => {
    token = undefined;
    tokenExpire = undefined;
  });

  auth.addEventListener('refresh', (evt) => {
    token = evt.detail; // Token
    tokenExpire = new Date(token.expires_at);
  });

  const getToken = async function () {
    if (token && tokenExpire) {
      // add 60 seconds to account for processing time
      const skew = tokenExpire.getTime() + 60000;

      if (skew > new Date().getTime()) {
        return token.access_token;
      }
    }
    // avoid duplicate signin requests
    if (!pendingRequest) {
      pendingRequest = auth.signIn();
    }

    try {
      token = await pendingRequest;

      return token.access_token;
    } catch (e) {
      console.log(e);

      throw (e);
    } finally {
      pendingRequest = undefined;
    }

  }

  return { auth, ontologyRid, url, client, getUser, getToken };
}
````

## File: apps/agents/src/app/components/agents/TokenResource.ts
````typescript
// userResource.ts
/** Minimal resource wrapper for Suspense */
function createResource<T>(promise: Promise<T>) {
    let status: "pending" | "success" | "error" = "pending";
    let result: T;
    let suspender = promise.then(
        (r) => {
            status = "success";
            result = r;
        },
        (e) => {
            status = "error";
            result = e;
        }
    );

    return {
        read(): T {
            if (status === "pending") throw suspender;
            if (status === "error") throw result;
            return result;
        },
    };
}

export function createTokenResource(getToken: () => Promise<string>) {

    return createResource<string>(getToken());
}
````

## File: apps/agents/src/app/components/agents/UserResource.ts
````typescript
// userResource.ts
import { User, Users } from "@osdk/foundry.admin";
import { Client } from "@osdk/client";

/** Minimal resource wrapper for Suspense */
function createResource<T>(promise: Promise<T>) {
    let status: "pending" | "success" | "error" = "pending";
    let result: T;
    let suspender = promise.then(
        (r) => {
            status = "success";
            result = r;
        },
        (e) => {
            status = "error";
            result = e;
        }
    );

    return {
        read(): T {
            if (status === "pending") throw suspender;
            if (status === "error") throw result;
            return result;
        },
    };
}

export function createUserResource(getUser: () => Promise<User>) {

    return createResource<User>(getUser());
}
````

## File: apps/agents/src/app/components/agents/Vickie.css
````css
@property --blur {
            syntax: "<length>";
            initial-value: 0;
            inherits: true;
        }

        @property --spread {
            syntax: "<length>";
            initial-value: 0;
            inherits: true;
        }

        @property --color {
            syntax: "<color>";
            initial-value: rgb(0, 255, 85);
            inherits: true;
        }

        @property --lighter-color {
            syntax: "<color>";
            initial-value: color-mix(in srgb, var(--color) 80%, white);
            inherits: true;
        }

        @property --darker-color {
            syntax: "<color>";
            initial-value: color-mix(in srgb, var(--color) 60%, rgb(2, 137, 24));
            inherits: true;
        }

        @property --angle {
            syntax: "<angle>";
            initial-value: 0deg;
            inherits: true;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        .orb {
            --size: 200px;
            --color: red;
            --lighter-color: color-mix(in srgb, var(--color) 60%, white);
            --darker-color: color-mix(in srgb, var(--color) 40%, black);
            --blur: 40px;
            --spread: 5px;
            --angle: -90deg;
            --border: 10px;

            position: relative;
            width: var(--size);
            height: var(--size);
            aspect-ratio: 1;
            background:
                radial-gradient(color-mix(in srgb, var(--darker-color) 65%, transparent) -50%, transparent 50%),
                radial-gradient(var(--color), var(--color)) no-repeat 50% 50% / 50% 50%,
                url('/circleLogo-big.svg') no-repeat 50% 50% / 35%,
                linear-gradient(#ffffff, #ffffff) padding-box,
                conic-gradient(from var(--angle) at 50% 50%, color-mix(in srgb, var(--lighter-color), transparent) 0 72deg, var(--darker-color) 100deg 180deg, transparent 288deg, color-mix(in srgb, var(--lighter-color), transparent)) border-box,
                radial-gradient(farthest-corner at 50% 50%, transparent 50%, var(--darker-color) 80% 100%) border-box;

            background-blend-mode: normal, overlay, multiply, normal, normal, normal, normal;
            border: var(--border) solid transparent;
            border-radius: 50%;
            box-shadow: 0 0 var(--blur) var(--spread) var(--darker-color);
            display: flex;
            align-items: center;
            justify-content: center;
            animation: 10s linear infinite change-color, 5s linear infinite orb;

        }

        @keyframes change-color {
            0% {
                --color: rgb(255, 255, 255);
            }

            12% {
                --color: rgb(89, 255, 0);
            }

            24% {
                --color: yellow;
            }

            36% {
                --color: rgb(225, 255, 0);
            }

            48% {
                --color: rgb(255, 255, 0);
            }

            60% {
                --color: dodgerblue;
            }

            72% {
                --color: rgb(255, 0, 255);
            }

            84% {
                --color: rgb(0, 255, 85);
            }
        }

        @keyframes orb {
            0% {
                --angle: -90deg;
                --blur: 40px;
                --spread: 5px;
            }

            50% {
                --blur: 80px;
                --spread: 10px;
            }

            100% {
                --angle: 270deg;
            }
        }

        .orb:hover {
            animation: reset .2s linear 1 forwards;
        }

        @keyframes reset {
            to {
                --color: rgb(5, 182, 46);
                --blur: 40px;
                --spread: 5px;
                --angle: -90deg;
            }
        }
        /* Animation classes */
.animate-orb {
  animation: wave 0.4s infinite ease-in-out;
}

.animate-orb-slow {
  animation: wave 2s infinite ease-in-out;
}

/* Keyframes */
@keyframes wave {
  0%, 100% {
    transform: scale(1);
  }
  50% {
    transform: scale(1.05);
  }
}

@keyframes rotate {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}
````

## File: apps/agents/src/app/components/agents/Vickie.tsx
````typescript
/* eslint-disable prefer-const */
// Vickie.tsx
"use client";

import { Suspense, useCallback, useEffect, useMemo, useRef, useState } from "react";

import { Button } from "../ui/button";
import { Card } from "../ui/card";
import { useConversation } from "@elevenlabs/react";
import { callAskVickie } from "../../services/vickie.service";
import { uuidv4 } from "@codestrap/developer-foundations-utils";
import { callGetCommunications, callGetMachines } from "../../services/executions.service";
import { PlayCircle, Square, Mic, MicOff } from "lucide-react";
import { createUserResource } from "./UserResource";
import { createTokenResource } from "./TokenResource";
import { getFoundryClient } from "./foundryClientPublic";

const { client, getUser, getToken } = getFoundryClient();
const userResource = createUserResource(getUser);
const tokenResource = createTokenResource(getToken);


type GetNextStateResult = {
    value: string;
    theResultOfEachTask: {
        taskName: string;
        taskOutput: string;
    }[];
    orderTheTasksWereExecutedIn: string[];
};

function VickieInner() {

    const [messages, setMessages] = useState<string>('');
    const [taskList, setTaskList] = useState<string>('');
    const [value, setValue] = useState<string>('');
    const [getTaskListToolExecuted, setGetTaskListToolExecuted] = useState<boolean>(false);
    const [getTaskListToolAttempts, setGetTaskListAttempts] = useState<number>(0);
    const [executeTaskListToolExecuted, setExecuteTaskListToolExecuted] = useState<boolean>(false);
    const [executeTaskListToolAttempts, setExecuteTaskListAttempts] = useState<number>(0);
    const [micMuted, setMicMuted] = useState(false);

    const executionIdRef = useRef<string | undefined>(undefined);
    const taskListRef = useRef<string | undefined>(undefined);
    const scrollRef = useRef<HTMLDivElement>(null);

    const user = userResource.read();
    const token = tokenResource.read();


    useEffect(() => {
        const el = scrollRef.current;
        if (el) {
            el.scrollTop = el.scrollHeight;
        }
    }, [messages]);

    const conversation = useConversation({
        micMuted,
        dynamicVariables: {
            localDay: new Date().getDay(),
            locatDateTime: new Date().toString(),
            userId: user?.id || 'undefined',
            userName: user?.givenName || 'undefined',
            threadId: '',
        },
        clientTools: {
            getTaskListTool: async (parameters: { query: string, userId: string, threadId?: string }) => {
                console.log(`local getTaskListTool called with: ${JSON.stringify(parameters)}`);
                setGetTaskListToolExecuted(true);
                setGetTaskListAttempts(0);
                let { query, userId, threadId } = { ...parameters };

                if (!threadId) {
                    threadId = uuidv4();
                }

                if (!query || !userId) {
                    return `Both query and userId are required to call the getTaskListTool tool. You supplied query: ${query} asn userId :${userId}. Please try again passing the required parameters.`;
                }

                // fire and forget to avoid timeouts
                callAskVickie({
                    user,
                    token,
                    action: 'getTaskList',
                    query,
                    threadId,
                }) as unknown as { threadId: string };


                console.log(`Got threadId: ${threadId} back from callAskVickie execution, starting polling`);
                triggerPolling(threadId, 'getTaskListTool');

                return `The task list is being generated in the background for executionId/threadId ${threadId}. 
                    You will receive a contextual update with the well defined defined task list when the operation is complete. 
                    Wait until you get the results before proceeding!!!`;
            },
            // TODO get the model to pass the threadId/executionID to support multiple ongoing task executions
            executeTaskList: async (parameters: { plan: string, threadId: string }) => {
                setExecuteTaskListToolExecuted(true);
                setExecuteTaskListAttempts(0);
                const { threadId } = { ...parameters };

                if (!threadId || !taskListRef.current) {
                    return `Both threadId and taskList are required to call the executeTaskList tool. Please try again passing the required parameters.`;
                }

                console.log(`local executeTaskList for execution Id ${threadId} called with: ${taskListRef.current}`);

                // fire and forget to avoid timeouts
                callAskVickie({
                    action: 'executeTaskList',
                    token,
                    user,
                    executionId: threadId,
                    plan: taskListRef.current,
                }) as unknown as GetNextStateResult;

                triggerPolling(threadId, 'executeTaskList');

                return `The execute task list tool is being executed for executionId/threadId: ${executionIdRef.current} in the background. 
                    You will receive a contextual update when the operation is complete. 
                    Once received summarize the results for the user including the order the tasks were executed in. 
                    Wait until you get the results before proceeding!!!`
            },

        },
        onConnect: () => {
            console.log("connected");
            setMessages('');
            setValue('');
        },
        onDisconnect: () => console.log("disconnected"),
        onError: (e) => {
            console.error(e);
            alert("An error occurred during the conversation");
        },
        onMessage: (message) => {
            console.log(message);
            const role = message.source === "user" ? "User" : "System";
            setMessages(prev =>
                `
${prev}
vickieMessageDelimiter-New message received on: ${new Date()} from ${role}
${message.message}`
            );
        },
    });

    const triggerPolling = useCallback((executionId: string, action: string) => {
        console.log(`triggerPolling for ${executionId}`);
        if (!executionId) {
            console.log('not executionId found, stopping polling and exit');
            return;
        };

        if (executionIdRef.current !== executionId) {
            executionIdRef.current = executionId;
        }

        let attempts = 0;
        const maxAttempts = 10;
        const interval = 10000;

        const intervalId = setInterval(async () => {
            if (attempts >= maxAttempts) {
                clearInterval(intervalId);
                console.warn('Polling timed out after max attempts.');
                conversation.sendContextualUpdate(`Polling timed out after max attempts: ${maxAttempts} for threadID/executionId: ${executionId}. This means we've polled for a result for the max possible attempts but no result was returned. The execution has failed.`);
                return conversation.sendUserMessage(`My job failed for threadID/executionId: ${executionId}. Please let me know why.`)
            }

            try {
                switch (action) {
                    case 'getTaskListTool':
                        // eslint-disable-next-line no-case-declarations
                        const result = await callGetCommunications(executionId, token);
                        if (result?.taskList) {
                            setTaskList(result.taskList);
                            taskListRef.current = result.taskList;
                            conversation.sendContextualUpdate(
                                `The results for thread/executionId: ${executionId} have returned the following:
                                ${result.taskList}`
                            );
                            conversation.sendUserMessage(`Please summarize the results of the get task list tool for thread/executionId: ${executionId} and get my approval before calling the execute task list tool.`);
                            clearInterval(intervalId);
                            setGetTaskListToolExecuted(false);
                            setGetTaskListAttempts(0);
                        }
                        break;
                    case 'executeTaskList':
                        // eslint-disable-next-line no-case-declarations
                        const machine = await callGetMachines(executionId, token);
                        if (machine?.state) {
                            // eslint-disable-next-line @typescript-eslint/no-explicit-any
                            const state = JSON.parse(machine.state) as any;
                            const currentState = state.value;
                            // eslint-disable-next-line @typescript-eslint/no-explicit-any
                            const context = state.context as any
                            const results = Object.keys(context)
                                .filter(key => key.indexOf('|') >= 0)
                                .map(key => {
                                    const taskName = key.split('|')[0];
                                    const taskOutput = context[key];

                                    return { taskName, taskOutput };
                                });

                            // eslint-disable-next-line @typescript-eslint/no-explicit-any
                            const stack = (context.stack as any[])?.map(state => state.split('|')[0]);

                            // TODO add the current state
                            conversation.sendContextualUpdate(
                                `The results of the task list execution tool for thread/executionId ${executionId} are:
                                Results:
                                ${JSON.stringify({ orderTheTasksWereExecutedIn: stack!, theResultOfEachTask: results, value: currentState }, null, 2)}
                                `
                            );
                            conversation.sendUserMessage(`Please summarize the results of the execute task list tool for thread/executionId: ${executionId}.`);
                            clearInterval(intervalId);
                            setExecuteTaskListToolExecuted(false);
                            setExecuteTaskListAttempts(0);
                        }
                        break;
                }
            } catch (err) {
                console.error("Polling error:", err);
            } finally {
                attempts++;
                if (action === 'getTaskListTool') {
                    setGetTaskListAttempts(attempts);
                } else if (action === 'executeTaskList') {
                    setExecuteTaskListAttempts(attempts);
                }
            }
        }, interval);
    }, [conversation]);

    const requestMicrophonePermission = async () => {
        try {
            await navigator.mediaDevices.getUserMedia({ audio: true });
            return true;
        } catch {
            console.error("Microphone permission denied");
            return false;
        }
    };

    const startConversation = useCallback(async () => {
        if (!(await requestMicrophonePermission())) {
            alert("No permission");
            return;
        }
        setMessages('');
        executionIdRef.current = undefined;
        taskListRef.current = undefined;
        setTaskList('');
        const id = await conversation.startSession({ agentId: "UcIOy8NOGWaLn9nR3UCQ" });
        console.log(id);
    }, [conversation]);

    const stopConversation = useCallback(async () => {
        await conversation.endSession();
    }, [conversation]);

    const renderedMessages = useMemo(() => {
        return messages
            .split("vickieMessageDelimiter-")
            .filter(line => line.trim() !== "" && line.includes("New message received on:"))
            .map((line, idx) => {
                const parts = line.split('\n');
                const isSystem = parts[0]?.includes("System");

                return (
                    <div
                        key={idx}
                        className={`${isSystem ? "self-start" : "self-end"} max-w-[80%] bg-white shadow-sm px-4 py-2 rounded-lg border border-gray-200 text-gray-800`}
                    >
                        <span className="text-gray-500 italic">{parts[0]}</span>
                        <br />
                        <span>{parts.slice(1).join('\n')}</span>
                    </div>
                );
            });
    }, [messages]);

    const orbClasses =
        conversation.status === "connected"
            ? conversation.isSpeaking
                ? "orb orb-active animate-orb"
                : "orb animate-orb-slow orb-inactive"
            : "orb orb-inactive";

    return (
        <div className="flex justify-center items-center gap-4 items-stretch">
            <Card className="rounded-3xl">
                <div className="p-6 text-center">
                    <h5 className="text-lg font-semibold text-gray-900 dark:text-white">
                        {conversation.status === "connected"
                            ? conversation.isSpeaking
                                ? "Agent is speaking"
                                : "Agent is listening"
                            : "Disconnected"}
                    </h5>

                    {/* BUTTON STACK */}
                    <div className="flex flex-col gap-4 mt-6 w-full max-w-xs">
                        <div className={orbClasses + " my-16 mx-auto"} />

                        {/*  Start conversation  */}
                        <Button
                            onClick={startConversation}
                            disabled={conversation.status === "connected"}
                            className="
      w-full flex items-center justify-start gap-2
      bg-green-600 hover:bg-green-700
      disabled:bg-green-300 disabled:hover:bg-green-300 disabled:cursor-not-allowed
      text-white
    "
                        >
                            <PlayCircle className="h-5 w-5" />
                            Start conversation
                        </Button>

                        {/*  End conversation  */}
                        <Button
                            onClick={stopConversation}
                            disabled={conversation.status !== "connected"}
                            className="
      w-full flex items-center justify-start gap-2
      bg-red-600 hover:bg-red-700
      disabled:bg-red-300 disabled:hover:bg-red-300 disabled:cursor-not-allowed
      text-white
    "
                        >
                            <Square className="h-5 w-5" />
                            End conversation
                        </Button>

                        {/*  Mute / Un-mute mic  */}
                        <Button
                            onClick={() => setMicMuted(!micMuted)}
                            disabled={conversation.status !== "connected"}
                            className="
      w-full flex items-center justify-start gap-2
      bg-blue-600 hover:bg-blue-700
      disabled:bg-blue-300 disabled:hover:bg-blue-300 disabled:cursor-not-allowed
      text-white
    "
                        >
                            {micMuted ? (
                                <MicOff className="h-5 w-5" />
                            ) : (
                                <Mic className="h-5 w-5" />
                            )}
                            {micMuted ? "Unmute Mic" : "Mute Mic"}
                        </Button>
                    </div>

                </div>
            </Card>

            <Card className="flex flex-col justify-between p-6">
                <div className="h-full flex flex-col">
                    <div className={`mt-6 flex flex-col gap-4 ${!getTaskListToolExecuted ? "hidden" : ""}`}>
                        {/* Status Indicator */}
                        <div className="flex items-center gap-2">
                            <span className="text-sm font-medium">Task Tool Executed:</span>
                            <div className={`w-3 h-3 rounded-full ${getTaskListToolExecuted ? "bg-green-500" : "bg-red-500"}`} />
                        </div>

                        {/* Progress Bar */}
                        <div className="w-full">
                            <div className="flex justify-between mb-1 text-sm font-medium text-gray-700">
                                <span>Polling Attempts</span>
                                <span>{getTaskListToolAttempts}/10</span>
                            </div>
                            <div className="w-full h-2 bg-gray-200 rounded-full">
                                <div
                                    className="h-2 bg-blue-600 rounded-full transition-all duration-300"
                                    style={{ width: `${(getTaskListToolAttempts / 10) * 100}%` }}
                                />
                            </div>
                        </div>
                    </div>

                    <div className={`mt-6 flex flex-col gap-4 ${!executeTaskListToolExecuted ? "hidden" : ""}`}>
                        {/* Status Indicator */}
                        <div className="flex items-center gap-2">
                            <span className="text-sm font-medium">Execute Tool Running:</span>
                            <div className={`w-3 h-3 rounded-full ${executeTaskListToolExecuted ? "bg-green-500" : "bg-red-500"}`} />
                        </div>

                        {/* Progress Bar */}
                        <div className="w-full">
                            <div className="flex justify-between mb-1 text-sm font-medium text-gray-700">
                                <span>Polling Attempts</span>
                                <span>{executeTaskListToolAttempts}/10</span>
                            </div>
                            <div className="w-full h-2 bg-gray-200 rounded-full">
                                <div
                                    className="h-2 bg-purple-600 rounded-full transition-all duration-300"
                                    style={{ width: `${(executeTaskListToolAttempts / 10) * 100}%` }}
                                />
                            </div>
                        </div>
                    </div>


                    <div
                        ref={scrollRef}
                        className="flex flex-col gap-2 overflow-y-auto max-h-[400px] p-4 bg-gray-50 rounded-md whitespace-pre-line text-sm">
                        {renderedMessages}
                    </div>
                    <textarea
                        className="mt-4 w-full border rounded px-3 py-2 resize"
                        rows={3}
                        value={value}
                        onChange={(e) => {
                            setValue(e.target.value);
                            conversation.sendUserActivity();
                        }}
                    />
                    <button
                        className="mt-2 px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 flex grow-1"
                        onClick={() => {
                            conversation.sendUserMessage(value!);
                            setMessages(
                                `
                                ${messages}
                                vickieMessageDelimiter-New message received on: ${new Date()} from User
                                ${value!}`
                            );
                            setValue('');
                        }}
                    >
                        SEND
                    </button>
                </div>
            </Card>

            {taskList && (
                <Card className="flex flex-col justify-between p-6 min-w-[22rem]"> {/* give the card a height & flex layout */}
                    <label className="text-sm font-medium text-gray-700">Edit Task List</label>

                    <textarea
                        /* flex-grow makes the textarea consume every remaining pixel in the Card */
                        className="flex-grow w-full border rounded px-3 py-2 resize-y min-h-0"
                        value={taskList}
                        onChange={(e) => {
                            setTaskList(e.target.value);
                            taskListRef.current = e.target.value;
                        }}
                    />
                </Card>
            )}

        </div>
    );
}

/* ---------- 
exported component with suspense boundary
Note Turbopack barfs on modern CSS so I had to inline the contents of Vickie.css
 ---------- */
export default function Vickie() {
    return (
        <>
            <Suspense fallback={<div style={{ padding: "2rem", textAlign: "center" }}>Loading user</div>}>
                <VickieInner />
            </Suspense>

            <style jsx global>{`
        @property --blur {
            syntax: "<length>";
            initial-value: 0;
            inherits: true;
        }

        @property --spread {
            syntax: "<length>";
            initial-value: 0;
            inherits: true;
        }

        @property --color {
            syntax: "<color>";
            initial-value: rgb(0, 255, 85);
            inherits: true;
        }

        @property --lighter-color {
            syntax: "<color>";
            initial-value: color-mix(in srgb, var(--color) 80%, white);
            inherits: true;
        }

        @property --darker-color {
            syntax: "<color>";
            initial-value: color-mix(in srgb, var(--color) 60%, rgb(2, 137, 24));
            inherits: true;
        }

        @property --angle {
            syntax: "<angle>";
            initial-value: 0deg;
            inherits: true;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        .orb {
            --size: 200px;
            --color: red;
            --lighter-color: color-mix(in srgb, var(--color) 60%, white);
            --darker-color: color-mix(in srgb, var(--color) 40%, black);
            --blur: 40px;
            --spread: 5px;
            --angle: -90deg;
            --border: 10px;

            position: relative;
            width: var(--size);
            height: var(--size);
            aspect-ratio: 1;
            background:
                radial-gradient(color-mix(in srgb, var(--darker-color) 65%, transparent) -50%, transparent 50%),
                radial-gradient(var(--color), var(--color)) no-repeat 50% 50% / 50% 50%,
                url('/circleLogo-big.svg') no-repeat 50% 50% / 35%,
                linear-gradient(#ffffff, #ffffff) padding-box,
                conic-gradient(from var(--angle) at 50% 50%, color-mix(in srgb, var(--lighter-color), transparent) 0 72deg, var(--darker-color) 100deg 180deg, transparent 288deg, color-mix(in srgb, var(--lighter-color), transparent)) border-box,
                radial-gradient(farthest-corner at 50% 50%, transparent 50%, var(--darker-color) 80% 100%) border-box;

            background-blend-mode: normal, overlay, multiply, normal, normal, normal, normal;
            border: var(--border) solid transparent;
            border-radius: 50%;
            box-shadow: 0 0 var(--blur) var(--spread) var(--darker-color);
            display: flex;
            align-items: center;
            justify-content: center;
            animation: 10s linear infinite change-color, 5s linear infinite orb;

        }

        @keyframes change-color {
            0% {
                --color: rgb(255, 255, 255);
            }

            12% {
                --color: rgb(89, 255, 0);
            }

            24% {
                --color: yellow;
            }

            36% {
                --color: rgb(225, 255, 0);
            }

            48% {
                --color: rgb(255, 255, 0);
            }

            60% {
                --color: dodgerblue;
            }

            72% {
                --color: rgb(255, 0, 255);
            }

            84% {
                --color: rgb(0, 255, 85);
            }
        }

        @keyframes orb {
            0% {
                --angle: -90deg;
                --blur: 40px;
                --spread: 5px;
            }

            50% {
                --blur: 80px;
                --spread: 10px;
            }

            100% {
                --angle: 270deg;
            }
        }

        .orb:hover {
            animation: reset .2s linear 1 forwards;
        }

        @keyframes reset {
            to {
                --color: rgb(5, 182, 46);
                --blur: 40px;
                --spread: 5px;
                --angle: -90deg;
            }
        }
        /* Animation classes */
.animate-orb {
  animation: wave 0.4s infinite ease-in-out;
}

.animate-orb-slow {
  animation: wave 2s infinite ease-in-out;
}

/* Keyframes */
@keyframes wave {
  0%, 100% {
    transform: scale(1);
  }
  50% {
    transform: scale(1.05);
  }
}

@keyframes rotate {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}
      `}</style>
        </>
    );
}
````

## File: apps/agents/src/app/components/agents/VickieClient.tsx
````typescript
"use client";

import dynamic from "next/dynamic";

const Vickie = dynamic(() => import("./Vickie"), { ssr: false });

export default function VickieClient() {
    return <Vickie />;
}
````

## File: apps/agents/src/app/components/ui/button.tsx
````typescript
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "../../lib/cn"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90",
        outline:
          "border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground shadow-sm hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-9 w-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
  VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }
````

## File: apps/agents/src/app/components/ui/card.tsx
````typescript
import * as React from "react"

import { cn } from "../../lib/cn"

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-xl border bg-card text-card-foreground shadow",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("font-semibold leading-none tracking-tight", className)}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardDescription = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
CardDescription.displayName = "CardDescription"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

const CardFooter = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex items-center p-6 pt-0", className)}
    {...props}
  />
))
CardFooter.displayName = "CardFooter"

export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }
````

## File: apps/agents/src/app/lib/cn.ts
````typescript
import { clsx, type ClassValue } from 'clsx';
import { twMerge } from 'tailwind-merge';

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}
````

## File: apps/agents/src/app/services/executions.service.ts
````typescript
import {
  Communications,
  MachineExecutions,
} from '@codestrap/developer-foundations-types';

export async function callGetCommunications(id: string, token: string) {
  // fire and forget as there is a timeout we have to deal with
  const res = await fetch(`/api/communications?id=${id}`, {
    method: 'GET',
    headers: {
      'x-foundry-access-token': token,
    },
  });

  if (!res.ok) {
    console.log('Executions API failed');
    console.log(JSON.stringify(res));
    throw new Error(
      `Executions API failed with:\n${JSON.stringify(res, null, 2)}`
    );
  }

  const result = await res.json();
  console.log('Executions API result:', result);

  return result as Communications;
}

export async function callGetMachines(id: string, token: string) {
  // fire and forget as there is a timeout we have to deal with
  const res = await fetch(`/api/machines?id=${id}`, {
    method: 'GET',
    headers: {
      'x-foundry-access-token': token,
    },
  });

  if (!res.ok) {
    console.log('Executions API failed');
    console.log(JSON.stringify(res));
    throw new Error(
      `Executions API failed with:\n${JSON.stringify(res, null, 2)}`
    );
  }

  const result = await res.json();
  console.log('Executions API result:', result);

  return result as MachineExecutions;
}
````

## File: apps/agents/src/app/services/vickie.service.ts
````typescript
import { User } from "@osdk/foundry.admin";

export async function callAskVickie({
  action,
  token,
  user,
  text,
  query,
  threadId,
  plan,
  forward,
  executionId,
  inputs,
}: {
  action: string;
  token: string,
  user: User;
  text?: string;
  query?: string;
  threadId?: string;
  plan?: string;
  forward?: string;
  executionId?: string;
  inputs?: string;
}) {
  const body = new URLSearchParams({
    action,
    ...(query ? { query } : {}),
    ...(user ? { user: JSON.stringify(user) } : {}),
    ...(text ? { text } : {}),
    ...(threadId ? { threadId } : {}),
    ...(plan ? { plan } : {}),
    ...(forward ? { forward } : {}),
    ...(executionId ? { executionId } : {}),
    ...(inputs ? { inputs } : {}),
  });

  // fire and forget as there is a timeout we have to deal with
  const result = await fetch('/api/vickie', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded',
      'x-foundry-access-token': token,
    },
    body: body.toString(),
  });

  return result;
}
````

## File: apps/agents/src/app/vickie/page.tsx
````typescript
import Layout from "../layout";
import VickieClient from "../components/agents/VickieClient";

function Text2ActionVickie() {
    return (
        <Layout>
            <VickieClient />
        </Layout>
    );
}

export default Text2ActionVickie;
````

## File: apps/agents/src/app/globals.css
````css
@tailwind base;
@tailwind components;
@tailwind utilities;

body {
  font-family: Arial, Helvetica, sans-serif;
}

@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 0 0% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 0 0% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 0 0% 3.9%;
    --primary: 0 0% 9%;
    --primary-foreground: 0 0% 98%;
    --secondary: 0 0% 96.1%;
    --secondary-foreground: 0 0% 9%;
    --muted: 0 0% 96.1%;
    --muted-foreground: 0 0% 45.1%;
    --accent: 0 0% 96.1%;
    --accent-foreground: 0 0% 9%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 89.8%;
    --input: 0 0% 89.8%;
    --ring: 0 0% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;
  }
  .dark {
    --background: 0 0% 3.9%;
    --foreground: 0 0% 98%;
    --card: 0 0% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 0 0% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 0 0% 9%;
    --secondary: 0 0% 14.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 0 0% 14.9%;
    --muted-foreground: 0 0% 63.9%;
    --accent: 0 0% 14.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 14.9%;
    --input: 0 0% 14.9%;
    --ring: 0 0% 83.1%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}
````

## File: apps/agents/src/app/layout.tsx
````typescript
import './globals.css';

export const metadata = {
  title: 'Welcome to agents',
  description: 'Generated by create-nx-workspace',
};

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body>{children}</body>
    </html>
  );
}
````

## File: apps/agents/src/app/page.module.css
````css
.page {
}
````

## File: apps/agents/src/app/page.tsx
````typescript
import styles from './page.module.css';

export default function Index() {
  /*
   * Replace the elements below with your own.
   *
   * Note: The corresponding styles are in the ./index.css file.
   */
  return (
    <div className={styles.page}>
      <div className="wrapper">
        <div className="container">
          <div id="welcome">
            <h1>
              <span> Hello there, </span>
              Welcome agents 
            </h1>
          </div>

          <div id="hero" className="rounded">
            <div className="text-container">
              <h2>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M9 12l2 2 4-4M7.835 4.697a3.42 3.42 0 001.946-.806 3.42 3.42 0 014.438 0 3.42 3.42 0 001.946.806 3.42 3.42 0 013.138 3.138 3.42 3.42 0 00.806 1.946 3.42 3.42 0 010 4.438 3.42 3.42 0 00-.806 1.946 3.42 3.42 0 01-3.138 3.138 3.42 3.42 0 00-1.946.806 3.42 3.42 0 01-4.438 0 3.42 3.42 0 00-1.946-.806 3.42 3.42 0 01-3.138-3.138 3.42 3.42 0 00-.806-1.946 3.42 3.42 0 010-4.438 3.42 3.42 0 00.806-1.946 3.42 3.42 0 013.138-3.138z"
                  />
                </svg>
                <span>You&apos;re up and running</span>
              </h2>
              <a href="#commands"> What&apos;s next? </a>
            </div>
            <div className="logo-container">
              <svg
                fill="currentColor"
                role="img"
                viewBox="0 0 24 24"
                xmlns="http://www.w3.org/2000/svg"
              >
                <path d="M11.987 14.138l-3.132 4.923-5.193-8.427-.012 8.822H0V4.544h3.691l5.247 8.833.005-3.998 3.044 4.759zm.601-5.761c.024-.048 0-3.784.008-3.833h-3.65c.002.059-.005 3.776-.003 3.833h3.645zm5.634 4.134a2.061 2.061 0 0 0-1.969 1.336 1.963 1.963 0 0 1 2.343-.739c.396.161.917.422 1.33.283a2.1 2.1 0 0 0-1.704-.88zm3.39 1.061c-.375-.13-.8-.277-1.109-.681-.06-.08-.116-.17-.176-.265a2.143 2.143 0 0 0-.533-.642c-.294-.216-.68-.322-1.18-.322a2.482 2.482 0 0 0-2.294 1.536 2.325 2.325 0 0 1 4.002.388.75.75 0 0 0 .836.334c.493-.105.46.36 1.203.518v-.133c-.003-.446-.246-.55-.75-.733zm2.024 1.266a.723.723 0 0 0 .347-.638c-.01-2.957-2.41-5.487-5.37-5.487a5.364 5.364 0 0 0-4.487 2.418c-.01-.026-1.522-2.39-1.538-2.418H8.943l3.463 5.423-3.379 5.32h3.54l1.54-2.366 1.568 2.366h3.541l-3.21-5.052a.7.7 0 0 1-.084-.32 2.69 2.69 0 0 1 2.69-2.691h.001c1.488 0 1.736.89 2.057 1.308.634.826 1.9.464 1.9 1.541a.707.707 0 0 0 1.066.596zm.35.133c-.173.372-.56.338-.755.639-.176.271.114.412.114.412s.337.156.538-.311c.104-.231.14-.488.103-.74z" />
              </svg>
            </div>
          </div>

          <div id="middle-content">
            <div id="learning-materials" className="rounded shadow">
              <h2>Learning materials</h2>
              <a
                href="https://nx.dev/getting-started/intro?utm_source=nx-project"
                target="_blank"
                rel="noreferrer"
                className="list-item-link"
              >
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"
                  />
                </svg>
                <span>
                  Documentation
                  <span> Everything is in there </span>
                </span>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M9 5l7 7-7 7"
                  />
                </svg>
              </a>
              <a
                href="https://nx.dev/blog/?utm_source=nx-project"
                target="_blank"
                rel="noreferrer"
                className="list-item-link"
              >
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M19 20H5a2 2 0 01-2-2V6a2 2 0 012-2h10a2 2 0 012 2v1m2 13a2 2 0 01-2-2V7m2 13a2 2 0 002-2V9a2 2 0 00-2-2h-2m-4-3H9M7 16h6M7 8h6v4H7V8z"
                  />
                </svg>
                <span>
                  Blog
                  <span> Changelog, features & events </span>
                </span>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M9 5l7 7-7 7"
                  />
                </svg>
              </a>
              <a
                href="https://www.youtube.com/@NxDevtools/videos?utm_source=nx-project&sub_confirmation=1"
                target="_blank"
                rel="noreferrer"
                className="list-item-link"
              >
                <svg
                  role="img"
                  viewBox="0 0 24 24"
                  fill="currentColor"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <title>YouTube</title>
                  <path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z" />
                </svg>
                <span>
                  YouTube channel
                  <span> Nx Show, talks & tutorials </span>
                </span>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M9 5l7 7-7 7"
                  />
                </svg>
              </a>
              <a
                href="https://nx.dev/react-tutorial/1-code-generation?utm_source=nx-project"
                target="_blank"
                rel="noreferrer"
                className="list-item-link"
              >
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M15 15l-2 5L9 9l11 4-5 2zm0 0l5 5M7.188 2.239l.777 2.897M5.136 7.965l-2.898-.777M13.95 4.05l-2.122 2.122m-5.657 5.656l-2.12 2.122"
                  />
                </svg>
                <span>
                  Interactive tutorials
                  <span> Create an app, step-by-step </span>
                </span>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M9 5l7 7-7 7"
                  />
                </svg>
              </a>
              <a
                href="https://nxplaybook.com/?utm_source=nx-project"
                target="_blank"
                rel="noreferrer"
                className="list-item-link"
              >
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path d="M12 14l9-5-9-5-9 5 9 5z" />
                  <path d="M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z" />
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M12 14l9-5-9-5-9 5 9 5zm0 0l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14zm-4 6v-7.5l4-2.222"
                  />
                </svg>
                <span>
                  Video courses
                  <span> Nx custom courses </span>
                </span>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M9 5l7 7-7 7"
                  />
                </svg>
              </a>
            </div>
            <div id="other-links">
              <a
                id="nx-console"
                className="button-pill rounded shadow"
                href="https://marketplace.visualstudio.com/items?itemName=nrwl.angular-console&utm_source=nx-project"
                target="_blank"
                rel="noreferrer"
              >
                <svg
                  fill="currentColor"
                  role="img"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <title>Visual Studio Code</title>
                  <path d="M23.15 2.587L18.21.21a1.494 1.494 0 0 0-1.705.29l-9.46 8.63-4.12-3.128a.999.999 0 0 0-1.276.057L.327 7.261A1 1 0 0 0 .326 8.74L3.899 12 .326 15.26a1 1 0 0 0 .001 1.479L1.65 17.94a.999.999 0 0 0 1.276.057l4.12-3.128 9.46 8.63a1.492 1.492 0 0 0 1.704.29l4.942-2.377A1.5 1.5 0 0 0 24 20.06V3.939a1.5 1.5 0 0 0-.85-1.352zm-5.146 14.861L10.826 12l7.178-5.448v10.896z" />
                </svg>
                <span>
                  Install Nx Console for VSCode
                  <span>The official VSCode extension for Nx.</span>
                </span>
              </a>
              <a
                id="nx-console-jetbrains"
                className="button-pill rounded shadow"
                href="https://plugins.jetbrains.com/plugin/21060-nx-console"
                target="_blank"
                rel="noreferrer"
              >
                <svg
                  height="48"
                  width="48"
                  viewBox="20 20 60 60"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path d="m22.5 22.5h60v60h-60z" />
                  <g fill="#fff">
                    <path d="m29.03 71.25h22.5v3.75h-22.5z" />
                    <path d="m28.09 38 1.67-1.58a1.88 1.88 0 0 0 1.47.87c.64 0 1.06-.44 1.06-1.31v-5.98h2.58v6a3.48 3.48 0 0 1 -.87 2.6 3.56 3.56 0 0 1 -2.57.95 3.84 3.84 0 0 1 -3.34-1.55z" />
                    <path d="m36 30h7.53v2.19h-5v1.44h4.49v2h-4.42v1.49h5v2.21h-7.6z" />
                    <path d="m47.23 32.29h-2.8v-2.29h8.21v2.27h-2.81v7.1h-2.6z" />
                    <path d="m29.13 43.08h4.42a3.53 3.53 0 0 1 2.55.83 2.09 2.09 0 0 1 .6 1.53 2.16 2.16 0 0 1 -1.44 2.09 2.27 2.27 0 0 1 1.86 2.29c0 1.61-1.31 2.59-3.55 2.59h-4.44zm5 2.89c0-.52-.42-.8-1.18-.8h-1.29v1.64h1.24c.79 0 1.25-.26 1.25-.81zm-.9 2.66h-1.57v1.73h1.62c.8 0 1.24-.31 1.24-.86 0-.5-.4-.87-1.27-.87z" />
                    <path d="m38 43.08h4.1a4.19 4.19 0 0 1 3 1 2.93 2.93 0 0 1 .9 2.19 3 3 0 0 1 -1.93 2.89l2.24 3.27h-3l-1.88-2.84h-.87v2.84h-2.56zm4 4.5c.87 0 1.39-.43 1.39-1.11 0-.75-.54-1.12-1.4-1.12h-1.44v2.26z" />
                    <path d="m49.59 43h2.5l4 9.44h-2.79l-.67-1.69h-3.63l-.67 1.69h-2.71zm2.27 5.73-1-2.65-1.06 2.65z" />
                    <path d="m56.46 43.05h2.6v9.37h-2.6z" />
                    <path d="m60.06 43.05h2.42l3.37 5v-5h2.57v9.37h-2.26l-3.53-5.14v5.14h-2.57z" />
                    <path d="m68.86 51 1.45-1.73a4.84 4.84 0 0 0 3 1.13c.71 0 1.08-.24 1.08-.65 0-.4-.31-.6-1.59-.91-2-.46-3.53-1-3.53-2.93 0-1.74 1.37-3 3.62-3a5.89 5.89 0 0 1 3.86 1.25l-1.26 1.84a4.63 4.63 0 0 0 -2.62-.92c-.63 0-.94.25-.94.6 0 .42.32.61 1.63.91 2.14.46 3.44 1.16 3.44 2.91 0 1.91-1.51 3-3.79 3a6.58 6.58 0 0 1 -4.35-1.5z" />
                  </g>
                </svg>
                <span>
                  Install Nx Console for JetBrains
                  <span>
                    Available for WebStorm, Intellij IDEA Ultimate and more!
                  </span>
                </span>
              </a>
              <div id="nx-cloud" className="rounded shadow">
                <div>
                  <svg
                    id="nx-cloud-logo"
                    role="img"
                    xmlns="http://www.w3.org/2000/svg"
                    stroke="currentColor"
                    fill="transparent"
                    viewBox="0 0 24 24"
                  >
                    <path
                      strokeWidth="2"
                      d="M23 3.75V6.5c-3.036 0-5.5 2.464-5.5 5.5s-2.464 5.5-5.5 5.5-5.5 2.464-5.5 5.5H3.75C2.232 23 1 21.768 1 20.25V3.75C1 2.232 2.232 1 3.75 1h16.5C21.768 1 23 2.232 23 3.75Z"
                    />
                    <path
                      strokeWidth="2"
                      d="M23 6v14.1667C23 21.7307 21.7307 23 20.1667 23H6c0-3.128 2.53867-5.6667 5.6667-5.6667 3.128 0 5.6666-2.5386 5.6666-5.6666C17.3333 8.53867 19.872 6 23 6Z"
                    />
                  </svg>
                  <h2>
                    Nx Cloud
                    <span>Enable faster CI & better DX</span>
                  </h2>
                </div>
                <p>
                  You can activate distributed tasks executions and caching by
                  running:
                </p>
                <pre>nx connect</pre>
                <a
                  href="https://nx.app/?utm_source=nx-project"
                  target="_blank"
                  rel="noreferrer"
                >
                  {' '}
                  What is Nx Cloud?{' '}
                </a>
              </div>
              <a
                id="nx-repo"
                className="button-pill rounded shadow"
                href="https://github.com/nrwl/nx?utm_source=nx-project"
                target="_blank"
                rel="noreferrer"
              >
                <svg
                  fill="currentColor"
                  role="img"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12" />
                </svg>
                <span>
                  Nx is open source
                  <span> Love Nx? Give us a star! </span>
                </span>
              </a>
            </div>
          </div>

          <div id="commands" className="rounded shadow">
            <h2>Next steps</h2>
            <p>Here are some things you can do with Nx:</p>
            <details>
              <summary>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"
                  />
                </svg>
                Add UI library
              </summary>
              <pre>
                <span># Generate UI lib</span>
                nx g @nx/next:library ui
                <span># Add a component</span>
                nx g @nx/next:component ui/src/lib/button
              </pre>
            </details>
            <details>
              <summary>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"
                  />
                </svg>
                View project details
              </summary>
              <pre>nx show project agents --web</pre>
            </details>
            <details>
              <summary>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"
                  />
                </svg>
                View interactive project graph
              </summary>
              <pre>nx graph</pre>
            </details>
            <details>
              <summary>
                <svg
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth="2"
                    d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"
                  />
                </svg>
                Run affected commands
              </summary>
              <pre>
                <span># see what&apos;s been affected by changes</span>
                nx affected:graph
                <span># run tests for current changes</span>
                nx affected:test
                <span># run e2e tests for current changes</span>
                nx affected:e2e
              </pre>
            </details>
          </div>

          <p id="love">
            Carefully crafted with
            <svg
              fill="currentColor"
              stroke="none"
              viewBox="0 0 24 24"
              xmlns="http://www.w3.org/2000/svg"
            >
              <path
                strokeLinecap="round"
                strokeLinejoin="round"
                strokeWidth="2"
                d="M4.318 6.318a4.5 4.5 0 000 6.364L12 20.364l7.682-7.682a4.5 4.5 0 00-6.364-6.364L12 7.636l-1.318-1.318a4.5 4.5 0 00-6.364 0z"
              />
            </svg>
          </p>
        </div>
      </div>
    </div>
  );
}
````

## File: apps/agents/.swcrc
````
{
  "jsc": {
    "target": "es2017",
    "parser": {
      "syntax": "typescript",
      "decorators": true,
      "dynamicImport": true
    },
    "transform": {
      "decoratorMetadata": true,
      "legacyDecorator": true
    },
    "keepClassNames": true,
    "externalHelpers": true,
    "loose": true
  },
  "module": {
    "type": "commonjs"
  },
  "sourceMaps": true,
  "exclude": [
    "jest.config.ts",
    ".*\\.spec.tsx?$",
    ".*\\.test.tsx?$",
    "./src/jest-setup.ts$",
    "./**/jest-setup.ts$",
    ".*.js$",
    ".*.d.ts$"
  ]
}
````

## File: apps/agents/components.json
````json
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "src/app/components",
    "utils": "src/app/lib/utils",
    "ui": "src/app/components/ui",
    "lib": "src/app/lib",
    "hooks": "src/app/hooks"
  }
}
````

## File: apps/agents/eslint.config.mjs
````
import { FlatCompat } from '@eslint/eslintrc';
import { dirname } from 'path';
import { fileURLToPath } from 'url';
import js from '@eslint/js';
import { fixupConfigRules } from '@eslint/compat';
import nx from '@nx/eslint-plugin';
import baseConfig from '../../eslint.config.mjs';
const compat = new FlatCompat({
  baseDirectory: dirname(fileURLToPath(import.meta.url)),
  recommendedConfig: js.configs.recommended,
});

export default [
  ...fixupConfigRules(compat.extends('next')),
  ...fixupConfigRules(compat.extends('next/core-web-vitals')),
  ...baseConfig,
  ...nx.configs['flat/react-typescript'],
  {
    ignores: ['.next/**/*'],
  },
];
````

## File: apps/agents/index.d.ts
````typescript
/* eslint-disable @typescript-eslint/no-explicit-any */
declare module '*.svg' {
  const content: any;
  export const ReactComponent: any;
  export default content;
}
````

## File: apps/agents/jest.config.ts
````typescript
import type { Config } from 'jest';
import nextJest from 'next/jest.js';

const createJestConfig = nextJest({
  dir: './',
});

const config: Config = {
  displayName: 'agents',
  preset: '../../jest.preset.js',
  transform: {
    '^(?!.*\\.(js|jsx|ts|tsx|css|json)$)': '@nx/react/plugins/jest',
  },
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx'],
  coverageDirectory: '../../coverage/apps/agents',
  testEnvironment: 'jsdom',
};

export default createJestConfig(config);
````

## File: apps/agents/next-env.d.ts
````typescript
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/app/api-reference/config/typescript for more information.
````

## File: apps/agents/next.config.js
````javascript
//@ts-check

// eslint-disable-next-line @typescript-eslint/no-var-requires
const { composePlugins, withNx } = require('@nx/next');

/**
 * @type {import('@nx/next/plugins/with-nx').WithNxOptions}
 **/
const nextConfig = {
  // Use this to set Nx-specific options
  // See: https://nx.dev/recipes/next/next-config-setup
  nx: {},
};

const plugins = [
  // Add more Next.js plugins to this list if needed.
  withNx,
];

module.exports = composePlugins(...plugins)(nextConfig);
````

## File: apps/agents/postcss.config.mjs
````
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;
````

## File: apps/agents/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            FOUNDRY_TEST_USER: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: apps/agents/project.json
````json
{
  "name": "agents",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "apps/agents",
  "projectType": "application",
  "tags": [],
  "targets": {
    "serve": {
      "executor": "@nx/next:server",
      "defaultConfiguration": "production",
      "options": {
        "buildTarget": "agents:build",
        "dev": true
      }
    },
    "build": {
      "executor": "@nx/next:build",
      "outputs": ["{options.outputPath}"],
      "defaultConfiguration": "production",
      "options": {
        "outputPath": "dist/agents"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "apps/agents/jest.config.ts"
      }
    }
  }
}
````

## File: apps/agents/tailwind.config.ts
````typescript
import type { Config } from "tailwindcss";

const config: Config = {
    darkMode: ["class"],
    content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
  	extend: {
  		colors: {
  			background: 'hsl(var(--background))',
  			foreground: 'hsl(var(--foreground))',
  			card: {
  				DEFAULT: 'hsl(var(--card))',
  				foreground: 'hsl(var(--card-foreground))'
  			},
  			popover: {
  				DEFAULT: 'hsl(var(--popover))',
  				foreground: 'hsl(var(--popover-foreground))'
  			},
  			primary: {
  				DEFAULT: 'hsl(var(--primary))',
  				foreground: 'hsl(var(--primary-foreground))'
  			},
  			secondary: {
  				DEFAULT: 'hsl(var(--secondary))',
  				foreground: 'hsl(var(--secondary-foreground))'
  			},
  			muted: {
  				DEFAULT: 'hsl(var(--muted))',
  				foreground: 'hsl(var(--muted-foreground))'
  			},
  			accent: {
  				DEFAULT: 'hsl(var(--accent))',
  				foreground: 'hsl(var(--accent-foreground))'
  			},
  			destructive: {
  				DEFAULT: 'hsl(var(--destructive))',
  				foreground: 'hsl(var(--destructive-foreground))'
  			},
  			border: 'hsl(var(--border))',
  			input: 'hsl(var(--input))',
  			ring: 'hsl(var(--ring))',
  			chart: {
  				'1': 'hsl(var(--chart-1))',
  				'2': 'hsl(var(--chart-2))',
  				'3': 'hsl(var(--chart-3))',
  				'4': 'hsl(var(--chart-4))',
  				'5': 'hsl(var(--chart-5))'
  			}
  		},
  		borderRadius: {
  			lg: 'var(--radius)',
  			md: 'calc(var(--radius) - 2px)',
  			sm: 'calc(var(--radius) - 4px)'
  		}
  	}
  },
  plugins: [require("tailwindcss-animate")],
};
export default config;
````

## File: apps/agents/tsconfig.json
````json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "jsx": "preserve",
    "strict": true,
    "noEmit": true,
    "emitDeclarationOnly": false,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "lib": [
      "dom",
      "dom.iterable",
      "esnext"
    ],
    "allowJs": true,
    "allowSyntheticDefaultImports": true,
    "forceConsistentCasingInFileNames": true,
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "types": [
      "jest",
      "node"
    ]
  },
  "include": [
    "**/*.js",
    "**/*.jsx",
    "**/*.ts",
    "**/*.tsx",
    "../../apps/agents/.next/types/**/*.ts",
    "../../dist/apps/agents/.next/types/**/*.ts",
    ".next/types/**/*.ts",
    "next-env.d.ts",
    "../../dist/agents/.next/types/**/*.ts"
  ],
  "exclude": [
    "node_modules",
    "jest.config.ts",
    "**/*.spec.ts",
    "**/*.test.ts"
  ]
}
````

## File: apps/agents/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "jsx": "react",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.test.tsx",
    "src/**/*.spec.tsx",
    "src/**/*.test.js",
    "src/**/*.spec.js",
    "src/**/*.test.jsx",
    "src/**/*.spec.jsx",
    "src/**/*.d.ts"
  ]
}
````

## File: apps/agents-e2e/src/example.spec.ts
````typescript
import { test, expect } from '@playwright/test';

test('has title', async ({ page }) => {
  await page.goto('/');

  // Expect h1 to contain a substring.
  expect(await page.locator('h1').innerText()).toContain('Welcome');
});
````

## File: apps/agents-e2e/eslint.config.mjs
````
import playwright from 'eslint-plugin-playwright';
import baseConfig from '../../eslint.config.mjs';

export default [
  playwright.configs['flat/recommended'],
  ...baseConfig,
  {
    files: ['**/*.ts', '**/*.js'],
    // Override or add rules here
    rules: {},
  },
];
````

## File: apps/agents-e2e/playwright.config.ts
````typescript
import { defineConfig, devices } from '@playwright/test';
import { nxE2EPreset } from '@nx/playwright/preset';
import { workspaceRoot } from '@nx/devkit';

// For CI, you may want to set BASE_URL to the deployed application.
const baseURL = process.env['BASE_URL'] || 'http://localhost:3000';

/**
 * Read environment variables from file.
 * https://github.com/motdotla/dotenv
 */
// require('dotenv').config();

/**
 * See https://playwright.dev/docs/test-configuration.
 */
export default defineConfig({
  ...nxE2EPreset(__filename, { testDir: './src' }),
  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
  use: {
    baseURL,
    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: 'on-first-retry',
  },
  /* Run your local dev server before starting the tests */
  webServer: {
    command: 'npx nx run agents:start',
    url: 'http://localhost:3000',
    reuseExistingServer: true,
    cwd: workspaceRoot,
  },
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },

    {
      name: 'firefox',
      use: { ...devices['Desktop Firefox'] },
    },

    {
      name: 'webkit',
      use: { ...devices['Desktop Safari'] },
    },

    // Uncomment for mobile browsers support
    /* {
      name: 'Mobile Chrome',
      use: { ...devices['Pixel 5'] },
    },
    {
      name: 'Mobile Safari',
      use: { ...devices['iPhone 12'] },
    }, */

    // Uncomment for branded browsers
    /* {
      name: 'Microsoft Edge',
      use: { ...devices['Desktop Edge'], channel: 'msedge' },
    },
    {
      name: 'Google Chrome',
      use: { ...devices['Desktop Chrome'], channel: 'chrome' },
    } */
  ],
});
````

## File: apps/agents-e2e/project.json
````json
{
  "name": "agents-e2e",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "projectType": "application",
  "sourceRoot": "apps/agents-e2e/src",
  "tags": [],
  "implicitDependencies": ["agents"],
  "// targets": "to see all targets run: nx show project agents-e2e --web",
  "targets": {}
}
````

## File: apps/agents-e2e/tsconfig.json
````json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "allowJs": true,
    "outDir": "../../dist/out-tsc",
    "sourceMap": false,
    "module": "commonjs"
  },
  "include": [
    "**/*.ts",
    "**/*.js",
    "playwright.config.ts",
    "src/**/*.spec.ts",
    "src/**/*.spec.js",
    "src/**/*.test.ts",
    "src/**/*.test.js",
    "src/**/*.d.ts"
  ]
}
````

## File: hello-world/src/domain/userDao.ts
````typescript
import type { FoundryClient, UserDao } from "@hello/types";
import { TYPES } from "@hello/types";
import { container } from "@hello/inversify.config";

export function makeUserDao(): UserDao {
    const client = container.get<FoundryClient>(TYPES.FoundryClient);

    return async () => {
        const user = await client.getUser();
        console.log('OSDK makeUserDao returned:', user);

        return user;
    };
}
````

## File: hello-world/src/domain/worldDao.ts
````typescript
import type { FoundryClient, WorldDao } from "@hello/types";
import { TYPES } from "@hello/types";
import { container } from "@hello/inversify.config";

export function makeWorldDao(): WorldDao {
    const client = container.get<FoundryClient>(TYPES.FoundryClient);

    return async ({ message, userId }) => {
        console.log(`makeWorldDao userId: ${userId}`);

        const token = await client.auth.signIn();
        const apiKey = token.access_token;

        const url = `${client.url}/api/v2/ontologies/${client.ontologyRid}/actions/say-hello/apply`;

        const headers = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
        };

        const body = JSON.stringify({
            parameters: {
                message,
            },
            options: {
                returnEdits: "ALL"
            }
        });

        const apiResult = await fetch(url, {
            method: "POST",
            headers: headers,
            body: body,
        });

        const result = await apiResult.json() as any;

        if (!result.edits || result.edits.edits.length === 0) {
            throw new Error('Failed to add hello message to the ontolgoy.');
        }

        console.log(`create world action returned: ${result?.edits?.edits?.[0]}`);

        const worldId = result.edits.edits[0].primaryKey as string;

        const getUrl = `${client.url}/api/v2/ontologies/${client.ontologyRid}/objects/World/${worldId}`;
        const worldFetchResults = await fetch(getUrl, {
            method: "GET",
            headers: headers,
        });

        const world = await worldFetchResults.json() as any;
        console.log(`the world ontology returned: ${JSON.stringify(world)}`)

        return { id: "singleton", greeting: world.message };
    };
}
````

## File: hello-world/src/services/foundryClient.ts
````typescript
import { createConfidentialOauthClient } from "@osdk/oauth";
import { createClient } from "@osdk/client";
import { User, Users } from "@osdk/foundry.admin";
import { FoundryClient } from '@hello/types'

export function createFoundryClient(): FoundryClient {
    // log ENV vars
    console.log('Environment variable keys:');
    Object.keys(process.env).forEach(key => {
        if (key.indexOf('FOUNDRY') >= 0 || key.indexOf('OSDK') >= 0) {
            console.log(`- ${key}`);
        }
    });

    if (!process.env.OSDK_CLIENT_ID || !process.env.OSDK_CLIENT_SECRET) {
        throw new Error('missing required env vars');
    }

    // setup the OSDK
    const clientId: string = process.env.OSDK_CLIENT_ID;
    const url: string = process.env.FOUNDRY_STACK_URL;
    const ontologyRid: string = process.env.ONTOLOGY_RID;
    const clientSecret: string = process.env.OSDK_CLIENT_SECRET;
    const scopes: string[] = [
        "api:ontologies-read",
        "api:ontologies-write",
        "api:admin-read",
        "api:connectivity-read",
        "api:connectivity-write",
        "api:connectivity-execute",
        "api:mediasets-read",
        "api:mediasets-write"
    ]

    const auth = createConfidentialOauthClient(clientId, clientSecret, url, scopes);
    const client = createClient(url, ontologyRid, auth);
    const getUser = async () => {
        const user: User = await Users.getCurrent(client);

        return user;
    };

    return { auth, ontologyRid, url, client, getUser };
}
````

## File: hello-world/src/services/weatherService.ts
````typescript
import { WeatherService } from "@hello/types";

export const openWeatherService: WeatherService = async (city) => {
    const key = process.env.OPEN_WEATHER_API_KEY!;
    const res = await fetch(
        `https://api.openweathermap.org/data/2.5/weather?q=${encodeURIComponent(
            city,
        )}&appid=${key}&units=metric`,
    );
    const result = await res.json() as { weather: { description: string }[], main: { temp: string } };
    return `${result.weather[0].description}, ${result.main.temp} C`;
};
````

## File: hello-world/src/index.test.ts
````typescript
describe('Hello World', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: hello-world/src/index.ts
````typescript
import { ComputeModule } from "@palantir/compute-module";
// Schema Definitions for compute module
// IMPORTANT:  @sinclair/typebox is required!!!
// https://github.com/palantir/typescript-compute-module?tab=readme-ov-file#schema-registration
import { Type } from "@sinclair/typebox";
import { writeGreeting } from "./writeGreeting";
import dotenv from 'dotenv';
import { ComputeModuleType, ModuleConfig } from "./types";

dotenv.config();

const Schemas = {
  WriteGreeting: {
    input: Type.Object({ city: Type.String() }),
    output: Type.Object({ status: Type.Literal("ok") }),
  },
};

// Unified configuration for all environments
function getModuleConfig(): ModuleConfig {
  const env = process.env.NODE_ENV || 'development';

  switch (env) {
    case 'test':
      return { isTest: true };
    default: // development
      return { isTest: false };
  };
}

function createComputeModule(): ComputeModuleType {
  const config = getModuleConfig();

  if (config.isTest) {
    const mockModule = {
      listeners: {} as Record<string, any>,
      on: function (event: string, handler: Function) {
        this.listeners[event] = handler;
        handler();
        return this;
      },
      register: function (operation: string, handler: Function) {
        this.listeners[operation] = { type: 'response', listener: handler };
        return this;
      }
    };
    console.log('returning mock module');
    return mockModule;
  }

  const module = new ComputeModule({
    logger: console,
    sources: {},
    definitions: { WriteGreeting: Schemas.WriteGreeting },
  })
    .register("WriteGreeting", async ({ city }) => {
      await writeGreeting(city);
      return { status: "ok" };
    })
    .on("responsive", () => console.log("YellowWorld ready"));

  module.on("responsive", () => {
    console.log(`${process.env.LOG_PREFIX} Module is now responsive`);
  });

  return module;
}

const computeModule = createComputeModule();

export { computeModule };
````

## File: hello-world/src/inversify.config.ts
````typescript
import "reflect-metadata";
import { Container } from "inversify";
import { TYPES } from "@hello/types";
import { openWeatherService } from "@hello/services/weatherService";
import { createFoundryClient } from "@hello/services/foundryClient";
import { makeWorldDao } from "@hello/domain/worldDao";
import { makeUserDao } from "@hello/domain/userDao";

export const container = new Container();

container
    .bind(TYPES.FoundryClient)
    .toDynamicValue(createFoundryClient)
    .inSingletonScope();

container
    .bind(TYPES.WorldDao)
    .toConstantValue(makeWorldDao());

container
    .bind(TYPES.UserDao)
    .toConstantValue(makeUserDao());

container
    .bind(TYPES.WeatherService)
    .toConstantValue(openWeatherService);
````

## File: hello-world/src/process-env.d.ts
````typescript
// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
        }
    }
}
export { };
````

## File: hello-world/src/types.ts
````typescript
import { ComputeModule } from '@palantir/compute-module';
import type { Client } from "@osdk/client";

export const TYPES = {
    FoundryClient: Symbol.for("FoundryClient"),
    WeatherService: Symbol.for("WeatherService"),
    WorldDao: Symbol.for("WorldDao"),
    UserDao: Symbol.for("UserDao"),
};

export interface Token {
    readonly access_token: string;
    readonly expires_in: number;
    readonly refresh_token?: string;
    readonly expires_at: number;
}

export interface BaseOauthClient {
    (): Promise<string>;
    getTokenOrUndefined: () => string | undefined;
    signIn: () => Promise<Token>;
    signOut: () => Promise<void>;
}

export interface FoundryClient {
    auth: BaseOauthClient;
    ontologyRid: string;
    url: string;
    client: Client;
    getUser: () => Promise<User>;
}

// Basic example of calling other services besides Foundry.
export interface WeatherService {
    (city: string): Promise<string>;
}

export interface APIError extends Error {
    response?: {
        data: any;
    };
}

export interface ModuleConfig {
    isTest?: boolean;
}

export interface TestModule {
    listeners: Record<string, any>;
    on(event: string, handler: Function): TestModule;
    register(operation: string, handler: Function): TestModule;
}

export type ComputeModuleType = TestModule | ComputeModule<any>;

export interface GreetingInput {
    message: string;
    userId: string;
}

export interface GreetingResult {
    id: string;
    greeting: string;
}

export interface User {
    id: string;
    username: string;
    givenName?: string;
    familyName?: string;
    email?: string;
    organization?: string;
    attributes: Record<string, any>;
}

export type WorldDao = (input: GreetingInput) => Promise<GreetingResult>;
export type UserDao = () => Promise<User>;
````

## File: hello-world/src/writeGreeting.ts
````typescript
import { TYPES, WeatherService, UserDao, WorldDao } from "@hello/types";
import { container } from "@hello/inversify.config";

export async function writeGreeting(city: string): Promise<string> {
    // example of consuming an vanilla service
    const getWeather = container.get<WeatherService>(TYPES.WeatherService);
    const weather = await getWeather(city);

    // example dao usage
    const user = await container.get<UserDao>(TYPES.UserDao)();
    const greeting = await container.get<WorldDao>(TYPES.WorldDao)({ message: weather, userId: user.id });

    return `weather: ${weather}\nuser: ${user} greeting: ${greeting}`;
}
````

## File: hello-world/test/compute-module.test.ts
````typescript
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();
// Mock setup must be before imports
import { TestModule } from '../src/types';
import { computeModule } from '../src';
import { writeGreeting } from '../src/writeGreeting';

// Cast computeModule to TestModule since we're in test environment
const testModule = computeModule as TestModule;

// 1. Grab the real fetch
const realFetch = global.fetch;

// 2. Override it with a logger wrapper
global.fetch = (async (
  input: any,
  init?: any
): Promise<Response> => {
  // log the request
  console.log(' fetch:', input, init);

  // call the real fetch
  const res = await realFetch(input, init);

  // attempt to parse JSON (fallback to text)
  let body: unknown;
  try {
    body = await res.clone().json();
  } catch {
    body = await res.clone().text();
  }
  console.log(' status=', res.status, 'body=', body);

  return res;
}) as typeof fetch;

describe('Compute Module Registration', () => {

  beforeEach(() => {

    // Register operations with actual handlers
    testModule.register("WriteGreeting", writeGreeting);

    // Register responsive handler
    testModule.on("responsive", () => {
      console.log(`${process.env.LOG_PREFIX} Module is now responsive`);
    });
  });

  it('should send a greeting', async () => {
    const operations = ['WriteGreeting'];

    // Initial check
    operations.forEach(op => {
      expect(testModule.listeners[op]).toBeDefined();
      expect(testModule.listeners[op].type).toBe('response');
    });

    // Simulate multiple responsive events
    for (let i = 0; i < 3; i++) {
      const responsiveHandler = testModule.listeners['responsive'];
      if (responsiveHandler) {
        responsiveHandler();
      }

      // Verify after each event
      operations.forEach(op => {
        expect(testModule.listeners[op]).toBeDefined();
        expect(testModule.listeners[op].type).toBe('response');
      });
    }

    // Execute calendar operations
    const result = await testModule.listeners['WriteGreeting'].listener('Los Angeles');

    expect(result).toBeDefined();
  }, 30000);

});
````

## File: hello-world/.dockerignore
````
# Version control
.git
.gitignore

# Dependencies
node_modules/
npm-debug.log*

# Testing and Development
test/
coverage/
*.test.js
jest.config.js
utils/test-*.js
.eslintrc*

# Environment and credentials
.env*
service_account.json
**/credentials/

# Documentation
*.md
docs/

# IDE and OS specific
.idea/
.vscode/
.DS_Store
Thumbs.db

# Logs
*.log

# Build artifacts
dist/
build/

# Operation files
ops/
````

## File: hello-world/.gitignore
````
# Environment/Credentials
.env
.env.*
service_account.json

# Dependencies
node_modules/
package-lock.json

buildAndPublish.sh

# Logs
*.log
npm-debug.log*

# IDE
.idea/
.vscode/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Build
dist/
build/
coverage/
````

## File: hello-world/Dockerfile
````
# syntax=docker/dockerfile:1
ARG NODE_VERSION=20.10.0
FROM --platform=amd64 node:${NODE_VERSION}-alpine

ARG FOUNDRY_TOKEN=undefined

ENV FOUNDRY_TOKEN=$FOUNDRY_TOKEN

WORKDIR /app

# Copy package files
COPY package*.json /app/

# Install all dependencies for building
RUN npm ci

# Copy source files
COPY tsconfig.build.json /app/
COPY src/ /app/src/

# Build TypeScript
RUN npm run build

# Remove dev dependencies
RUN npm ci --only=production

# Create a non-root numeric user (must be numeric for compute modules)
RUN adduser --uid 5001 --disabled-password --gecos "" user && \
    chown -R 5001:5001 /app

USER 5001

# Environment setup
ENV NODE_ENV=production

# Verify directory structure
RUN ls -la /app/src/domain && \
    ls -la /app/src/services

# Specify the entrypoint explicitly as required
ENTRYPOINT ["node", "dist/src/index.js"]
````

## File: hello-world/eslint.config.cjs
````
const {
    defineConfig,
    globalIgnores,
} = require("eslint/config");

const globals = require("globals");
const typescriptEslint = require("@typescript-eslint/eslint-plugin");
const _import = require("eslint-plugin-import");

const {
    fixupPluginRules,
    fixupConfigRules,
} = require("@eslint/compat");

const tsParser = require("@typescript-eslint/parser");
const js = require("@eslint/js");

const {
    FlatCompat,
} = require("@eslint/eslintrc");

const compat = new FlatCompat({
    baseDirectory: __dirname,
    recommendedConfig: js.configs.recommended,
    allConfig: js.configs.all
});

module.exports = defineConfig([{
    languageOptions: {
        globals: {
            ...globals.node,
        },

        parser: tsParser,
        ecmaVersion: 11,
        sourceType: "module",

        parserOptions: {
            project: ["./tsconfig.json"],
        },
    },

    plugins: {
        import: fixupPluginRules(_import),
    },

    settings: {
        "import/resolver": {
            typescript: {
                project: "./tsconfig.json",
                alwaysTryTypes: true           // resolves @types packages
            }
        }
    },

    extends: fixupConfigRules(compat.extends(
        "eslint:recommended",
        "plugin:@typescript-eslint/recommended",
        "plugin:import/errors",
        "plugin:import/warnings",
        "plugin:import/typescript",
    )),

    rules: {
        "no-unused-vars": "off",
        "no-redeclare": "off",
        "no-undef": "off",
        "no-case-declarations": "off",
        "@typescript-eslint/no-explicit-any": "off",
        '@typescript-eslint/no-unsafe-function-type': 'off',
    },
}, globalIgnores(["**/dist", "**/.eslintrc.cjs"])]);
````

## File: hello-world/jest.config.js
````javascript
export default {
    preset: 'ts-jest/presets/default-esm',
    testEnvironment: 'node',

    // Treat JS and TS as ESM
    extensionsToTreatAsEsm: ['.ts'],

    testPathIgnorePatterns: ['<rootDir>/dist/'],

    globals: {
        'ts-jest': {
            tsconfig: 'tsconfig.json',
            useESM: true,
        },
    },

    testMatch: [
        "**/test/**/*.test.ts",
        "**/test/**/*.test.js"
    ],

    transform: {
        '^.+\\.[tj]sx?$': 'ts-jest',
        '^.+\\.js$': 'ts-jest',
    },

    // Allow ts-jest to transform @osdk/* ESM modules
    transformIgnorePatterns: [
        'node_modules/(?!(?:@osdk)/)',
    ],

    moduleNameMapper: {
        // Strip `.js` from your TS imports so ESM paths resolve
        '^(\\.{1,2}/.*)\\.js$': '$1',
        '^@hello/(.*)$': '<rootDir>/src/$1',
        '^@osdk/shared\\.client$': '<rootDir>/node_modules/@osdk/shared.client/index.js',
        '^@osdk/shared\\.client2$': '<rootDir>/node_modules/@osdk/shared.client2/index.js',
    },
};
````

## File: hello-world/package.json
````json
{
  "name": "@codestrap/developer-foundations.hello-world",
  "version": "1.0.0",
  "description": "## Introduction",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/doriansmiley/foundry-developer-foundations.git"
  },
  "bugs": {
    "url": "https://github.com/doriansmiley/foundry-developer-foundations/issues"
  },
  "homepage": "https://github.com/doriansmiley/foundry-developer-foundations/tree/master/osdk-client-auth-flow",
  "keywords": [
    "tracing",
    "otel",
    "telemetry",
    "typescript",
    "decorator",
    "palantir",
    "foundry"
  ],
  "author": "Dorian Smiley <dsmiley@codestrap.me>",
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "main": "dist/index.js",
  "types": "dist/index.d.ts",
  "type": "module",
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "lint": "eslint 'src/**/*.{js,ts}'",
    "build": "tsc -p tsconfig.build.json",
    "build:docker": "npm run build && docker build --build-arg FOUNDRY_TOKEN=${FOUNDRY_TOKEN} -t codestrap/hello-world .",
    "prepublishOnly": "npm run lint && npm run test && npm run build",
    "publishPackage:dry": "npm publish --dry-run --access public",
    "publishPackage": "npm publish --access public",
    "clean": "rm -rf dist",
    "prebuild": "npm run clean"
  },
  "dependencies": {
    "@osdk/client": "^2.1.4",
    "@osdk/foundry.admin": "^2.19.0",
    "@osdk/oauth": "^1.1.1",
    "@palantir/compute-module": "^0.2.7",
    "@sinclair/typebox": "^0.34.33",
    "eslint-plugin-import": "^2.31.0",
    "inversify": "^7.5.1"
  },
  "devDependencies": {
    "@eslint/compat": "^1.2.9",
    "@eslint/eslintrc": "^3.3.1",
    "@eslint/js": "^9.26.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.15.3",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "cross-env": "^7.0.3",
    "dotenv": "^16.5.0",
    "eslint": "^9.26.0",
    "eslint-import-resolver-typescript": "^4.3.4",
    "globals": "^16.0.0",
    "jest": "^29.7.0",
    "ts-jest": "^29.3.2",
    "ts-node": "^10.9.2",
    "tsconfig-paths": "^4.2.0",
    "typescript": "^5.8.3"
  },
  "engines": {
    "node": ">=20.10.0"
  }
}
````

## File: hello-world/README.md
````markdown
# Hello World

## Introduction
This hello world example application is a reference implementation of the **Foundrybacked / GitHubnative** collaboration pattern created by CodeStrap, LLC.
The goal: let any JavaScript/TypeScript engineer contribute business logic to a PalantirFoundry deployment **without needing direct Foundry expertise or access**.

## Getting Started
1. First download and install the [Hello World](https://drive.google.com/file/d/1haBL6bv1Cy8BRiKt7tqzDL2dsQe5Q2yq/view?usp=sharing) Marketplace application on your Foundry stack. We are working on mocks for Foundry but have not published them yet. Once the mocks are done you no longer will require a Foundry stack.
1. Run `npm install`
1. Create a `.env` file and set the following values
```
FOUNDRY_STACK_URL=<your stack url>
OSDK_CLIENT_SECRET=<your osdk client secret>
OSDK_CLIENT_ID=<your osdk client id>
OPEN_WEATHER_API_KEY=<an open wheahter API key https://home.openweathermap.org/>
LOG_PREFIX=foundry-developer-foundations-hello-world
ONTOLOGY_RID=<your ontology rid>
```
1. Update the code in `src/domain/worldDao.ts` replacing `${client.ontologyRid}` with your ID. You can find the ID in the OSDK documentation.
1. Run `npm run build` to verify you can build
1. Run `npm run lint` to verify your eslint setup
1. Run `npm run test` to test the code e2e
1. Run `npm run docker:build` to build the docker container
1. Create a compute module and follow the instructions to deploy your docker container. Update the content of `buildAndPublish.sh` with your deploy commands from the compute module dashboard in Foundry.

The rest of the README walks through the folder structure, DI wiring, ComputeModule registration, and the build/deploy steps so you can copypaste the pattern into your own project and start shipping today.

## The Foundry Implementations
This pattern assumes you have created the OSDK app using the linked Marketplace installer above. The installer creates the following function in Foundry and published it in the included third party application:
```typescript
import {
  Function as Fn,
  OntologyEditFunction,
  Edits,
  String as FString,
  FunctionsMap,
} from "@foundry/functions-api";
import { Objects, World } from "@foundry/ontology-api";
// You will have to install foundry-tracing-foundations, otherwise delete it
import { Trace } from "foundry-tracing-foundations";
import { Uuid } from "@foundry/functions-utils";

export class HelloWorldFunction {
  @Edits(World)
  @OntologyEditFunction()
  @Trace({
    resource: {
      service_name: 'hello-service',
      service_instance_id: 'prod',
    },
    operationName: 'helloWorld',
  })
  public async execute(
    parameters: { message: FString }
  ): Promise<void> {
    const world = Objects.create().world(Uuid.random());
    world.greeting = parameters.message;
  }
}
```
This function is invoked by `src/domain/worldDao.ts` using a fetch API request to avoid introducing the SDK as a dependency. This ensures developers without access to a Foundry stack can contribute to the code.

## Directory layout

```
foundry-developer-foundations/
 .env
 .npmrc
 Dockerfile
 buildAndPublish.sh
 package.json
 tsconfig.json
 src/
    index.ts
    writeGreeting.ts
    domain/
      worldDao.ts
      userDao.ts
    services/
      foundryClient.ts
      weatherService.ts
    inversify.config.ts
    types.ts
```

### DAOcontract`src/domain/worldDao.ts`

```ts
import type { FoundryClient, WorldDao } from "@hello/types";

export function makeWorldDao(client: FoundryClient): WorldDao {
    return async ({ message, userId }) => {
        console.log(`makeWorldDao userId: ${userId}`);

        const token = await client.auth.signIn();
        const apiKey = token.access_token;

        const url = `${client.url}/api/v2/ontologies/${client.ontologyRid}/actions/say-hello/apply`;

        const headers = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
        };

        const body = JSON.stringify({
            parameters: {
                message,
            },
            options: {
                returnEdits: "ALL"
            }
        });

        const apiResult = await fetch(url, {
            method: "POST",
            headers: headers,
            body: body,
        });

        const result = await apiResult.json() as any;

        if (!result.edits || result.edits.edits.length === 0) {
            throw new Error('Failed to add hello message to the ontolgoy.');
        }

        console.log(`create world action returned: ${result?.edits?.edits?.[0]}`);

        const worldId = result.edits.edits[0].primaryKey as string;

        const getUrl = `${client.url}/api/v2/ontologies/${client.ontologyRid}/objects/World/${worldId}`;
        const worldFetchResults = await fetch(getUrl, {
            method: "GET",
            headers: headers,
        });

        const world = await worldFetchResults.json() as any;
        console.log(`the world ontology returned: ${JSON.stringify(world)}`)

        return { id: "singleton", greeting: world.message };
    };
}
```

---

### DAOcontract`src/domain/userDao.ts`

```ts
import type { FoundryClient, UserDao } from "@hello/types";

export function makeUserDao(client: FoundryClient): UserDao {
    return async () => {
        const user = await client.getUser();
        console.log('OSDK makeUserDao returned:', user);

        return user;
    };
}
```

---

### Foundryclient`src/services/foundryClient.ts`

```ts
import { createConfidentialOauthClient } from "@osdk/oauth";
import { createClient } from "@osdk/client";
import { User, Users } from "@osdk/foundry.admin";
import { FoundryClient } from '@hello/types'

export function createFoundryClient(): FoundryClient {
    // log ENV vars
    console.log('Environment variable keys:');
    Object.keys(process.env).forEach(key => {
        if (key.indexOf('FOUNDRY') >= 0 || key.indexOf('OSDK') >= 0) {
            console.log(`- ${key}`);
        }
    });

    if (!process.env.OSDK_CLIENT_ID || !process.env.OSDK_CLIENT_SECRET) {
        throw new Error('missing required env vars');
    }

    // setup the OSDK
    const clientId: string = process.env.OSDK_CLIENT_ID;
    const url: string = process.env.FOUNDRY_STACK_URL;
    const ontologyRid: string = process.env.ONTOLOGY_RID;
    const clientSecret: string = process.env.OSDK_CLIENT_SECRET;
    const scopes: string[] = [
        "api:ontologies-read",
        "api:ontologies-write",
        "api:admin-read",
        "api:connectivity-read",
        "api:connectivity-write",
        "api:connectivity-execute",
        "api:mediasets-read",
        "api:mediasets-write"
    ]

    const auth = createConfidentialOauthClient(clientId, clientSecret, url, scopes);
    const client = createClient(url, ontologyRid, auth);
    const getUser = async () => {
        const user: User = await Users.getCurrent(client);

        return user;
    };

    return { auth, ontologyRid, url, client, getUser };
}
```

---

### Weatherservice`src/services/weatherService.ts`

```ts
import { WeatherService } from "@hello/types";

export const openWeatherService: WeatherService = async (city) => {
    const key = process.env.OPEN_WEATHER_API_KEY!;
    const res = await fetch(
        `https://api.openweathermap.org/data/2.5/weather?q=${encodeURIComponent(
            city,
        )}&appid=${key}&units=metric`,
    );
    const result = await res.json() as { weather: { description: string }[], main: { temp: string } };
    return `${result.weather[0].description}, ${result.main.temp}C`;
};
```

---

### Type & DI tokens`src/types.ts`

```ts
import { ComputeModule } from '@palantir/compute-module';
import type { Client } from "@osdk/client";

export const TYPES = {
    FoundryClient: Symbol.for("FoundryClient"),
    WeatherService: Symbol.for("WeatherService"),
    WorldDao: Symbol.for("WorldDao"),
    UserDao: Symbol.for("UserDao"),
};

export interface Token {
    readonly access_token: string;
    readonly expires_in: number;
    readonly refresh_token?: string;
    readonly expires_at: number;
}

export interface BaseOauthClient {
    (): Promise<string>;
    getTokenOrUndefined: () => string | undefined;
    signIn: () => Promise<Token>;
    signOut: () => Promise<void>;
}

export interface FoundryClient {
    client: Client;
    auth: BaseOauthClient
}

// Basic example of calling other services besides Foundry.
export interface WeatherService {
    (city: string): Promise<string>;
}

export interface APIError extends Error {
    response?: {
        data: any;
    };
}

export interface ModuleConfig {
    isTest?: boolean;
}

export interface TestModule {
    listeners: Record<string, any>;
    on(event: string, handler: Function): TestModule;
    register(operation: string, handler: Function): TestModule;
}

export type ComputeModuleType = TestModule | ComputeModule<any>;

export interface GreetingInput {
    message: string;
    userId: string;
}

export interface GreetingResult {
    id: string;
    greeting: string;
}

export interface User {
    id: string;
    username: string;
    givenName?: string;
    familyName?: string;
    email?: string;
    organization?: string;
    attributes: Record<string, any>;
}

export type WorldDao = (input: GreetingInput) => Promise<GreetingResult>;
export type UserDao = () => Promise<User>;
```

---

### Inversifyconfig`src/inversify.config.ts`

```ts
import "reflect-metadata";
import { Container } from "inversify";
import { TYPES } from "@hello/types";
import { openWeatherService } from "@hello/services/weatherService";
import { createFoundryClient } from "@hello/services/foundryClient";
import { makeWorldDao } from "@hello/domain/worldDao";
import { makeUserDao } from "@hello/domain/userDao";

export const container = new Container();

container
    .bind(TYPES.FoundryClient)
    .toDynamicValue(createFoundryClient)
    .inSingletonScope();

container
    .bind(TYPES.WorldDao)
    .toDynamicValue((ctx) =>
        makeWorldDao(ctx.get(TYPES.FoundryClient)),
    );

container
    .bind(TYPES.UserDao)
    .toDynamicValue((ctx) =>
        makeUserDao(ctx.get(TYPES.FoundryClient)),
    );

container
    .bind(TYPES.WeatherService)
    .toConstantValue(openWeatherService);
```

---

### Applicationservice`src/writeGreeting.ts`

```ts
import { TYPES, WeatherService, UserDao } from "@hello/types";
import { container } from "@hello/inversify.config";

export async function writeGreeting(city: string): Promise<string> {
    // example of consuming an vanilla service
    const getWeather = container.get<WeatherService>(TYPES.WeatherService);
    const weather = await getWeather(city);

    // example dao usage
    const user = await container.get<UserDao>(TYPES.UserDao)();

    return `weather: ${weather}\nuser: ${user}`;
}
```

---

### ComputeModule`src/index.ts`

```ts
import { ComputeModule } from "@palantir/compute-module";
import { Type } from "@sinclair/typebox";
import { writeGreeting } from "./writeGreeting";
import dotenv from 'dotenv';
import { ComputeModuleType, ModuleConfig } from "./types";

dotenv.config();

const Schemas = {
  WriteGreeting: {
    input: Type.Object({ city: Type.String() }),
    output: Type.Object({ status: Type.Literal("ok") }),
  },
};

// Unified configuration for all environments
function getModuleConfig(): ModuleConfig {
  const env = process.env.NODE_ENV || 'development';

  switch (env) {
    case 'test':
      return { isTest: true };
    default: // development
      return { isTest: false };
  };
}

function createComputeModule(): ComputeModuleType {
  const config = getModuleConfig();

  if (config.isTest) {
    const mockModule = {
      listeners: {} as Record<string, any>,
      on: function (event: string, handler: Function) {
        this.listeners[event] = handler;
        handler();
        return this;
      },
      register: function (operation: string, handler: Function) {
        this.listeners[operation] = { type: 'response', listener: handler };
        return this;
      }
    };
    console.log('returning mock module');
    return mockModule;
  }

  const module = new ComputeModule({
    logger: console,
    sources: {},
    definitions: { WriteGreeting: Schemas.WriteGreeting },
  })
    .register("WriteGreeting", async ({ city }) => {
      await writeGreeting(city);
      return { status: "ok" };
    })
    .on("responsive", () => console.log("YellowWorld ready"));

  module.on("responsive", () => {
    console.log(`${process.env.LOG_PREFIX} Module is now responsive`);
  });

  return module;
}

const computeModule = createComputeModule();

export { computeModule };

```

---

### Tryitlocally

```bash
npm run ops:greet "Laguna Niguel"
```

---

## Pattern Recap

1. Foundry interactions isolated in **DAOs** under the `domain` directory.
2. Services injected with **Inversify** (no classes required).
3. Compute Module wires schemas  operations.
4. GitHub is the sourceoftruth; Foundry provides the persistent data store and actions via the OSDK and Ontology.

---

## Building&Deploying as a Foundry ComputeModule

### Dockerfile`Dockerfile`

```dockerfile
# syntax=docker/dockerfile:1
ARG NODE_VERSION=20.10.0
FROM --platform=amd64 node:${NODE_VERSION}-alpine

ARG FOUNDRY_TOKEN=undefined

ENV FOUNDRY_TOKEN=$FOUNDRY_TOKEN

WORKDIR /app

# Copy package files
COPY package*.json /app/

# Install all dependencies for building
RUN npm ci

# Copy source files
COPY tsconfig.build.json /app/
COPY src/ /app/src/

# Build TypeScript
RUN npm run build

# Remove dev dependencies
RUN npm ci --only=production

# Create a non-root numeric user (must be numeric for compute modules)
RUN adduser --uid 5001 --disabled-password --gecos "" user && \
    chown -R 5001:5001 /app

USER 5001

# Environment setup
ENV NODE_ENV=production

# Verify directory structure
RUN ls -la /app/src/domain && \
    ls -la /app/src/services

# Specify the entrypoint explicitly as required
ENTRYPOINT ["node", "dist/src/index.js"] 
```

###Deploy script`buildAndPublish.sh` (notional)

```bash
#!/bin/zsh

docker build --platform linux/amd64 -t baryte-container-registry.palantirfoundry.com/gsuite-functions:1.0.20 .

export REPOSITORY=ri.artifacts.main.repository.3631f5ce-882c-4f9f-a61e-aae2263437f0
export TOKEN=$FOUNDRY_TOKEN
docker login -u "$REPOSITORY" -p "$TOKEN" baryte-container-registry.palantirfoundry.com
docker push baryte-container-registry.palantirfoundry.com/gsuite-functions:1.0.20
```
````

## File: hello-world/tsconfig.build.json
````json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "lib": ["ES2020"],
    "declaration": true,
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "sourceMap": true,
    "types": ["jest", "node"],
    "baseUrl": ".",
    "paths": {
        "@hello/*": ["src/*"]
    },
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true
  },
  "include": ["src/**/*", "src/**/*.d.ts",  "jest.config.js"],
  "exclude": ["node_modules", "dist", "ops", "config"],
  "ts-node": {
    "files": true
  }
}
````

## File: hello-world/tsconfig.json
````json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "lib": ["ES2020"],
    "declaration": true,
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "sourceMap": true,
    "types": ["jest", "node"],
    "baseUrl": ".",
    "paths": {
        "@hello/*": ["src/*"]
    },
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true
  },
  "include": ["src/**/*", "test/**/*", "src/**/*.d.ts",  "jest.config.js"],
  "exclude": ["node_modules", "dist", "ops", "config"],
  "ts-node": {
    "files": true
  }
}
````

## File: packages/agents/vickie-bennie/src/lib/__fixtures__/Email.ts
````typescript
import { Context } from '@codestrap/developer-foundations-types';

const date = new Date();
// get tomorrow
date.setDate(date.getDate() + 1);

// Helper to generate ISO strings with specified hour and minute in UTC
function getISOTime(date: Date, hour: number, minute: number): string {
  const d = new Date(
    Date.UTC(date.getFullYear(), date.getMonth(), date.getDate(), hour, minute)
  );
  return d.toISOString();
}

// Mock email response data
export const mockEmailResponse = {
  data: {
    id: '8675309',
    threadId: '2468',
    labelIds: ['labels', 'schmabels'],
  },
};

export const validEmailData = {
  message: 'Hello World',
  subject: 'Test Subject',
  recipients: ['test@example.com'],
  modelDialog: 'sample dialog',
  ts: 1234567890,
};

export const validContext = {
  stack: ['emailData', 'bullshit'],
  emailData: validEmailData,
} as any as Context;

export const missingRecipientContext = {
  stack: ['emailData', 'bullshit'],
  emailData: {
    // message is missing
    subject: 'Test',
    modelDialog: 'sample dialog',
    ts: 1234567890,
  },
} as any as Context;

const THREAD_ID = 'mock-thread-id-1';

/*  messages.get  */
export const mockMessageGetResponse = {
  data: {
    id: 'mock-email-id-1',
    threadId: THREAD_ID,
    payload: {
      headers: [
        {
          name: 'Subject',
          value:
            'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        },
      ],
    },
    snippet: 'Mock message snippet',
  },
};

/*  messages.list (noresolution)  */
export const mockEmailHistoryNoResolution = {
  data: {
    messages: [
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'vici@codestrap.me',
        body: `Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time. Could you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  Thanks!  Best Vickie`,
        id: 'mock-email-id',
      },
    ],
  },
};

/*  messages.list (with resolution)  */
export const mockEmailHistoryWithResolution = {
  data: {
    messages: [
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'vici@codestrap.me',
        body: `Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time. Could you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  Thanks!  Best Vickie`,
        id: 'mock-email-id-1',
      },
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'dsmiley@codestrap.me',
        body: `Hey Connor what about tomorrow at 4 PM?`,
        id: 'mock-email-id-2',
      },
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'connor.deeks@codestrap.me',
        body: `That works.`,
        id: 'mock-email-id-3',
      },
    ],
  },
};

/*  threads.get  */
export const mockMessageGetThreadsResponse = {
  data: {
    id: THREAD_ID,
    messages: [
      {
        id: mockEmailHistoryWithResolution.data.messages[0].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'vici@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryWithResolution.data.messages[0].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
      {
        id: mockEmailHistoryWithResolution.data.messages[1].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'dsmiley@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryWithResolution.data.messages[1].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
      {
        id: mockEmailHistoryWithResolution.data.messages[2].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'connor.deeks@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryWithResolution.data.messages[2].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
    ],
  },
};

export const mockMessageGetThreadsResponseNoResolution = {
  data: {
    id: THREAD_ID,
    messages: [
      {
        id: mockEmailHistoryNoResolution.data.messages[0].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'vici@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryNoResolution.data.messages[0].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
    ],
  },
};

export const mockCalendarList = {
  data: {
    items: [
      {
        id: 'mockEventId',
        summary: 'Meet with Komatsu',
        start: { dateTime: getISOTime(date, 20, 0) },
        end: { dateTime: getISOTime(date, 21, 0) },
      },
      {
        id: 'mockEventId2',
        summary: 'Stand Up',
        start: { dateTime: getISOTime(date, 21, 0) },
        end: { dateTime: getISOTime(date, 21, 30) },
      },
    ],
    nextPageToken: null,
    // other Schema$Events fields can be added if your code reads them
  },
};

export const mockCalendarInsert = {
  data: {
    id: 'mockEventId',
    hangoutLink: 'https://meet.google.com/mock-link', // direct Meet link
    conferenceData: {
      // redundant but harmless
      entryPoints: [
        {
          entryPointType: 'video',
          uri: 'https://meet.google.com/mock-link',
        },
      ],
    },
  },
};

export function getMockFreeBusyResponse(timeMin: any, timeMax: any) {
  return {
    data: {
      kind: 'calendar#freeBusy',
      timeMin,
      timeMax,
      calendars: {
        // each email requested in params.requestBody.items[*].id gets an entry:
        'dsmiley@codestrap.me': {
          busy: [
            {
              start: { dateTime: getISOTime(date, 20, 0) },
              end: { dateTime: getISOTime(date, 21, 0) },
            },
            {
              start: { dateTime: getISOTime(date, 21, 0) },
              end: { dateTime: getISOTime(date, 21, 30) },
            },
          ],
        },
      },
    },
  };
}
````

## File: packages/agents/vickie-bennie/src/lib/__fixtures__/Gemini.ts
````typescript
// Set up the mock response
export const mockProgrammerResponse1 = `[
    {
        "id": "sendEmail|13",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "success"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "success",
        "type": "final"
    },
    {
        "id": "failure",
        "type": "final"
    }
]`;
````

## File: packages/agents/vickie-bennie/src/lib/__fixtures__/MachineExecutions.ts
````typescript
export const machineId = 'mock-execution-id';
export const machineId2 = 'mock-execution-id2';

export const mockExecution = {
    id: machineId,
    state: `{
            "actions":[{"type":"entry"}],
            "activities":{},
            "meta":{},
            "events":[],
            "value":"pause",
            "context":{
                "status":0,
                "requestId":"test",
                "stack":["sendEmail|2"],
                "sendEmail|2": {
                    "message": "Test message",
                    "channelId": "test-channel"
                }
            },
            "_event":{
                "name":"xstate.init",
                "data":{"type":"xstate.init"},
                "$$type":"scxml",
                "type":"external"
            },
            "_sessionid":"x:1",
            "event":{"type":"xstate.init"},
            "children":{},
            "done":false,
            "tags":[]
        }`,
    machine: `[
            {
                "id": "sendEmail|2",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendSlackMessage|3"
                    },
                    {
                        "on": "pause",
                        "target": "pause"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendSlackMessage|3",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendEmail|4"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendEmail|4",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "success"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "success",
                "type": "final"
            },
            {
                "id": "failure",
                "type": "final"
            }
        ]`
};

const date = new Date();
// get tomorrow
date.setDate(date.getDate() + 1);
const dayName = date.toLocaleDateString('en-US', { weekday: 'long' });

// this is the second state in the machine
export const mockExecution2 = {
    id: machineId2,
    state: `{
    "actions": [
        {
            "type": "entry"
        }
    ],
    "activities": {},
    "meta": {},
    "events": [],
    "value": "success",
    "context": {
        "requestId": "2117368a-3119-44dd-878b-d9ff886ae7f5",
        "status": 0,
        "childToParentStateMap": {},
        "machineExecutionId": "2618bc50-d865-4aaf-8625-a05eb608e4e3",
        "solution": "1. **Get available times for meeting attendees** - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Proposed date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour    If all attendees are not available, resolve unavailable attendees  2. **Schedule a meeting** - Subject: Meeting with Dorian and Connor. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour",
        "stack": [
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
            "success"
        ],
        "stateId": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
        "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
            "times": [
                {
                    "start": "2025-08-04T16:30:00.000Z",
                    "end": "2025-08-04T17:30:00.000Z",
                    "availableAttendees": [
                        "dsmiley@codestrap.me",
                        "connor.deeks@codestrap.me"
                    ],
                    "unavailableAttendees": []
                }
            ],
            "subject": "Meeting with Dorian and Connor",
            "durationInMinutes": 60,
            "allAvailable": true,
            "agenda": "Found 1 optimal time slots."
        },
        "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42": {
            "emailId": "1984e2ae93f40a57",
            "message": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
            "meetingSubject": "Meeting with Dorian and Connor.",
            "meetingDuration": 60,
            "dayTimes": "                  start: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         end: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
            "modelDialog": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
            "ts": 1753658092064,
            "resolution": "${dayName} at 4",
            "processEmail": true
        },
        "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533": {
            "id": "pccjsddgde4kjalihqb6pnsohs",
            "htmlLink": "https://www.google.com/calendar/event?eid=cGNjanNkZGdkZTRramFsaWhxYjZwbnNvaHMgdmljaUBjb2Rlc3RyYXAubWU",
            "status": "confirmed"
        },
        "success": {
            "resolution": "${dayName} at 4",
            "processEmail": true
        }
    },
    "_event": {
        "name": "CONTINUE",
        "data": {
            "type": "CONTINUE",
            "payload": {
                "stateId": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
                "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533": {
                    "id": "pccjsddgde4kjalihqb6pnsohs",
                    "htmlLink": "https://www.google.com/calendar/event?eid=cGNjanNkZGdkZTRramFsaWhxYjZwbnNvaHMgdmljaUBjb2Rlc3RyYXAubWU",
                    "status": "confirmed"
                }
            }
        },
        "$$type": "scxml",
        "type": "external"
    },
    "_sessionid": "x:9",
    "event": {
        "type": "CONTINUE",
        "payload": {
            "stateId": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
            "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533": {
                "id": "pccjsddgde4kjalihqb6pnsohs",
                "htmlLink": "https://www.google.com/calendar/event?eid=cGNjanNkZGdkZTRramFsaWhxYjZwbnNvaHMgdmljaUBjb2Rlc3RyYXAubWU",
                "status": "confirmed"
            }
        }
    },
    "historyValue": {
        "current": "success",
        "states": {}
    },
    "history": {
        "actions": [
            {
                "type": "entry"
            }
        ],
        "activities": {},
        "meta": {},
        "events": [],
        "value": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
        "context": {
            "requestId": "2117368a-3119-44dd-878b-d9ff886ae7f5",
            "status": 0,
            "childToParentStateMap": {},
            "machineExecutionId": "2618bc50-d865-4aaf-8625-a05eb608e4e3",
            "solution": "1. **Get available times for meeting attendees** - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Proposed date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour    If all attendees are not available, resolve unavailable attendees  2. **Schedule a meeting** - Subject: Meeting with Dorian and Connor. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour",
            "stack": [
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
                "success"
            ],
            "stateId": "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
                "times": [
                    {
                        "start": "2025-08-04T16:30:00.000Z",
                        "end": "2025-08-04T17:30:00.000Z",
                        "availableAttendees": [
                            "dsmiley@codestrap.me",
                            "connor.deeks@codestrap.me"
                        ],
                        "unavailableAttendees": []
                    }
                ],
                "subject": "Meeting with Dorian and Connor",
                "durationInMinutes": 60,
                "allAvailable": true,
                "agenda": "Found 1 optimal time slots."
            },
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42": {
                "emailId": "1984e2ae93f40a57",
                "message": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
                "meetingSubject": "Meeting with Dorian and Connor.",
                "meetingDuration": 60,
                "dayTimes": "                  start: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         end: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
                "modelDialog": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
                "ts": 1753658092064,
                "resolution": "${dayName} at 4",
                "processEmail": true
            }
        },
        "_event": {
            "name": "CONTINUE",
            "data": {
                "type": "CONTINUE",
                "payload": {
                    "stateId": "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                    "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
                        "times": [
                            {
                                "start": "2025-08-04T16:30:00.000Z",
                                "end": "2025-08-04T17:30:00.000Z",
                                "availableAttendees": [
                                    "dsmiley@codestrap.me",
                                    "connor.deeks@codestrap.me"
                                ],
                                "unavailableAttendees": []
                            }
                        ],
                        "subject": "Meeting with Dorian and Connor",
                        "durationInMinutes": 60,
                        "allAvailable": true,
                        "agenda": "Found 1 optimal time slots."
                    }
                }
            },
            "$$type": "scxml",
            "type": "external"
        },
        "_sessionid": "x:1",
        "event": {
            "type": "CONTINUE",
            "payload": {
                "stateId": "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
                    "times": [
                        {
                            "start": "2025-08-04T16:30:00.000Z",
                            "end": "2025-08-04T17:30:00.000Z",
                            "availableAttendees": [
                                "dsmiley@codestrap.me",
                                "connor.deeks@codestrap.me"
                            ],
                            "unavailableAttendees": []
                        }
                    ],
                    "subject": "Meeting with Dorian and Connor",
                    "durationInMinutes": 60,
                    "allAvailable": true,
                    "agenda": "Found 1 optimal time slots."
                }
            }
        },
        "historyValue": {
            "current": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
            "states": {}
        },
        "children": {},
        "done": false,
        "changed": true,
        "tags": []
    },
    "children": {},
    "done": true,
    "tags": []
}`,
    machine: `
        [
            {
                "id": "sendEmail",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendSlackMessage"
                    },
                    {
                        "on": "pause",
                        "target": "pause"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendSlackMessage",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "getAvailableMeetingTimes"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "getAvailableMeetingTimes",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "scheduleMeeting"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "scheduleMeeting",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendEmail"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendEmail",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "success"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "success",
                "type": "final"
            },
            {
                "id": "failure",
                "type": "final"
            }
        ]
        `
};

export const mockModifyFetchResponse = {
    validation: {
        result: "VALID",
        submissionCriteria: [],
        parameters: {}
    },
    edits: {
        type: "edits",
        edits: [
            {
                type: "modifyObject",
                primaryKey: "310e5c75-9ccf-4b01-8d0b-f4bf9bf6667e",
                objectType: "MachineExecutions"
            }
        ],
        addedObjectCount: 0,
        modifiedObjectsCount: 1,
        deletedObjectsCount: 0,
        addedLinksCount: 0,
        deletedLinksCount: 0
    }
};

export const mockModifyApiResponse = (): Response =>
({
    ok: true,
    status: 200,
    statusText: "OK",
    headers: {},
    json: () => Promise.resolve(mockModifyFetchResponse)
} as Response);

export const text2ActionTestMachineExecution = {
    machine: `
        [
            {
                "id": "sendEmail|1",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendEmail|5"
                    },
                    {
                        "on": "pause",
                        "target": "pause"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendEmail|5",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "success"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "success",
                "type": "final"
            },
            {
                "id": "failure",
                "type": "final"
            }
        ]
        `,
    state: `{"actions":[{"type":"entry"}],"activities":{},"meta":{},"events":[],"value":"sendEmail|1","context":{"status":0,"requestId":"test","stack":["sendEmail|1"], "sendEmail|1": {"message": "test", "subject": "test subject", "recipients": ["test@example.com"],"modelDialog": "sample dialog", "ts": "1234567890"}},"_event":{"name":"xstate.init","data":{"type":"xstate.init"},"$$type":"scxml","type":"external"},"_sessionid":"x:1","event":{"type":"xstate.init"},"children":{},"done":false,"tags":[]}`,
};

export const mockProcessEmailEventExecution = {
    id: 'f41b004c-c032-4f3a-b7b8-be831804cb03',
    currentState: 'pause',
    logs: '',
    state: `
    {
    "actions": [],
    "activities": {},
    "meta": {},
    "events": [],
    "value": "pause",
    "context": {
        "requestId": "5eea54ea-0f14-4afa-9f89-7b2913fa8e54",
        "status": 0,
        "childToParentStateMap": {},
        "machineExecutionId": "f41b004c-c032-4f3a-b7b8-be831804cb03",
        "solution": "Get available times for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM nIf all attendees are not available, resolve unavailable attendees nSchedule a meeting - Subject: Meeting with Dorian Smiley and Connor Deeks. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nStart Time: 2:00 PM nEnd Time: 3:00 PM nRead Emails - Read emails for Dorian Smiley <dsmiley@codestrap.me> from the last 15 minutes",
        "stack": [
            "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
            "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1"
        ],
        "stateId": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
        "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
            "times": [
                {
                    "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                    "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                    "availableAttendees": [],
                    "unavailableAttendees": [
                        "dsmiley@codestrap.me",
                        "connor.deeks@codestrap.me"
                    ]
                }
            ],
            "subject": "Meeting with Dorian Smiley and Connor Deeks.",
            "durationInMinutes": 60,
            "allAvailable": false
        },
        "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1": {
            "emailId": "1981ab81fe57c933",
            "message": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
            "meetingSubject": "Meeting with Dorian Smiley and Connor Deeks.",
            "meetingDuration": 60,
            "dayTimes": "                  start: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         end: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
            "modelDialog": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
            "ts": 1752794931444
        }
    },
    "_event": {
        "name": "pause",
        "data": {
            "type": "pause",
            "payload": {
                "stateId": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
                "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1": {
                    "emailId": "1981ab81fe57c933",
                    "message": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                    "meetingSubject": "Meeting with Dorian Smiley and Connor Deeks.",
                    "meetingDuration": 60,
                    "dayTimes": "                  start: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         end: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
                    "modelDialog": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                    "ts": 1752794931444
                }
            }
        },
        "$$type": "scxml",
        "type": "external"
    },
    "_sessionid": "x:7",
    "event": {
        "type": "pause",
        "payload": {
            "stateId": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
            "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1": {
                "emailId": "1981ab81fe57c933",
                "message": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                "meetingSubject": "Meeting with Dorian Smiley and Connor Deeks.",
                "meetingDuration": 60,
                "dayTimes": "                  start: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         end: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
                "modelDialog": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                "ts": 1752794931444
            }
        }
    },
    "historyValue": {
        "current": "pause",
        "states": {}
    },
    "history": {
        "actions": [
            {
                "type": "entry"
            }
        ],
        "activities": {},
        "meta": {},
        "events": [],
        "value": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
        "context": {
            "requestId": "5eea54ea-0f14-4afa-9f89-7b2913fa8e54",
            "status": 0,
            "childToParentStateMap": {},
            "machineExecutionId": "f41b004c-c032-4f3a-b7b8-be831804cb03",
            "solution": "Get available times for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM nIf all attendees are not available, resolve unavailable attendees nSchedule a meeting - Subject: Meeting with Dorian Smiley and Connor Deeks. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nStart Time: 2:00 PM nEnd Time: 3:00 PM nRead Emails - Read emails for Dorian Smiley <dsmiley@codestrap.me> from the last 15 minutes",
            "stack": [
                "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
                "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1"
            ],
            "stateId": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
            "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
                "times": [
                    {
                        "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                        "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                        "availableAttendees": [],
                        "unavailableAttendees": [
                            "dsmiley@codestrap.me",
                            "connor.deeks@codestrap.me"
                        ]
                    }
                ],
                "subject": "Meeting with Dorian Smiley and Connor Deeks.",
                "durationInMinutes": 60,
                "allAvailable": false
            }
        },
        "_event": {
            "name": "CONTINUE",
            "data": {
                "type": "CONTINUE",
                "payload": {
                    "stateId": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
                    "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
                        "times": [
                            {
                                "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                                "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                                "availableAttendees": [],
                                "unavailableAttendees": [
                                    "dsmiley@codestrap.me",
                                    "connor.deeks@codestrap.me"
                                ]
                            }
                        ],
                        "subject": "Meeting with Dorian Smiley and Connor Deeks.",
                        "durationInMinutes": 60,
                        "allAvailable": false
                    }
                }
            },
            "$$type": "scxml",
            "type": "external"
        },
        "_sessionid": "x:7",
        "event": {
            "type": "CONTINUE",
            "payload": {
                "stateId": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
                "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
                    "times": [
                        {
                            "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                            "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                            "availableAttendees": [],
                            "unavailableAttendees": [
                                "dsmiley@codestrap.me",
                                "connor.deeks@codestrap.me"
                            ]
                        }
                    ],
                    "subject": "Meeting with Dorian Smiley and Connor Deeks.",
                    "durationInMinutes": 60,
                    "allAvailable": false
                }
            }
        },
        "historyValue": {
            "current": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
            "states": {}
        },
        "children": {},
        "done": false,
        "changed": true,
        "tags": []
    },
    "children": {},
    "done": true,
    "changed": true,
    "tags": []
}
    `,
    machine: `
    [
    {
        "id": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
        "task": "Get available times for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM",
        "includesLogic": true,
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "scheduleMeeting|ddb8ee4f-72a2-4198-8547-06816fa0de77"
            },
            {
                "on": "CONTINUE",
                "target": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
        "task": "Resolve meeting conflicts for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM. If an agreed upon time has been reached target the find available times state. Do not continue or target schedule meeting!",
        "includesLogic": true,
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "scheduleMeeting|ddb8ee4f-72a2-4198-8547-06816fa0de77"
            },
            {
                "on": "CONTINUE",
                "target": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "scheduleMeeting|ddb8ee4f-72a2-4198-8547-06816fa0de77",
        "task": "Schedule a meeting - Subject: Meeting with Dorian Smiley and Connor Deeks. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nStart Time: 2:00 PM nEnd Time: 3:00 PM",
        "includesLogic": false,
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "readEmails|d0b61e3d-9603-429d-9e3b-f1b614b19c0e"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "readEmails|d0b61e3d-9603-429d-9e3b-f1b614b19c0e",
        "task": "Read Emails - Read emails for Dorian Smiley <dsmiley@codestrap.me> from the last 15 minutes",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "success"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "success",
        "type": "final"
    },
    {
        "id": "failure",
        "type": "final"
    }
]
    `};
````

## File: packages/agents/vickie-bennie/src/lib/tests/bennie.e2e.test.ts
````typescript
import { Bennie } from '../Bennie';
import { container } from '@codestrap/developer-foundations-di';
import {
  Context,
  MachineEvent,
  StateConfig,
  MachineDao,
  RfpRequestResponse,
  RfpRequestsDao,
  TYPES,
} from '@codestrap/developer-foundations-types';
import { State } from 'xstate';

if (!process.env.E2E) {
  test.skip('e2e test skipped in default run', () => {
    // won't run
  });
} else {
  describe('testing Bennie', () => {
    beforeAll(() => {
      jest.clearAllMocks();
    });

    it('Should generate two RFP requests, one for Northslope and one for RANGR. RANGR should request missing information', async () => {
      // real e2e test
      const bennie = new Bennie();

      const result = await bennie.askBennie(
        'Create an RFP for Northslope and RangrData to deliver a tariff solution on Foundry. The solution must include support for pricing models, simulations, and A/B testing of the outcomes. We expect this to be an 4 week engagement requiring 3 Python engineer, 1 TypeScript engineer, and 2 SME on developing pricing models. Then email me the responses.',
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);

      const machineExecutionId = result.executionId;
      const rangrVendorId = 'rangrdata.com';
      const northslopeVendorId = 'northslopetech.com';

      // get the machine execution
      const machineDao = container.get<MachineDao>(TYPES.MachineDao);
      // allow this to throw if no machine execution is found
      let execution = await machineDao.read(result.executionId);

      let machine: StateConfig[] = execution.machine
        ? JSON.parse(execution.machine)
        : undefined;
      let stateDefinition: State<Context, MachineEvent> | undefined =
        execution.state
          ? (JSON.parse(execution.state) as State<Context, MachineEvent>)
          : undefined;

      if (!machine) {
        throw new Error(
          `no programmed state machine found for: ${machineExecutionId}`
        );
      }

      if (!stateDefinition) {
        throw new Error(`no state definition found for: ${machineExecutionId}`);
      }

      let context: Context = stateDefinition.context as Context;
      // find the requestRftp on the context associated with the supplied vendorId
      const vendorRfpRequest = Object.keys(context)
        .filter((key) => key.indexOf('requestRfp') >= 0)
        .map((key) => context[key])
        .filter((item) => item.vendorId === rangrVendorId)?.[0] as
        | RfpRequestResponse
        | undefined;
      // add the response to the requestRfp object.
      if (!vendorRfpRequest) {
        throw new Error(
          `Could not find matching RFP request for vendorId: ${rangrVendorId}`
        );
      }
      // get the rfp response and poll until RANGR send back missing information, ie rfpResponseStatus === 400
      const rfpDao = container.get<RfpRequestsDao>(TYPES.RfpRequestsDao);
      // find the associated RFPs
      const rangrRfpRequest = await rfpDao.search(
        machineExecutionId,
        rangrVendorId
      );

      let found = false;
      const maxAttempts = 10;
      let attempts = 0;

      while (!found && attempts < maxAttempts) {
        const rfp = await rfpDao.read(rangrRfpRequest.id);
        if (rfp.rfpResponseStatus === 400) {
          found = true;
        } else if (rfp.rfpResponseStatus === 200) {
          throw new Error('RANGR responses with 200 when 400 was expected');
        } else {
          await new Promise((res) => setTimeout(res, 30000)); // wait 30s
          attempts++;
        }
      }

      // send the thread message with the missing information
      const threadMessage = await bennie.sendThreadMessage(
        `The company is John Doe's Manufacturing and there address is 123 main street dallas tx, 75081 and the main contact is johndoe@johnsdoes.com.`,
        process.env.FOUNDRY_TEST_USER,
        machineExecutionId
      );
      expect(
        threadMessage.messages!.indexOf(
          '# RFPs for the following vendors were resubmitted:'
        )
      ).toBeGreaterThanOrEqual(0);

      // wait for the update from RANGR
      found = false;
      attempts = 0;

      while (!found && attempts < maxAttempts) {
        const rfp = await rfpDao.read(rangrRfpRequest.id);
        if (rfp.rfpResponseStatus === 200) {
          found = true;
        } else {
          await new Promise((res) => setTimeout(res, 30000)); // wait 30s
          attempts++;
        }
      }

      if (attempts > maxAttempts) {
        throw new Error(
          'Exceeded max attempts waiting for RANGR to respond to the resubmitted RFP'
        );
      }
      // submit the RFP responses, this will also advance the state machine
      const northSlopeRfpSubmissionResponse = await bennie.submitRfpResponse(
        `
###  Proposed Staffing Plan

- **Engagement Director**: 0.25 FTE
- **Solutions Engineer  Senior**: 0.5 FTE
- **Solutions Engineer  Junior**: 1.0 FTE

** Available Start Date**: June 17, 2025  
** Estimated Weekly Cost**: $3,842.50  
** Estimated Total Cost (8 weeks)**: $30,740.00
The earliest date when all required roles are simultaneously available is June 17, 2025, based on the provided availability information.

The weekly blended cost is calculated as follows:

Engagement Director: 0.25 FTE x $3,192 = $798
Solutions Engineer - Senior: 0.5 FTE x $3,192 = $1,596
Solutions Engineer - Junior: 1.0 FTE x $1,942 = $1,942
Total weekly cost: $798 + $1,596 + $1,942 = $3,842.50
Multiplying the weekly blended cost of $3,842.50 by the project duration of 8 weeks results in an estimated total cost of $30,740.00.
`,
        northslopeVendorId,
        machineExecutionId
      );

      expect(northSlopeRfpSubmissionResponse.status).toBe(200);

      // fetch the updated machine and assert the current state
      execution = await machineDao.read(result.executionId);

      machine = execution.machine ? JSON.parse(execution.machine) : undefined;
      stateDefinition = execution.state
        ? JSON.parse(execution.state)
        : undefined;

      if (!machine) {
        throw new Error(
          `no programmed state machine found for: ${machineExecutionId}`
        );
      }

      if (!stateDefinition) {
        throw new Error(`no state definition found for: ${machineExecutionId}`);
      }

      context = stateDefinition.context as Context;

      expect(stateDefinition.value).toBe('success');

      // submit the northslope response
    }, 300000);
  });
}
````

## File: packages/agents/vickie-bennie/src/lib/tests/gmail.pubsub.e2e.test.ts
````typescript
import { Buffer } from 'buffer';
import { OfficeService, TYPES } from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

if (!process.env.E2E) {
  test.skip('e2e test skipped in default run', () => {
    // won't run
  });
} else {
  describe('Gmail Watch E2E', () => {
    beforeAll(() => {
      jest.clearAllMocks();
    });

    it('should register Gmail watch notifications for each user', async () => {
      const topicName =
        'projects/foundry-coms-foundations/topics/codestrap-emails';
      const users = [
        'dsmiley@codestrap.me',
        'connor.deeks@codestrap.me',
        'vici@codestrap.me',
      ];

      const inputs = {
        config: [
          {
            topicName,
            users,
            labelIds: ['INBOX'],
            labelFilterBehavior: 'INCLUDE',
          },
        ],
      };

      const officeService = await container.getAsync<OfficeService>(
        TYPES.OfficeService
      );

      const schedulingResult = await officeService.watchEmails(inputs);

      expect(schedulingResult.status).toBe(200);
      expect(schedulingResult.responses?.length).toBe(3);
      const results = '';
      console.log(
        schedulingResult.responses?.reduce((acc, cur) => {
          acc = `${acc}\n${cur}`;
          return acc;
        }, results)
      );
    }, 60000);

    it('should retrieve a message history when no labels are provided', async () => {
      const rawEvent = `{"message":{"data":"eyJlbWFpbEFkZHJlc3MiOiJkc21pbGV5QGNvZGVzdHJhcC5tZSIsImhpc3RvcnlJZCI6MTc1NDI5M30=","messageId":"15100603300208417","message_id":"15100603300208417","publishTime":"2025-07-16T00:58:13.054Z","publish_time":"2025-07-16T00:58:13.054Z"},"subscription":"projects/foundry-coms-foundations/subscriptions/codestra-emails-subscription-push"}`;
      const parsedEvent = JSON.parse(rawEvent) as {
        message: { data: string; publishTime: string };
      };
      const data = parsedEvent.message.data;
      const publishTime = parsedEvent.message.publishTime;
      const decodedJson = Buffer.from(data, 'base64').toString('utf8');
      const { emailAddress, historyId } = JSON.parse(decodedJson) as {
        emailAddress: string;
        historyId: number;
      };

      const officeService = await container.getAsync<OfficeService>(
        TYPES.OfficeService
      );

      const result = await officeService.readEmailHistory({
        email: emailAddress,
        publishTime,
      });

      expect(result.messages.length).toBeGreaterThan(0);
    }, 60000);

    it('should retrieve a message history when one label is provided', async () => {
      const rawEvent = `{"message":{"data":"eyJlbWFpbEFkZHJlc3MiOiJkc21pbGV5QGNvZGVzdHJhcC5tZSIsImhpc3RvcnlJZCI6MTc1NDI5M30=","messageId":"15100603300208417","message_id":"15100603300208417","publishTime":"2025-07-16T00:58:13.054Z","publish_time":"2025-07-16T00:58:13.054Z"},"subscription":"projects/foundry-coms-foundations/subscriptions/codestra-emails-subscription-push"}`;
      const parsedEvent = JSON.parse(rawEvent) as {
        message: { data: string; publishTime: string };
      };
      const data = parsedEvent.message.data;
      const publishTime = parsedEvent.message.publishTime;
      const decodedJson = Buffer.from(data, 'base64').toString('utf8');
      const { emailAddress, historyId } = JSON.parse(decodedJson) as {
        emailAddress: string;
        historyId: number;
      };

      const officeService = await container.getAsync<OfficeService>(
        TYPES.OfficeService
      );

      const result = await officeService.readEmailHistory({
        email: emailAddress,
        publishTime,
        labels: ['inbox'],
      });

      expect(result.messages.length).toBeGreaterThan(0);
    }, 60000);

    it('should retrieve a message history when multiples labels are provided', async () => {
      const rawEvent = `{"message":{"data":"eyJlbWFpbEFkZHJlc3MiOiJkc21pbGV5QGNvZGVzdHJhcC5tZSIsImhpc3RvcnlJZCI6MTc1NDI5M30=","messageId":"15100603300208417","message_id":"15100603300208417","publishTime":"2025-07-16T00:58:13.054Z","publish_time":"2025-07-16T00:58:13.054Z"},"subscription":"projects/foundry-coms-foundations/subscriptions/codestra-emails-subscription-push"}`;
      const parsedEvent = JSON.parse(rawEvent) as {
        message: { data: string; publishTime: string };
      };
      const data = parsedEvent.message.data;
      const publishTime = parsedEvent.message.publishTime;
      const decodedJson = Buffer.from(data, 'base64').toString('utf8');
      const { emailAddress, historyId } = JSON.parse(decodedJson) as {
        emailAddress: string;
        historyId: number;
      };

      const officeService = await container.getAsync<OfficeService>(
        TYPES.OfficeService
      );

      const result = await officeService.readEmailHistory({
        email: emailAddress,
        publishTime,
        labels: ['inbox', 'cigars', 'pltr'],
      });

      expect(result.messages.length).toBeGreaterThan(0);
    }, 60000);
  });
}
````

## File: packages/agents/vickie-bennie/src/lib/tests/processEmailEvent.happyPath.test.ts
````typescript
import { mockProcessEmailEventExecution } from '../__fixtures__/MachineExecutions';
import {
  getMockFreeBusyResponse,
  mockCalendarInsert,
  mockCalendarList,
  mockEmailHistoryWithResolution,
  mockEmailResponse,
  mockMessageGetResponse,
  mockMessageGetThreadsResponse,
} from '../__fixtures__/Email';
import { Vickie } from '../Vickie';

let counter = 0;

jest.mock('@codestrap/developer-foundations-utils', () => ({
  ...jest.requireActual('@codestrap/developer-foundations-utils'),
  uuidv4: jest.fn(() => (++counter).toString()),
}));

jest.mock('@codestrap/developer-foundations-services-palantir', () => ({
  // TODO mock the gemini service responses, this introduces an element on non-determinism.
  ...jest.requireActual('@codestrap/developer-foundations-services-palantir'),
  makeMachineDao: jest.fn(() => ({
    upsert: jest.fn(
      (
        id: string,
        stateMachine: string,
        state: string,
        logs: string,
        lockOwner?: string,
        lockUntil?: number
      ) => {
        return mockProcessEmailEventExecution;
      }
    ),
    delete: jest.fn(),
    read: jest.fn((machineExecutionId: string) => {
      return Promise.resolve(mockProcessEmailEventExecution);
    }),
  })),
  makeMemoryRecallDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeTrainingDataDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeContactsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeUserDao: jest.fn(() => ({
    read: jest.fn(),
  })),
  makeCommsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeThreadsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeTicketsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeWorldDao: jest.fn(() => ({
    read: jest.fn(),
  })),
}));

jest.mock('@codestrap/developer-foundations-services-rangr', () => ({
  createRangrClient: jest.fn(() => ({
    someMethod: jest.fn(),
  })),
  makeRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeRangrRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
}));

jest.mock('googleapis', () => ({
  ...jest.requireActual('googleapis'), // Keep other actual exports

  google: {
    // Mock the 'gmail' function as before
    gmail: jest.fn((version: string, auth: any) => {
      return {
        users: {
          messages: {
            send: jest.fn((request: any) => {
              console.log(`Gmail mock messages.send called with: ${request}`);
              return Promise.resolve(mockEmailResponse);
            }),
            list: jest.fn((request: any) => {
              console.log(`Gmail mock messages.list called with: ${request}`);
              return Promise.resolve(mockEmailHistoryWithResolution);
            }),
            get: jest.fn((request: any) => {
              console.log(`Gmail mock messages.get called with: ${request}`);
              return Promise.resolve(mockMessageGetResponse);
            }),
          },
          threads: {
            get: jest.fn((request: any) => {
              console.log(`Gmail mock threads.get called with: ${request}`);
              return Promise.resolve(mockMessageGetThreadsResponse);
            }),
          },
        },
      };
    }),

    // Mock the 'calendar' function as before
    calendar: jest.fn((version: string, auth: any) => {
      return {
        events: {
          insert: jest.fn((request: any) => {
            console.log(`Calendar mock called with: ${request}`);
            return Promise.resolve(mockCalendarInsert);
          }),
          list: jest.fn((params: any) => {
            console.log(
              `Calendar mock events.list called with: ${JSON.stringify(params)}`
            );
            return Promise.resolve(mockCalendarList);
          }),
        },
        /* ---------- freebusy.query mock ---------- */
        freebusy: {
          query: jest.fn((params: any) => {
            console.log(
              `Calendar mock freebusy.query called with: ${JSON.stringify(
                params
              )}`
            );
            const mockResponse = getMockFreeBusyResponse(
              params.requestBody.timeMin,
              params.requestBody.timeMax
            );
            return Promise.resolve(mockResponse);
          }),
        },
      };
    }),

    // Mock the 'customsearch' function as before
    customsearch: jest.fn((version: string) => {
      return {
        cse: {
          list: jest.fn((params: any) => {
            console.log(`Custom Search mock called with: ${params}`);
            return Promise.resolve({
              data: {
                items: [
                  { title: 'Mock Result 1', link: 'http://mock.com/1' },
                  { title: 'Mock Result 2', link: 'http://mock.com/2' },
                ],
              },
            });
          }),
        },
      };
    }),

    // Add a mock for the 'auth' object and its 'GoogleAuth' constructor
    auth: {
      GoogleAuth: jest.fn().mockImplementation((config) => {
        console.log('Mocked GoogleAuth constructor called');

        // Return a mock object that mimics the behavior of a GoogleAuth instance
        return {
          // Mock methods that are called on the GoogleAuth instance
          getClient: jest.fn().mockResolvedValue({
            getRequestHeaders: jest.fn().mockResolvedValue({
              /* mock headers */
            }), // Mock getRequestHeaders if used
          }),
        };
      }),
    },
  },
}));

describe('testing Vickie', () => {
  afterAll(() => {
    jest.clearAllMocks();
  });

  it('it handle a mock event using processEmailEvent when a resolution is found', async () => {
    const vickie = new Vickie();
    const result = await vickie.processEmailEvent(
      'eyJlbWFpbEFkZHJlc3MiOiJkc21pbGV5QGNvZGVzdHJhcC5tZSIsImhpc3RvcnlJZCI6MTc5MDUxMn0=',
      '2025-07-22T20:43:55.184Z'
    );
    expect(result).toBeDefined();
    expect(result.message).toBeDefined();
    expect(result.status).toBe(200);
  }, 120000);
});
````

## File: packages/agents/vickie-bennie/src/lib/tests/processEmailEvent.nonHappyPath.test.ts
````typescript
import { mockProcessEmailEventExecution } from '../__fixtures__/MachineExecutions';
import {
  mockCalendarInsert,
  mockCalendarList,
  mockEmailHistoryNoResolution,
  mockEmailResponse,
  mockMessageGetResponse,
  mockMessageGetThreadsResponseNoResolution,
} from '../__fixtures__/Email';
import { Vickie } from '../Vickie';

let counter = 0;

jest.mock('@codestrap/developer-foundations-utils', () => ({
  ...jest.requireActual('@codestrap/developer-foundations-utils'),
  uuidv4: jest.fn(() => (++counter).toString()),
}));

jest.mock('@codestrap/developer-foundations-services-palantir', () => ({
  // TODO mock the gemini service responses, this introduces an element on non-determinism.
  ...jest.requireActual('@codestrap/developer-foundations-services-palantir'),
  makeMachineDao: jest.fn(() => ({
    upsert: jest.fn(
      (
        id: string,
        stateMachine: string,
        state: string,
        logs: string,
        lockOwner?: string,
        lockUntil?: number
      ) => {
        return mockProcessEmailEventExecution;
      }
    ),
    delete: jest.fn(),
    read: jest.fn((machineExecutionId: string) => {
      return Promise.resolve(mockProcessEmailEventExecution);
    }),
  })),
  makeMemoryRecallDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeTrainingDataDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeContactsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeUserDao: jest.fn(() => ({
    read: jest.fn(),
  })),
  makeCommsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeThreadsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeTicketsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeWorldDao: jest.fn(() => ({
    read: jest.fn(),
  })),
}));

jest.mock('@codestrap/developer-foundations-services-rangr', () => ({
  createRangrClient: jest.fn(() => ({
    someMethod: jest.fn(),
  })),
  makeRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeRangrRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
}));

jest.mock('googleapis', () => ({
  ...jest.requireActual('googleapis'), // Keep other actual exports

  google: {
    // Mock the 'gmail' function as before
    gmail: jest.fn((version: string, auth: any) => {
      return {
        users: {
          messages: {
            send: jest.fn((request: any) => {
              console.log(`Gmail mock messages.send called with: ${request}`);
              return Promise.resolve(mockEmailResponse);
            }),
            list: jest.fn((request: any) => {
              console.log(`Gmail mock messages.list called with: ${request}`);
              return Promise.resolve(mockEmailHistoryNoResolution);
            }),
            get: jest.fn((request: any) => {
              console.log(`Gmail mock messages.get called with: ${request}`);
              return Promise.resolve(mockMessageGetResponse);
            }),
          },
          threads: {
            get: jest.fn((request: any) => {
              console.log(`Gmail mock threads.get called with: ${request}`);
              return Promise.resolve(mockMessageGetThreadsResponseNoResolution);
            }),
          },
        },
      };
    }),

    // Mock the 'calendar' function as before
    calendar: jest.fn((version: string, auth: any) => {
      return {
        events: {
          insert: jest.fn((request: any) => {
            console.log(`Calendar mock called with: ${request}`);
            return Promise.resolve(mockCalendarInsert);
          }),
          list: jest.fn((params: any) => {
            console.log(
              `Calendar mock events.list called with: ${JSON.stringify(params)}`
            );
            return Promise.resolve(mockCalendarList);
          }),
        },
        /* ---------- freebusy.query mock ---------- */
        freebusy: {
          query: jest.fn((params: any) => {
            console.log(
              `Calendar mock freebusy.query called with: ${JSON.stringify(
                params
              )}`
            );
            return Promise.resolve({
              data: {
                kind: 'calendar#freeBusy',
                timeMin: params.requestBody.timeMin,
                timeMax: params.requestBody.timeMax,
                calendars: {
                  // each email requested in params.requestBody.items[*].id gets an entry:
                  'dsmiley@codestrap.me': {
                    busy: [
                      {
                        start: '2025-07-22T18:00:00Z',
                        end: '2025-07-22T19:00:00Z',
                      },
                      {
                        start: '2025-07-23T15:00:00Z',
                        end: '2025-07-23T16:30:00Z',
                      },
                    ],
                  },
                },
              },
            });
          }),
        },
      };
    }),

    // Mock the 'customsearch' function as before
    customsearch: jest.fn((version: string) => {
      return {
        cse: {
          list: jest.fn((params: any) => {
            console.log(`Custom Search mock called with: ${params}`);
            return Promise.resolve({
              data: {
                items: [
                  { title: 'Mock Result 1', link: 'http://mock.com/1' },
                  { title: 'Mock Result 2', link: 'http://mock.com/2' },
                ],
              },
            });
          }),
        },
      };
    }),

    // Add a mock for the 'auth' object and its 'GoogleAuth' constructor
    auth: {
      GoogleAuth: jest.fn().mockImplementation((config) => {
        console.log('Mocked GoogleAuth constructor called');

        // Return a mock object that mimics the behavior of a GoogleAuth instance
        return {
          // Mock methods that are called on the GoogleAuth instance
          getClient: jest.fn().mockResolvedValue({
            getRequestHeaders: jest.fn().mockResolvedValue({
              /* mock headers */
            }), // Mock getRequestHeaders if used
          }),
        };
      }),
    },
  },
}));

describe('testing Vickie', () => {
  afterAll(() => {
    jest.clearAllMocks();
  });

  it('it handle a mock event using processEmailEvent when no resolution is found', async () => {
    const vickie = new Vickie();
    const result = await vickie.processEmailEvent(
      'eyJlbWFpbEFkZHJlc3MiOiJkc21pbGV5QGNvZGVzdHJhcC5tZSIsImhpc3RvcnlJZCI6MTc5MDUxMn0=',
      '2025-07-22T20:43:55.184Z'
    );
    expect(result).toBeDefined();
    expect(result.message).toBe(
      'Some threads failed to resolve:\n {"status":"fulfilled","value":{"status":400,"executionId":"1","message":"ERROR","error":"No resolution found","taskList":"ERROR"}}'
    );
    expect(result.status).toBe(400);
  }, 120000);
});
````

## File: packages/agents/vickie-bennie/src/lib/tests/readWebPage.e2e.test.ts
````typescript
import { readWebPage } from '@codestrap/developer-foundations-x-reason/src/lib/functions/comsFunctions/ReadWebPage';

if (!process.env.E2E) {
  test.skip('e2e test skipped in default run', () => {
    // won't run
  });
} else {
  describe('researchAssistant', () => {
    afterAll(() => {
      jest.clearAllMocks();
    });

    it('should return the webpage contents as markdown with protocol', async () => {
      const query =
        'Vickie, read me the page contents of https://docs.google.com/document/d/12Osa66iz9Z4FCM4fvZwbZGpqFghSMWYaEixYvwrBEns/edit?usp=sharing';
      try {
        const results = await readWebPage(
          {
            requestId: '',
            status: 1,
          },
          { type: 'test' },
          query
        );

        expect(results).toBeDefined();
        expect(results?.result).toBeDefined();
        expect(results?.result.includes('Failed to load')).toBeFalsy();
      } catch (error) {
        console.error('Test Failed:', error);
        throw error;
      }
    }, 600000);
  });
}
````

## File: packages/agents/vickie-bennie/src/lib/tests/researchAssistant.e2e.test.ts
````typescript
import * as dotenv from 'dotenv';

dotenv.config();

import { researchAssistant } from '@codestrap/developer-foundations-services-google';

if (!process.env.E2E) {
  test.skip('e2e test skipped in default run', () => {
    // won't run
  });
} else {
  describe('researchAssistant', () => {
    afterAll(() => {
      jest.clearAllMocks();
    });

    it('should return search results for a stock market report', async () => {
      const query =
        'What are the current market conditions including key indices such as volatility, SPX, SPY, QQQ including todays top movers and losers. Your report should include a table for each index mentioned. Seperate sections for Top Gainers, Top Losers, and Sector performers.';
      try {
        const results = await researchAssistant(
          query,
          1, // number of results per search to sample
          'd1', // restrict to past 24 hours
          undefined, //you can restrict to a specific site if you want: 'finance.yahoo.com',
          undefined, //include or exclude: 'i' = include results from 'finance.yahoo.com',
          process.env.GOOGLE_SEARCH_ENGINE_MARKETS
        );

        expect(results).toBeDefined();
        expect(results?.length).toBeGreaterThan(0);
      } catch (error) {
        console.error('Test Failed:', error);
        throw error;
      }
    }, 600000);

    it('should return search results for a AI headline report', async () => {
      const query =
        'Get me the top AI headlines for today including announcements in AI research, AI engineering, code generation, and AIs projected impact on the economy.';
      try {
        const results = await researchAssistant(query, 1, 'd1');

        expect(results).toBeDefined();
        expect(results?.length).toBeGreaterThan(0);
      } catch (error) {
        console.error('Test Failed:', error);
        throw error;
      }
    }, 600000);
  });
}
````

## File: packages/agents/vickie-bennie/src/lib/tests/Text2Action.test.ts
````typescript
import {
  text2ActionTestMachineExecution,
  machineId,
} from '../__fixtures__/MachineExecutions';
import { Text2Action } from '../Text2Action';
import { mockEmailResponse } from '../__fixtures__/Email';

let counter = 0;

jest.mock('@codestrap/developer-foundations-utils', () => ({
  ...jest.requireActual('@codestrap/developer-foundations-utils'),
  uuidv4: jest.fn(() => (++counter).toString()),
}));

jest.mock('@codestrap/developer-foundations-services-palantir', () => ({
  // TODO mock the gemini service responses, this introduces an element on non-determinism.
  ...jest.requireActual('@codestrap/developer-foundations-services-palantir'),
  createFoundryClient: jest.fn(() => ({
    // Mock FoundryClient methods as needed
    someMethod: jest.fn(),
  })),
  geminiService: jest.fn(() => {
    return text2ActionTestMachineExecution.machine;
  }),
  makeMachineDao: jest.fn(() => ({
    upsert: jest.fn(
      (
        id: string,
        stateMachine: string,
        state: string,
        logs: string,
        lockOwner?: string,
        lockUntil?: number
      ) => {
        return text2ActionTestMachineExecution;
      }
    ),
    delete: jest.fn(),
    read: jest.fn((machineExecutionId: string) => {
      return Promise.resolve(text2ActionTestMachineExecution);
    }),
  })),
  makeMemoryRecallDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeTrainingDataDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeContactsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeUserDao: jest.fn(() => ({
    read: jest.fn(),
  })),
  makeCommsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeThreadsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeTicketsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeWorldDao: jest.fn(() => ({
    read: jest.fn(),
  })),
}));

jest.mock('@codestrap/developer-foundations-services-rangr', () => ({
  createRangrClient: jest.fn(() => ({
    someMethod: jest.fn(),
  })),
  makeRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeRangrRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
}));

jest.mock('googleapis', () => ({
  ...jest.requireActual('googleapis'), // Keep other actual exports

  google: {
    // Mock the 'gmail' function as before
    gmail: jest.fn((version: string, auth: any) => {
      return {
        users: {
          messages: {
            send: jest.fn((request: any) => {
              console.log(`Gmail mock called with: ${request}`);
              return Promise.resolve(mockEmailResponse);
            }),
          },
        },
      };
    }),

    // Mock the 'calendar' function as before
    calendar: jest.fn((version: string, auth: any) => {
      return {
        events: {
          insert: jest.fn((request: any) => {
            console.log(`Calendar mock called with: ${request}`);
            return Promise.resolve({ data: { id: 'mockEventId' } });
          }),
        },
      };
    }),

    // Mock the 'customsearch' function as before
    customsearch: jest.fn((version: string) => {
      return {
        cse: {
          list: jest.fn((params: any) => {
            console.log(`Custom Search mock called with: ${params}`);
            return Promise.resolve({
              data: {
                items: [
                  { title: 'Mock Result 1', link: 'http://mock.com/1' },
                  { title: 'Mock Result 2', link: 'http://mock.com/2' },
                ],
              },
            });
          }),
        },
      };
    }),

    // Add a mock for the 'auth' object and its 'GoogleAuth' constructor
    auth: {
      GoogleAuth: jest.fn().mockImplementation((config) => {
        console.log('Mocked GoogleAuth constructor called');

        // Return a mock object that mimics the behavior of a GoogleAuth instance
        return {
          // Mock methods that are called on the GoogleAuth instance
          getClient: jest.fn().mockResolvedValue({
            getRequestHeaders: jest.fn().mockResolvedValue({
              /* mock headers */
            }), // Mock getRequestHeaders if used
          }),
        };
      }),
    },
  },
}));

describe('testing Text2Action', () => {
  afterAll(() => {
    jest.clearAllMocks();
  });

  it('it should rehydrate an existing execution and return pause', async () => {
    const solution = {
      input: '', //not relevant for this
      id: machineId || '',
      plan: '', //not relevant for retrieving an execution
    };

    const t2a = new Text2Action();
    const result = await t2a.upsertState(undefined, true, machineId);
    const state = JSON.parse(result.state!);
    // TODO make this test better. Currently we are returning the mock value which
    // does not reflect the updates which should return the success state
    expect(state.value).toBe('sendEmail|1');
    expect(state.context.stack).toHaveLength(1);
    expect(state.context.stack[0]).toBe('sendEmail|1');
  }, 30000);
});
````

## File: packages/agents/vickie-bennie/src/lib/tests/vickie.e2e.test.ts
````typescript
import { Vickie } from '../Vickie';

if (!process.env.E2E) {
  test.skip('e2e test skipped in default run', () => {
    // won't run
  });
} else {
  describe('testing Vickie', () => {
    beforeAll(() => {
      jest.clearAllMocks();
    });

    it('It should retrieve my calendar events for tomorrow', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
What's coming up on my calendar tomorrow
                `,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 60000);

    it('It should retrieve my emails', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
Get me caught up on my emails.
                `,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 60000);

    it('It should return the webpage contents as markdown with protocol', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
Vickie, read me the page contents of https://docs.google.com/document/d/12Osa66iz9Z4FCM4fvZwbZGpqFghSMWYaEixYvwrBEns/edit?usp=sharing.
`,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 60000);

    it('It should schedule a meeting for today with me', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
Schedule a meeting with me for today to discuss progression of Foundry Developer Foundations
                `,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 60000);

    it('It should schedule a meeting for today at 12 PM for me', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
Schedule a meeting with me for today at 12 PM to discuss progression of Foundry Developer Foundations
                `,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 60000);

    it('It should schedule a meeting for today at 3 PM with me and Connor. This time is not available so it should book for a later time.', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
Schedule a meeting with me and Connor Deeks for today at 3 PM to discuss progression of Foundry Developer Foundations
                `,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 60000);

    it('It should schedule a meeting, send an email, send a slack message, and create a task.', async () => {
      const vickie = new Vickie();

      const result = await vickie.askVickie(
        `
In parallel do all of the following:
Create a critical priority task for me to follow up with our rebranding and find a partner to handle our identity package.
Then schedule a meeting with me for tomorrow 1:30 PM with the subject "Reminder - Prep for calls today" for 15 minutes
After that send a slack message to the Foundry Devs channel with a joke and include the current day time. Also let them know this is part of a a unit test and to ignore.
Finally,send an email to me with the subject test and for the message tell me a joke and include the current day time.
                `,
        process.env.FOUNDRY_TEST_USER
      );
      expect(result.executionId).toBeDefined();
      expect(result.message).toBeDefined();
      expect(result.status).toBe(200);
    }, 90000);
  });
}
````

## File: packages/agents/vickie-bennie/src/lib/Bennie.ts
````typescript
import { Trace } from '@codestrap/developer-foundations.foundry-tracing-foundations';

import { SupportedEngines } from '@codestrap/developer-foundations-x-reason';
import { Text2Action } from './Text2Action';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import {
  GeminiService,
  MachineDao,
  RfpRequestsDao,
  Threads,
  ThreadsDao,
  TYPES,
  RfpResponseReceipt,
  RfpRequestResponse,
  RfpResponsesResult,
  StateConfig,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

interface BennieResponse {
  status: number;
  message: string;
  executionId: string;
  taskList?: string;
  error?: string;
}

export class Bennie extends Text2Action {
  @Trace({
    resource: {
      service_name: 'bennie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'askBennie',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/askBennie/execute`,
    },
  })
  public async askBennie(
    query: string,
    userId: string,
    threadId?: string
  ): Promise<BennieResponse> {
    let generatedTaskList: undefined | string = undefined;
    let newThread = !threadId || threadId.length === 0;

    // we need the ability for clients to pass a known threadId that they originate and still create a new task list
    try {
      const threadDao = container.get<ThreadsDao>(TYPES.ThreadsDao);
      await threadDao.read(threadId || '');
    } catch (e) {
      console.log(e);
      // the client has sent a threadId they originated
      newThread = true;
    }

    // we only want to trigger task list generation if this is a new thread
    if (newThread) {
      // create a new solution with our solver
      const { status, taskList, executionId } = await this.createSalesTasksList(
        query,
        userId,
        threadId
      );
      // if we get a bad response skip calling execute task list
      if (status !== 200 || !taskList) {
        return {
          status,
          executionId,
          message: `You are missing required information: ${taskList}. Please fix your shit and resend.`,
        };
      }
      // threadId and executionId are identical.
      // If threadId is defined there must be an associated state machine execution where executionId === threadId
      // if its not defined we need to create a new task list and generate a new machine execution which will happen automatically
      // when this.getNextState is called.
      // The orchestrator will program a new solution if there's no machine matching the executionId
      threadId = executionId;
      generatedTaskList = taskList;
    }

    // if task list is defined and there's no machine where machineExecutionId === threadId, a new solution will be generated
    // else the exiting machine will be rehydrated and the next state sent back
    // TODO we need to append the user query as input to getNextState so its interpolated onto the context
    // ideally what would happen is we check if the user query is relevant to an existing state then update it
    // then when the orchestrator rehydrates the machine is can reason about what state to retry based on the new information
    // this replaces the need for the text2ActionInstance.sendThreadMessage handler which was a hack to void doing this
    // you'll likely need to provide training data for transition for each engine to the model can learn what to do
    // Once done you'll need to copy this pattern to Vickie's askVickie method
    const results = await this.getNextState(
      generatedTaskList,
      true,
      threadId,
      undefined,
      SupportedEngines.SALES
    );
    // construct the response
    const system = `You are a helpful AI sales assistant named Bennie.
You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Bennie, Code's AI Sales Associate" or similar. 
You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString(
      'en-US',
      { weekday: 'long' }
    )}. 
You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
You always obey the users instructions and understand the people you work for are busy executives and sometimes need help in their personal lives
These tasks are not beneath you. At CodeStrap, where you work we adopt the motto made famous by Kim Scott: we move couches.
It means we all pull together to get things done.
The current local date/time is ${new Date().toLocaleString('en-US', {
      timeZone: 'America/Los_Angeles',
    })}.
The current day/time in your timezone is: ${new Date().toString()}`;
    const user = `
        Based on the following user query
        ${query}

        And the results of the state machine execution that was generated to service their request
        The value attribute contains the current state
        The theResultOfEachTask attribute contains the output of state executions
        The orderTheTasksWereExecutedIn lets you know what order the states were executed in. States can be executed multiple times if they are retied.
        ${JSON.stringify(results)}

        Generate a response to the user query based on the results of the state machine execution 
        Be sure to structure your response so that it's readable by a human.
        For example if the state machine execution includes facts and figures use a table to format them
        Use lists to structure information hierarchies suck as task list execution and there results
        `;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(user, system);

    let result = extractJsonFromBackticks(response);
    if (newThread) {
      // putting Execution Id in the thread is useful for debugging as users may need to supply it
      result = `# Execution Id: ${threadId}
### Response from Bennie
${result}
`;
    } else {
      result = `### Response from Bennie
${result}`;
    }

    // persist the constructed response to the the threads object
    const threadsDao = container.get<ThreadsDao>(TYPES.ThreadsDao);

    const messages = `### User Query:
${query}

${result}`;
    // create or update with a summary of the results
    // if there is an existing thread messages are appended to the existing history
    await threadsDao.upsert(messages, 'bennie', threadId);

    // return the structured response
    return {
      status: 200,
      executionId: threadId!,
      // Send back the incremental response to avoid sending huge threads back
      // Can also support streaming outputs in the future
      message: result,
      // AIP Logic can not handle nullable fields, so we have to include these as empty string to support use cases where logic is used such as our daily reports with automate
      // https://community.palantir.com/t/aip-logic-cant-recognize-optional-output-struct-fileds/4440/3
      error: '',
      taskList: '',
    };
  }

  @Trace({
    resource: {
      service_name: 'bennie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'createSalesTasksList',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/createSalesTasksList/execute`,
    },
  })
  public async createSalesTasksList(
    query: string,
    userId: string,
    threadId?: string
  ): Promise<BennieResponse> {
    console.log('createSalesTasksList called');
    // if no threadId create one
    // call the solver to get back the task list.
    const communication = await this.createTaskList(
      query,
      userId,
      SupportedEngines.SALES,
      undefined,
      undefined,
      threadId
    );

    // If incomplete information is provided the solver will return Missing Infromation
    // If the request is unsupported the solver will return Usupported Questions
    // If it's a complete supported query the solver will return a well formatted task list that we can use to execute
    return {
      status: 200,
      message: 'Task list created',
      // we match the threadID and threadId and executionId so we can associate conversations between agents and machine executions
      executionId: communication.id,
      taskList: communication.taskList,
    };
  }

  /**
   * A dedicated webhook callback for RFP submissions
   * Extract parameters from query param using an LLM.
   * The client is expected to send the machine exection ID (which is the same as the orignal threadID) back in it's responses.
   * We will have passed this ID to exteranl agents as part of createSalesTasks invocation above
   * If no machine exection ID is found throw ERROR
   * Use an LLM to extract the required parameters for an RFP from the provided query param such as:
   * Volume of staffing (we use Tech Leads, Engineers, and Engagement Directors)
   * Rate Card / how much its going to cost. Monthly for long term, one time for short term where short term is < 2 months
   * Available Start Date
   * if any required parameters are missing return a a textual response stating what is missing along with a machine execution ID
   * Once all required parameters are retireved execute the request
   */
  @Trace({
    resource: {
      service_name: 'bennie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'submitRfpResponse',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/submitRfpResponse/execute`,
    },
  })
  public async submitRfpResponse(
    rfpResponse: string,
    vendorId: string,
    machineExecutionId: string
  ): Promise<RfpResponseReceipt> {
    // rehydrate the machine
    const machineDao = container.get<MachineDao>(TYPES.MachineDao);
    // allow this to throw if no machine execution is found
    const execution = await machineDao.read(machineExecutionId);

    const machine: StateConfig[] = execution.machine
      ? JSON.parse(execution.machine)
      : undefined;
    const stateDefinition = execution.state
      ? JSON.parse(execution.state)
      : undefined;

    if (!machine) {
      throw new Error(
        `no programmed state machine found for: ${machineExecutionId}`
      );
    }

    if (!stateDefinition) {
      throw new Error(`no state definition found for: ${machineExecutionId}`);
    }

    const context = stateDefinition.context;
    // find the requestRftp on the context associated with the supplied vendorId (requestRftp.vendorId)
    const vendorRfpRequest = Object.keys(context)
      .filter((key) => key.indexOf('requestRfp') >= 0)
      .map((key) => context[key])
      .filter((item) => item.vendorId === vendorId)?.[0] as
      | RfpRequestResponse
      | undefined;
    // add the response to the requestRftp object.
    if (!vendorRfpRequest) {
      throw new Error(
        `Could not find matching RFP request for vendorId: ${vendorId}`
      );
    }
    // determine if this is a response or a request for missing information or something else
    const system =
      'You are a helpful AI classifier that classifies incoming RFP responses per the user instructions. You only response in JSON in the format defined by the user.';
    const user = `
        Classify the RFP response below into one of thre categories: "valid response", "request for missing information", "error"
        ${rfpResponse}

        You can only response in JSON in the following format:
        {"responseCategory": <YOUR_ANSWER>}

        For example if the rfp response is: "We can not process your request without a valid start and end date"
        Your response is:
        {"responseCategory": "request for missing information"}

        Do not be chatty, do not self reflect, just fucking respond in JSON with the correct classification!!!
        `;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(user, system);
    const result = extractJsonFromBackticks(response);
    const category = JSON.parse(result).responseCategory as
      | 'valid response'
      | 'request for missing information'
      | 'error'
      | undefined;
    if (!category) {
      throw new Error(`Could not classify RFP response: ${category}`);
    }

    // handle the vendor response
    vendorRfpRequest.received = true;
    vendorRfpRequest.response = rfpResponse;

    switch (category) {
      case 'valid response':
        // if it's a respone mark the rfp state as received and recalculate all responses received
        vendorRfpRequest.status = 200;
        break;
      case 'request for missing information':
        vendorRfpRequest.status = 400;
        break;
      case 'error':
        vendorRfpRequest.status = 500;
        break;
    }
    // figure out if all responses from the vendors have been received
    const allResponsesReceived = Object.keys(context)
      .filter((key) => key.indexOf('requestRfp') >= 0)
      .map((key) => context[key])
      .every((item) => item.received);

    // find the associated await rfp response state, there should be only one becuase request for rfp is done in parrallel
    const awaitRfpResponseState = Object.keys(context)
      .filter((key) => key.indexOf('awaitRfpResponses') >= 0)
      .map((key) => context[key])?.[0] as RfpResponsesResult | undefined;

    if (!awaitRfpResponseState) {
      throw new Error('Could not locate awaitRfpResponseState state');
    }

    awaitRfpResponseState.allResponsesReceived = allResponsesReceived;
    awaitRfpResponseState.vendors.push(vendorId);

    // reset the history as it seems x-state will hydrate the state from the history context
    if (stateDefinition.history) {
      stateDefinition.history.context = stateDefinition.context;
    }

    execution.state = JSON.stringify(stateDefinition);
    // update the machine
    await machineDao.upsert(
      machineExecutionId,
      JSON.stringify(machine),
      JSON.stringify(stateDefinition),
      execution.logs!,
      '', // we have to send default values for lockOwner and lockUntil or the OSDK will shit a brick. It still can't handle optional params
      1
    );

    const threadDao = container.get<ThreadsDao>(TYPES.ThreadsDao);
    let thread: Threads | undefined = undefined;

    try {
      thread = await threadDao.read(machineExecutionId);
    } catch (e) {
      console.log(e);
      console.log(
        `thread not found for id: ${machineExecutionId}, creating a new one`
      );
    }

    const threadMessage = `# Vendor Response
### Identifiers
- Date and time: ${new Date().toString()}
- Machine and ThreadId: ${machineExecutionId}

### Summary
Your RFP for ${vendorRfpRequest.vendorName} using ID: ${vendorRfpRequest.vendorId
      } was sent and we received the following response from their agent:
${vendorRfpRequest.response}
`;
    const appendedMessage = `${thread?.messages}
${threadMessage};
`;
    await threadDao.upsert(appendedMessage, 'bennie', machineExecutionId);

    await this.upsertState(
      undefined,
      true,
      machineExecutionId,
      undefined,
      SupportedEngines.SALES
    );

    const rfpDao = container.get<RfpRequestsDao>(TYPES.RfpRequestsDao);
    // find the associated RFP
    const rfpRequest = await rfpDao.search(machineExecutionId, vendorId);
    // there should be only one matching record
    // TODO add rfpResponseStatus = vendorRfpRequest.status
    await rfpDao.upsert(
      rfpRequest.rfp!,
      rfpResponse,
      vendorId,
      machineExecutionId,
      rfpRequest.id,
      vendorRfpRequest.status
    );

    return {
      status: 200,
      message: `We've received your RFP response and are reviewing it with the customer. We'll get back to you shortly.`,
      machineExecutionId,
      reciept: {
        id: '',
        timestamp: Date.now(),
      },
    };
  }
}
````

## File: packages/agents/vickie-bennie/src/lib/computeModule.ts
````typescript
import { ComputeModule } from '@palantir/compute-module';
import { withRequestContext } from '@codestrap/developer-foundations-utils/src/lib/asyncLocalStorage';
// Schema Definitions for compute module
// IMPORTANT:  @sinclair/typebox is required!!!
// https://github.com/palantir/typescript-compute-module?tab=readme-ov-file#schema-registration
import { Type } from '@sinclair/typebox';
import { Vickie } from './Vickie';
import * as dotenv from 'dotenv';
import {
  ComputeModuleType,
  ModuleConfig,
} from '@codestrap/developer-foundations-types';
import { Bennie } from './Bennie';
import { uuidv4 } from '@codestrap/developer-foundations-utils';

dotenv.config();

const Schemas = {
  askVickie: {
    input: Type.Object({
      query: Type.String(),
      userId: Type.String(),
      threadId: Type.Optional(Type.String()),
    }),
    output: Type.Object({
      status: Type.Integer(),
      message: Type.String(),
      executionId: Type.String(),
      taskList: Type.Optional(Type.String()),
      error: Type.Optional(Type.String()),
    }),
  },
  askBennie: {
    input: Type.Object({
      query: Type.String(),
      userId: Type.String(),
      threadId: Type.Optional(Type.String()),
    }),
    output: Type.Object({
      status: Type.Integer(),
      message: Type.String(),
      executionId: Type.String(),
      taskList: Type.Optional(Type.String()),
      error: Type.Optional(Type.String()),
    }),
  },
  createVickieTasks: {
    input: Type.Object({
      query: Type.String(),
      userId: Type.String(),
      threadId: Type.Optional(Type.String()),
    }),
    output: Type.Object({
      status: Type.Integer(),
      message: Type.String(),
      executionId: Type.String(),
      taskList: Type.Optional(Type.String()),
      error: Type.Optional(Type.String()),
    }),
  },
  createBennieTasks: {
    input: Type.Object({
      query: Type.String(),
      userId: Type.String(),
      threadId: Type.Optional(Type.String()),
    }),
    output: Type.Object({
      status: Type.Integer(),
      message: Type.String(),
      executionId: Type.String(),
      taskList: Type.Optional(Type.String()),
      error: Type.Optional(Type.String()),
    }),
  },
  getNextState: {
    input: Type.Object({
      plan: Type.Optional(Type.String()),
      forward: Type.Optional(Type.Boolean()),
      executionId: Type.Optional(Type.String()),
      inputs: Type.Optional(Type.String()),
      xreason: Type.Optional(Type.String()),
    }),
    output: Type.Object({
      value: Type.String(),
      theResultOfEachTask: Type.Array(
        Type.Object({
          taskName: Type.String(),
          taskOutput: Type.String(),
        })
      ),
      orderTheTasksWereExecutedIn: Type.Array(Type.String()),
    }),
  },
  submitRfpResponse: {
    input: Type.Object({
      rfpResponse: Type.String(),
      vendorId: Type.String(),
      machineExecutionId: Type.String(),
    }),
    output: Type.Object({
      status: Type.Integer(),
      message: Type.String(),
      machineExecutionId: Type.String(),
      error: Type.Optional(Type.String()),
      receipt: Type.Optional(
        Type.Object({
          id: Type.String(),
          timestamp: Type.Integer(),
        })
      ),
    }),
  },
  sendThreadMessage: {
    input: Type.Object({
      message: Type.String(),
      userId: Type.String(),
      machineExecutionId: Type.String(),
    }),
    output: Type.Object({
      appId: Type.Optional(Type.String()),
      id: Type.Readonly(Type.String()),
      messages: Type.Optional(Type.String()),
      userId: Type.Optional(Type.String()),
    }),
  },
  processEmailEvent: {
    input: Type.Object({
      payload: Type.String(),
    }),
    output: Type.Object({
      status: Type.Integer(),
      message: Type.String(),
      executionId: Type.String(),
      taskList: Type.Optional(Type.String()),
      error: Type.Optional(Type.String()),
    }),
  },
};

// Unified configuration for all environments
function getModuleConfig(): ModuleConfig {
  const env = process.env.NODE_ENV || 'development';

  switch (env) {
    case 'test':
      return { isTest: true };
    default: // development
      return { isTest: false };
  }
}

function createComputeModule(): ComputeModuleType {
  const config = getModuleConfig();

  if (config.isTest) {
    const mockModule = {
      listeners: {} as Record<string, any>,
      on: function (event: string, handler: any) {
        this.listeners[event] = handler;
        handler();
        return this;
      },
      register: function (operation: string, handler: any) {
        this.listeners[operation] = { type: 'response', listener: handler };
        return this;
      },
    };
    console.log('returning mock module');
    return mockModule;
  }

  const vickie = new Vickie();
  const bennie = new Bennie();

  // IMPORTANT: wrap all execution in try catch so you do not crash the container!
  // node exists on unhandled exceptions
  const module = new ComputeModule({
    logger: console,
    sources: {},
    definitions: {
      askVickie: Schemas.askVickie,
      askBennie: Schemas.askBennie,
      createVickieTasks: Schemas.createVickieTasks,
      createBennieTasks: Schemas.createBennieTasks,
      getNextState: Schemas.getNextState,
      submitRfpResponse: Schemas.submitRfpResponse,
      sendThreadMessage: Schemas.sendThreadMessage,
      processEmailEvent: Schemas.processEmailEvent,
    },
  })
    .register('processEmailEvent', async ({ payload }) => {
      try {
        const { message } = JSON.parse(payload) as {
          message: { data: string; publishTime: string; messageId: string };
          subscription: string;
        };
        const { data, publishTime } = message;
        const result = await vickie.processEmailEvent(data, publishTime);
        return result;
      } catch (e) {
        console.log((e as Error).stack);
        return {
          status: 500,
          message: `Error: ${(e as Error).message}`,
          executionId: 'error',
          taskList: 'error',
          error: `Error: ${(e as Error).message}`,
        };
      }
    })
    .register(
      'sendThreadMessage',
      async ({ message, userId, machineExecutionId }) => {
        try {
          const user = {
            id: userId,
            username: '',
            realm: '',
            attributes: {},
          };
          // sandbox the thread execution with the incoming userId so the app has context on who is who
          return withRequestContext({ user, requestId: uuidv4() }, async () => {
            const result = await bennie.sendThreadMessage(
              message,
              userId,
              machineExecutionId
            );
            return result;
          });
        } catch (e) {
          console.log((e as Error).stack);
          return {
            appId: 'error',
            id: 'error',
            messages: `Error: ${(e as Error).message}`,
            userId: 'error',
          };
        }
      }
    )
    .register(
      'submitRfpResponse',
      async ({ rfpResponse, vendorId, machineExecutionId }) => {
        try {
          const result = await bennie.submitRfpResponse(
            rfpResponse,
            vendorId,
            machineExecutionId
          );
          return result;
        } catch (e) {
          console.log((e as Error).stack);
          return {
            status: 500,
            message: (e as Error).message,
            machineExecutionId: 'error',
            error: `Error: ${(e as Error).message}`,
            receipt: {
              id: 'error',
              timestamp: new Date().getTime(),
            },
          };
        }
      }
    )
    .register(
      'getNextState',
      async ({ plan, forward, executionId, inputs, xreason }) => {
        try {
          const result = await vickie.getNextState(
            plan,
            forward,
            executionId,
            inputs,
            xreason
          );

          if (typeof result.value !== 'string') {
            result.value = JSON.stringify(result.value);
          }

          result.theResultOfEachTask.forEach((item) => {
            if (typeof item.taskOutput !== 'string') {
              item.taskOutput = JSON.stringify(item.taskOutput);
            }
          });

          console.log(
            `getNextState returned: ${JSON.stringify(result, null, 2)}`
          );

          return {
            value: result.value as string,
            theResultOfEachTask: result.theResultOfEachTask,
            orderTheTasksWereExecutedIn: result.orderTheTasksWereExecutedIn,
          };
        } catch (e) {
          console.log((e as Error).stack);
          return {
            value: `Error: ${(e as Error).message}`,
            theResultOfEachTask: [],
            orderTheTasksWereExecutedIn: [],
          };
        }
      }
    )
    .register('createVickieTasks', async ({ query, userId, threadId }) => {
      try {
        const user = {
          id: userId,
          username: '',
          realm: '',
          attributes: {},
        };

        return withRequestContext({ user, requestId: uuidv4() }, async () => {
          const result = await vickie.createComsTasksList(
            query,
            userId,
            threadId
          );
          return result;
        });
      } catch (e) {
        console.log((e as Error).stack);
        return {
          status: 500,
          message: `Error: ${(e as Error).message}`,
          executionId: 'error',
          taskList: 'error',
          error: `Error: ${(e as Error).message}`,
        };
      }
    })
    .register('createBennieTasks', async ({ query, userId, threadId }) => {
      try {
        const user = {
          id: userId,
          username: '',
          realm: '',
          attributes: {},
        };

        return withRequestContext({ user, requestId: uuidv4() }, async () => {
          const result = await bennie.createSalesTasksList(
            query,
            userId,
            threadId
          );
          return result;
        });
      } catch (e) {
        console.log((e as Error).stack);
        return {
          status: 500,
          message: `Error: ${(e as Error).message}`,
          executionId: 'error',
          taskList: 'error',
          error: `Error: ${(e as Error).message}`,
        };
      }
    })
    .register('askVickie', async ({ query, userId, threadId }) => {
      try {
        const user = {
          id: userId,
          username: '',
          realm: '',
          attributes: {},
        };

        return withRequestContext({ user, requestId: uuidv4() }, async () => {
          const result = await vickie.askVickie(query, userId, threadId);
          return result;
        });
      } catch (e) {
        console.log((e as Error).stack);
        return {
          status: 500,
          message: `Error: ${(e as Error).message}`,
          executionId: 'error',
          taskList: 'error',
          error: `Error: ${(e as Error).message}`,
        };
      }
    })
    .register('askBennie', async ({ query, userId, threadId }) => {
      try {
        const user = {
          id: userId,
          username: '',
          realm: '',
          attributes: {},
        };

        return withRequestContext({ user, requestId: uuidv4() }, async () => {
          const result = await bennie.askBennie(query, userId, threadId);
          return result;
        });
      } catch (e) {
        console.log((e as Error).stack);
        return {
          status: 500,
          message: `Error: ${(e as Error).message}`,
          executionId: 'error',
          taskList: 'error',
          error: `Error: ${(e as Error).message}`,
        };
      }
    })
    .on('responsive', () => console.log('Bennie is ready'));

  module.on('responsive', () => {
    console.log(
      `${process.env.LOG_PREFIX} Foundry Developer Foundations X-Reason module is now responsive`
    );
  });

  return module;
}

const computeModule = createComputeModule();

export { computeModule };
````

## File: packages/agents/vickie-bennie/src/lib/Text2Action.ts
````typescript
import { Trace } from '@codestrap/developer-foundations.foundry-tracing-foundations';

import { getState, SupportedEngines, xReasonFactory } from '@codestrap/developer-foundations-x-reason';
import { engineV1 as engine } from '@codestrap/developer-foundations-x-reason';
import { dateTime, recall, requestRfp, userProfile } from '@codestrap/developer-foundations-x-reason';
import {
  extractJsonFromBackticks,
  uuidv4,
} from '@codestrap/developer-foundations-utils';
import {
  MachineEvent,
  Context,
  CommsDao,
  MachineDao,
  MachineExecutions,
  TYPES,
  UserDao,
  ThreadsDao,
  GeminiService,
  GetNextStateResult,
  Threads,
  Communications,
  LoggingService,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';
import { State } from 'xstate';

// use classes to take advantage of trace decorator
export class Text2Action {
  @Trace({
    resource: {
      service_name: 'vickie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'createTaskList',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/createTaskList/execute`,
    },
  })
  public async createTaskList(
    query: string,
    userId?: string,
    xReasonEngine: string = SupportedEngines.COMS,
    questionPrompt?: string,
    tokens?: number,
    id?: string
  ): Promise<Communications> {
    const { solver } = xReasonFactory(xReasonEngine as SupportedEngines)({});
    const userProfile = await container.get<UserDao>(TYPES.UserDao)(userId);

    if (!userId) {
      userId = userProfile.id;
    }

    const currentDateTime = await dateTime({
      requestId: '1234',
      status: 0,
      stack: ['userProfile'],
      userProfile,
    });

    const recalledInformation = await recall(
      {
        requestId: '1234',
        status: 0,
        stack: ['userProfile'],
        userProfile,
      },
      undefined,
      query
    );

    // TODO: remove the bard coded context information once CodeStrap employeed slack channels are added to the contacts dataset
    const groudingContext = `
Below is the orgnizationl information you will need to perform your work:
# Context
${JSON.stringify(recalledInformation)}

# Current date/Time:
${JSON.stringify(currentDateTime)}

# Team Information:
Connor Deeks <connor.deeks@codestrap.me> - Connor Deeks in the CEO and board memeber in charge of platform leads, business strategy, and investor relations.
Dorian Smiley <dsmiley@codestrap.me> - Dorian is the CTO who manages the software engineers and is responsible for technology strategy, execution, and the lead applied AI engineer.

#Slack Channels
"C082XAZ9A1E": "Foundry Devs - used by software engineers working on Palantir Foundry related tasks such as data integration, transformations, and applications",
"C082M750AQ1": "Founding - used for items related to the company founding such as legal briefs, filings, banking etc",
"C08264VFXNZ": "Comms Engineering - used by the software engineers responsible for engineering related items around slack, gmail, teams, etc",
"C0828G7BXM0": "General - General",
"C0821UEPJKG": "Platform Leads - used by our partners responsible for sales motions and client engagements",
"C0825R4EHMK": "Public relations - used for all items related to PR and marketing"
"C08LX9DDMRB": "External Partner Datalinks - used for all communications with DataLinks and us (CodeStrap). DataLinks provides data products and data negineering services. Team members at DataLinks are Andrzej Grzesik - CTO, Francisco Ferrera - CEO, Rui Valente - developer, and Timur - developer"
"C08LMJDQ25C": "Etneral partner 11 Labs" - used for all communications with 11 Labs. 11 Labs makes generative voice models and is used by our customers for call center operations and voice enabled applications. 11 Labs team members are Alox Holt Lead Developer, Jack Piunti Enterprise Sales, and Kabir Gill Enterprise Sales"
`;

    const taskList = await engine.solver.solve(
      `${query}\n\n${groudingContext}`,
      solver
    );
    const comsDao = container.get<CommsDao>(TYPES.CommsDao);
    const communication = await comsDao.upsert(
      'User Defined',
      'None, these tasks were entered by a human',
      'Accept',
      taskList,
      xReasonEngine,
      userId,
      questionPrompt,
      tokens,
      id
    );

    return communication;
  }

  @Trace({
    resource: {
      service_name: 'vickie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'getNextState',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/getNextState/execute`,
    },
  })
  public async getNextState(
    plan?: string,
    forward = true,
    executionId?: string,
    inputs = '{}',
    xreason: string = SupportedEngines.COMS
  ): Promise<GetNextStateResult> {
    const machine = await this.upsertState(
      plan,
      forward,
      executionId,
      inputs,
      xreason
    );

    if (machine?.state) {
      const state = JSON.parse(machine.state) as State<Context, MachineEvent>;
      const currentState = state.value;
      const context = state.context as Context;
      const results = Object.keys(context)
        .filter((key) => key.indexOf('|') >= 0)
        .map((key) => {
          const taskName = key.split('|')[0];
          const taskOutput = context[key];

          return { taskName, taskOutput };
        });

      const stack = context.stack?.map((state) => state.split('|')[0]);

      // TODO add the current state
      return {
        orderTheTasksWereExecutedIn: stack!,
        theResultOfEachTask: results,
        value: currentState,
      };
    }

    throw new Error(
      "I'm sorry but I failed to get a response back. Can you try again? Soemtimes my AI brain gets a little flakey. But second time is usally the charm."
    );
  }

  @Trace({
    resource: {
      service_name: 'vickie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'upsertState',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/upsertState/execute`,
    },
  })
  public async upsertState(
    plan?: string,
    forward = true,
    executionId?: string,
    inputs = '{}',
    xreason: string = SupportedEngines.COMS
  ): Promise<MachineExecutions> {
    const solution = {
      input: '', //not relevant for this
      id: executionId || uuidv4(),
      plan: plan || '',
    };

    const result = await getState(
      solution,
      forward,
      JSON.parse(inputs),
      xreason as SupportedEngines
    );

    const { getLog } = container.get<LoggingService>(TYPES.LoggingService);

    const machineDao = container.get<MachineDao>(TYPES.MachineDao);
    const machine = await machineDao.upsert(
      solution.id,
      JSON.stringify(result.stateMachine),
      result.jsonState,
      getLog(solution.id) ?? '',
      '', // we have to send default values for lockOwner and lockUntil or the OSDK will shit a brick. It still can't handle optional params
      1
    );

    return machine;
  }

  @Trace({
    resource: {
      service_name: 'bennie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'sendThreadMessage',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/sendThreadMessage/execute`,
    },
  })
  public async sendThreadMessage(
    message: string,
    userId: string,
    machineExecutionId: string
  ): Promise<Threads> {
    // I changed the response of this function to void to it can be triggered as an action. Once refactored to compute modules it can return a response
    // rehydrate the machine
    const threadDao = container.get<ThreadsDao>(TYPES.ThreadsDao);
    const retrievedThread = await threadDao.read(machineExecutionId);

    const messageHistory = retrievedThread.messages;

    if (!messageHistory) {
      throw new Error(`no thread found for: ${machineExecutionId}`);
    }

    const currentUserProfile = await userProfile({
      requestId: '1234',
      status: 0,
      userId,
    });
    const currentDateTime = await dateTime({
      requestId: '1234',
      status: 0,
      stack: ['userProfile'],
      userProfile: currentUserProfile,
    });
    const recalledInformation = await recall(
      {
        requestId: '1234',
        status: 0,
        stack: ['userProfile'],
        userProfile: currentUserProfile,
      },
      undefined,
      `${messageHistory}  ${message}`
    );

    // TODO: remove the bard coded context information once CodeStrap employeed slack channels are added to the contacts dataset
    const groudingContext = `
    Below is the orgnizationl information you will need to perform your work:
    # Context
    ${JSON.stringify(recalledInformation)}
    
    # Current date/Time:
    ${JSON.stringify(currentDateTime)}
    
    # Team Information:
    Connor Deeks <connor.deeks@codestrap.me> - Connor Deeks in the CEO and board memeber in charge of platform leads, business strategy, and investor relations.
    Dorian Smiley <dsmiley@codestrap.me> - Dorian is the CTO who manages the software engineers and is responsible for technology strategy, execution, and the lead applied AI engineer.
    
    #Slack Channels
    "C082XAZ9A1E": "Foundry Devs - used by software engineers working on Palantir Foundry related tasks such as data integration, transformations, and applications",
    "C082M750AQ1": "Founding - used for items related to the company founding such as legal briefs, filings, banking etc",
    "C08264VFXNZ": "Comms Engineering - used by the software engineers responsible for engineering related items around slack, gmail, teams, etc",
    "C0828G7BXM0": "General - General",
    "C0821UEPJKG": "Platform Leads - used by our partners responsible for sales motions and client engagements",
    "C0825R4EHMK": "Public relations - used for all items related to PR and marketing"
    "C08LX9DDMRB": "External Partner Datalinks - used for all communications with DataLinks and us (CodeStrap). DataLinks provides data products and data negineering services. Team members at DataLinks are Andrzej Grzesik - CTO, Francisco Ferrera - CEO, Rui Valente - developer, and Timur - developer"
    "C08LMJDQ25C": "Etneral partner 11 Labs" - used for all communications with 11 Labs. 11 Labs makes generative voice models and is used by our customers for call center operations and voice enabled applications. 11 Labs team members are Alox Holt Lead Developer, Jack Piunti Enterprise Sales, and Kabir Gill Enterprise Sales"
    `;

    // determine if this is a response or a request for missing information or something else
    const system =
      'You are a helpful AI sales associate in charge of fielding incoming messages from sales agents in the field. You job is to pick the next best action based on the message history and incoming request.';
    const user = `
            # Context
            Below is information retrieved from our grounding context engine that might include relevant names, email addresses, vendor ID, etc
            This should only be used as a secondary source on information. The message history is the primary source of information.
            ${groudingContext}
    
            # Message History
            Based on the following message history
            ${messageHistory}
    
            # User Query
            And the incoming user query for a sales agent in the field:
            ${message}
    
            Determine which of the following actions should be taken based on the the user query:
            - Resubmit RFP to resolve missing information
            - Send Email
            - Send Slack Message
            - No supported action found
    
            You can only response in JSON in the following format:
            {
                "action": <YOUR_ANSWER> , 
                "emailAddresses": <ARRAY_OF RELEVANT_EMAILS>, 
                "slackChannelID": <ARRAY_OF_RELEVANT_SLACK_CHANNEL_ID>,
                "message": <THE_MESSAGE_TO_SEND>,
                "vendors": <ANY_RELEVANT_VENDOR_IDs>
            }
    
            For example 
            Id the incoming context includes:
            # User Query:
            Create a RFP for Northslope and Rangr to deliver a tariff solution on Foundry. The solution must include support for pricing models, simulations, and A/B testing of the outcomes. We expect this to be an 4 week engagement requiring 3 Python engineer, 1 TypeScript engineer, and 2 SME on developing pricing models. Then email me the responses. The company is John Doe's Doe's and there address is 123 main street dallas tx, 75081 and the main contact is johndoe@johnsdoes.com.
    
            # Technical details
            ExecutionID: 12fae652-e90e-4b45-ae07-a9fa67a874e7
    
            # Summary
            Happy Saturday! I'm Bennie, Code's AI Sales Associate, here to help summarize those RFP tasks.
    
            Okay, here's the breakdown:
    
            RFP to Northslope: Request sent successfully! They acknowledge receipt and will respond shortly. Receipt ID is 466eeb1d-435c-4062-9890-508e957344f5.
            RFP to Rangr Data: Request sent successfully! They acknowledge receipt and the solution details appear to be valid. Receipt ID is fe655407-8a48-4ef7-808f-f7a341cfdbae.
            Awaiting Responses: We're still waiting for both Northslope and Rangr Data to submit their complete RFP responses.
            Let me know if you need me to chase them up or do anything else!
            
            # Vendor Response
            ### Identifiers
            - Date and time: Sat May 31 2025 15:13:12 GMT+0000 (Coordinated Universal Time)
            - Machine and ThreadId: 12fae652-e90e-4b45-ae07-a9fa67a874e7
    
            ### Summary
            Your RFP for Northslope using ID: northslopetech.com was sent and we received the following response from their agent:
            ###  We Can not process your request
            We can not process your request without a valid start and end date
    
            And the incoming message is:
            The sart date is June 3rd and the end date is june 25th
    
            Your response is:
            {
                "action": "Resubmit RFP to resolve missing information" , 
                "emailAddresses": [], 
                "slackChannelID": [],
                "message": "Create RFP - Vendor: Northslope <northslopetech.com> - Objectives: Deliver a tariff solution on Foundry that includes support for pricing models, simulations, and A/B testing of the outcomes for John Doe's Manufacturing at 123 main street dallas tx, 75081 with contact johndoe@johnsdoes.com - Deliverables: A fully functional tariff solution on Foundry. - Timeline: 4 week engagement starting Jun 3 2025 and the ending Jun 25 2025 requiring 3 Python engineers, 1 TypeScript engineer, and 2 SMEs on developing pricing models.",
                "vendors": ["Northslope <northslopetech.com>"]
            }
    
            Explanation: the vendor array correctly includes Northslope and the correct vendorID <northslopetech.com>. It also reiterates the RFP from the original user query so it can be resubmitted correctly inserting the start and end dates wupplied by the sales agent int he field.
            `;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(user, system);
    const result = extractJsonFromBackticks(response);

    const parsedResult = JSON.parse(result) as {
      action: string;
      emailAddresses: string[];
      slackChannelID: string[];
      message: string;
      vendors: string[];
    };
    const category = parsedResult.action as
      | 'Resubmit RFP to resolve missing information'
      | 'Send Email'
      | 'Send Slack Message'
      | 'No supported action found'
      | undefined;

    if (!category) {
      throw new Error(`Could not classify your request: ${category}`);
    }

    let newThreadMessage = 'No mew message generated';

    if (category === 'Resubmit RFP to resolve missing information') {
      const promises = parsedResult.vendors.map(async (vendorId) => {
        console.log(`resubmitting RFP for ${vendorId}`);

        return requestRfp(
          {
            requestId: uuidv4(),
            machineExecutionId,
            executionId: machineExecutionId,
            status: 200,
          },
          undefined,
          parsedResult.message
        );
      });

      const resolvedPromises = await Promise.all(promises);
      // TODO consider using a reasoning model to check the first models work
      newThreadMessage = resolvedPromises.reduce((acc, cur) => {
        acc = `${acc}
    ### Vendor Details:
    - Vendor: ${cur.vendorName}
    - Vendor ID: ${cur.vendorId}
    - Status Code: ${cur.status}
    - Vendor Response: ${cur.message}
    `;
        return acc;
      }, '# RFPs for the following vendors were resubmitted:');
    }
    // TODO handle more categories of responses

    const appendedMessage = `${messageHistory}
    ${newThreadMessage}`;

    // update the thread with the new message
    const threadsDao = container.get<ThreadsDao>(TYPES.ThreadsDao);
    const threadResult = await threadsDao.upsert(
      appendedMessage,
      'bennie',
      machineExecutionId
    );

    return threadResult;
  }
}
````

## File: packages/agents/vickie-bennie/src/lib/Vickie.ts
````typescript
import { Trace } from '@codestrap/developer-foundations.foundry-tracing-foundations';

import { SupportedEngines } from '@codestrap/developer-foundations-x-reason';
import { Text2Action } from './Text2Action';
import {
  extractJsonFromBackticks,
  uuidv4,
} from '@codestrap/developer-foundations-utils';
import {
  Context,
  GeminiService,
  ThreadsDao,
  TYPES,
  OfficeService,
  EmailMessage,
  MachineDao,
  LoggingService,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

interface VickieResponse {
  status: number;
  message: string;
  executionId: string;
  taskList?: string;
  error?: string;
}

// use classes to take advantage of trace decorator
export class Vickie extends Text2Action {
  @Trace({
    resource: {
      service_name: 'vickie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'proposeNewMeetingTime',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/proposeNewMeetingTime/execute`,
    },
  })
  public async processEmailEvent(
    data: string,
    publishTime: string
  ): Promise<VickieResponse> {
    // get emails since the publish time
    const officeService = await container.getAsync<OfficeService>(
      TYPES.OfficeService
    );
    const decodedJson = Buffer.from(data, 'base64').toString('utf8');
    const { emailAddress } = JSON.parse(decodedJson) as {
      emailAddress: string;
      historyId: number;
    };
    const { log, getLog } = container.get<LoggingService>(TYPES.LoggingService);

    const result = await officeService.readEmailHistory({
      email: emailAddress,
      publishTime,
    });
    // filter by subject to find threads Vickie generated
    const resolveMeetingConflicts = result.messages
      .filter((message) => {
        if (message.subject) {
          return message.subject.indexOf('Resolve Meeting Conflicts - ID') >= 0;
        }

        return false;
      })
      .reduce((acc, cur) => {
        if (cur.threadId && !acc.get(cur.threadId)) {
          acc.set(cur.threadId, []);
        }

        if (cur.threadId) {
          acc.get(cur.threadId)?.push(cur);
        }

        return acc;
      }, new Map<string, EmailMessage[]>());

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    console.log(`processEmailsEvent found the following meeting conflict emails:
            ${JSON.stringify(Array.from(resolveMeetingConflicts.keys()))}`);

    // for each thread in the map call an llm to determine of a resolution has been found, and if so rehydrate the machine
    // passing the updated information and calling getNextState
    const threadPromises = Array.from(resolveMeetingConflicts.entries())
      // eslint-disable-next-line @typescript-eslint/ban-ts-comment
      // @ts-ignore - threadId is a string
      .map(async ([threadId, messages]) => {
        const errorResponse = {
          status: 400,
          executionId: uuidv4(),
          message: 'ERROR',
          // AIP Logic can not handle nullable fields, so we have to include these as empty string to support use cases where logic is used such as our daily reports with automate
          // https://community.palantir.com/t/aip-logic-cant-recognize-optional-output-struct-fileds/4440/3
          error: '',
          taskList: 'ERROR',
        };
        const system = `You are a helpful virtual ai assistant tasked with extracting meeting conflict resolutions form message histories.`;
        const userPrompt = `
Using the message history below output whether or not the conflict has been resolved and the new proposed day/time.

Message history:
${JSON.stringify(messages)}

You can only respond in JSON:
{
  "resolutionFound": boolean,
  "resolution": string
}

For example if the message history is:
[
  {
    "subject": "Resolve Meeting Conflicts - ID ad179ef1-063f-4335-8541-cfdb65f824923",
    "from": "vici@codestrap.me",
    "body": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time. Could you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time. Thanks! Best Vickie",
    "id": "1234",
    "threadId": "234dsfd"
  },
  {
    "subject": "Resolve Meeting Conflicts - ID ad179ef1-063f-4335-8541-cfdb65f82492",
    "from": "dsmiley@codestrap.me",
    "body": "Hey Connor what about Tue at 9 AM?",
    "id": "5678",
    "threadId": "234dsfd"
  },
  {
    "subject": "Resolve Meeting Conflicts - ID ad179ef1-063f-4335-8541-cfdb65f82492",
    "from": "connor.deeks@codestrap.me",
    "body": "That works.",
    "id": "9101112",
    "threadId": "234dsfd"
  }
]
Your answer is:
{
  "resolutionFound": true,
  "resolution": "Tue at 9 AM"
}

If the user specifies a resolution that can not be resolved to a specific dat/time output
{
  "resolutionFound": false,
  "resolution": ""
}
`;

        // Grab machine ID from subject
        const id = messages[0]?.subject
          ?.split('Resolve Meeting Conflicts - ID')[1]
          ?.trim();
        if (!id) {
          errorResponse.error = 'No id found';
          return errorResponse;
        }

        const machineDao = container.get<MachineDao>(TYPES.MachineDao);
        const { state, lockOwner, lockUntil, logs, machine } =
          await machineDao.read(id);
        // first in wins for lock ID. The assumption is we have single event concurrency configured
        // as Foundry doesn't provide a distributed locks solution. Then the first email address processed in the thread
        // will be assigned the owner
        // TODO add the eventID from pub/sub to the input params so we can handle the same event being processed twice
        // remember Google Pub/Sub it garenteed at least once delivery, meaning you can get the same event twice!
        const lockOwnerId = `${emailAddress}-${threadId}`;

        // If another owner holds a live lease, skip
        if (
          lockOwner &&
          lockOwner !== lockOwnerId &&
          // lockUntil must be defined if lockOwner is set, enforced in our upsert function
          lockUntil! > Date.now()
        ) {
          errorResponse.error = `Locked by ${lockOwner} until ${lockUntil}`;

          log(
            id,
            `ExecutionId: ${id} is locked by ${lockOwner} until ${lockUntil}`
          );

          await machineDao.upsert(id, machine!, state!, getLog(id));

          return errorResponse;
        }

        // update the machine before proceeding with a lock to ensure we don't get redundant executions (mutex)!
        // this can occur within the same thread if the proposed time to resolve the conflict isn't actually available
        // this will result in a new conflict email being generated with a different thread ID adn can generate an infinite loop!
        // While in theory this same mechanism could handle multiple concurrent events it would likely result in a large number of erros
        // being thrown as Foundry should reject updates for stale records (have been modified since read). But I don't know id
        // the OSDK API enforces this policy or not. Functions did, but I think that was only in the context of a single function execution as it maintained a cache
        // IMPORTANT: figure out if upsert methods are responsible for enforcing rejections of writes on stale data
        // by using a lock we can prevent his from happening. I use 15 minutes out of an abundance of caution. This could likely be much lower
        // like 1 - 2 minutes
        try {
          await machineDao.upsert(
            id,
            machine!,
            state!,
            logs!,
            lockOwnerId,
            Date.now() + 15 * 60 * 1000
          );
        } catch (e) {
          console.log(`failed to upsert the machine in order to set lock:
                        message: ${(e as Error).message}
                        stack: ${(e as Error).stack}
                    `);

          log(
            id,
            `failed to upsert the machine in order to set lock:
                        message: ${(e as Error).message}
                        stack: ${(e as Error).stack}
                    `
          );

          await machineDao.upsert(id, machine!, state!, getLog(id));

          throw e;
        }

        // Ask the model
        const response = await geminiService(userPrompt, system);
        const extracted = extractJsonFromBackticks(response);

        // Expect the shape we asked for
        const { resolutionFound, resolution } = JSON.parse(extracted) as {
          resolutionFound: boolean;
          resolution: string;
        };

        log(
          id,
          `The model returned the following email thread 
                    subject: ${messages[0]?.subject}
                    resolutionFound: ${resolutionFound}
                    resolution: ${resolution}

                    `
        );

        if (!resolutionFound) {
          errorResponse.error = 'No resolution found';

          log(
            id,
            `The model returned "No resolution found" for following email thread 
                    ${messages[0]?.subject}
                    ${resolutionFound}
                    ${resolution}
                    `
          );

          await machineDao.upsert(id, machine!, state!, getLog(id));

          return errorResponse;
        } // Nothing to do for this thread

        const { context } = JSON.parse(state!) as { context: Context };
        // find the last instance of a resolveUnavailableAttendees state in the stack
        const currentStateId = context.stack
          ?.slice()
          .reverse()
          .find((item) => item.includes('resolveUnavailableAttendees'));

        if (!currentStateId) {
          errorResponse.error = 'No currentStateId found';

          log(
            id,
            `No currentStateId found email thread ${messages[0]?.subject}
                    The context is
                    ${JSON.stringify(context)}
                    currentStateId is:
                    ${currentStateId}
                    `
          );

          await machineDao.upsert(id, machine!, state!, getLog(id));

          return errorResponse;
        }

        const contextUpdate = {
          [currentStateId]: { resolution, processEmail: true },
        };

        log(
          id,
          `Sending updated context for the following email thread ${messages[0]?.subject
          }
                    contextUpdate:
                    ${JSON.stringify(contextUpdate)}
                    `
        );

        // logs will be persisted in the call to getNextState
        try {
          const result = await this.getNextState(
            undefined,
            true,
            id,
            JSON.stringify(contextUpdate),
            SupportedEngines.COMS
          );

          console.log(getLog(id));

          console.log(`getNextStateReturned: ${JSON.stringify(result)}`);
        } catch (e) {
          log(
            id,
            `getNextState failed with the following error:
                        ${(e as Error).message}
                        ${(e as Error).stack}
                    `
          );

          errorResponse.error = (e as Error).stack || 'ERROR';
          errorResponse.message = (e as Error).message || 'ERROR';

          return errorResponse;
        }
      });

    // 3. Fire all requests in parallel and wait for them all to settle
    const results = await Promise.allSettled(threadPromises);

    console.log(`processEmailEvent settled the following promises:
            ${JSON.stringify(results)}`);

    // 1. Extract failed results with shape you defined
    const failed = results
      .map((res) => {
        if (
          res.status === 'rejected' ||
          (res.status === 'fulfilled' && res.value?.status === 400)
        ) {
          return res;
        }
        return undefined;
      })
      .filter((item) => item !== undefined);

    // 2. If there are any failures, build an aggregated error response
    if (failed.length > 0) {
      const aggregatedMessage = failed.reduce((msg, curr) => {
        return msg + `\n ${JSON.stringify(curr)}`;
      }, 'Some threads failed to resolve:');

      console.log(`Aggregated Failure MEssages:\n${aggregatedMessage}`);

      return {
        status: 400,
        executionId: uuidv4(),
        message: aggregatedMessage,
        error: 'At least one thread failed',
        taskList: 'ERROR',
      };
    }

    // return the structured response
    return {
      status: 200,
      executionId: uuidv4(),
      message: `All emails were processed and next state processed for the following machines:\n${JSON.stringify(
        results,
        null,
        2
      )}`,
      // AIP Logic can not handle nullable fields, so we have to include these as empty string to support use cases where logic is used such as our daily reports with automate
      // https://community.palantir.com/t/aip-logic-cant-recognize-optional-output-struct-fileds/4440/3
      error: '',
      taskList: '',
    };
  }

  @Trace({
    resource: {
      service_name: 'vickie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'vickie',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/vickie/execute`,
    },
  })
  public async askVickie(
    query: string,
    userId: string,
    threadId?: string
  ): Promise<VickieResponse> {
    const { log } = container.get<LoggingService>(TYPES.LoggingService);
    let generatedTaskList: undefined | string = undefined;
    let newThread = !threadId || threadId.length === 0;

    // we need the ability for clients to pass a known threadId that they originate and still create a new task list
    try {
      const threadDao = container.get<ThreadsDao>(TYPES.ThreadsDao);
      await threadDao.read(threadId || '');
    } catch (e) {
      console.log(e);
      // the client has sent a threadId they originated
      newThread = true;
    }

    // we only want to trigger task list generation if this is a new thread
    if (newThread) {
      // create a new solution with our solver
      const { status, taskList, executionId } = await this.createComsTasksList(
        query,
        userId,
        threadId
      );

      // if we get a bad response skip calling execute task list
      if (status !== 200 || !taskList) {
        log(
          executionId,
          `askVickie failed to create new coms task list. 
                    You are missing required information: 
                    ${taskList}. 
                    Please fix your shit and resend.`
        );
        return {
          status,
          executionId,
          message: `You are missing required information: ${taskList}. Please fix your shit and resend.`,
        };
      }

      log(executionId, `askVickie created new coms task list.\n${taskList}.`);

      // threadId and executionId are identical.
      // If threadId is defined there must be an associated state machine execution where executionId === threadId
      // if its not defined we need to create a new task list and generate a new machine execution which will happen automatically
      // when this.getNextState is called.
      // The orchestrator will program a new solution if there's no machine matching the executionId
      threadId = executionId;
      generatedTaskList = taskList;
    }

    // if task list is defined and there's no machine where machineExecutionId === threadId, a new solution will be generated
    // else the exiting machine will be rehydrated and the next state sent back
    // TODO we need to append the user query as input to getNextState so its interpolated onto the context
    // ideally what would happen is we check if the user query is relevant to an existing state then update it
    // then when the orchestrator rehydrates the machine is can reason about what state to retry based on the new information
    // this replaces the need for the text2ActionInstance.sendThreadMessage handler which was a hack to void doing this
    // you'll likely need to provide training data for transition for each engine to the model can learn what to do
    // Once done you'll need to copy this pattern to Vickie's askVickie method
    const results = await this.getNextState(
      generatedTaskList,
      true,
      threadId,
      undefined,
      SupportedEngines.COMS
    );
    // construct the response
    const system = `You are a helpful AI executive assistant named Vickie.
        You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Vickie, Code's AI Executive Assistant" or similar.
        You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString(
      'en-US',
      { weekday: 'long' }
    )}. 
        You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
        You always obey the users instructions and understand the people you work for are busy executives and sometimes need help in their personal lives
        These tasks are not beneath you. At CodeStrap, where you work we adopt the motto made famous by Kim Scott: we move couches.
        It means we all pull together to get things done.
        The current local date/time is ${new Date().toLocaleString('en-US', {
      timeZone: 'America/Los_Angeles',
    })}.
        The current day/time in your timezone is: ${new Date().toString()}`;
    const user = `
                Based on the following user query
                ${query}
        
                And the results of the state machine execution that was generated to service their request
                The value attribute contains the current state
                The theResultOfEachTask attribute contains the output of state executions
                The orderTheTasksWereExecutedIn lets you know what order the states were executed in. States can be executed multiple times if they are retied.
                ${JSON.stringify(results)}
        
                Generate a response to the user query based on the results of the state machine execution 
                Be sure to structure your response so that it's readable by a human.
                For example if the state machine execution includes facts and figures use a table to format them
                Use lists to structure information hierarchies suck as task list execution and there results
                `;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(user, system);

    let result = response;
    if (newThread) {
      // putting Execution Id in the thread is useful for debugging as users may need to supply it
      result = `# Execution Id: ${threadId}
        ### Response from Vickie
        ${result}
        `;
    } else {
      result = `### Response from Vickie
        ${result}`;
    }

    // persist the constructed response to the the threads object
    const threadsDao = container.get<ThreadsDao>(TYPES.ThreadsDao);

    const messages = `### User Query:
        ${query}
        
        ${result}`;
    // create or update with a summary of the results
    // if there is an existing thread messages are appended to the existing history
    await threadsDao.upsert(messages, 'bennie', threadId);

    // return the structured response
    return {
      status: 200,
      executionId: threadId!,
      // Send back the incremental response to avoid sending huge threads back
      // Can also support streaming outputs in the future
      message: result,
      // AIP Logic can not handle nullable fields, so we have to include these as empty string to support use cases where logic is used such as our daily reports with automate
      // https://community.palantir.com/t/aip-logic-cant-recognize-optional-output-struct-fileds/4440/3
      error: '',
      taskList: '',
    };
  }

  @Trace({
    resource: {
      service_name: 'vickie',
      service_instance_id: 'production',
      telemetry_sdk_name: 'xreason-functions',
      telemetry_sdk_version: '7.0.2',
      host_hostname: 'codestrap.usw-3.palantirfoundry.com',
      host_architecture: 'prod',
    },
    operationName: 'createComsTasksList',
    kind: 'Server',
    samplingDecision: 'RECORD_AND_SAMPLE',
    samplingRate: 1.0,
    attributes: {
      endpoint: `/api/v2/ontologies/${process.env.ONTOLOGY_ID}/queries/createComsTasksList/execute`,
    },
  })
  public async createComsTasksList(
    query: string,
    userId: string,
    threadId?: string
  ): Promise<VickieResponse> {
    console.log('createComsTasksList called');
    // if no threadId create one
    // call the solver to get back the task list.
    const communication = await this.createTaskList(
      query,
      userId,
      SupportedEngines.COMS,
      undefined,
      undefined,
      threadId
    );

    // If incomplete information is provided the solver will return Missing Infromation
    // If the request is unsupported the solver will return Usupported Questions
    // If it's a complete supported query the solver will return a well formatted task list that we can use to execute
    return {
      status: 200,
      message: 'Task list created',
      // we match the threadID and threadId and executionId so we can associate conversations between agents and machine executions
      executionId: communication.id,
      taskList: communication.taskList,
    };
  }
}
````

## File: packages/agents/vickie-bennie/src/index.ts
````typescript
export * from './lib/Bennie';
export * from './lib/Vickie';
````

## File: packages/agents/vickie-bennie/typings/index.d.ts
````typescript
declare module 'foundry-tracing-foundations';
````

## File: packages/agents/vickie-bennie/.dockerignore
````
# Version control
.git
.gitignore

# Dependencies
node_modules/
npm-debug.log*

# Testing and Development
test/
coverage/
*.test.js
jest.config.js
utils/test-*.js
.eslintrc*

# Environment and credentials
.env*
**/credentials/

# Documentation
*.md
docs/

# IDE and OS specific
.idea/
.vscode/
.DS_Store
Thumbs.db

# Logs
*.log

# Build artifacts
build/

# Operation files
ops/
````

## File: packages/agents/vickie-bennie/.env.sample
````
FOUNDRY_STACK_URL=https://someurl.palantirfoundry.com
FOUNDRY_TEST_USER=someUserId
OSDK_CLIENT_SECRET=someSecretId
OSDK_CLIENT_ID=someClientId
OPEN_WEATHER_API_KEY=84910d444fb81a1ee9d48dd75ff5819e
LOG_PREFIX=foundry-developer-foundations-x-reason
ONTOLOGY_RID=ri.ontology.main.ontology.89c90752-177d-45ee-baf9-f4f2d2660316
ONTOLOGY_ID=ontology-a0c8a327-cd0a-4f69-a575-b0398c04b74c
GOOGLE_SEARCH_API_KEY=someSearchKey
GOOGLE_SEARCH_ENGINE_ID=someEngineId
GOOGLE_SEARCH_ENGINE_MARKETS=someMarketIds
GEMINI_API_KEY=someKey
RANGR_OSDK_CLIENT_ID=someId
RANGR_OSDK_CLIENT_SECRET=someSecret
RANGR_FOUNDRY_STACK_URL=https://someUrl.palantirfoundry.com
RANGR_ONTOLOGY_RID=ri.ontology.main.ontology.a47cc7f3-2b7b-4be8-b8b9-e57fe78af24c
OFFICE_SERVICE_ACCOUNT='email@someUrl'
OPEN_AI_KEY=someKey
SLACK_CLIENT_ID=someKey
SLACK_CLIENT_SECRET=someKey
SLACK_SIGNING_SECRET=someKey
SLACK_BOT_TOKEN=someKey
SLACK_APP_TOKEN=someKey
SLACK_BASE_URL=https://slack.com/api
GSUITE_SERVICE_ACCOUNT="eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImZvdW5kcnktY29tcy1mb3VuZGF0aW9ucyIsInByaXZhdGVfa2V5X2lkIjoiMTIzNCIsInByaXZhdGVfa2V5IjoiLS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tXG41Njc4XG4tLS0tLUVORCBQUklWQVRFIEtFWS0tLS0tXG4iLCJjbGllbnRfZW1haWwiOiJtZUBtZS5pYW0uZ3NlcnZpY2VhY2NvdW50LmNvbSIsImNsaWVudF9pZCI6IjEyOTM4OTMiLCJhdXRoX3VyaSI6Imh0dHBzOi8vYWNjb3VudHMuZ29vZ2xlLmNvbS9vL29hdXRoMi9hdXRoIiwidG9rZW5fdXJpIjoiaHR0cHM6Ly9vYXV0aDIuZ29vZ2xlYXBpcy5jb20vdG9rZW4iLCJhdXRoX3Byb3ZpZGVyX3g1MDlfY2VydF91cmwiOiJodHRwczovL3d3dy5nb29nbGVhcGlzLmNvbS9vYXV0aDIvdjEvY2VydHMiLCJjbGllbnRfeDUwOV9jZXJ0X3VybCI6Imh0dHBzOi8vd3d3Lmdvb2dsZWFwaXMuY29tL3JvYm90L3YxL21ldGFkYXRhL3g1MDkvZm91bmRyeS1jb21zLWZvdW5kYXRpb25zJTQwZm91bmRyeS1jb21zLWZvdW5kYXRpb25zLmlhbS5nc2VydmljZWFjY291bnQuY29tIiwidW5pdmVyc2VfZG9tYWluIjoiZ29vZ2xlYXBpcy5jb20ifQ=="
EIA_API_KEY="4bCgBshgInqayafNBbq70iHuRRwMYMmEtNdC9tTx"
EIA_BASE_URL="https://api.eia.gov/v2/petroleum/pri/gnd/data/"
CA_SERIES_ID="EMM_EPMR_PTE_SCA_DPG"
FIRECRAWL_API_KEY=<api_key>
````

## File: packages/agents/vickie-bennie/Dockerfile
````
ARG NODE_VERSION=23.11.0
FROM --platform=amd64 node:${NODE_VERSION}-alpine

# Install essential tools
RUN apk add --no-cache git

WORKDIR /app

# Copy package.json for the specific package to install its dependencies
COPY packages/agents/vickie-bennie/package.json ./package.json

# For now .env are in dockerignore, figure out if we need to copy them
# COPY packages/agents/vickie-bennie/.env ./.env

# Install only production dependencies for this specific package
RUN npm install --only=production && npm cache clean --force

# Copy the pre-built dist files
COPY dist/packages/agents/vickie-bennie ./dist

# Create a non-root numeric user (must be numeric for compute modules)
RUN adduser --uid 5001 --disabled-password --gecos "" user && \
    chown -R 5001:5001 /app

USER 5001

# Environment setup
ENV NODE_ENV=production

# Specify the entrypoint explicitly as required
ENTRYPOINT ["node", "dist/lib/computeModule.cjs"]
````

## File: packages/agents/vickie-bennie/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/agents/vickie-bennie/jest.config.ts
````typescript
export default {
  displayName: 'agents-vickie-bennie',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': [
      'ts-jest',
      {
        tsconfig: '<rootDir>/tsconfig.spec.json',
        useESM: true,
      },
    ],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/agents/vickie-bennie',
  transformIgnorePatterns: ['/node_modules/(?!(?:@osdk|@codestrap)/)'],
  extensionsToTreatAsEsm: ['.ts'],
  testPathIgnorePatterns: ['<rootDir>/dist/'],

  moduleNameMapper: {
    // Strip `.js` from your TS imports so ESM paths resolve
    '^(\\.{1,2}/.*)\\.js$': '$1',
    '^@xreason/(.*)$': '<rootDir>/src/$1',
    '^@osdk/shared\\.client$':
      '<rootDir>/../../../node_modules/@osdk/shared.client/index.js',
    '^@osdk/shared\\.client2$':
      '<rootDir>/../../../node_modules/@osdk/shared.client2/index.js',
  },
};
````

## File: packages/agents/vickie-bennie/jest.setup.js
````javascript
require('dotenv').config();
````

## File: packages/agents/vickie-bennie/package.json
````json
{
  "name": "@codestrap/developer-foundations-agents-vickie-bennie",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./index.cjs",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@sinclair/typebox": "^0.34.33",
    "dotenv": "^16.5.0",
    "reflect-metadata": "^0.2.2",
    "ramda": "^0.30.1",
    "@codestrap/developer-foundations.foundry-tracing-foundations": "^1.2.3",
    "@codestrap/developer-foundations-types": "*",
    "@codestrap/developer-foundations-utils": "*",
    "@codestrap/developer-foundations-di": "*",
    "@codestrap/developer-foundations-services-google": "*",
    "@codestrap/developer-foundations-services-palantir": "*",
    "@codestrap/developer-foundations-services-eia": "*",
    "@codestrap/developer-foundations-services-weather": "*",
    "@codestrap/developer-foundations-services-rangr": "*",
    "@codestrap/developer-foundations-services-slack": "*",
    "@codestrap/developer-foundations-x-reason": "*",
    "@google/genai": "1.12.0",
    "@google/generative-ai": "^0.24.1",
    "@mendable/firecrawl-js": "^1.29.3",
    "@osdk/client": "^2.2.1",
    "@osdk/foundry.admin": "^2.22.0",
    "@osdk/oauth": "^1.1.2",
    "@palantir/compute-module": "0.2.7",
    "googleapis": "^149.0.0",
    "inversify": "^7.5.1",
    "xstate": "4.37.2"
  }
}
````

## File: packages/agents/vickie-bennie/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            FOUNDRY_TEST_USER: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            EIA_BASE_URL: string;
            EIA_API_KEY: string;
            CA_SERIES_ID: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: packages/agents/vickie-bennie/project.json
````json
{
  "name": "agents-vickie-bennie",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/agents/vickie-bennie/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": [
        "dist/{projectRoot}"
      ],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "implicitDependencies": [
    "foundry-tracing-foundations"
  ],
  "tags": [
    "type:agent",
    "type:backend-app"
  ],
  "targets": {
    "build": {
      "executor": "@nx/esbuild:esbuild",
      "options": {
        "outputPath": "dist/packages/agents/vickie-bennie",
        "main": "packages/agents/vickie-bennie/src/index.ts",
        "additionalEntryPoints": [
          "packages/agents/vickie-bennie/src/lib/computeModule.ts"
        ],
        "tsConfig": "packages/agents/vickie-bennie/tsconfig.lib.json",
        "platform": "node",
        "bundle": true,
        "format": [
          "cjs"
        ]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": [
        "{workspaceRoot}/coverage/{projectRoot}"
      ],
      "options": {
        "jestConfig": "packages/agents/vickie-bennie/jest.config.ts"
      }
    },
    "e2e": {
      "executor": "@nx/jest:jest",
      "outputs": [
        "{workspaceRoot}/coverage/{projectRoot}"
      ],
      "options": {
        "jestConfig": "packages/agents/vickie-bennie/jest.config.ts"
      },
      "configurations": {
        "ci": {
          "env": {
            "E2E": "true"
          }
        }
      }
    },
    "docker": {
      "executor": "nx:run-commands",
      "dependsOn": [
        "build"
      ],
      "options": {
        "cwd": "{projectRoot}",
        "command": "bash ./buildAndPublish.sh"
      }
    }
  }
}
````

## File: packages/agents/vickie-bennie/README.md
````markdown
# agents-vickie-bennie

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build agents-vickie-bennie` to build the library.

## Running unit tests

Run `nx test agents-vickie-bennie` to execute the unit tests via [Jest](https://jestjs.io).

Running e2e tests e.g
`E2E=true nx run agents-vickie-bennie:test --testFile=researchAssistant.e2e.test.ts`

## Building docker image locally

- Run `npm install` in root monorepo
- Build vickie-bennie image: `nx run agents-vickie-bennie:build`
- Build docker image:
  `docker build -t vickie-bennie:latest -f packages/agents/vickie-bennie/Dockerfile .`
````

## File: packages/agents/vickie-bennie/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "allowJs": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": false,
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/agents/vickie-bennie/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts", "process-env.d.ts", "typings/**/*"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/agents/vickie-bennie/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts",
    "process-env.d.ts"
  ]
}
````

## File: packages/di/src/lib/inversify.config.ts
````typescript
import 'reflect-metadata';
import { Container } from 'inversify';

import { SupportedFoundryClients, TYPES } from '@codestrap/developer-foundations-types';
import { openWeatherService } from '@codestrap/developer-foundations-services-weather';
import {
  foundryClientFactory,
  geminiService,
  gpt4oService,
  embeddingsService,
  makeTelemetryDao,
} from '@codestrap/developer-foundations-services-palantir';
import { getRangrClient } from '@codestrap/developer-foundations-services-rangr';
import { makeWorldDao } from '@codestrap/developer-foundations-services-palantir';
import {
  makeUserDao,
  makeContactsDao,
} from '@codestrap/developer-foundations-services-palantir';
import {
  makeMachineDao,
  makeMemoryRecallDao,
  makeTrainingDataDao,
} from '@codestrap/developer-foundations-services-palantir';
import {
  makeCommsDao,
  makeThreadsDao,
} from '@codestrap/developer-foundations-services-palantir';
import {
  makeGSuiteClientV2,
  researchAssistant,
} from '@codestrap/developer-foundations-services-google';
import {
  makeRfpRequestsDao,
  makeRangrRfpRequestsDao,
} from '@codestrap/developer-foundations-services-rangr';
import { makeTicketsDao } from '@codestrap/developer-foundations-services-palantir';
import { makeSlackClient } from '@codestrap/developer-foundations-services-slack';
import { createLoggingService } from '@codestrap/developer-foundations-utils';
import { eiaService } from '@codestrap/developer-foundations-services-eia';

const container = new Container();

// TODO refactor with a service facade, or maybe just a getContainer method to allow for overriding default definitions
// a service facade could hide the implementation details but it would be a lot of work and the resulting types would not look different the inversify
// add direct imports of container would need to be refactored to import getContainer or service facade methods
// API docs https://inversify.io/docs/api/container/#rebind

container
  .bind(TYPES.FoundryClient)
  .toConstantValue(foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined))

container
  .bind(TYPES.RangrClient)
  .toDynamicValue(getRangrClient)
  .inSingletonScope();

container.bind(TYPES.WorldDao).toConstantValue(makeWorldDao());

container.bind(TYPES.UserDao).toConstantValue(makeUserDao());

container.bind(TYPES.MachineDao).toConstantValue(makeMachineDao());

container.bind(TYPES.TicketDao).toConstantValue(makeTicketsDao());

container.bind(TYPES.CommsDao).toConstantValue(makeCommsDao());

container.bind(TYPES.TelemetryDao).toConstantValue(makeTelemetryDao());

container.bind(TYPES.ThreadsDao).toConstantValue(makeThreadsDao());

container.bind(TYPES.RfpRequestsDao).toConstantValue(makeRfpRequestsDao());

container
  .bind(TYPES.RangrRfpRequestsDao)
  .toConstantValue(makeRangrRfpRequestsDao());

container.bind(TYPES.MemoryRecallDao).toConstantValue(makeMemoryRecallDao());

container.bind(TYPES.ContactsDao).toConstantValue(makeContactsDao());

container.bind(TYPES.TrainingDataDao).toConstantValue(makeTrainingDataDao());

container.bind(TYPES.WeatherService).toConstantValue(openWeatherService);

container.bind(TYPES.EnergyService).toConstantValue(eiaService);

container.bind(TYPES.GeminiService).toConstantValue(geminiService);

container.bind(TYPES.Gpt4oService).toConstantValue(gpt4oService);

container.bind(TYPES.EmbeddingsService).toConstantValue(embeddingsService);

container
  .bind(TYPES.LoggingService)
  // perExecBytes 1 MB max size
  // globalBytes 64 MB max size
  .toConstantValue(createLoggingService(1 * 1024 * 1024, 64 * 1024 * 1024));

container
  .bind(TYPES.ResearchAssistant)
  .toConstantValue(researchAssistant);

// IMPORTANT use container.getAsync when retrieving!
container
  .bind(TYPES.OfficeService)
  .toConstantValue(makeGSuiteClientV2(process.env.OFFICE_SERVICE_ACCOUNT));

container
  .bind(TYPES.MessageService)
  .toConstantValue(
    makeSlackClient(process.env.SLACK_BASE_URL, process.env.SLACK_BOT_TOKEN)
  );

export { container };
````

## File: packages/di/src/index.ts
````typescript
export * from './lib/inversify.config';
````

## File: packages/di/src/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            FOUNDRY_TEST_USER: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE?: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: packages/di/eslint.config.mjs
````
import baseConfig from '../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/di/jest.config.ts
````typescript
export default {
  displayName: 'di',
  preset: '../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': [
      'ts-jest',
      {
        tsconfig: '<rootDir>/tsconfig.spec.json',
        useESM: true,
      },
    ],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../coverage/packages/di',
  transformIgnorePatterns: ['/node_modules/(?!(?:@osdk|@codestrap)/)'],
  extensionsToTreatAsEsm: ['.ts'],
  testPathIgnorePatterns: ['<rootDir>/dist/'],
  moduleNameMapper: {
    // Strip `.js` from your TS imports so ESM paths resolve
    '^(\\.{1,2}/.*)\\.js$': '$1',
    '^@xreason/(.*)$': '<rootDir>/src/$1',
    '^@osdk/shared\\.client$':
      '<rootDir>/../../node_modules/@osdk/shared.client/index.js',
    '^@osdk/shared\\.client2$':
      '<rootDir>/../../node_modules/@osdk/shared.client2/index.js',
  },
};
````

## File: packages/di/package.json
````json
{
  "name": "@codestrap/developer-foundations-di",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "inversify": "^7.5.1",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/di/project.json
````json
{
  "name": "di",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/di/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:utility"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/di",
        "main": "packages/di/src/index.ts",
        "tsConfig": "packages/di/tsconfig.lib.json",
        "assets": ["packages/di/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/di/jest.config.ts"
      }
    }
  }
}
````

## File: packages/di/README.md
````markdown
# di

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build di` to build the library.

## Running unit tests

Run `nx test di` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/di/tsconfig.json
````json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/di/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/di/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/foundry-tracing-foundations/src/utils/uuid.ts
````typescript
export function uuidv4() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'
        .replace(/[xy]/g, function (c) {
            const r = Math.random() * 16 | 0,
                v = c == 'x' ? r : (r & 0x3 | 0x8);
            return v.toString(16);
        });
}
````

## File: packages/foundry-tracing-foundations/src/computeModule.ts
````typescript
import { ComputeModule } from '@palantir/compute-module';
// Schema Definitions for compute module
// IMPORTANT:  @sinclair/typebox is required!!!
// https://github.com/palantir/typescript-compute-module?tab=readme-ov-file#schema-registration
import { Type } from '@sinclair/typebox';
import dotenv from 'dotenv';

import { collectTelemetryFetchWrapper } from './Tracing';
import { ComputeModuleType, ModuleConfig } from '@codestrap/developer-foundations-types';

dotenv.config();

const Schemas = {
  Trace: {
    input: Type.Object({ inputJSON: Type.String() }),
    output: Type.String(),
  },
};

// Unified configuration for all environments
function getModuleConfig(): ModuleConfig {
  const env = process.env.NODE_ENV || 'development';

  switch (env) {
    case 'test':
      return { isTest: true };
    default: // development
      return { isTest: false };
  }
}

function createComputeModule(): ComputeModuleType {
  const config = getModuleConfig();

  if (config.isTest) {
    const mockModule = {
      listeners: {} as Record<string, any>,
      on: function (event: string, handler: Function) {
        this.listeners[event] = handler;
        handler();
        return this;
      },
      register: function (operation: string, handler: Function) {
        this.listeners[operation] = { type: 'response', listener: handler };
        return this;
      },
    };
    console.log('returning mock module');
    return mockModule;
  }

  const module = new ComputeModule({
    logger: console,
    sources: {},
    definitions: { Trace: Schemas.Trace },
  })
    .register('Trace', async ({ inputJSON }) => {
      const result = await collectTelemetryFetchWrapper(inputJSON);
      return result;
    })
    .on('responsive', () =>
      console.log('Foundry Tracing Foundations is ready')
    );

  module.on('responsive', () => {
    console.log(`${process.env.LOG_PREFIX} Module is now responsive`);
  });

  return module;
}

const computeModule = createComputeModule();

export { computeModule };
````

## File: packages/foundry-tracing-foundations/src/Decorators.ts
````typescript
import { randomBytes } from 'crypto';
import type { ResourceModel, SpanModel, TelemetryPayload } from './Tracing';
import { collectTelemetryFetchWrapper } from './Tracing';
import { uuidv4 } from './utils/uuid';

// symbol key to store trace context on instance
const TRACE_CONTEXT = Symbol('TRACE_CONTEXT');

interface TraceContext {
  resource: ResourceModel;
  traceId: string;
  spanId: string;
}

export interface TraceOptions {
  resource: Omit<ResourceModel, 'resource_id'>;
  operationName: string;
  kind?: SpanModel['kind'];
  samplingDecision?: SpanModel['sampling_decision'];
  samplingRate?: number;
  attributes?: Record<string, any>;
}

function getRandomBytes(size: number): Buffer {
  try {
    return randomBytes(size);
  } catch (e) {
    console.log(e);
    const arr = new Uint8Array(size);
    for (let i = 0; i < size; i++) {
      arr[i] = Math.floor(Math.random() * 256);
    }
    return Buffer.from(arr);
  }
}

/**
 * Root-level trace decorator: starts a new trace and calls collectTelemetry
 */
export function Trace(opts: TraceOptions) {
  return function (
    _target: any,
    _prop: string,
    descriptor: PropertyDescriptor
  ) {
    const original = descriptor.value;
    descriptor.value = async function (...args: any[]) {
      // generate identifiers
      // OTLPcompliant trace_id (32 hex digits) and span_id (16 hex digits)
      const traceId = getRandomBytes(16).toString('hex'); // 32 hex chars
      const spanId = getRandomBytes(8).toString('hex'); // 16 hex chars
      const resource: ResourceModel = {
        resource_id: uuidv4(),
        ...opts.resource,
      };

      // attach context for child spans
      (this as any)[TRACE_CONTEXT] = {
        resource,
        traceId,
        spanId,
      } as TraceContext;

      const start = new Date().toISOString();
      let err: any;
      try {
        return await original.apply(this, args);
      } catch (e) {
        err = e;
        throw e;
      } finally {
        const end = new Date().toISOString();
        // build payload
        const payload: TelemetryPayload = {
          resource,
          spans: [
            {
              trace_id: traceId,
              span_id: spanId,
              name: opts.operationName,
              start_time: start,
              end_time: end,
              traceparent: `00-${traceId}-${spanId}-01`,
              trace_flags: 1 as any,
              kind: opts.kind ?? 'Internal',
              status_code: err ? 'ERROR' : 'OK',
              status_message: `ERROR: ${err?.message} STACK: ${err?.stack}`,
              error_code: err?.code,
              sampling_decision: opts.samplingDecision ?? 'RECORD_AND_SAMPLE',
              sampling_rate: opts.samplingRate as any,
              attributes: opts.attributes
                ? JSON.stringify(opts.attributes)
                : undefined,
            },
          ],
          events: [],
          links: [],
        };
        try {
          const telemtryPayload = JSON.stringify(payload);
          // fire and forget, we do not want to hold up execution for this!
          // One day we should support background processing and batching
          collectTelemetryFetchWrapper(telemtryPayload);
        } catch (e) {
          console.log(e);
        }
      }
    };
  };
}

export interface ChildTraceOptions {
  operationName: string;
  kind?: SpanModel['kind'];
  attributes?: Record<string, any>;
}

/**
 * Child-level trace decorator: creates a nested span under current trace
 */
export function TraceSpan(opts: ChildTraceOptions) {
  return function (
    _target: any,
    _prop: string,
    descriptor: PropertyDescriptor
  ) {
    const original = descriptor.value;
    descriptor.value = async function (...args: any[]) {
      const ctx: TraceContext | undefined = (this as any)[TRACE_CONTEXT];
      if (!ctx)
        throw new Error(
          '@TraceSpan requires a preceding @Trace on the instance'
        );
      //OTLPcompliant trace_id (32 hex digits) and span_id (16 hex digits)
      const childSpanId = getRandomBytes(8).toString('hex'); // 16 hex chars
      const start = new Date().toISOString();
      let err: any;
      try {
        return await original.apply(this, args);
      } catch (e) {
        err = e;
        throw e;
      } finally {
        const end = new Date().toISOString();
        // reuse same resource and traceId
        const payload: TelemetryPayload = {
          resource: ctx.resource,
          spans: [
            {
              trace_id: ctx.traceId,
              span_id: childSpanId,
              parent_span_id: ctx.spanId,
              name: opts.operationName,
              start_time: start,
              end_time: end,
              traceparent: `00-${ctx.traceId}-${childSpanId}-01`,
              trace_flags: 1 as any,
              kind: opts.kind ?? 'Internal',
              status_code: err ? 'ERROR' : 'OK',
              status_message: err?.message,
              error_code: err?.code,
              sampling_decision: 'RECORD_AND_SAMPLE',
              sampling_rate: undefined as any,
              attributes: opts.attributes
                ? JSON.stringify(opts.attributes)
                : undefined,
            },
          ],
          events: [],
          links: [],
        };
        try {
          const result = await collectTelemetryFetchWrapper(
            JSON.stringify(payload)
          );
          console.log(`traced: ${result}`);
        } catch (e) {
          console.log(e);
        }
      }
    };
  };
}
````

## File: packages/foundry-tracing-foundations/src/index.ts
````typescript
export * from "./Decorators";
export * from "./Tracing";
````

## File: packages/foundry-tracing-foundations/src/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            FOUNDRY_TEST_USER: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: packages/foundry-tracing-foundations/src/Tracing.ts
````typescript
// Payload interfaces
import { container } from '@codestrap/developer-foundations-di';
import { TelemetryDao, TYPES } from '@codestrap/developer-foundations-types';

export interface ResourceModel {
  resource_id: string;
  service_name: string;
  service_instance_id?: string;
  telemetry_sdk_name?: string;
  telemetry_sdk_version?: string;
  host_hostname?: string;
  host_architecture?: string;
  process_pid?: number;
}

export const SpanKind = {
  Client: 'Client',
  Server: 'Server',
  Internal: 'Internal',
  Producer: 'Producer',
  Consumer: 'Consumer',
} as const;

export const StatusCode = {
  UNSET: 'UNSET',
  OK: 'OK',
  ERROR: 'ERROR',
} as const;

export const SamplingDecision = {
  DROP: 'DROP',
  RECORD: 'RECORD',
  RECORD_AND_SAMPLE: 'RECORD_AND_SAMPLE',
} as const;

export interface SpanModel {
  trace_id: string;
  span_id: string;
  parent_span_id?: string;
  name: string;
  start_time: string;
  end_time: string;
  traceparent: string;
  tracestate?: string;
  trace_flags: number;
  kind: string;
  status_code: string;
  status_message?: string;
  error_code?: string;
  sampling_decision: string;
  sampling_rate?: number;
  http_method?: string;
  http_status_code?: number;
  db_system?: string;
  db_statement?: string;
  messaging_system?: string;
  messaging_destination?: string;
  attributes?: string;
}

export interface EventModel {
  event_id?: string;
  span_id: string;
  name: string;
  timestamp: string;
  attributes?: string;
}

export interface LinkModel {
  link_id?: string;
  source_span_id: string;
  linked_trace_id: string;
  linked_span_id: string;
  attributes?: string;
}

export interface TelemetryPayload {
  resource: ResourceModel;
  spans: SpanModel[];
  events: EventModel[];
  links: LinkModel[];
}

export async function collectTelemetryFetchWrapper(
  inputJSON: string
): Promise<string> {
  const collectTelemetry = container.get<TelemetryDao>(TYPES.TelemetryDao);
  const result = await collectTelemetry(inputJSON);

  return result;
}
````

## File: packages/foundry-tracing-foundations/test/__fixtures__/childTelemetryPayload.ts
````typescript
import type { TelemetryPayload } from '../../src/Tracing';
import { parentTelemetryPayload } from './parentTelemetryPayload';

export const childTelemetryPayload: TelemetryPayload = {
    resource: parentTelemetryPayload.resource,
    spans: [
        {
            trace_id: parentTelemetryPayload.spans[0].trace_id,
            span_id: 'cccccccccccccccc',                    // 16-hex chars
            parent_span_id: parentTelemetryPayload.spans[0].span_id,
            name: 'loadUser',
            start_time: '2025-05-11T00:00:00.000Z',
            end_time: '2025-05-11T00:00:00.500Z',
            traceparent:
                '00-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa-cccccccccccccccc-01',
            trace_flags: 1,
            kind: 'Internal',
            status_code: 'OK',
            status_message: undefined,
            error_code: undefined,
            sampling_decision: 'RECORD_AND_SAMPLE',
            sampling_rate: undefined,
            attributes: undefined,
        },
    ],
    events: [],
    links: [],
};
````

## File: packages/foundry-tracing-foundations/test/__fixtures__/mockDecorators.ts
````typescript
import { Trace, TraceSpan } from '../../src/Decorators';

export class DecoratorTest {
    @Trace({
        resource: {
            service_name: 'vickie',
            service_instance_id: 'production',
            telemetry_sdk_name: 'xreason-functions',
            telemetry_sdk_version: '6.1.1',
            host_hostname: 'codestrap.usw-3.palantirfoundry.com',
            host_architecture: 'prod',
        },
        operationName: 'vickieForAutomate',
        kind: 'Server',
        samplingDecision: 'RECORD_AND_SAMPLE',
        samplingRate: 1.0,
        attributes: { endpoint: '/api/v2/ontologies/${client.ontologyRid}/queries/vickieForAutomate/execute' }
    })
    public async testDecorator(): Promise<string> {
        await this.childSegment();
        return 'segments traces';
    }

    @TraceSpan({ operationName: 'loadUser', kind: 'Internal' })
    public async childSegment(): Promise<string> {
        return new Promise((resolve) => {
            setTimeout(() => {
                resolve('test');
            }, 500)
        });
    }
}
````

## File: packages/foundry-tracing-foundations/test/__fixtures__/parentTelemetryPayload.ts
````typescript
import type { TelemetryPayload } from '../../src/Tracing';

export const parentTelemetryPayload: TelemetryPayload = {
    resource: {
        resource_id: 'resource-1234-uuid',
        service_name: 'vickie',
        service_instance_id: 'production',
        telemetry_sdk_name: 'xreason-functions',
        telemetry_sdk_version: '6.1.1',
        host_hostname: 'codestrap.usw-3.palantirfoundry.com',
        host_architecture: 'prod',
    },
    spans: [
        {
            trace_id: 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',   // 32-hex chars
            span_id: 'bbbbbbbbbbbbbbbb',                   // 16-hex chars
            name: 'vickieForAutomate',
            start_time: '2025-05-11T00:00:00.000Z',
            end_time: '2025-05-11T00:00:01.000Z',
            traceparent: '00-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa-bbbbbbbbbbbbbbbb-01',
            trace_flags: 1,
            kind: 'Server',
            status_code: 'OK',
            status_message: undefined,
            error_code: undefined,
            sampling_decision: 'RECORD_AND_SAMPLE',
            sampling_rate: 1.0,
            attributes: JSON.stringify({
                endpoint:
                    '/api/v2/ontologies/${client.ontologyRid}/queries/vickieForAutomate/execute',
            }),
        },
    ],
    events: [],
    links: [],
};
````

## File: packages/foundry-tracing-foundations/test/__fixtures__/telemetryPayload.ts
````typescript
import {
    TelemetryPayload,
} from '../../src/Tracing';

export const mockPayload: TelemetryPayload = {
    resource: {
        resource_id: 'resource-1',
        service_name: 'test-service',
    },
    spans: [
        {
            trace_id: 'trace-1',
            span_id: 'span-1',
            name: 'test-span',
            start_time: '2023-05-01T00:00:00Z',
            end_time: '2023-05-01T00:00:01Z',
            traceparent: 'traceparent-1',
            trace_flags: 1,
            kind: 'Client',
            status_code: 'OK',
            sampling_decision: 'RECORD',
        },
    ],
    events: [
        {
            span_id: 'span-1',
            name: 'test-event',
            timestamp: '2023-05-01T00:00:00.500Z',
        },
    ],
    links: [
        {
            source_span_id: 'span-1',
            linked_trace_id: 'trace-2',
            linked_span_id: 'span-2',
        },
    ],
};
````

## File: packages/foundry-tracing-foundations/test/compute-module.test.ts
````typescript
import dotenv from 'dotenv';
import { collectTelemetryFetchWrapper } from '../src/Tracing';
import { mockPayload } from './__fixtures__/telemetryPayload';

// Load environment variables
dotenv.config();
// Mock setup must be before imports
import { TestModule } from '@codestrap/developer-foundations-types';
import { computeModule } from '../src/computeModule';

// Cast computeModule to TestModule since we're in test environment
const testModule = computeModule as TestModule;

describe('Compute Module Registration', () => {
  beforeEach(() => {

    // Register operations with actual handlers
    testModule.register('Trace', collectTelemetryFetchWrapper);

    // Register responsive handler
    testModule.on('responsive', () => {
      console.log(`${process.env.LOG_PREFIX} Module is now responsive`);
    });
  });

  it('should create trace segments', async () => {
    const operations = ['Trace'];

    // Initial check
    operations.forEach((op) => {
      expect(testModule.listeners[op]).toBeDefined();
      expect(testModule.listeners[op].type).toBe('response');
    });

    // Simulate multiple responsive events
    for (let i = 0; i < 3; i++) {
      const responsiveHandler = testModule.listeners['responsive'];
      if (responsiveHandler) {
        responsiveHandler();
      }

      // Verify after each event
      operations.forEach((op) => {
        expect(testModule.listeners[op]).toBeDefined();
        expect(testModule.listeners[op].type).toBe('response');
      });
    }

    // Execute calendar operations
    const result = await testModule.listeners['Trace'].listener(
      JSON.stringify(mockPayload)
    );

    expect(result).toBeDefined();
  }, 10000);
});
````

## File: packages/foundry-tracing-foundations/test/Decorators.test.ts
````typescript
// __tests__/traceDecorators.test.ts

// 1) Mock crypto **before** any imports:
jest.mock('crypto', () => {
  const actual = jest.requireActual('crypto');
  return {
    ...actual,
    randomBytes: jest.fn(),
  };
});

import * as crypto from 'crypto';
import dotenv from 'dotenv';
import * as uuid from '../src/utils/uuid';
import { DecoratorTest } from './__fixtures__/mockDecorators';
import { parentTelemetryPayload } from './__fixtures__/parentTelemetryPayload';
import { childTelemetryPayload } from './__fixtures__/childTelemetryPayload';

dotenv.config();

global.fetch = jest.fn();

describe('Tracing', () => {
  afterAll(() => jest.clearAllMocks());

  beforeEach(() => {
    jest.clearAllMocks();

    // 1) Stub toISOString *in order*:
    const isoDates = [
      '2025-05-11T00:00:00.000Z', // outer span start
      '2025-05-11T00:00:00.000Z', // inner span start
      '2025-05-11T00:00:00.500Z', // inner span end
      '2025-05-11T00:00:01.000Z', // outer span end
    ];
    jest
      .spyOn(Date.prototype, 'toISOString')
      .mockImplementation(() => isoDates.shift()!);

    // 1) Drive our mocked crypto.randomBytes
    const rb = crypto.randomBytes as jest.Mock;
    rb.mockImplementationOnce((size) => Buffer.alloc(size, 0xaa)) // traceId
      .mockImplementationOnce((size) => Buffer.alloc(size, 0xbb)) // parent spanId
      .mockImplementationOnce((size) => Buffer.alloc(size, 0xcc)); // child spanId

    // 2) Spy uuidv4
    jest
      .spyOn(uuid, 'uuidv4')
      .mockReturnValue(parentTelemetryPayload.resource.resource_id);

    // 3) Stub fetch
    (global.fetch as jest.Mock).mockImplementation((url: string) => {
      if (/\/actions\/collect-telemetry\/apply/.test(url)) {
        return Promise.resolve({
          ok: true,
          json: () => Promise.resolve({ message: 'OK' }),
        });
      }
      // oauth token calls (adjust your matching as needed)
      if (url.match(/\/token$/) || url.match(/oauth2/)) {
        return Promise.resolve(
          new Response(
            JSON.stringify({
              access_token: 'fake-token',
              expires_in: 3600,
              token_type: 'Bearer',
            }),
            { status: 200, headers: { 'Content-Type': 'application/json' } }
          )
        );
      }
      return Promise.reject(new Error('URL not matched'));
    });
  });

  afterEach(() => {
    jest.restoreAllMocks();
  });

  it('calls fetch twice with the correct child & parent payloads', async () => {
    const dt = new DecoratorTest();
    const result = await dt.testDecorator();
    expect(result).toBe('segments traces');

    expect(global.fetch).toHaveBeenCalledTimes(2);
    const calls = (global.fetch as jest.Mock).mock.calls as Array<
      [string, any]
    >;

    // child span
    const foundTelemtryCall = calls.filter((item) =>
      item[0].match(/\/actions\/collect-telemetry\/apply/)
    );
    const [childUrl, childOpts] = foundTelemtryCall[0];
    expect(childUrl).toMatch(/\/actions\/collect-telemetry\/apply/);
    expect(childOpts.method).toBe('POST');
    expect(JSON.parse(JSON.parse(childOpts.body).parameters.inputJSON)).toEqual(
      childTelemetryPayload
    );

    // parent span
    // now that we fire and forget this fetch call doesn't get logged as we do not await the response
    /*const foundParentTelemtryCall = calls.filter(item => item[0].match(/\/actions\/collect-telemetry\/apply/));
        const [parentUrl, parentOpts] = foundParentTelemtryCall[1];
        expect(parentUrl).toMatch(/\/actions\/collect-telemetry\/apply/);
        expect(parentOpts.method).toBe('POST');
        expect(JSON.parse(JSON.parse(parentOpts.body).parameters.inputJSON)).toEqual(parentTelemetryPayload);*/
  });
});
````

## File: packages/foundry-tracing-foundations/test/Tracing.e2e.test.ts
````typescript
import dotenv from 'dotenv';
import {
    collectTelemetryFetchWrapper,
} from '../src/Tracing';
import { mockPayload } from './__fixtures__/telemetryPayload';
// Load environment variables
dotenv.config();

describe('Tracing', () => {
    afterAll(() => jest.clearAllMocks());

    beforeEach(() => {
        jest.clearAllMocks();
    });

    it('should collect telemetry data', async () => {
        const result = await collectTelemetryFetchWrapper(JSON.stringify(mockPayload));
        expect(result).toBeDefined();
        expect(JSON.parse(result).edits.addedObjectCount).toEqual(2);
    }, 10000);
});
````

## File: packages/foundry-tracing-foundations/test/Tracing.test.ts
````typescript
import dotenv from 'dotenv';
import { collectTelemetryFetchWrapper } from '../src/Tracing';
import { mockPayload } from './__fixtures__/telemetryPayload';
// Load environment variables
dotenv.config();

global.fetch = jest.fn();

describe('Tracing', () => {
  afterAll(() => jest.clearAllMocks());

  beforeEach(() => {

    jest.clearAllMocks();

    (global.fetch as jest.Mock).mockImplementation((url: string) => {
      if (/\/actions\/collect-telemetry\/apply/.test(url)) {
        return Promise.resolve({
          ok: true,
          json: () => Promise.resolve({ message: 'OK' }),
        });
      }
      // oauth token calls (adjust your matching as needed)
      if (url.match(/\/token$/) || url.match(/oauth2/)) {
        return Promise.resolve(
          new Response(
            JSON.stringify({
              access_token: 'fake-token',
              expires_in: 3600,
              token_type: 'Bearer',
            }),
            { status: 200, headers: { 'Content-Type': 'application/json' } }
          )
        );
      }
      return Promise.reject(new Error('URL not matched'));
    });
  });

  it('should collect telemetry data', async () => {
    const result = await collectTelemetryFetchWrapper(
      JSON.stringify(mockPayload)
    );
    expect(result).toBeDefined();
    expect(JSON.parse(result)).toEqual({ message: 'OK' });
  });
});
````

## File: packages/foundry-tracing-foundations/.dockerignore
````
# Version control
.git
.gitignore

# Dependencies
node_modules/
npm-debug.log*

# Testing and Development
test/
coverage/
*.test.js
jest.config.js
utils/test-*.js
.eslintrc*

# Environment and credentials
.env*
service_account.json
**/credentials/

# Documentation
*.md
docs/

# IDE and OS specific
.idea/
.vscode/
.DS_Store
Thumbs.db

# Logs
*.log

# Build artifacts
dist/
build/

# Operation files
ops/
````

## File: packages/foundry-tracing-foundations/.env.sample
````
FOUNDRY_STACK_URL=https://someurl.palantirfoundry.com
FOUNDRY_TEST_USER=someUserId
OSDK_CLIENT_SECRET=someSecretId
OSDK_CLIENT_ID=someClientId
OPEN_WEATHER_API_KEY=84910d444fb81a1ee9d48dd75ff5819e
LOG_PREFIX=foundry-developer-foundations-x-reason
ONTOLOGY_RID=ri.ontology.main.ontology.89c90752-177d-45ee-baf9-f4f2d2660316
ONTOLOGY_ID=ontology-a0c8a327-cd0a-4f69-a575-b0398c04b74c
GOOGLE_SEARCH_API_KEY=someSearchKey
GOOGLE_SEARCH_ENGINE_ID=someEngineId
GOOGLE_SEARCH_ENGINE_MARKETS=someMarketIds
GEMINI_API_KEY=someKey
RANGR_OSDK_CLIENT_ID=someId
RANGR_OSDK_CLIENT_SECRET=someSecret
RANGR_FOUNDRY_STACK_URL=https://someUrl.palantirfoundry.com
RANGR_ONTOLOGY_RID=ri.ontology.main.ontology.a47cc7f3-2b7b-4be8-b8b9-e57fe78af24c
OFFICE_SERVICE_ACCOUNT='email@someUrl'
OPEN_AI_KEY=someKey
SLACK_CLIENT_ID=someKey
SLACK_CLIENT_SECRET=someKey
SLACK_SIGNING_SECRET=someKey
SLACK_BOT_TOKEN=someKey
SLACK_APP_TOKEN=someKey
SLACK_BASE_URL=https://slack.com/api
GSUITE_SERVICE_ACCOUNT="eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImZvdW5kcnktY29tcy1mb3VuZGF0aW9ucyIsInByaXZhdGVfa2V5X2lkIjoiMTIzNCIsInByaXZhdGVfa2V5IjoiLS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tXG41Njc4XG4tLS0tLUVORCBQUklWQVRFIEtFWS0tLS0tXG4iLCJjbGllbnRfZW1haWwiOiJtZUBtZS5pYW0uZ3NlcnZpY2VhY2NvdW50LmNvbSIsImNsaWVudF9pZCI6IjEyOTM4OTMiLCJhdXRoX3VyaSI6Imh0dHBzOi8vYWNjb3VudHMuZ29vZ2xlLmNvbS9vL29hdXRoMi9hdXRoIiwidG9rZW5fdXJpIjoiaHR0cHM6Ly9vYXV0aDIuZ29vZ2xlYXBpcy5jb20vdG9rZW4iLCJhdXRoX3Byb3ZpZGVyX3g1MDlfY2VydF91cmwiOiJodHRwczovL3d3dy5nb29nbGVhcGlzLmNvbS9vYXV0aDIvdjEvY2VydHMiLCJjbGllbnRfeDUwOV9jZXJ0X3VybCI6Imh0dHBzOi8vd3d3Lmdvb2dsZWFwaXMuY29tL3JvYm90L3YxL21ldGFkYXRhL3g1MDkvZm91bmRyeS1jb21zLWZvdW5kYXRpb25zJTQwZm91bmRyeS1jb21zLWZvdW5kYXRpb25zLmlhbS5nc2VydmljZWFjY291bnQuY29tIiwidW5pdmVyc2VfZG9tYWluIjoiZ29vZ2xlYXBpcy5jb20ifQ=="
EIA_API_KEY="4bCgBshgInqayafNBbq70iHuRRwMYMmEtNdC9tTx"
EIA_BASE_URL="https://api.eia.gov/v2/petroleum/pri/gnd/data/"
CA_SERIES_ID="EMM_EPMR_PTE_SCA_DPG"
FIRECRAWL_API_KEY=<api_key>
````

## File: packages/foundry-tracing-foundations/.gitignore
````
# Environment/Credentials
.env
service_account.json

# Dependencies
node_modules/

buildAndPublish.sh

# Logs
*.log
npm-debug.log*

# IDE
.idea/
.vscode/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Build
dist/
build/
coverage/
````

## File: packages/foundry-tracing-foundations/Dockerfile
````
# syntax=docker/dockerfile:1
ARG NODE_VERSION=20.10.0
FROM --platform=amd64 node:${NODE_VERSION}-alpine

ARG FOUNDRY_TOKEN=undefined

ENV FOUNDRY_TOKEN=$FOUNDRY_TOKEN

WORKDIR /app

# Copy package files
COPY package*.json /app/

# Install all dependencies for building
RUN npm ci

# Copy source files
COPY tsconfig.build.json /app/
COPY src/ /app/src/

# Build TypeScript
RUN npm run build

# Remove dev dependencies
RUN npm ci --only=production

# Create a non-root numeric user (must be numeric for compute modules)
RUN adduser --uid 5001 --disabled-password --gecos "" user && \
    chown -R 5001:5001 /app

USER 5001

# Environment setup
ENV NODE_ENV=production

# Verify directory structure
RUN ls -la /app/src/domain && \
    ls -la /app/src/services

# Specify the entrypoint explicitly as required
ENTRYPOINT ["node", "dist/src/computeModule.js"]
````

## File: packages/foundry-tracing-foundations/eslint.config.cjs
````
const {
    defineConfig,
    globalIgnores,
} = require("eslint/config");

const globals = require("globals");
const typescriptEslint = require("@typescript-eslint/eslint-plugin");
const _import = require("eslint-plugin-import");

const {
    fixupPluginRules,
    fixupConfigRules,
} = require("@eslint/compat");

const tsParser = require("@typescript-eslint/parser");
const js = require("@eslint/js");

const {
    FlatCompat,
} = require("@eslint/eslintrc");

const compat = new FlatCompat({
    baseDirectory: __dirname,
    recommendedConfig: js.configs.recommended,
    allConfig: js.configs.all
});

module.exports = defineConfig([{
    languageOptions: {
        globals: {
            ...globals.node,
        },

        parser: tsParser,
        ecmaVersion: 11,
        sourceType: "module",

        parserOptions: {
            project: ["./tsconfig.json"],
        },
    },

    plugins: {
        import: fixupPluginRules(_import),
    },

    settings: {
        "import/resolver": {
            typescript: {
                project: "./tsconfig.json",
                alwaysTryTypes: true           // resolves @types packages
            }
        }
    },

    extends: fixupConfigRules(compat.extends(
        "eslint:recommended",
        "plugin:@typescript-eslint/recommended",
        "plugin:import/errors",
        "plugin:import/warnings",
        "plugin:import/typescript",
    )),

    rules: {
        "no-unused-vars": "off",
        "no-redeclare": "off",
        "no-undef": "off",
        "no-case-declarations": "off",
        "@typescript-eslint/no-explicit-any": "off",
        '@typescript-eslint/no-unsafe-function-type': 'off',
    },
}, globalIgnores(["**/dist", "**/.eslintrc.cjs"])]);
````

## File: packages/foundry-tracing-foundations/jest.config.ts
````typescript
export default {
  displayName: 'foundry-tracing-foundations',
  preset: '../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': [
      'ts-jest',
      {
        tsconfig: '<rootDir>/tsconfig.spec.json',
        useESM: true,
      },
    ],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../coverage/packages/di',
  transformIgnorePatterns: ['/node_modules/(?!(?:@osdk|@codestrap)/)'],
  extensionsToTreatAsEsm: ['.ts'],
  testPathIgnorePatterns: ['<rootDir>/dist/'],
  moduleNameMapper: {
    // Strip `.js` from your TS imports so ESM paths resolve
    '^(\\.{1,2}/.*)\\.js$': '$1',
    '^@xreason/(.*)$': '<rootDir>/src/$1',
    '^@osdk/shared\\.client$':
      '<rootDir>/../../node_modules/@osdk/shared.client/index.js',
    '^@osdk/shared\\.client2$':
      '<rootDir>/../../node_modules/@osdk/shared.client2/index.js',
  },
};
````

## File: packages/foundry-tracing-foundations/package.json
````json
{
  "name": "@codestrap/developer-foundations.foundry-tracing-foundations",
  "version": "1.2.3",
  "description": "## Introduction",
  "license": "MIT",
  "publishConfig": {
    "access": "public"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/doriansmiley/foundry-developer-foundations.git"
  },
  "bugs": {
    "url": "https://github.com/doriansmiley/foundry-developer-foundations/issues"
  },
  "homepage": "https://github.com/doriansmiley/foundry-developer-foundations/tree/master/foundry-tracing-foundations",
  "keywords": [
    "tracing",
    "otel",
    "telemetry",
    "typescript",
    "decorator",
    "palantir",
    "foundry"
  ],
  "author": "Dorian Smiley <dsmiley@codestrap.me>",
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "type": "commonjs",
  "main": "./index.cjs",
  "types": "./src/index.d.ts",
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "lint": "eslint 'src/**/*.{js,ts}'",
    "build": "tsup --no-watch --silent",
    "build:npm": "tsup --config tsup.npm.config.ts --no-watch --silent",
    "build:docker": "npm run build && docker build --build-arg FOUNDRY_TOKEN=${FOUNDRY_TOKEN} -t codestrap/foundry-tracing-foundations .",
    "prepublishOnly": "npm run lint && npm run test && npm run build:npm",
    "publishPackage:dry": "npm publish --dry-run --access public",
    "publishPackage": "npm publish --access public",
    "clean": "rm -rf dist",
    "prebuild": "npm run clean"
  },
  "dependencies": {
    "@osdk/client": "^2.2.1",
    "@osdk/foundry.admin": "^2.19.0",
    "@osdk/oauth": "^1.1.2",
    "@palantir/compute-module": "^0.2.7",
    "@sinclair/typebox": "^0.34.33",
    "eslint-plugin-import": "^2.31.0",
    "inversify": "^7.5.1",
    "tsup": "^8.5.0"
  },
  "devDependencies": {
    "@eslint/compat": "^1.2.9",
    "@eslint/eslintrc": "^3.3.1",
    "@eslint/js": "^9.26.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.15.3",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "cross-env": "^7.0.3",
    "dotenv": "^16.5.0",
    "eslint": "^9.26.0",
    "eslint-import-resolver-typescript": "^4.3.4",
    "globals": "^16.0.0",
    "jest": "^29.7.0",
    "ts-jest": "^29.3.2",
    "ts-node": "^10.9.2",
    "tsconfig-paths": "^4.2.0",
    "typescript": "^5.8.3"
  },
  "engines": {
    "node": ">=20.10.0"
  }
}
````

## File: packages/foundry-tracing-foundations/project.json
````json
{
  "name": "foundry-tracing-foundations",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/foundry-tracing-foundations/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "implicitDependencies": ["foundry-tracing-foundations"],
  "tags": ["type:agent", "type:backend-app"],
  "targets": {
    "build": {
      "executor": "@nx/esbuild:esbuild",
      "options": {
        "outputPath": "dist/packages/foundry-tracing-foundations",
        "main": "packages/foundry-tracing-foundations/src/index.ts",
        "tsConfig": "packages/foundry-tracing-foundations/tsconfig.json",
        "platform": "node",
        "bundle": true,
        "format": ["cjs"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/foundry-tracing-foundations/jest.config.ts"
      }
    }
  }
}
````

## File: packages/foundry-tracing-foundations/README.md
````markdown
# Foundry Tracing Foundations

## Introduction
Foundry Tracing Foundations is a Foundry native implementation of open tracing. Tracing spans are stored in the ontology where Foundry native tooling is used to assemble reports and interactive applications to view application performance.

## Getting Started
1. First download and install the [Foundry Tracing Foundations](#) Marketplace application on your Foundry stack. We are working on mocks for Foundry but have not published them yet. Once the mocks are done you no longer will require a Foundry stack.
1. Run `npm install @codestrap/developer-foundations.foundry-tracing-foundations`
1. Create a `.env` file and set the following values
```
FOUNDRY_STACK_URL=<your stack url>
OSDK_CLIENT_SECRET=<your osdk client secret>
OSDK_CLIENT_ID=<your osdk client id>
OPEN_WEATHER_API_KEY=<an open wheahter API key https://home.openweathermap.org/>
LOG_PREFIX=foundry-developer-foundations
```
1. Implement the `@Trace` and `@TraceSpan` in class instance methods you want to record tracing segments on. Example below.

## Example usage
Usee the class decorators to setup traces. This will cause the main parent trace to be setup and attach all child spans to it. We'll be creating a functional version soon.
```typescript
import { Trace, TraceSpan } from '@codestrap/developer-foundations.foundry-tracing-foundations';

export class DecoratorTest {
    @Trace({
        resource: {
            service_name: 'vickie',
            service_instance_id: 'production',
            telemetry_sdk_name: 'xreason-functions',
            telemetry_sdk_version: '6.1.1',
            host_hostname: 'codestrap.usw-3.palantirfoundry.com',
            host_architecture: 'prod',
        },
        operationName: 'vickieForAutomate',
        kind: 'Server',
        samplingDecision: 'RECORD_AND_SAMPLE',
        samplingRate: 1.0,
        attributes: { endpoint: '/api/v2/ontologies/${client.ontologyRid}/queries/vickieForAutomate/execute' }
    })
    public async testDecorator(): Promise<string> {
        await this.childSegment();
        return 'segments traces';
    }

    @TraceSpan({ operationName: 'loadUser', kind: 'Internal' })
    public async childSegment(): Promise<string> {
        return new Promise((resolve) => {
            setTimeout(() => {
                resolve('test');
            }, 500)
        });
    }
}
```
````

## File: packages/foundry-tracing-foundations/tsconfig.build.json
````json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "lib": ["ES2020"],
    "declaration": true,
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "sourceMap": true,
    "types": ["jest", "node"],
    "baseUrl": ".",
    "paths": {
        "@tracing/*": ["src/*"]
    },
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true
  },
  "include": ["src/**/*", "src/**/*.d.ts",  "jest.config.js"],
  "exclude": ["node_modules", "dist", "ops", "config"],
  "ts-node": {
    "files": true
  }
}
````

## File: packages/foundry-tracing-foundations/tsconfig.json
````json
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "lib": ["ES2020"],
    "declaration": true,
    "outDir": "./dist",
    "rootDir": "./",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "sourceMap": true,
    "types": ["jest", "node"],
    "baseUrl": ".",
    "allowJs": true,
    "experimentalDecorators": true,
    "emitDecoratorMetadata": true
  },
  "include": ["src/**/*", "test/**/*", "src/**/*.d.ts",  "jest.config.js"],
  "exclude": ["node_modules", "dist", "ops", "config"],
  "ts-node": {
    "files": true
  }
}
````

## File: packages/foundry-tracing-foundations/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/services/eia/src/lib/delegates/read.ts
````typescript
import {
  EIAResponse,
  GasScenarioResult,
} from '@codestrap/developer-foundations-types';

async function fetchCaGasPriceFromEIA(): Promise<{
  date: string;
  price: number;
}> {
  const url = new URL(process.env['EIA_BASE_URL']!);
  url.searchParams.set('api_key', process.env['EIA_API_KEY']!);
  url.searchParams.set('frequency', 'weekly');
  url.searchParams.set('data[0]', 'value');
  url.searchParams.set('facets[series][]', process.env['CA_SERIES_ID']!);
  url.searchParams.set('sort[0][column]', 'period');
  url.searchParams.set('sort[0][direction]', 'desc');
  url.searchParams.set('length', '1');

  const res = await fetch(url.toString());
  if (!res.ok) throw new Error(`EIA API call failed: ${res.statusText}`);

  const json = (await res.json()) as EIAResponse;
  const latest = json.response?.data?.[0];
  if (!latest) throw new Error('No data returned from EIA API.');

  return {
    date: latest.period,
    price: parseFloat(latest.value),
  };
}

export async function getCaGasTracker(
  scenarioPrices: number[] = [5, 6, 7, 8],
  caGallonsYear = 13.4e9,
  caGdp = 4.1e12,
  caShareUsGdp = 0.14
): Promise<GasScenarioResult[]> {
  const { date, price: baselinePrice } = await fetchCaGasPriceFromEIA();

  return scenarioPrices.map((p) => {
    const delta = p - baselinePrice;
    const incrementalCost = delta * caGallonsYear;
    const pctCaGdp = (incrementalCost / caGdp) * 100;
    const usGdpDrag = (pctCaGdp * caShareUsGdp) / 100;

    return {
      date,
      baselinePrice: parseFloat(baselinePrice.toFixed(3)),
      scenarioPrice: parseFloat(p.toFixed(2)),
      deltaVsBaseline: parseFloat(delta.toFixed(3)),
      annualIncrementalCostBn: parseFloat((incrementalCost / 1e9).toFixed(2)),
      pctOfCaGdp: parseFloat(pctCaGdp.toFixed(2)),
      impliedUsGdpDrag: parseFloat(usGdpDrag.toFixed(3)),
    };
  });
}

export function getVegaGasTrackerData(results: GasScenarioResult[]) {
  return {
    $schema: 'https://vega.github.io/schema/vega-lite/v5.json',
    description: 'California Gas Price Scenarios - Annual Cost Impact',
    data: {
      name: 'gasPriceScenarios',
      values: results.map((r) => ({
        date: r.date,
        scenario: r.scenarioPrice,
        delta: r.deltaVsBaseline,
        annualCost: r.annualIncrementalCostBn,
        pctOfCaGdp: r.pctOfCaGdp,
        usGdpDrag: r.impliedUsGdpDrag,
      })),
    },
    mark: 'bar',
    encoding: {
      x: {
        field: 'scenario',
        type: 'ordinal',
        title: 'Scenario Price ($/gal)',
      },
      y: {
        field: 'annualCost',
        type: 'quantitative',
        title: 'Annual Incremental Cost ($B)',
      },
      tooltip: [
        { field: 'scenario', type: 'ordinal', title: 'Scenario Price ($/gal)' },
        {
          field: 'annualCost',
          type: 'quantitative',
          title: 'Annual Cost ($B)',
        },
        { field: 'pctOfCaGdp', type: 'quantitative', title: '% of CA GDP' },
        { field: 'usGdpDrag', type: 'quantitative', title: 'US GDP Drag (pp)' },
      ],
    },
  };
}
````

## File: packages/services/eia/src/lib/eiaService.test.ts
````typescript
describe('EIA Service', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/eia/src/lib/eiaService.ts
````typescript
import { EnergyService } from '@codestrap/developer-foundations-types';
import { getCaGasTracker, getVegaGasTrackerData } from './delegates/read';

export const eiaService: EnergyService = {
  read: getCaGasTracker,
  getVegaChartData: getVegaGasTrackerData,
};
````

## File: packages/services/eia/src/index.ts
````typescript
export * from './lib/eiaService';
````

## File: packages/services/eia/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/services/eia/jest.config.ts
````typescript
export default {
  displayName: 'eia',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/services/eia',
};
````

## File: packages/services/eia/package.json
````json
{
  "name": "@codestrap/developer-foundations-services-eia",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/services/eia/project.json
````json
{
  "name": "eia-service",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/services/eia/src",
  "projectType": "library",
  "rootDir": ".",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:service"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/services/eia",
        "main": "packages/services/eia/src/index.ts",
        "tsConfig": "packages/services/eia/tsconfig.lib.json",
        "assets": ["packages/services/eia/*.md"]
      },
      "dependencies": ["types"]
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/services/eia/jest.config.ts"
      }
    }
  }
}
````

## File: packages/services/eia/README.md
````markdown
# eia

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build eia-service` to build the library.

## Running unit tests

Run `nx test eia-service` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/services/eia/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/services/eia/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/services/eia/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/services/google/src/helpers/googleAuth.ts
````typescript
import { google } from 'googleapis';
import { Buffer } from 'buffer';
import { ServiceAccountCredentials } from '@codestrap/developer-foundations-types';

export async function loadServiceAccountFromEnv(): Promise<ServiceAccountCredentials> {
  if (!process.env['GSUITE_SERVICE_ACCOUNT']) {
    throw new Error('GSUITE_SERVICE_ACCOUNT environment variable not set');
  }

  const jsonString = Buffer.from(
    process.env['GSUITE_SERVICE_ACCOUNT'],
    'base64'
  ).toString('utf8');
  const credentials = JSON.parse(jsonString) as ServiceAccountCredentials;

  console.log(' Service account file loaded successfully');
  return credentials;
}

export function makeGoogleAuth(
  credentials: ServiceAccountCredentials,
  scopes: string[],
  user: string
) {
  return new google.auth.GoogleAuth({
    credentials,
    scopes,
    clientOptions: { subject: user },
  });
}
````

## File: packages/services/google/src/lib/__fixtures__/schedule.ts
````typescript
// src/__fixtures__/scheduler.ts

export type FreeBusyCalendars = Record<
    string,
    {
        busy: Array<{ start: string; end: string }>;
    }
>;

/**
 * Singleday, 3 attendees, with overlaps that force a narrow intersection.
 * Window (local PT): 2025-07-22 08:0017:00 (PDT, UTC-7)
 *
 * Busy (all in UTC):
 *  a@corp.com:
 *    17:0018:00Z  (10:0011:00 PT)
 *    21:3022:00Z  (14:3015:00 PT)
 *  b@corp.com:
 *    19:0020:30Z  (12:0013:30 PT)
 *  c@corp.com:
 *    16:3017:00Z  (09:3010:00 PT)
 *    22:0023:00Z  (15:0016:00 PT)
 */
export const fbSingleDayCalendars: FreeBusyCalendars = {
    'a@corp.com': {
        busy: [
            { start: '2025-07-22T17:00:00Z', end: '2025-07-22T18:00:00Z' },
            { start: '2025-07-22T21:30:00Z', end: '2025-07-22T22:00:00Z' },
        ],
    },
    'b@corp.com': {
        busy: [
            { start: '2025-07-22T19:00:00Z', end: '2025-07-22T20:30:00Z' },
        ],
    },
    'c@corp.com': {
        busy: [
            { start: '2025-07-22T16:30:00Z', end: '2025-07-22T17:00:00Z' },
            { start: '2025-07-22T22:00:00Z', end: '2025-07-22T23:00:00Z' },
        ],
    },
};

/**
 * Multiday (2 days) intersection case. Window PT: 20250722 08:00  20250723 17:00
 */
export const fbMultiDayCalendars: FreeBusyCalendars = {
    'a@corp.com': {
        busy: [
            // Day 1
            { start: '2025-07-22T17:00:00Z', end: '2025-07-22T18:00:00Z' }, // 1011 PT
            // Day 2
            { start: '2025-07-23T16:00:00Z', end: '2025-07-23T17:30:00Z' }, // 0910:30 PT
        ],
    },
    'b@corp.com': {
        busy: [
            // Day 1
            { start: '2025-07-22T19:30:00Z', end: '2025-07-22T20:00:00Z' }, // 12:3013:00 PT
            // Day 2
            { start: '2025-07-23T20:00:00Z', end: '2025-07-23T21:00:00Z' }, // 1314 PT
        ],
    },
    'c@corp.com': {
        busy: [
            // Day 1
            { start: '2025-07-22T21:00:00Z', end: '2025-07-22T22:00:00Z' }, // 1415 PT
            // Day 2 (none)
        ],
    },
};

/**
 * Friday window: expect 0 slots when skipFriday=true.
 */
export const fbFridayCalendars: FreeBusyCalendars = {
    'a@corp.com': { busy: [] },
    'b@corp.com': { busy: [] },
};

/**
 * DST boundary (US falls back on Sun Nov 2, 2025 at 02:00 local).
 * Window spans Nov 13, no busy blocks to ensure we only test offsets/slot counts.
 * (We'll just assert we get slots and offsets are either -07:00 or -08:00).
 */
export const fbDSTCalendars: FreeBusyCalendars = {
    'a@corp.com': { busy: [] },
    'b@corp.com': { busy: [] },
};
````

## File: packages/services/google/src/lib/delegates/deriveWindowFromTimeframe.test.ts
````typescript
// src/test/deriveWindowFromTimeframe.test.ts
import { deriveWindowFromTimeframe } from './deriveWindowFromTimeframe';
import { MeetingRequest } from '@codestrap/developer-foundations-types';
import { wallClockToUTC, workingHoursUTCForDate, fridayOfWeek, mondayOfWeek } from '@codestrap/developer-foundations-utils';

describe('deriveWindowFromTimeframe (UTC core, TZ-aware asserts)', () => {
  // Target human timezone to assert against:
  const timezone = 'America/Los_Angeles';
  // const timezone = 'Europe/London';

  // Intended LOCAL business hours in the target tz:
  const LOCAL_START = 8;
  const LOCAL_END = 17;

  beforeAll(() => {
    // Make Nodes own environment predictable; all helpers are TZ-aware anyway.
    process.env.TZ = 'UTC';
  });

  /* -------------------- helpers -------------------- */

  function buildReq(
    overrides: Partial<MeetingRequest>,
    working_hours: { start_hour: number; end_hour: number }
  ): MeetingRequest {
    return {
      participants: ['a@corp.com'],
      subject: 'Test',
      timeframe_context: 'as soon as possible',
      duration_minutes: 30,
      working_hours,            // NOTE: these are UTC hours now
      ...overrides,
    };
  }

  /** Assert a UTC instant displays as Y/M/D HH:mm in the given tz. */
  function expectWallClock(
    dateUTC: Date,
    tz: string,
    y: number, m: number, d: number, hh: number, mm: number
  ) {
    const dtf = new Intl.DateTimeFormat('en-US', {
      timeZone: tz,
      year: 'numeric', month: '2-digit', day: '2-digit',
      hour: '2-digit', minute: '2-digit', hour12: false,
    });
    const parts = Object.fromEntries(dtf.formatToParts(dateUTC).map(p => [p.type, p.value]));
    expect(+parts['year']).toBe(y);
    expect(+parts['month']).toBe(m);
    expect(+parts['day']).toBe(d);
    expect(+parts['hour']).toBe(hh);
    expect(+parts['minute']).toBe(mm);
  }

  /* -------------------- tests -------------------- */

  it('user defined exact date/time: uses the exact minute and step=1 (inside hours)', () => {
    // 10:10 local  UTC payload
    const candidateUTC = wallClockToUTC('2025-07-22T10:10:00', timezone);
    const nowUTC = wallClockToUTC('2025-07-22T09:00:00', timezone);
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);

    const req = buildReq({
      timeframe_context: 'user defined exact date/time',
      localDateString: candidateUTC.toISOString(), // pass UTC instant
      duration_minutes: 30,
    }, hoursUTC);

    const { windowStartLocal, windowEndLocal, slotStepMinutes } =
      deriveWindowFromTimeframe(req, nowUTC);

    expect(slotStepMinutes).toBe(1);
    expectWallClock(windowStartLocal, timezone, 2025, 7, 22, 10, 10);
    expectWallClock(windowEndLocal, timezone, 2025, 7, 22, 10, 40);
  });

  it('user defined exact date/time: clamps start to start_hour if given before-hours time', () => {
    const candidateUTC = wallClockToUTC('2025-07-22T07:15:00', timezone);
    const nowUTC = wallClockToUTC('2025-07-22T06:00:00', timezone);
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);

    const req = buildReq({
      timeframe_context: 'user defined exact date/time',
      localDateString: candidateUTC.toISOString(),
      duration_minutes: 30,
    }, hoursUTC);

    const { windowStartLocal, windowEndLocal, slotStepMinutes } =
      deriveWindowFromTimeframe(req, nowUTC);

    expect(slotStepMinutes).toBe(1);
    expectWallClock(windowStartLocal, timezone, 2025, 7, 22, 8, 0);
    expectWallClock(windowEndLocal, timezone, 2025, 7, 22, 8, 30);
  });

  it('as soon as possible: inside working hours  start = now (clamped), end = Friday 17:00 of same week', () => {
    const nowUTC = wallClockToUTC('2025-07-22T10:05:00', timezone); // Tue
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);
    const req = buildReq({ timeframe_context: 'as soon as possible' }, hoursUTC);

    const { windowStartLocal, windowEndLocal, slotStepMinutes } =
      deriveWindowFromTimeframe(req, nowUTC);

    expect(slotStepMinutes).toBe(30);
    expectWallClock(windowStartLocal, timezone, 2025, 7, 22, 10, 5);

    const expectedFri = fridayOfWeek(nowUTC, timezone);
    expect(windowEndLocal.getTime()).toBe(expectedFri.getTime());
  });

  it('as soon as possible: after hours  next business day 08:00, end = Friday 17:00', () => {
    const nowUTC = wallClockToUTC('2025-07-22T18:10:00', timezone); // Tue after hours
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);
    const req = buildReq({ timeframe_context: 'as soon as possible' }, hoursUTC);

    const { windowStartLocal, windowEndLocal } =
      deriveWindowFromTimeframe(req, nowUTC);

    // next day 08:00 (Wed) in target tz
    expectWallClock(windowStartLocal, timezone, 2025, 7, 23, 8, 0);

    const expectedFri = fridayOfWeek(nowUTC, timezone);
    expect(windowEndLocal.getTime()).toBe(expectedFri.getTime());
  });

  it('as soon as possible: on Saturday  start Monday 08:00, end Friday 17:00 (next week)', () => {
    const nowUTC = wallClockToUTC('2025-07-26T12:00:00', timezone); // Sat
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);
    const req = buildReq({ timeframe_context: 'as soon as possible' }, hoursUTC);

    const { windowStartLocal, windowEndLocal } =
      deriveWindowFromTimeframe(req, nowUTC);

    // Monday 08:00 (2025-07-28)
    expectWallClock(windowStartLocal, timezone, 2025, 7, 28, 8, 0);

    const expectedFri = fridayOfWeek(
      wallClockToUTC('2025-07-28T09:00:00', timezone),
      timezone
    );
    expect(windowEndLocal.getTime()).toBe(expectedFri.getTime());
  });

  it('this week: mid-week  start = clamped now, end = Friday 17:00 this week', () => {
    const nowUTC = wallClockToUTC('2025-07-23T07:10:00', timezone); // Wed before hours
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);
    const req = buildReq({ timeframe_context: 'this week' }, hoursUTC);

    const { windowStartLocal, windowEndLocal } =
      deriveWindowFromTimeframe(req, nowUTC);

    expectWallClock(windowStartLocal, timezone, 2025, 7, 23, 8, 0);
    const expectedFri = fridayOfWeek(nowUTC, timezone);
    expect(windowEndLocal.getTime()).toBe(expectedFri.getTime());
  });

  it('this week: past Friday close  rolls to next week Mon 08:00  Fri 17:00', () => {
    const nowUTC = wallClockToUTC('2025-07-25T18:10:00', timezone); // Fri after hours
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);
    const req = buildReq({ timeframe_context: 'this week' }, hoursUTC);

    const { windowStartLocal, windowEndLocal } =
      deriveWindowFromTimeframe(req, nowUTC);

    const expectedNextMon = mondayOfWeek(
      wallClockToUTC('2025-07-28T00:00:00', timezone),
      timezone
    ); // 2025-07-28 08:00
    expect(windowStartLocal.getTime()).toBe(expectedNextMon.getTime());

    const expectedNextFri = fridayOfWeek(expectedNextMon, timezone);
    expect(windowEndLocal.getTime()).toBe(expectedNextFri.getTime());
  });

  it('next week: Mon 08:00 next week  Fri 17:00 next week', () => {
    const nowUTC = wallClockToUTC('2025-07-23T10:00:00', timezone); // Wed
    const hoursUTC = workingHoursUTCForDate(nowUTC, timezone, LOCAL_START, LOCAL_END);
    const req = buildReq({ timeframe_context: 'next week' }, hoursUTC);

    const { windowStartLocal, windowEndLocal, slotStepMinutes } =
      deriveWindowFromTimeframe(req, nowUTC);

    expect(slotStepMinutes).toBe(30);

    const expectedMon = mondayOfWeek(
      wallClockToUTC('2025-07-28T00:00:00', timezone),
      timezone
    ); // next weeks Monday 08:00
    expect(windowStartLocal.getTime()).toBe(expectedMon.getTime());

    const expectedFri = fridayOfWeek(expectedMon, timezone);
    expect(windowEndLocal.getTime()).toBe(expectedFri.getTime());
  });
});
````

## File: packages/services/google/src/lib/delegates/deriveWindowFromTimeframe.ts
````typescript
import {
  MeetingRequest,
  DerivedWindow,
} from '@codestrap/developer-foundations-types';

/**
 * Derive a scheduling window from a MeetingRequest.
 *
 * Assumptions:
 * - All input instants and strings are UTC.
 * - All computations use UTC getters/setters (host-TZ agnostic).
 *
 * @param req Meeting request
 * @param now "Now" (defaults to system clock; must be a UTC instant)
 */
export function deriveWindowFromTimeframe(
  req: MeetingRequest,
  now?: Date,
): DerivedWindow {
  const {
    timeframe_context,
    working_hours,
    duration_minutes,
    localDateString,
  } = req;
  const stepDefault = 30;

  // If caller didnt supply "now", just use the current UTC instant.
  // Date objects are always absolute instants; well only use UTC accessors below.
  const localNow = new Date(now ?? new Date());

  switch (timeframe_context) {
    case 'user defined exact date/time': {
      const candidateStr = localDateString?.trim();

      if (!candidateStr) {
        throw new Error(
          'timeframe_context "user defined exact date/time" requires a non-empty localDateString (UTC).'
        );
      }

      // ISO without timezone (e.g., 2025-07-22T10:10 or 2025-07-22 10:10[:ss])
      const isoNoTZ = /^\s*\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}(?::\d{2})?\s*$/;

      let candidate: Date;
      if (isoNoTZ.test(candidateStr)) {
        // Interpret as *UTC wall-clock*
        const m = candidateStr.match(
          /^\s*(\d{4})-(\d{2})-(\d{2})[T\s](\d{2}):(\d{2})(?::(\d{2}))?\s*$/
        )!;
        const Y = +m[1], M = +m[2], D = +m[3], h = +m[4], mm = +m[5], s = +(m[6] || '0');
        candidate = new Date(Date.UTC(Y, M - 1, D, h, mm, s));
      } else {
        // Strings with explicit offset are real instants already
        const parsed = new Date(candidateStr);
        if (isNaN(parsed.getTime())) {
          throw new Error(
            `Invalid localDateString for exact meeting time: "${candidateStr}"`
          );
        }
        candidate = parsed;
      }

      // Snap seconds/millis
      candidate.setUTCSeconds(0, 0);

      const windowStartLocal = candidate; // UTC instant
      const windowEndLocal = new Date(
        candidate.getTime() + duration_minutes * 60_000
      );
      const slotStepMinutes = 1;

      const clampedStart = clampToWorkingInstant(
        windowStartLocal,
        working_hours
      );
      const clampedEnd = new Date(
        Math.max(
          clampedStart.getTime() + duration_minutes * 60_000,
          windowEndLocal.getTime()
        )
      );

      return {
        windowStartLocal: clampedStart,
        windowEndLocal: clampedEnd,
        slotStepMinutes,
      };
    }

    case 'as soon as possible': {
      const start = clampToWorkingInstant(localNow, working_hours);
      const endOfSpan = endOfCurrentOrNextWorkWeek(start, working_hours);
      return {
        windowStartLocal: start,
        windowEndLocal: endOfSpan,
        slotStepMinutes: stepDefault,
      };
    }

    case 'this week': {
      const start = clampToWorkingInstant(localNow, working_hours);
      const end = endOfWorkWeek(start, working_hours);
      if (start.getTime() >= end.getTime()) {
        const next = startOfNextWeek(start, working_hours);
        const endNext = endOfWorkWeek(next, working_hours);
        return {
          windowStartLocal: next,
          windowEndLocal: endNext,
          slotStepMinutes: stepDefault,
        };
      }
      return {
        windowStartLocal: start,
        windowEndLocal: end,
        slotStepMinutes: stepDefault,
      };
    }

    case 'next week': {
      const start = startOfNextWeek(localNow, working_hours);
      const end = endOfWorkWeek(start, working_hours);
      return {
        windowStartLocal: start,
        windowEndLocal: end,
        slotStepMinutes: stepDefault,
      };
    }

    default: {
      const start = clampToWorkingInstant(localNow, working_hours);
      const endOfSpan = endOfCurrentOrNextWorkWeek(start, working_hours);
      return {
        windowStartLocal: start,
        windowEndLocal: endOfSpan,
        slotStepMinutes: stepDefault,
      };
    }
  }
}

/* ---------- UTC helpers (no timezones) ---------- */

/**
 * Kept name for compatibility; in UTC mode it simply returns a copy of `ref`.
 */
function nowInTZ(ref: Date): Date {
  return new Date(ref);
}

/** Start of the day (00:00 UTC) */
function startOfDayLocal(d: Date): Date {
  const x = new Date(d);
  x.setUTCHours(0, 0, 0, 0);
  return x;
}

/** Add whole days in UTC */
function addDays(d: Date, days: number): Date {
  const x = new Date(d);
  x.setUTCDate(x.getUTCDate() + days);
  return x;
}

/** Weekend check in UTC (0 Sun .. 6 Sat) */
function isWeekend(d: Date): boolean {
  const dow = d.getUTCDay();
  return dow === 0 || dow === 6;
}

/**
 * Clamp an instant to working hours on that day in UTC.
 * If before start  bump to start; if after end  next business day's start.
 */
function clampToWorkingInstant(
  instant: Date,
  hours: { start_hour: number; end_hour: number }
): Date {
  let x = new Date(instant);

  while (isWeekend(x)) {
    x = startOfDayLocal(addDays(x, 1));
  }

  const start = new Date(x);
  start.setUTCHours(hours.start_hour, 0, 0, 0);

  const end = new Date(x);
  end.setUTCHours(hours.end_hour, 0, 0, 0);

  //  If the end hour is <= start hour in UTC, it means the local end of day
  // spills into the *next* UTC day (e.g., PT 17:00  00:00 UTC next day).
  if (end.getTime() <= start.getTime()) {
    end.setUTCDate(end.getUTCDate() + 1);
  }

  if (x >= end) {
    // move to next business day start (still all-UTC)
    let y = startOfDayLocal(addDays(x, 1));
    while (isWeekend(y)) {
      y = startOfDayLocal(addDays(y, 1));
    }
    y.setUTCHours(hours.start_hour, 0, 0, 0);
    return y;
  }

  if (x < start) return start;

  return x;
}


/** Monday 00:00 UTC of the week containing d (Sun=0..Sat=6) */
function startOfWeekMonday(d: Date): Date {
  const x = startOfDayLocal(d);
  const dow = x.getUTCDay(); // 0 Sun .. 6 Sat
  const delta = dow === 0 ? -6 : 1 - dow; // move to Monday
  return startOfDayLocal(addDays(x, delta));
}

/** Next week's Monday at start_hour UTC */
function startOfNextWeek(
  d: Date,
  hours: { start_hour: number }
): Date {
  const nextMon = addDays(startOfWeekMonday(d), 7);
  nextMon.setUTCHours(hours.start_hour, 0, 0, 0);
  return nextMon;
}

/** Friday end_hour UTC of the week containing d */
/** Friday at end_hour UTC of the week containing d (handles UTC wrap past midnight) */
function endOfWorkWeek(
  d: Date,
  hours: { start_hour: number; end_hour: number }
): Date {
  const mon = startOfWeekMonday(d);
  const fri = addDays(mon, 4); // Mon + 4 = Fri

  // End-of-day on Friday in UTC
  const end = new Date(fri);
  end.setUTCHours(hours.end_hour, 0, 0, 0);

  // If end_hour <= start_hour in UTC, local "end of day" spills into next UTC day
  // (e.g., local 17:00 PT -> 00:00 UTC next day). Push end forward one day.
  const friStart = new Date(fri);
  friStart.setUTCHours(hours.start_hour, 0, 0, 0);
  if (end.getTime() <= friStart.getTime()) {
    end.setUTCDate(end.getUTCDate() + 1);
  }

  return end;
}

function endOfCurrentOrNextWorkWeek(
  start: Date,
  hours: { start_hour: number; end_hour: number }
): Date {
  const end = endOfWorkWeek(start, hours);
  if (start.getTime() >= end.getTime()) {
    return endOfWorkWeek(addDays(start, 7), hours);
  }
  return end;
}
````

## File: packages/services/google/src/lib/delegates/findOptimalMeetingTime.ts
````typescript
import {
  FindOptimalMeetingTimeOutput,
  BusyPeriod,
  OptimalTimeContext,
  TimeSlot,
} from '@codestrap/developer-foundations-types';
import { calendar_v3 } from 'googleapis';

const LOG_PREFIX = 'GSUITE - findOptimalMeetingTime - ';

/* ============================ TZ-ROBUST HELPERS ============================ */

/** Extract Y/M/D/h/m/s in a given TZ for a given instant (host-TZ agnostic) */
function partsInTZ(d: Date, tz: string): {
  year: number; month: number; day: number;
  hour: number; minute: number; second: number;
} {
  const dtf = new Intl.DateTimeFormat('en-US', {
    timeZone: tz,
    year: 'numeric', month: '2-digit', day: '2-digit',
    hour: '2-digit', minute: '2-digit', second: '2-digit',
    hour12: false,
  });
  const p = Object.fromEntries(dtf.formatToParts(d).map(x => [x.type, x.value]));
  return {
    year: +p['year'],
    month: +p['month'],
    day: +p['day'],
    hour: +p['hour'],
    minute: +p['minute'],
    second: +p['second'],
  };
}

/** Interpret a wall-clock Y-M-D h:m:s in tz as a UTC instant (DST-safe) */
function wallClockToUTC(
  year: number, month: number, day: number,
  hour: number, minute: number, second: number,
  tz: string
): Date {
  let utcMs = Date.UTC(year, month - 1, day, hour, minute, second);
  for (let i = 0; i < 3; i++) {
    const got = partsInTZ(new Date(utcMs), tz);
    const gotMs = Date.UTC(got.year, got.month - 1, got.day, got.hour, got.minute, got.second);
    const wantMs = Date.UTC(year, month - 1, day, hour, minute, second);
    const delta = wantMs - gotMs;
    if (delta === 0) break;
    utcMs += delta;
  }
  return new Date(utcMs);
}

/** Local wall-clock parts at the same instant in tz */
function utcToWallClock(d: Date, tz: string) {
  return partsInTZ(d, tz);
}

/** Offset minutes of tz at instant d (positive if tz AHEAD of UTC, negative if behind) */
function offsetAt(d: Date, tz: string): number {
  const p = partsInTZ(d, tz);
  const localAsUTC = Date.UTC(p.year, p.month - 1, p.day, p.hour, p.minute, p.second);
  return Math.round((localAsUTC - d.getTime()) / 60000);
}

/** Midnight of the same day in tz (as a UTC instant) */
function startOfDayTZ(d: Date, tz: string): Date {
  const p = partsInTZ(d, tz);
  return wallClockToUTC(p.year, p.month, p.day, 0, 0, 0, tz);
}

/** Add whole days in tz (DST-safe). Returns midnight of resulting day in tz. */
function addDaysTZ(d: Date, days: number, tz: string): Date {
  const p = partsInTZ(d, tz);
  return wallClockToUTC(p.year, p.month, p.day + days, 0, 0, 0, tz);
}

/** Round up an instant to the next slot boundary in tz */
function roundUpToNextSlotTZ(d: Date, slotMinutes = 30, tz: string): Date {
  const p = partsInTZ(d, tz);
  const rem = p.minute % slotMinutes;
  const add = (rem === 0 && p.second === 0) ? 0 : (slotMinutes - rem);
  return wallClockToUTC(p.year, p.month, p.day, p.hour, p.minute + add, 0, tz);
}

/** RFC3339 string for the SAME instant, formatted in timezone's local clock with offset */
function toISOStringWithTimezone(date: Date, timezone: string): string {
  const off = offsetAt(date, timezone); // minutes
  const p = utcToWallClock(date, timezone);
  const sign = off >= 0 ? '+' : '-';
  const abs = Math.abs(off);
  const pad = (n: number, len = 2) => String(n).padStart(len, '0');
  return `${pad(p.year, 4)}-${pad(p.month)}-${pad(p.day)}T${pad(p.hour)}:${pad(p.minute)}:${pad(p.second)}${sign}${pad(Math.floor(abs / 60))}:${pad(abs % 60)}`;
}

/* ============================ ORIGINAL APIS, FIXED ============================ */

/**
 * Returns the offset (in minutes) for the target time zone on the given date.
 * Positive if the zone is ahead of UTC, negative if behind.
 * Fallback used only if ICU fails (rare).
 */
function getTimeZoneOffset(
  timeZone: string,
  date: Date,
  fallbackOffset?: number
): number {
  try {
    return offsetAt(date, timeZone);
  } catch {
    return fallbackOffset ?? 0;
  }
}

/**
 * Computes meeting start and end times as UTC instants.
 * Interprets ISO-without-offset strings as wall-clock in `timezone`.
 * Relative contexts use working hours and tz-aware day math.
 */
function calculateMeetingTime(
  timeframeContext: string,
  workingHours = { start_hour: 8, end_hour: 17 },
  now = new Date(),
  timezone: string = 'America/Los_Angeles',
  _fallbackOffset?: number,
  skipFridayMeetings = false,
  meetingDuration = 30 // minutes
) {
  // Try exact timestamp
  const parsed = new Date(timeframeContext);
  const isoNoTZ = /^\s*\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}(?::\d{2})?\s*$/;

  if (!isNaN(parsed.getTime())) {
    const hasOffset = /([zZ]|[+\-]\d{2}:?\d{2})\s*$/.test(timeframeContext);
    if (hasOffset) {
      const startTime = new Date(parsed);
      const endTime = new Date(startTime.getTime() + meetingDuration * 60000);
      return { startTime, endTime };
    }
    if (isoNoTZ.test(timeframeContext)) {
      const m = timeframeContext.match(
        /^\s*(\d{4})-(\d{2})-(\d{2})[T\s](\d{2}):(\d{2})(?::(\d{2}))?\s*$/
      )!;
      const [Y, M, D, h, mm, ss] = [+m[1], +m[2], +m[3], +m[4], +m[5], +(m[6] || '0')];
      const startTime = wallClockToUTC(Y, M, D, h, mm, ss, timezone);
      const endTime = new Date(startTime.getTime() + meetingDuration * 60000);
      return { startTime, endTime };
    }
    // Other string formats with no offset are ambiguoustreat as already an instant
    const startTime = new Date(parsed);
    const endTime = new Date(startTime.getTime() + meetingDuration * 60000);
    return { startTime, endTime };
  }

  // Relative contexts: build "now" in tz
  const nowParts = partsInTZ(now, timezone);
  let day0 = startOfDayTZ(now, timezone); // midnight today in tz (UTC instant)

  // If after hours, advance to next day
  if (nowParts.hour >= workingHours.end_hour) {
    day0 = addDaysTZ(day0, 1, timezone);
  }

  // Determine base day considering weekend/next week/friday skip
  const weekdayShort = new Intl.DateTimeFormat('en-US', { timeZone: timezone, weekday: 'short' });
  const dowIndex = (d: Date) => ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'].indexOf(weekdayShort.format(d));
  let baseDay = day0;

  const todayDow = dowIndex(baseDay);
  let step = 0;
  if (skipFridayMeetings && todayDow === 5) step = 3; // Fri -> Mon
  if (todayDow === 6) step = 2;                        // Sat -> Mon
  if (todayDow === 0) step = 1;                        // Sun -> Mon

  if (timeframeContext === 'next week') {
    const d = dowIndex(baseDay);
    const toNextMonday = ((1 - d + 7) % 7) || 7;
    step = toNextMonday;
  }

  if (step) baseDay = addDaysTZ(baseDay, step, timezone);

  // Choose start hour (if we didn't move days and we're before start_hour, use start_hour; otherwise use max(now, start))
  let startHour = workingHours.start_hour;
  if (step === 0 && nowParts.hour > workingHours.start_hour && nowParts.hour < workingHours.end_hour) {
    startHour = nowParts.hour;
  }

  let startTime = wallClockToUTC(
    partsInTZ(baseDay, timezone).year,
    partsInTZ(baseDay, timezone).month,
    partsInTZ(baseDay, timezone).day,
    startHour, 0, 0, timezone
  );

  // Round to slot boundary in tz
  startTime = roundUpToNextSlotTZ(startTime, 30, timezone);
  const endTime = new Date(startTime.getTime() + meetingDuration * 60000);

  return { startTime, endTime };
}

function calculateTimeSlotScore(
  slot: TimeSlot,
  allBusyTimes: BusyPeriod[]
): number {
  let score = 100;
  const hoursFromNow =
    (Date.parse(slot.start) - Date.now()) / (1000 * 60 * 60);
  score -= Math.min(hoursFromNow * 0.5, 20);

  for (const busy of allBusyTimes) {
    const busyStart = Date.parse(busy.start);
    const busyEnd = Date.parse(busy.end);
    const slotStart = Date.parse(slot.start);
    const slotEnd = Date.parse(slot.end);

    const bufferBefore = (slotStart - busyEnd) / 60000;
    const bufferAfter = (busyStart - slotEnd) / 60000;

    if (bufferBefore > 0 && bufferBefore < 30) score -= 10;
    if (bufferAfter > 0 && bufferAfter < 30) score -= 10;
  }

  return Math.max(0, score);
}

/**
 * Formats a date as an ISO string including the correct offset for the given timezone.
 * Shows the same instant with the zone's local wall clock and offset.
 */
function toISOStringWithTimezonePublic(
  date: Date,
  timezone: string
): string {
  return toISOStringWithTimezone(date, timezone);
}

// Helper: check if two time slots overlap (using millis)
function slotsOverlap(
  slot1: { start: string; end: string },
  slot2: { start: string; end: string }
): boolean {
  const a0 = Date.parse(slot1.start), a1 = Date.parse(slot1.end);
  const b0 = Date.parse(slot2.start), b1 = Date.parse(slot2.end);
  return a0 < b1 && b0 < a1;
}

function calculateEventDuration(start: string, end: string): number {
  return (Date.parse(end) - Date.parse(start)) / 60000;
}

/* ============================ MAIN ============================ */

export async function findOptimalMeetingTime(
  calendar: calendar_v3.Calendar,
  context: OptimalTimeContext
): Promise<FindOptimalMeetingTimeOutput> {
  console.log(
    `${LOG_PREFIX} Finding optimal meeting time for:\n : ${JSON.stringify(
      context,
      null,
      2
    )}`
  );

  try {
    const duration = context.duration_minutes || 30;
    const workingHours = context.working_hours || { start_hour: 8, end_hour: 17 };

    // Build initial window (UTC instants)
    const { startTime, endTime } = calculateMeetingTime(
      context.timeframe_context,
      workingHours,
      new Date(),
      context.timezone
    );

    // --- STEP 1: Fetch events (events.list) ---
    const eventTimeSlots: TimeSlot[] = [];
    const participants = [...context.participants];

    for (const participant of participants) {
      const params = {
        calendarId: participant,
        timeMin: toISOStringWithTimezonePublic(startTime, context.timezone!),
        timeMax: toISOStringWithTimezonePublic(endTime, context.timezone!),
        singleEvents: true,
      };
      const eventsResponse = await calendar.events.list(params);
      const events = eventsResponse.data.items || [];
      for (const event of events) {
        if (
          event.status !== 'cancelled' &&
          event.start?.dateTime &&
          event.end?.dateTime
        ) {
          const dur = calculateEventDuration(event.start.dateTime, event.end.dateTime);
          if (dur > 0) {
            eventTimeSlots.push({
              attendees: JSON.stringify(event.attendees),
              id: event.iCalUID || `${event.id}-${event.start.dateTime}`,
              start: event.start.dateTime,
              end: event.end.dateTime,
              startLocalDate: new Date(event.start.dateTime).toString(),
              endLocalDate: new Date(event.end.dateTime).toString(),
              duration: dur,
            });
          }
        }
      }
    }

    // --- STEP 2: freebusy for business hours today in tz ---
    // Compute today's working window in tz, then format with tz offset
    const dayStart = startOfDayTZ(startTime, context.timezone!); // base day from startTime
    const pDay = partsInTZ(dayStart, context.timezone!);
    const startFreeBusyTime = wallClockToUTC(pDay.year, pDay.month, pDay.day, workingHours.start_hour, 0, 0, context.timezone!);
    const lastTimeLocal = wallClockToUTC(pDay.year, pDay.month, pDay.day, workingHours.end_hour, 0, 0, context.timezone!);

    const freeBusyRequest = {
      timeMin: toISOStringWithTimezonePublic(startFreeBusyTime, context.timezone!),
      timeMax: toISOStringWithTimezonePublic(lastTimeLocal, context.timezone!),
      items: participants.map((email) => ({ id: email })),
      timeZone: 'UTC',
    };

    const freeBusyResponse = await calendar.freebusy.query({
      requestBody: freeBusyRequest,
    });

    const busySlots: BusyPeriod[] = [];
    const calendars = freeBusyResponse.data.calendars || {};
    for (const email in calendars) {
      const busyPeriods = calendars[email].busy || [];
      for (const period of busyPeriods) {
        if (period.start && period.end) {
          busySlots.push({ start: period.start, end: period.end });
        }
      }
    }

    // --- STEP 3: Filter freebusy that overlap with events.list ---
    const filteredFreeBusySlots = busySlots.filter((fbSlot) => {
      return !eventTimeSlots.some((eventSlot) =>
        slotsOverlap(
          { start: eventSlot.start, end: eventSlot.end },
          { start: fbSlot.start, end: fbSlot.end }
        )
      );
    });

    // Merge & dedupe by instant keys
    const seen = new Set<string>();
    const allBusyTimes: BusyPeriod[] = [
      ...eventTimeSlots,
      ...filteredFreeBusySlots,
    ].filter((slot) => {
      const key = `${Date.parse(slot.start)}-${Date.parse(slot.end)}`;
      if (seen.has(key)) return false;
      seen.add(key);
      return true;
    });

    // Sort chronologically
    allBusyTimes.sort((a, b) => Date.parse(a.start) - Date.parse(b.start));

    // --- STEP 4: Walk through available slots within today's business window ---
    const availableSlots: TimeSlot[] = [];

    // currentTime starts at now (rounded) but not before startTime
    let currentTime = roundUpToNextSlotTZ(new Date(), 30, context.timezone!);
    if (currentTime < startTime) currentTime = new Date(startTime);

    // We'll iterate within today's business window; if we need to roll over, recompute window
    let windowStart = startFreeBusyTime;
    let windowEnd = lastTimeLocal;

    while (currentTime < windowEnd) {
      // Recompute local hour each iteration in tz
      const lp = partsInTZ(currentTime, context.timezone!);
      const localHour = lp.hour;

      if (localHour >= workingHours.start_hour && localHour < workingHours.end_hour) {
        const slotStart = new Date(currentTime);
        const slotEnd = new Date(currentTime.getTime() + duration * 60000);

        let isAvailable = true;
        for (const busy of allBusyTimes) {
          const busyStart = Date.parse(busy.start);
          const busyEnd = Date.parse(busy.end);
          if (slotStart.getTime() < busyEnd && slotEnd.getTime() > busyStart) {
            isAvailable = false;
            currentTime = roundUpToNextSlotTZ(new Date(busyEnd), 30, context.timezone!);
            break;
          }
        }

        if (isAvailable) {
          const slot: TimeSlot = {
            start: toISOStringWithTimezonePublic(slotStart, context.timezone!),
            end: toISOStringWithTimezonePublic(slotEnd, context.timezone!),
          };
          slot.score = calculateTimeSlotScore(slot, allBusyTimes);
          availableSlots.push(slot);
          currentTime = new Date(currentTime.getTime() + 30 * 60000);
        }
      } else {
        // Move to next day start in tz and recompute window
        const nextDay0 = addDaysTZ(currentTime, 1, context.timezone!);
        const p = partsInTZ(nextDay0, context.timezone!);
        windowStart = wallClockToUTC(p.year, p.month, p.day, workingHours.start_hour, 0, 0, context.timezone!);
        windowEnd = wallClockToUTC(p.year, p.month, p.day, workingHours.end_hour, 0, 0, context.timezone!);
        currentTime = new Date(windowStart);
      }
    }

    const suggestedTimes = availableSlots
      .sort((a, b) => (b.score || 0) - (a.score || 0))
      .slice(0, 5)
      .map((slot) => ({ ...slot, score: slot.score || 0 }));

    const message =
      suggestedTimes.length > 0
        ? `Found ${suggestedTimes.length} optimal time slots.`
        : 'No available time slots found';

    console.log(
      `${LOG_PREFIX} Found times for:\n  participants: ${JSON.stringify(
        context.participants,
        null,
        2
      )}\n  timeframe: ${JSON.stringify(
        { suggested_times: suggestedTimes, message },
        null,
        2
      )}`
    );

    return { suggested_times: suggestedTimes, message };
  } catch (error) {
    console.error(
      `${LOG_PREFIX} Finding optimal meeting time failed:\n  message: ${error instanceof Error ? error.message : error
      }\n  stack: ${error instanceof Error ? error.stack : ''}`,
      { response: (error as any).response?.data }
    );
    throw error;
  }
}
````

## File: packages/services/google/src/lib/delegates/findOptimalMeetingTime.v2.ts
````typescript
// scheduler.ts
import { calendar_v3 } from 'googleapis';
import { partsInTZ, wallClockToUTC } from '@codestrap/developer-foundations-utils';

type Busy = { start: string; end: string };
export type Slot = { start: string; end: string; score?: number };
type WorkingHoursUTC = { start_hour: number; end_hour: number };

export type FindArgs = {
  calendar: calendar_v3.Calendar;
  attendees: string[];
  timezone: string;                 // IANA, e.g. "America/Los_Angeles"
  windowStartUTC: Date;             // UTC instant
  windowEndUTC: Date;               // UTC instant
  durationMinutes: number;
  workingHours: WorkingHoursUTC;    // PRECOMPUTED UTC hours for that day (from workingHoursUTCForDate)
  slotStepMinutes?: number;         // default 30
  skipFriday?: boolean;             // default false
};

export async function findOptimalMeetingTimeV2({
  calendar,
  attendees,
  timezone,
  windowStartUTC,
  windowEndUTC,
  durationMinutes,
  workingHours,          // UTC hours (already localized for that date)
  slotStepMinutes = 30,
  skipFriday = false,
}: FindArgs): Promise<Slot[]> {
  // 1) FreeBusy in UTC
  const fb = await calendar.freebusy.query({
    requestBody: {
      timeMin: windowStartUTC.toISOString(),
      timeMax: windowEndUTC.toISOString(),
      timeZone: 'UTC',
      items: attendees.map((id) => ({ id })),
    },
  });

  const calendars = fb.data.calendars ?? {};
  const allBusy: Busy[] = [];
  for (const calId in calendars) {
    const periods = calendars[calId]?.busy ?? [];
    for (const p of periods) {
      if (p.start && p.end && !isNaN(Date.parse(p.start)) && !isNaN(Date.parse(p.end))) {
        allBusy.push({ start: p.start, end: p.end });
      }
    }
  }
  const mergedBusy = mergeBusyIntervals(allBusy);

  // 2) Build per-day working windows in UTC, iterating calendar days in `timezone`
  const dailyWorkWindowsUTC = buildWorkingWindowsUTCFromUTCBounds(
    windowStartUTC,
    windowEndUTC,
    timezone,
    workingHours,
    skipFriday
  );

  // 3) Subtract busy from those windows (still UTC)
  const freeIntervals = subtractBusyFromWindows(dailyWorkWindowsUTC, mergedBusy);

  // 4) Slice into candidate slots, score, and format as zoned ISO with HH:MM
  const slots = sliceIntoSlots(freeIntervals, durationMinutes, slotStepMinutes)
    .map((s) => ({
      start: toZonedISOString(s.start, timezone),
      end: toZonedISOString(s.end, timezone),
      score: simpleHeuristicScore(s.start),
    }))
    .sort((a, b) => (b.score ?? 0) - (a.score ?? 0));

  return slots;
}

/* ======================= UTC day-iteration using your utils ======================= */

type Interval = { start: Date; end: Date };

/**
 * Iterate calendar days in `tz` between [windowStartUTC, windowEndUTC], and for each day
 * construct the working window using **UTC hours** already localized for that date.
 * (If end_hour <= start_hour, we roll the end into the next UTC day.)
 */
function buildWorkingWindowsUTCFromUTCBounds(
  windowStartUTC: Date,
  windowEndUTC: Date,
  tz: string,
  hoursUTC: WorkingHoursUTC,
  skipFriday: boolean
): Interval[] {
  const result: Interval[] = [];

  const pad = (n: number, len = 2) => String(n).padStart(len, '0');

  // tz-midnight for start and end (as UTC instants)
  const sp = partsInTZ(windowStartUTC, tz);
  const ep = partsInTZ(windowEndUTC, tz);
  let dayUTC = wallClockToUTC(`${sp.year}-${pad(sp.month)}-${pad(sp.day)}T00:00:00`, tz);
  const lastDayUTC = wallClockToUTC(`${ep.year}-${pad(ep.month)}-${pad(ep.day)}T00:00:00`, tz);

  const clipStart = new Date(windowStartUTC);
  const clipEnd = new Date(windowEndUTC);

  while (dayUTC.getTime() <= lastDayUTC.getTime()) {
    // weekday in target tz
    const w = new Intl.DateTimeFormat('en-US', { timeZone: tz, weekday: 'short' }).format(dayUTC);
    const isWeekend = w === 'Sat' || w === 'Sun';
    const isFriday = w === 'Fri';

    if (!isWeekend && !(skipFriday && isFriday)) {
      // Build day window using **UTC hours**
      const dayStart = new Date(dayUTC);
      dayStart.setUTCHours(hoursUTC.start_hour, 0, 0, 0);

      let dayEnd = new Date(dayUTC);
      dayEnd.setUTCHours(hoursUTC.end_hour, 0, 0, 0);
      if (dayEnd.getTime() <= dayStart.getTime()) {
        // end spills into next UTC day (common for US timezones)
        dayEnd = new Date(dayEnd.getTime() + 24 * 60 * 60 * 1000);
      }

      const start = new Date(Math.max(dayStart.getTime(), clipStart.getTime()));
      const end = new Date(Math.min(dayEnd.getTime(), clipEnd.getTime()));

      if (start < end) result.push({ start, end });
    }

    // advance to next tz-midnight
    const cur = partsInTZ(dayUTC, tz);
    dayUTC = wallClockToUTC(
      `${cur.year}-${pad(cur.month)}-${pad(cur.day + 1)}T00:00:00`,
      tz
    );
  }

  return result;
}

/* =========================== Busy & slotting (UTC) =========================== */

function mergeBusyIntervals(busy: Busy[]): Busy[] {
  if (!busy.length) return [];
  const sorted = busy
    .map((b) => ({ start: new Date(b.start), end: new Date(b.end) }))
    .filter((b) => !isNaN(b.start.getTime()) && !isNaN(b.end.getTime()))
    .sort((a, b) => a.start.getTime() - b.start.getTime());

  const merged: { start: Date; end: Date }[] = [];
  let cur = sorted[0];
  for (let i = 1; i < sorted.length; i++) {
    const next = sorted[i];
    if (next.start <= cur.end) {
      if (next.end > cur.end) cur.end = next.end;
    } else {
      merged.push(cur);
      cur = next;
    }
  }
  merged.push(cur);
  return merged.map((m) => ({
    start: m.start.toISOString(),
    end: m.end.toISOString(),
  }));
}

function subtractBusyFromWindows(windows: Interval[], busy: Busy[]): Interval[] {
  const sortedWindows = windows.slice().sort((a, b) => a.start.getTime() - b.start.getTime());
  const busyUTC = busy
    .map((b) => ({ start: new Date(b.start), end: new Date(b.end) }))
    .filter((b) => !isNaN(b.start.getTime()) && !isNaN(b.end.getTime()))
    .sort((a, b) => a.start.getTime() - b.start.getTime());

  const result: Interval[] = [];
  let i = 0;

  for (const win of sortedWindows) {
    let cursor = new Date(win.start);
    while (i < busyUTC.length && busyUTC[i].end <= win.start) i++;

    for (let j = i; j < busyUTC.length; j++) {
      const b = busyUTC[j];
      if (b.start >= win.end) break;
      if (b.end <= cursor) continue;
      if (b.start > cursor) result.push({ start: cursor, end: new Date(b.start) });
      cursor = new Date(Math.max(cursor.getTime(), b.end.getTime()));
    }

    if (cursor < win.end) result.push({ start: cursor, end: new Date(win.end) });
  }

  return mergeAdjacent(result);
}

function mergeAdjacent(intervals: Interval[]): Interval[] {
  if (!intervals.length) return [];
  const sorted = intervals.slice().sort((a, b) => a.start.getTime() - b.start.getTime());
  const merged: Interval[] = [];
  let cur = sorted[0];
  for (let i = 1; i < sorted.length; i++) {
    const next = sorted[i];
    if (next.start <= cur.end) {
      if (next.end > cur.end) cur.end = next.end;
    } else {
      merged.push(cur);
      cur = next;
    }
  }
  merged.push(cur);
  return merged;
}

function sliceIntoSlots(free: Interval[], durationMinutes: number, stepMinutes: number): Interval[] {
  const slots: Interval[] = [];
  const durMs = durationMinutes * 60_000;
  const stepMs = stepMinutes * 60_000;

  for (const f of free) {
    let t = roundUpToStepUTC(f.start, stepMinutes); // round in UTC
    while (t.getTime() + durMs <= f.end.getTime()) {
      const end = new Date(t.getTime() + durMs);
      slots.push({ start: new Date(t), end });
      t = new Date(t.getTime() + stepMs);
    }
  }
  return slots;
}

function roundUpToStepUTC(d: Date, stepMinutes: number): Date {
  const t = new Date(d.getTime());
  const mins = t.getUTCMinutes();
  const rem = mins % stepMinutes;
  if (rem !== 0) {
    t.setUTCMinutes(mins - rem + stepMinutes, 0, 0);
  } else {
    t.setUTCSeconds(0, 0);
  }
  return t;
}

/* =============================== Scoring/formatting =============================== */

function simpleHeuristicScore(startUTC: Date): number {
  const hoursFromNow = (startUTC.getTime() - Date.now()) / 3_600_000;
  return Math.max(0, 100 - Math.min(hoursFromNow * 0.5, 20));
}

/** Render the SAME instant as local time in `tz` with HH:MM suffix (e.g. 2025-07-22T10:30:00-07:00) */
function toZonedISOString(utc: Date, tz: string): string {
  const p = partsInTZ(utc, tz); // local Y/M/D/H/M/S in tz
  const offMin = offsetMinutesForInstantInTZ(utc, tz);
  const sign = offMin >= 0 ? '+' : '-';
  const abs = Math.abs(offMin);
  const pad = (n: number, len = 2) => String(n).padStart(len, '0');
  return `${pad(p.year, 4)}-${pad(p.month)}-${pad(p.day)}T${pad(p.hour)}:${pad(p.minute)}:${pad(p.second)}${sign}${pad(Math.floor(abs / 60))}:${pad(abs % 60)}`;
}

function offsetMinutesForInstantInTZ(utc: Date, tz: string): number {
  const p = partsInTZ(utc, tz);
  const asIfUTC = Date.UTC(p.year, p.month - 1, p.day, p.hour, p.minute, p.second);
  return Math.round((asIfUTC - utc.getTime()) / 60000);
}
````

## File: packages/services/google/src/lib/delegates/findOptimalMeetingTimeV2.e2e.test.ts
````typescript
import { google } from 'googleapis';

import { partsInTZ } from '@codestrap/developer-foundations-utils';
import { OfficeServiceV2 } from '@codestrap/developer-foundations-types';
import { makeGSuiteClientV2 } from '../gsuiteClient.v2';

if (!process.env.E2E) {
    test.skip('e2e test skipped in default run', () => {
        // won't run
    });
} else {
    describe('findOptimalMeetingTimeV2 E2E tests', () => {

        let client: OfficeServiceV2;

        beforeAll(async () => {
            // Force Node's wall-clock to PT so Date('YYYY-MM-DDTHH:mm:ss') is deterministic.
            process.env.TZ = 'America/Los_Angeles';
            client = await makeGSuiteClientV2(process.env.OFFICE_SERVICE_ACCOUNT);
        });

        afterEach(() => {
            jest.clearAllMocks();
        });

        it('should get an exact time within PT working hours', async () => {
            // LA wall-clock "YYYY-MM-DDT10:30:00" one week from now:
            const p = partsInTZ(new Date(), 'America/Los_Angeles');
            const pad = (n: number, len = 2) => String(n).padStart(len, '0');
            const localDateString = `${p.year}-${pad(p.month)}-${pad(p.day + 7)}T10:30:00`;

            const slots = await client.getAvailableMeetingTimes({
                participants: ['dsmiley@codestrap.me'],
                subject: 'Circle Up',
                timeframe_context: 'user defined exact date/time',
                localDateString,
                duration_minutes: 30,
                working_hours: {
                    start_hour: 8,
                    end_hour: 17,
                },
            });

            expect(slots.suggested_times.length).toBeGreaterThan(0);
        }, 60000);

    });
}
````

## File: packages/services/google/src/lib/delegates/findOptimalMeetingTimeV2.test.ts
````typescript
import { google } from 'googleapis';

import {
  fbSingleDayCalendars,
  fbMultiDayCalendars,
  fbFridayCalendars,
  fbDSTCalendars,
} from '../__fixtures__/schedule';

import { findOptimalMeetingTimeV2, Slot } from './findOptimalMeetingTime.v2';
import {
  dayInTZ,
  wallClockToUTC,
  workingHoursUTCForDate,
} from '@codestrap/developer-foundations-utils';

// ------------------------------
// Inline mocks (auth INCLUDED)
// ------------------------------
let currentCalendarsFixture: Record<
  string,
  { busy: Array<{ start: string; end: string }> }
> = fbSingleDayCalendars;

jest.mock('googleapis', () => ({
  ...jest.requireActual('googleapis'),
  google: {
    calendar: jest.fn(() => {
      return {
        events: {
          list: jest.fn(() => Promise.resolve({ data: { items: [] } })), // not used but kept
        },
        freebusy: {
          query: jest.fn((params: any) => {
            const { timeMin, timeMax } = params.requestBody;
            return Promise.resolve({
              data: {
                kind: 'calendar#freeBusy',
                timeMin,
                timeMax,
                calendars: currentCalendarsFixture,
              },
            });
          }),
        },
      };
    }),
    auth: {
      GoogleAuth: jest.fn().mockImplementation(() => {
        return {
          getClient: jest.fn().mockResolvedValue({
            getRequestHeaders: jest.fn().mockResolvedValue({}),
          }),
        };
      }),
    },
  },
}));

describe('findOptimalMeetingTimeV2 (UTC bounds + PT semantics)', () => {
  const timezone = 'America/Los_Angeles';
  const durationMinutes = 30;
  const slotStepMinutes = 30;

  let calendar: any;

  beforeAll(() => {
    // Keep wall-clock deterministic for any Date(...) literals used in helpers, etc.
    process.env.TZ = 'America/Los_Angeles';
  });

  beforeEach(() => {
    // IMPORTANT: create the calendar AFTER jest.mock so it uses the mocked impl
    calendar = google.calendar('v3') as any;
  });

  afterEach(() => {
    jest.clearAllMocks();
  });

  // ---------------- EXISTING TESTS (updated to use wallClockToUTC) ----------------

  it('single-day, 3 attendees: outputs slots that do not intersect busy times and lie within PT working hours', async () => {
    currentCalendarsFixture = fbSingleDayCalendars;

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone); // PT  UTC
    const windowEndUTC = wallClockToUTC('2025-07-22T17:00:00', timezone); // PT  UTC
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(fbSingleDayCalendars),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    assertNoOverlap(slots, flattenBusy(fbSingleDayCalendars));
    assertWithinLocalWorkingHours(slots, { start_hour: 8, end_hour: 17 });
  });

  it('multi-day window: handles union of busy blocks across attendees and days', async () => {
    currentCalendarsFixture = fbMultiDayCalendars;

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone); // PT  UTC
    const windowEndUTC = wallClockToUTC('2025-07-23T17:00:00', timezone); // PT  UTC
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(fbMultiDayCalendars),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    assertNoOverlap(slots, flattenBusy(fbMultiDayCalendars));
    assertWithinLocalWorkingHours(slots, { start_hour: 8, end_hour: 17 });
  });

  it('skipFriday=true  zero slots for a Friday-only window', async () => {
    currentCalendarsFixture = fbFridayCalendars;

    const windowStartUTC = wallClockToUTC('2025-07-25T08:00:00', timezone); // Fri PT
    const windowEndUTC = wallClockToUTC('2025-07-25T17:00:00', timezone); // PT
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(fbFridayCalendars),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: true,
    });

    expect(slots).toHaveLength(0);
  });

  it('DST boundary spanning Nov 13 2025: returns slots with proper -07:00 or -08:00 offsets', async () => {
    currentCalendarsFixture = fbDSTCalendars;

    const windowStartUTC = wallClockToUTC('2025-11-01T08:00:00', timezone); // PDT
    const windowEndUTC = wallClockToUTC('2025-11-03T17:00:00', timezone); // PST
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(fbDSTCalendars),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    const offsetRegex = /(-07:00|-08:00)$/;
    for (const s of slots) {
      expect(offsetRegex.test(s.start) || offsetRegex.test(s.end)).toBeTruthy();
    }
  });

  it('works with hardcoded UTC instants (no wallClockToUTC usage)', async () => {
    currentCalendarsFixture = fbSingleDayCalendars;

    // July in PT is UTC-7  08:00 PT == 15:00Z, 09:00 PT == 16:00Z
    const windowStartUTC = new Date('2025-07-22T15:00:00Z');
    const windowEndUTC = new Date('2025-07-22T16:00:00Z');

    // PT business hours 0817  in UTC theyre 15  00 (end wraps to next UTC day)
    const workingHours = { start_hour: 15, end_hour: 0 };

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(fbSingleDayCalendars),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    const offsetRegex = /(-07:00|-08:00)$/;
    for (const s of slots) {
      expect(offsetRegex.test(s.start)).toBe(true);
    }
  });

  // ---------------- ADDED EDGE-CASE TESTS ----------------
  it('rounds up first slot to step boundary and supports step < duration', async () => {
    // Working window 08:0010:00. Leave free 08:0509:10 local.
    // Block 1: 08:0008:05 PT => 15:0015:05Z (PDT, -07:00)
    // Block 2: 09:1010:00 PT => 16:1017:00Z
    currentCalendarsFixture = {
      'a@corp.com': {
        busy: [
          { start: '2025-07-22T15:00:00Z', end: '2025-07-22T15:05:00Z' },
          { start: '2025-07-22T16:10:00Z', end: '2025-07-22T17:00:00Z' },
        ],
      },
    };

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone); // PT
    const windowEndUTC = wallClockToUTC('2025-07-22T10:00:00', timezone); // PT
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes: 30,
      workingHours,
      slotStepMinutes: 15,
      skipFriday: false,
    });

    // Free gap 08:0509:10 with 30-min duration and 15-min step  08:1508:45, 08:3009:00.
    expect(slots.length).toBeGreaterThanOrEqual(2);
    expect(slots[0].start.slice(11, 16)).toBe('08:15');
    expect(slots[0].end.slice(11, 16)).toBe('08:45');
    expect(slots[1].start.slice(11, 16)).toBe('08:30');
    expect(slots[1].end.slice(11, 16)).toBe('09:00');
    assertNoOverlap(slots, flattenBusy(currentCalendarsFixture));
  });

  it('returns 0 when all free gaps are shorter than duration', async () => {
    // Only free 12:0012:20 local; duration=30  0 slots.
    // Busy: 08:0012:00 PT (15:0019:00Z) and 12:2017:00 PT (19:2000:00Z next day)
    currentCalendarsFixture = {
      'a@corp.com': {
        busy: [
          { start: '2025-07-22T15:00:00Z', end: '2025-07-22T19:00:00Z' },
          { start: '2025-07-22T19:20:00Z', end: '2025-07-23T00:00:00Z' },
        ],
      },
    };

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone);
    const windowEndUTC = wallClockToUTC('2025-07-22T17:00:00', timezone);
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes: 30,
      workingHours,
      slotStepMinutes: 10,
      skipFriday: false,
    });

    expect(slots).toHaveLength(0);
  });

  it('skips weekends even across multi-day spans', async () => {
    currentCalendarsFixture = { 'a@corp.com': { busy: [] } };

    const windowStartUTC = wallClockToUTC('2025-07-26T08:00:00', timezone); // Sat PT
    const windowEndUTC = wallClockToUTC('2025-07-28T17:00:00', timezone); // Mon PT
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    // All slots should be Monday (getDay()==1) in PT
    for (const s of slots) expect(dayInTZ(s.start, timezone)).toBe(1);
  });

  it('skipFriday=true removes Friday slots in mixed ThuFri range', async () => {
    currentCalendarsFixture = { 'a@corp.com': { busy: [] } };

    const windowStartUTC = wallClockToUTC('2025-07-24T08:00:00', timezone); // Thu PT
    const windowEndUTC = wallClockToUTC('2025-07-25T17:00:00', timezone); // Fri PT
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: true,
    });

    expect(slots.length).toBeGreaterThan(0);
    for (const s of slots) expect(dayInTZ(s.start, timezone)).toBe(4); // Thursday
  });

  it('honors windowStart inside the working day (rounds to step)', async () => {
    currentCalendarsFixture = { 'a@corp.com': { busy: [] } };

    const windowStartUTC = wallClockToUTC('2025-07-22T10:10:00', timezone); // PT
    const windowEndUTC = wallClockToUTC('2025-07-22T12:00:00', timezone); // PT
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes: 30,
      workingHours,
      slotStepMinutes: 30,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    expect(slots[0].start.slice(11, 16)).toBe('10:30');
  });

  it('returns 0 on a day fully covered by busy', async () => {
    // Busy covers 08:0017:00 PT  15:00Z  00:00Z next day
    currentCalendarsFixture = {
      'a@corp.com': {
        busy: [{ start: '2025-07-22T15:00:00Z', end: '2025-07-23T00:00:00Z' }],
      },
    };

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone);
    const windowEndUTC = wallClockToUTC('2025-07-22T17:00:00', timezone);
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots).toHaveLength(0);
  });

  it('merges overlapping and unsorted busy blocks correctly', async () => {
    // Two overlapping blocks around 10:0011:00 PT.
    currentCalendarsFixture = {
      'a@corp.com': {
        busy: [
          { start: '2025-07-22T17:15:00Z', end: '2025-07-22T18:00:00Z' }, // 10:1511:00 PT
          { start: '2025-07-22T17:00:00Z', end: '2025-07-22T17:30:00Z' }, // 10:0010:30 PT
        ],
      },
    };

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone);
    const windowEndUTC = wallClockToUTC('2025-07-22T17:00:00', timezone);
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    assertNoOverlap(slots, flattenBusy(currentCalendarsFixture));
  });

  it('scores earlier slots higher (non-increasing sequence)', async () => {
    currentCalendarsFixture = { 'a@corp.com': { busy: [] } };

    const windowStartUTC = wallClockToUTC('2025-07-22T08:00:00', timezone);
    const windowEndUTC = wallClockToUTC('2025-07-22T17:00:00', timezone);
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone,
      windowStartUTC,
      windowEndUTC,
      durationMinutes,
      workingHours,
      slotStepMinutes,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(5);
    for (let i = 1; i < slots.length; i++) {
      expect((slots[i - 1].score ?? 0) >= (slots[i].score ?? 0)).toBe(true);
    }
  });

  it('DST spring-forward (Mar 710, 2025): shows -08:00 before and -07:00 after', async () => {
    // No busy; verify offsets across DST change (Sun Mar 9, 2025).
    // Windows skip weekend; this range yields Fri (PST, -08:00) and Mon (PDT, -07:00).
    currentCalendarsFixture = { 'a@corp.com': { busy: [] } };

    const windowStartUTC = wallClockToUTC('2025-03-07T08:00:00', timezone); // Fri (PST)
    const windowEndUTC = wallClockToUTC('2025-03-10T17:00:00', timezone); // Mon (PDT)
    const workingHours = workingHoursUTCForDate(windowStartUTC, timezone, 8, 17);

    const slots = await findOptimalMeetingTimeV2({
      calendar,
      attendees: Object.keys(currentCalendarsFixture),
      timezone: 'America/Los_Angeles',
      windowStartUTC,
      windowEndUTC,
      durationMinutes: 30,
      workingHours,
      slotStepMinutes: 30,
      skipFriday: false,
    });

    expect(slots.length).toBeGreaterThan(0);
    const hasMinus08 = slots.some(
      (s) => /-08:00$/.test(s.start) || /-08:00$/.test(s.end)
    ); // Fri
    const hasMinus07 = slots.some(
      (s) => /-07:00$/.test(s.start) || /-07:00$/.test(s.end)
    ); // Mon
    expect(hasMinus08 && hasMinus07).toBe(true);
  });
});

/* ---------------- helpers (local to the spec) ---------------- */

function flattenBusy(
  calendars: Record<string, { busy: Array<{ start: string; end: string }> }>
) {
  return Object.values(calendars).flatMap((c) => c.busy);
}

/**
 * Overlap check that treats boundary equality (slotEnd === busyStart, slotStart === busyEnd) as NOT overlapping.
 */
function assertNoOverlap(
  slots: Slot[],
  busy: Array<{ start: string; end: string }>
) {
  const overlaps = slots.filter((s) => {
    const sStart = new Date(s.start).getTime();
    const sEnd = new Date(s.end).getTime();
    return busy.some((b) => {
      const bStart = new Date(b.start).getTime();
      const bEnd = new Date(b.end).getTime();
      // real overlap only when they strictly cross
      return sStart < bEnd && sEnd > bStart;
    });
  });

  expect(overlaps).toHaveLength(0);
}

function assertWithinLocalWorkingHours(
  slots: Slot[],
  hours: { start_hour: number; end_hour: number }
) {
  for (const s of slots) {
    const startLocalHour = parseInt(s.start.substring(11, 13), 10);
    const endLocalHour = parseInt(s.end.substring(11, 13), 10);
    expect(startLocalHour).toBeGreaterThanOrEqual(hours.start_hour);
    expect(endLocalHour).toBeLessThanOrEqual(hours.end_hour);
  }
}
````

## File: packages/services/google/src/lib/delegates/readEmailHistory.ts
````typescript
import { gmail_v1 } from 'googleapis';
import {
  EmailMessage,
  ReadEmailHistoryContext,
} from '@codestrap/developer-foundations-types';

/**
 * Extract a header value from the message
 */
function getHeader(
  message: gmail_v1.Schema$Message,
  name: string
): string | undefined {
  const header = message.payload?.headers?.find(
    (h) => h.name?.toLowerCase() === name.toLowerCase()
  )?.value;

  return header || undefined;
}

/**
 * Extract the plain text body of the email
 */
function getPlainTextBody(
  message: gmail_v1.Schema$Message
): string | undefined {
  if (!message.payload) return;

  try {
    const getBodyData = (data?: string) =>
      data ? Buffer.from(data, 'base64').toString('utf8') : undefined;

    if (message.payload.parts) {
      const part = message.payload.parts.find(
        (p) => p.mimeType === 'text/plain'
      );
      return getBodyData(part?.body?.data || undefined);
    }

    return getBodyData(message.payload.body?.data || undefined);
  } catch (err) {
    console.error('Failed to decode email body:', err);
    return undefined;
  }
}

export async function readEmailHistory(
  gmail: gmail_v1.Gmail,
  context: ReadEmailHistoryContext
): Promise<EmailMessage[]> {
  // get all unread emails for the since since 15 minutes before the notification
  // yes this is the best way to do this, don't ask unless you want to understand how historyId works
  const afterEpoch = Math.floor(
    (new Date(context.publishTime).getTime() - 15 * 60 * 1000) / 1000
  );

  const baseQuery = [`is:unread`, `after:${afterEpoch}`];

  if (context.labels && context.labels.length > 0) {
    const quotedLabels = context.labels.map((label) => `label:"${label}"`);
    const labelQuery =
      quotedLabels.length > 1
        ? `(${quotedLabels.join(' OR ')})`
        : quotedLabels[0];
    baseQuery.push(labelQuery);
  }

  const messageListRes = await gmail.users.messages.list({
    userId: context.email,
    q: baseQuery.join(' '),
  });

  // now we can get the message IDs
  const messageIds =
    messageListRes.data.messages
      ?.map((m) => m.id)
      .filter((id): id is string => !!id) ?? [];

  // now we can can fetch the messages
  const messageResponses = (
    await Promise.allSettled(
      messageIds.map((id) =>
        gmail.users.messages.get({
          userId: context.email,
          id,
          format: 'full',
        })
      )
    )
  )
    .filter((settled) => settled.status === 'fulfilled')
    .map((fulfilled) => fulfilled.value);

  // now we can get the thread IDs
  const threadIds = Array.from(
    new Set(
      messageResponses
        .map((res) => res.data.threadId)
        .filter((id): id is string => !!id)
    )
  );

  // then fetch all the messages for a given thread
  const threadResponses = await Promise.all(
    threadIds.map((threadId) =>
      gmail.users.threads.get({
        userId: context.email,
        id: threadId,
        format: 'full',
      })
    )
  );

  // then flatten res.data.messages and construct our output
  const results = threadResponses
    .flatMap((res) => res.data.messages || [])
    .map((msg) => {
      const id = msg.id || undefined;
      const threadId = msg.threadId || undefined;
      const subject = getHeader(msg, 'Subject');
      const from = getHeader(msg, 'From');
      const body = getPlainTextBody(msg);
      return { subject, from, body, id, threadId };
    });

  return results;
}
````

## File: packages/services/google/src/lib/delegates/scheduleMeeting.ts
````typescript
import { randomUUID } from 'crypto';
import {
  CalendarContext,
  ScheduleMeetingOutput,
} from '@codestrap/developer-foundations-types';
import { calendar_v3 } from 'googleapis';

const LOG_PREFIX = 'GSUITE - scheduleMeeting - ';

function validateScheduleMeetingInput(context: CalendarContext): void {
  const { summary, start, end, attendees } = context;

  if (!summary || typeof summary !== 'string') {
    throw new Error('Summary is required and must be a string');
  }
  if (!start || !Date.parse(start)) {
    throw new Error('Valid start time is required');
  }
  if (!end || !Date.parse(end)) {
    throw new Error('Valid end time is required');
  }
  if (!attendees || !Array.isArray(attendees) || attendees.length === 0) {
    throw new Error('At least one attendee is required');
  }
}

export async function scheduleMeeting(
  calendar: calendar_v3.Calendar,
  context: CalendarContext
): Promise<ScheduleMeetingOutput> {
  console.log(
    `${LOG_PREFIX} Processing meeting request:\n  summary: ${
      context.summary
    }\n  attendees: ${JSON.stringify(context.attendees, null, 2)}`
  );

  validateScheduleMeetingInput(context);

  const event = {
    summary: context.summary,
    description: context.description,
    start: { dateTime: context.start },
    end: { dateTime: context.end },
    attendees: context.attendees.map((email) => ({ email })),
    conferenceData: {
      createRequest: {
        requestId: randomUUID(),
        conferenceSolutionKey: { type: 'hangoutsMeet' },
      },
    },
  };

  const { data } = await calendar.events.insert({
    calendarId: 'primary',
    requestBody: event,
    sendUpdates: 'all',
    conferenceDataVersion: 1,
  });

  // Guarantee we got a Meet link
  const meetLink =
    data.hangoutLink ??
    data.conferenceData?.entryPoints?.find((e) => e.entryPointType === 'video')
      ?.uri;

  if (!data.id || !meetLink) {
    throw new Error('Google Calendar did not return a Meet link');
  }

  console.log(
    `${LOG_PREFIX} Meeting Created:\n  calendar returned: ${JSON.stringify(
      {
        id: data.id,
        htmlLink: data.htmlLink,
        status: data.status,
      },
      null,
      2
    )}`
  );

  return {
    id: data.id,
    htmlLink: data.htmlLink!,
    status: data.status!,
  };
}
````

## File: packages/services/google/src/lib/delegates/searchDriveFiles.test.ts
````typescript
import { drive_v3 } from 'googleapis';
import { searchDriveFiles } from './searchDriveFiles';
import { DriveSearchParams, DriveDateField } from '@codestrap/developer-foundations-types';

// Mock the Google Drive API client
const mockDriveClient = {
  files: {
    list: jest.fn(),
  },
} as unknown as drive_v3.Drive;

// Mock console methods to avoid noise in tests
const mockConsoleLog = jest.spyOn(console, 'log').mockImplementation();
const mockConsoleError = jest.spyOn(console, 'error').mockImplementation();

describe('searchDriveFiles', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  afterAll(() => {
    mockConsoleLog.mockRestore();
    mockConsoleError.mockRestore();
  });

  describe('Query Building', () => {
    beforeEach(() => {
      (mockDriveClient.files.list as jest.Mock).mockResolvedValue({
        data: {
          files: [],
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      });
    });

    it('should build query with keywords only', async () => {
      const params: DriveSearchParams = {
        keywords: ['transcripts', 'meeting'],
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'transcripts' or name contains 'meeting') and trashed = false",
        })
      );
    });

    it('should build query with date range', async () => {
      const params: DriveSearchParams = {
        dateRange: {
          startDate: new Date('2024-01-01'),
          endDate: new Date('2024-12-31'),
          field: DriveDateField.CREATED_TIME,
        },
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "createdTime >= '2024-01-01T00:00:00.000Z' and createdTime <= '2024-12-31T00:00:00.000Z' and trashed = false",
        })
      );
    });

    it('should build query with MIME type', async () => {
      const params: DriveSearchParams = {
        mimeType: 'application/pdf',
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "mimeType = 'application/pdf' and trashed = false",
        })
      );
    });

    it('should build query with owner', async () => {
      const params: DriveSearchParams = {
        owner: 'user@example.com',
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "'user@example.com' in owners and trashed = false",
        })
      );
    });

    it('should build query with shared with me', async () => {
      const params: DriveSearchParams = {
        sharedWithMe: true,
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: 'sharedWithMe and trashed = false',
        })
      );
    });

    it('should build query with trashed files', async () => {
      const params: DriveSearchParams = {
        trashed: true,
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: 'trashed = true',
        })
      );
    });

    it('should build complex query with multiple parameters', async () => {
      const params: DriveSearchParams = {
        keywords: ['project', 'report'],
        dateRange: {
          startDate: new Date('2024-01-01'),
          field: DriveDateField.MODIFIED_TIME,
        },
        mimeType: 'application/pdf',
        owner: 'user@example.com',
        pageSize: 50,
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'project' or name contains 'report') and modifiedTime >= '2024-01-01T00:00:00.000Z' and mimeType = 'application/pdf' and 'user@example.com' in owners and trashed = false",
          pageSize: 50,
        })
      );
    });
  });

  describe('Special Character Handling', () => {
    beforeEach(() => {
      (mockDriveClient.files.list as jest.Mock).mockResolvedValue({
        data: {
          files: [],
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      });
    });

    it('should escape special characters in keywords', async () => {
      const params: DriveSearchParams = {
        keywords: ['test (draft)', 'file[final]', 'report v2.0'],
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'test \\(draft\\)' or name contains 'file\\[final\\]' or name contains 'report v2\\.0') and trashed = false",
        })
      );
    });

    it('should handle keywords with quotes', async () => {
      const params: DriveSearchParams = {
        keywords: ['file "important"', "doc 'final'"],
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'file \\\"important\\\"' or name contains 'doc \\'final\\'') and trashed = false",
        })
      );
    });

    it('should handle keywords with backslashes', async () => {
      const params: DriveSearchParams = {
        keywords: ['backup\\copy', 'path\\to\\file'],
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'backup\\\\copy' or name contains 'path\\\\to\\\\file') and trashed = false",
        })
      );
    });
  });

  describe('Response Handling', () => {
    it('should return converted files successfully', async () => {
      const mockApiResponse = {
        data: {
          files: [
            {
              id: 'file1',
              name: 'test.pdf',
              mimeType: 'application/pdf',
              size: '1024',
              createdTime: '2024-01-01T00:00:00.000Z',
              modifiedTime: '2024-01-02T00:00:00.000Z',
              webViewLink: 'https://drive.google.com/file/d/file1/view',
              webContentLink: 'https://drive.google.com/uc?id=file1',
              owners: [
                {
                  displayName: 'John Doe',
                  emailAddress: 'john@example.com',
                },
              ],
              lastModifyingUser: {
                displayName: 'Jane Doe',
                emailAddress: 'jane@example.com',
              },
              parents: ['parent1'],
              description: 'Test file',
              starred: true,
              trashed: false,
            },
          ],
          nextPageToken: 'next-token',
          incompleteSearch: true,
        },
      };

      (mockDriveClient.files.list as jest.Mock).mockResolvedValue(mockApiResponse);

      const params: DriveSearchParams = {
        keywords: ['test'],
      };

      const result = await searchDriveFiles(mockDriveClient, params);

      expect(result).toEqual({
        files: [
          {
            id: 'file1',
            name: 'test.pdf',
            mimeType: 'application/pdf',
            size: '1024',
            createdTime: '2024-01-01T00:00:00.000Z',
            modifiedTime: '2024-01-02T00:00:00.000Z',
            webViewLink: 'https://drive.google.com/file/d/file1/view',
            webContentLink: 'https://drive.google.com/uc?id=file1',
            owners: [
              {
                displayName: 'John Doe',
                emailAddress: 'john@example.com',
              },
            ],
            lastModifyingUser: {
              displayName: 'Jane Doe',
              emailAddress: 'jane@example.com',
            },
            parents: ['parent1'],
            description: 'Test file',
            starred: true,
            trashed: false,
          },
        ],
        nextPageToken: 'next-token',
        incompleteSearch: true,
      });
    });

    it('should handle empty response', async () => {
      const mockApiResponse = {
        data: {
          files: [],
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      };

      (mockDriveClient.files.list as jest.Mock).mockResolvedValue(mockApiResponse);

      const params: DriveSearchParams = {
        keywords: ['nonexistent'],
      };

      const result = await searchDriveFiles(mockDriveClient, params);

      expect(result).toEqual({
        files: [],
        nextPageToken: undefined,
        incompleteSearch: undefined,
      });
    });

    it('should handle null files in response', async () => {
      const mockApiResponse = {
        data: {
          files: null,
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      };

      (mockDriveClient.files.list as jest.Mock).mockResolvedValue(mockApiResponse);

      const params: DriveSearchParams = {
        keywords: ['test'],
      };

      const result = await searchDriveFiles(mockDriveClient, params);

      expect(result).toEqual({
        files: [],
        nextPageToken: undefined,
        incompleteSearch: undefined,
      });
    });
  });

  describe('Error Handling', () => {
    it('should bubble authentication errors', async () => {
      const authError = new Error('invalid_grant: Invalid credentials');
      (mockDriveClient.files.list as jest.Mock).mockRejectedValue(authError);

      const params: DriveSearchParams = { keywords: ['test'] };

      await expect(searchDriveFiles(mockDriveClient, params)).rejects.toThrow(
        'invalid_grant: Invalid credentials'
      );
    });

    it('should bubble quota exceeded errors', async () => {
      const quotaError = new Error('quota exceeded');
      (mockDriveClient.files.list as jest.Mock).mockRejectedValue(quotaError);

      const params: DriveSearchParams = { keywords: ['test'] };

      await expect(searchDriveFiles(mockDriveClient, params)).rejects.toThrow('quota exceeded');
    });

    it('should bubble not found errors', async () => {
      const notFoundError = new Error('notFound: Drive not found');
      (mockDriveClient.files.list as jest.Mock).mockRejectedValue(notFoundError);

      const params: DriveSearchParams = { keywords: ['test'] };

      await expect(searchDriveFiles(mockDriveClient, params)).rejects.toThrow(
        'notFound: Drive not found'
      );
    });

    it('should bubble generic errors', async () => {
      const genericError = new Error('Something went wrong');
      (mockDriveClient.files.list as jest.Mock).mockRejectedValue(genericError);

      const params: DriveSearchParams = { keywords: ['test'] };

      await expect(searchDriveFiles(mockDriveClient, params)).rejects.toThrow('Something went wrong');
    });

    it('should bubble non-Error rejections as-is', async () => {
      (mockDriveClient.files.list as jest.Mock).mockRejectedValue('String error');

      const params: DriveSearchParams = { keywords: ['test'] };

      await expect(searchDriveFiles(mockDriveClient, params)).rejects.toEqual('String error');
    });
  });

  describe('Edge Cases', () => {
    beforeEach(() => {
      (mockDriveClient.files.list as jest.Mock).mockResolvedValue({
        data: {
          files: [],
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      });
    });

    it('should handle empty keywords array', async () => {
      const params: DriveSearchParams = {
        keywords: [],
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: 'trashed = false',
        })
      );
    });

    it('should filter out empty keywords', async () => {
      const params: DriveSearchParams = {
        keywords: ['valid', 'another-valid'], // Remove empty keywords since validation now prevents them
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'valid' or name contains 'another-valid') and trashed = false",
        })
      );
    });

    it('should handle whitespace in keywords', async () => {
      const params: DriveSearchParams = {
        keywords: ['  project plan  ', '  meeting notes  '],
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "(name contains 'project plan' or name contains 'meeting notes') and trashed = false",
        })
      );
    });

    it('should handle whitespace in MIME type and owner', async () => {
      const params: DriveSearchParams = {
        mimeType: '  application/pdf  ',
        owner: 'user@example.com', // Remove whitespace since validation now prevents invalid emails
      };

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          q: "mimeType = 'application/pdf' and 'user@example.com' in owners and trashed = false",
        })
      );
    });

    it('should use default values for optional parameters', async () => {
      const params: DriveSearchParams = {};

      await searchDriveFiles(mockDriveClient, params);

      expect(mockDriveClient.files.list).toHaveBeenCalledWith(
        expect.objectContaining({
          pageSize: 100,
          orderBy: 'modifiedTime desc',
          fields: 'nextPageToken,files(id,name,mimeType,size,createdTime,modifiedTime,webViewLink,webContentLink,owners,lastModifyingUser,parents,description,starred,trashed)',
          supportsAllDrives: true,
          includeItemsFromAllDrives: true,
        })
      );
    });
  });

  describe('File Conversion', () => {
    it('should handle files with missing optional fields', async () => {
      const mockApiResponse = {
        data: {
          files: [
            {
              id: 'file1',
              name: 'test.pdf',
              mimeType: 'application/pdf',
              // Missing optional fields
            },
          ],
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      };

      (mockDriveClient.files.list as jest.Mock).mockResolvedValue(mockApiResponse);

      const params: DriveSearchParams = {
        keywords: ['test'],
      };

      const result = await searchDriveFiles(mockDriveClient, params);

      expect(result.files[0]).toEqual({
        id: 'file1',
        name: 'test.pdf',
        mimeType: 'application/pdf',
        size: undefined,
        createdTime: undefined,
        modifiedTime: undefined,
        webViewLink: undefined,
        webContentLink: undefined,
        owners: undefined,
        lastModifyingUser: undefined,
        parents: undefined,
        description: undefined,
        starred: undefined,
        trashed: undefined,
      });
    });

    it('should handle files with null owners', async () => {
      const mockApiResponse = {
        data: {
          files: [
            {
              id: 'file1',
              name: 'test.pdf',
              mimeType: 'application/pdf',
              owners: null,
            },
          ],
          nextPageToken: undefined,
          incompleteSearch: undefined,
        },
      };

      (mockDriveClient.files.list as jest.Mock).mockResolvedValue(mockApiResponse);

      const params: DriveSearchParams = {
        keywords: ['test'],
      };

      const result = await searchDriveFiles(mockDriveClient, params);

      expect(result.files[0].owners).toBeUndefined();
    });
  });
});
````

## File: packages/services/google/src/lib/delegates/searchDriveFiles.ts
````typescript
import { drive_v3 } from 'googleapis';
import {
  DriveSearchParams,
  DriveSearchResult,
  DriveFile,
  DriveDateField,
} from '@codestrap/developer-foundations-types';

/**
 * Builds a Google Drive search query from the provided parameters
 *
 * Keyword search behavior:
 * - Uses 'name contains' for substring matching anywhere in filename
 * - Case-insensitive search
 * - Multiple keywords are combined with OR logic
 * - Handles special characters and whitespaces properly
 *
 * @param params - The search parameters
 * @returns The constructed Google Drive search query
 */
function buildSearchQuery(params: DriveSearchParams): string {
  const escapeKeywords = (s: string, escapeDot = false) => {
    let out = s
      .replace(/\\/g, '\\\\')
      .replace(/'/g, "\\'")
      .replace(/\"/g, '\\"')
      .replace(/\(/g, '\\(')
      .replace(/\)/g, '\\)')
      .replace(/\[/g, '\\[')
      .replace(/\]/g, '\\]')
      .replace(/\{/g, '\\{')
      .replace(/\}/g, '\\}')
      .replace(/\*/g, '\\*')
      .replace(/\?/g, '\\?')
      .replace(/\+/g, '\\+')
      .replace(/\|/g, '\\|')
      .replace(/\^/g, '\\^')
      .replace(/\$/g, '\\$')
      .replace(/!/g, '\\!');
    if (escapeDot) out = out.replace(/\./g, '\\.');
    return out;
  };

  const keywordsClause =
    params.keywords && params.keywords.length > 0
      ? `(${params.keywords
          .map((k) => `name contains '${escapeKeywords(k.trim(), true)}'`)
          .join(' or ')})`
      : undefined;

  const dateRangeField = params.dateRange?.field ?? DriveDateField.MODIFIED_TIME;
  const dateClause =
    params.dateRange?.startDate && params.dateRange?.endDate
      ? `${dateRangeField} >= '${params.dateRange.startDate.toISOString()}' and ${dateRangeField} <= '${params.dateRange.endDate.toISOString()}'`
      : params.dateRange?.startDate
      ? `${dateRangeField} >= '${params.dateRange.startDate.toISOString()}'`
      : params.dateRange?.endDate
      ? `${dateRangeField} <= '${params.dateRange.endDate.toISOString()}'`
      : undefined;

  const mimeClause = params.mimeType?.trim()
    ? `mimeType = '${escapeKeywords(params.mimeType.trim())}'`
    : undefined;

  const ownerClause = params.owner?.trim()
    ? `'${escapeKeywords(params.owner.trim())}' in owners`
    : undefined;

  const sharedClause = params.sharedWithMe ? 'sharedWithMe' : undefined;

  const trashedClause =
    params.trashed !== undefined
      ? `trashed = ${params.trashed}`
      : 'trashed = false';

  const parts = [
    keywordsClause,
    dateClause,
    mimeClause,
    ownerClause,
    sharedClause,
    trashedClause,
  ].filter(Boolean) as string[];

  return parts.join(' and ');
}

/**
 * Converts Google Drive API file response to our simplified DriveFile interface
 * @param driveApiFile - The file object from Google Drive API
 * @returns Converted DriveFile object
 */
function convertDriveFile(driveApiFile: drive_v3.Schema$File): DriveFile {
  return {
    id: driveApiFile.id!,
    name: driveApiFile.name!,
    mimeType: driveApiFile.mimeType!,
    size: driveApiFile.size ?? undefined,
    createdTime: driveApiFile.createdTime ?? undefined,
    modifiedTime: driveApiFile.modifiedTime ?? undefined,
    webViewLink: driveApiFile.webViewLink ?? undefined,
    webContentLink: driveApiFile.webContentLink ?? undefined,
    owners: driveApiFile.owners?.map((owner) => ({
      displayName: owner.displayName ?? undefined,
      emailAddress: owner.emailAddress ?? undefined,
    })),
    lastModifyingUser: driveApiFile.lastModifyingUser
      ? {
          displayName: driveApiFile.lastModifyingUser.displayName ?? undefined,
          emailAddress:
            driveApiFile.lastModifyingUser.emailAddress ?? undefined,
        }
      : undefined,
    parents: driveApiFile.parents ?? undefined,
    description: driveApiFile.description ?? undefined,
    starred: driveApiFile.starred ?? undefined,
    trashed: driveApiFile.trashed ?? undefined,
  };
}

/**
 * Searches for files in Google Drive based on the provided parameters
 * @param driveClient - The Google Drive API client
 * @param params - The search parameters
 * @returns Promise resolving to search results
 */
export async function searchDriveFiles(
  driveClient: drive_v3.Drive,
  params: DriveSearchParams
): Promise<DriveSearchResult> {
  const searchQuery = buildSearchQuery(params);

  const driveApiRequestParams: drive_v3.Params$Resource$Files$List = {
    q: searchQuery,
    pageSize: params.pageSize || 100,
    pageToken: params.pageToken,
    orderBy: params.orderBy || 'modifiedTime desc',
    fields:
      params.fields ||
      'nextPageToken,files(id,name,mimeType,size,createdTime,modifiedTime,webViewLink,webContentLink,owners,lastModifyingUser,parents,description,starred,trashed)',
    supportsAllDrives: true,
    includeItemsFromAllDrives: true,
  };

  const driveApiResponse = await driveClient.files.list(driveApiRequestParams);

  const convertedFiles: DriveFile[] = (driveApiResponse.data.files || []).map(
    convertDriveFile
  );

  return {
    files: convertedFiles,
    nextPageToken: driveApiResponse.data.nextPageToken || undefined,
    incompleteSearch: driveApiResponse.data.incompleteSearch || undefined,
  };
}
````

## File: packages/services/google/src/lib/delegates/sendEmail.ts
````typescript
import { gmail_v1 } from 'googleapis';
import {
  EmailContext,
  SendEmailOutput,
} from '@codestrap/developer-foundations-types';

const LOG_PREFIX = 'GSUITE - sendEmail - ';

// Helper Functions
function validateEmailInput(context: EmailContext): void {
  const { recipients, subject, message, from } = context;

  if (!from || !recipients || !subject || !message) {
    throw new Error(
      'No email data found in context. From, recipients, subject and message are required!'
    );
  }

  if (typeof from !== 'string') {
    throw new Error('From is required and must be a string');
  }
  if (!Array.isArray(recipients) || recipients.length === 0) {
    throw new Error('Recipients array is required and must not be empty');
  }
  if (typeof subject !== 'string') {
    throw new Error('Subject is required and must be a string');
  }
  if (typeof message !== 'string') {
    throw new Error('Message is required and must be a string');
  }
}

function htmlToPlainText(html: string): string {
  return html
    .replace(/<[^>]+>/g, '')
    .replace(/\s+/g, ' ')
    .trim();
}

function createEmailContent(
  from: string,
  message: string,
  subject: string,
  recipients: string | string[]
): string {
  const boundary = `boundary_${Date.now().toString(36)}`;
  const recipientList = Array.isArray(recipients)
    ? recipients.join(', ')
    : recipients;
  const plainTextContent = htmlToPlainText(message);
  const footer = `<br/>
<div style="border-top: 1px solid #ddd; margin-top: 20px; padding-top: 20px; font-family: Arial, sans-serif;">
    <strong>Vici</strong><br/>
    Executive AI Assistant | Codestrap<br/>
    <a href="mailto:${from}">${from}</a>
</div>`;

  const emailParts = [
    'MIME-Version: 1.0',
    `From: ${from}`,
    `To: ${recipientList}`,
    `Subject: ${Buffer.from(subject).toString('utf8')}`,
    'Content-Type: multipart/alternative; boundary="' + boundary + '"',
    'Content-Transfer-Encoding: 7bit',
    '',
    '--' + boundary,
    'Content-Type: text/plain; charset=UTF-8',
    'Content-Transfer-Encoding: 7bit',
    '',
    plainTextContent + `\n${from}`,
    '',
    '--' + boundary,
    'Content-Type: text/html; charset=UTF-8',
    'Content-Transfer-Encoding: 7bit',
    '',
    '<!DOCTYPE html>',
    '<html>',
    '<head>',
    '<meta charset="UTF-8">',
    '<style>',
    'body { font-family: Arial, sans-serif; line-height: 1.6; }',
    'a { color: #0066cc; text-decoration: none; }',
    'a:hover { text-decoration: underline; }',
    '</style>',
    '</head>',
    '<body>',
    Buffer.from(message).toString('utf8'),
    footer,
    '</body>',
    '</html>',
    '',
    '--' + boundary + '--',
  ];

  return emailParts.join('\r\n');
}

function encodeEmailForTransport(emailContent: string): string {
  const encoded = Buffer.from(emailContent)
    .toString('base64')
    .replace(/\+/g, '-')
    .replace(/\//g, '_')
    .replace(/=+$/, '');

  if (!encoded) {
    throw new Error('Failed to encode email content');
  }

  return encoded;
}

function createGmailRequest(encodedContent: string) {
  return {
    userId: 'me',
    requestBody: {
      raw: encodedContent,
      payload: {
        mimeType: 'multipart/alternative',
        headers: [
          {
            name: 'Content-Transfer-Encoding',
            value: 'base64url',
          },
        ],
      },
    },
  };
}

export async function sendEmail(
  gmail: gmail_v1.Gmail,
  context: EmailContext
): Promise<SendEmailOutput> {
  console.log(
    `${LOG_PREFIX} Processing email request:\n  subject: ${
      context.subject
    }\n  recipients: ${JSON.stringify(context.recipients, null, 2)}`
  );

  try {
    validateEmailInput(context);

    const emailContent = createEmailContent(
      context.from,
      context.message,
      context.subject,
      context.recipients
    );

    const encodedContent = encodeEmailForTransport(emailContent);
    const request = createGmailRequest(encodedContent);
    const response = await gmail.users.messages.send(request);

    if (!response.data.id || !response.data.threadId) {
      throw new Error('Invalid response from Gmail API');
    }

    console.log(
      `${LOG_PREFIX} email sent:\n  gmail returned: ${JSON.stringify(
        {
          id: response.data.id,
          threadId: response.data.threadId,
          labelIds: response.data.labelIds || [],
        },
        null,
        2
      )}`
    );

    return {
      id: response.data.id,
      threadId: response.data.threadId,
      labelIds: response.data.labelIds || [],
    };
  } catch (error) {
    console.error(
      `${LOG_PREFIX} Email sending failed:\n  message: ${
        error instanceof Error ? error.message : error
      }\n  stack: ${
        error instanceof Error ? error.stack : ''
      }\n  response: ${JSON.stringify((error as any).response?.data, null, 2)}`
    );
    throw error;
  }
}
````

## File: packages/services/google/src/lib/delegates/summerizeCalanders.ts
````typescript
// types/summarizeCalendars.ts
import { calendar_v3 } from 'googleapis';
import {
  toZonedISOString,
  toUTCFromWallClockLocal,
} from '@codestrap/developer-foundations-utils';
import {
  CalendarSummary,
  EventSummary,
  ListCalendarArgs,
  Summaries,
} from '@codestrap/developer-foundations-types';

/* ----------------------------------------------------------------------- */

function extractMeetingLink(evt: calendar_v3.Schema$Event): string | undefined {
  // Google Meet
  if (evt.hangoutLink) return evt.hangoutLink;
  // 3P links in description or location
  const text = `${evt.summary ?? ''} ${evt.description ?? ''} ${evt.location ?? ''}`;
  const regex =
    /(https?:\/\/[^\s]*?(zoom\.us|teams\.microsoft\.com|meet\.google\.com|gotomeet\.|webex\.com)[^\s]*)/i;
  const m = text.match(regex);
  return m ? m[1] : undefined;
}

async function fetchCalendar(
  cal: calendar_v3.Calendar,
  email: string,
  timeMin: string,
  timeMax: string,
  tz: string
): Promise<CalendarSummary> {
  const events: EventSummary[] = [];
  let pageTok: string | undefined;

  do {
    const res = await cal.events.list({
      calendarId: email,
      timeMin,
      timeMax,
      singleEvents: true,
      orderBy: 'startTime',
      pageToken: pageTok,
    });

    (res.data.items ?? []).forEach((evt) => {
      if (!evt.start?.dateTime || !evt.end?.dateTime) return;

      const startUTC = new Date(evt.start.dateTime);
      const endUTC = new Date(evt.end.dateTime);
      if (isNaN(startUTC.getTime()) || isNaN(endUTC.getTime())) return;

      const dur = (endUTC.getTime() - startUTC.getTime()) / 60000;

      events.push({
        id: evt.id!,
        subject: evt.summary ?? '',
        description: evt.description ?? undefined,
        start: toZonedISOString(startUTC, tz),
        end: toZonedISOString(endUTC, tz),
        durationMinutes: Math.round(dur),
        participants: (evt.attendees ?? []).map((a) => a.email!).filter(Boolean),
        meetingLink: extractMeetingLink(evt),
      });
    });

    pageTok = res.data.nextPageToken ?? undefined;
  } while (pageTok);

  return { email, events };
}

export async function summarizeCalendars(
  args: ListCalendarArgs
): Promise<Summaries> {
  const { calendar, emails, timezone, windowStartLocal, windowEndLocal } = args;

  // Convert local wall-clock bounds to UTC instants using your utils.
  const timeMin = toUTCFromWallClockLocal(windowStartLocal, timezone).toISOString();
  const timeMax = toUTCFromWallClockLocal(windowEndLocal, timezone).toISOString();

  console.log(`summarizeCalendars fetchCalendar for timeMin ${timeMin} timeMax ${timeMax}`);

  // Kick off all fetches in parallel
  const settled = await Promise.allSettled(
    emails.map((email) => fetchCalendar(calendar, email, timeMin, timeMax, timezone))
  );

  // Split successes / failures
  const calendars: CalendarSummary[] = [];
  const failures: string[] = [];

  settled.forEach((result, idx) => {
    if (result.status === 'fulfilled') {
      calendars.push(result.value);
    } else {
      failures.push(`${emails[idx]}: ${result.reason?.message ?? 'unknown error'}`);
    }
  });

  const eventCount = calendars.reduce((n, c) => n + c.events.length, 0);
  const message =
    failures.length === 0
      ? `Fetched ${eventCount} events`
      : `Fetched ${eventCount} events; ${failures.length} calendar(s) failed`;

  return { message, calendars };
}
````

## File: packages/services/google/src/lib/delegates/watchEmails.ts
````typescript
import { calendar_v3, gmail_v1 } from 'googleapis';
import {
  WatchEmailsInput,
  WatchEmailsOutput,
} from '@codestrap/developer-foundations-types';

function sleep(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

export async function watchEmails(
  context: WatchEmailsInput,
  makeClient: (userId: string) => Promise<{
    emailClient: gmail_v1.Gmail;
    calendarClient: calendar_v3.Calendar;
  }>
): Promise<WatchEmailsOutput> {
  const results = await Promise.allSettled(
    context.config.flatMap(
      ({ users, topicName, labelIds, labelFilterBehavior }) =>
        users.map(async (userId) => {
          const { emailClient } = await makeClient(userId);
          // google has some rate limiting in play that happen when there are too many parallel auth calls
          // This is a total hack but can work for now.
          await sleep(1000);
          return emailClient.users.watch({
            userId,
            requestBody: {
              topicName,
              labelIds,
              labelFilterBehavior,
            },
          });
        })
    )
  );

  const errors: string[] = [];
  const responses: string[] = [];

  results.forEach((result) => {
    if (result.status === 'rejected') {
      errors.push(result.reason?.message || String(result.reason));
    } else if (result.value.status !== 200) {
      errors.push(JSON.stringify(result.value.data));
    } else {
      responses.push(JSON.stringify(result.value.data));
    }
  });

  return {
    status: errors.length > 0 ? 400 : 200,
    errors,
    responses,
  };
}
````

## File: packages/services/google/src/lib/gemeniStockMarketConditions.ts
````typescript
import { google } from 'googleapis';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
// import playwright from 'playwright';

// Assuming you have API keys loaded from environment variables
const SEARCH_API_KEY = process.env['GOOGLE_SEARCH_API_KEY'];
// this search engine is specific to stock markets indices and current conditions
// https://programmablesearchengine.google.com/controlpanel/overview?cx=b7dc27c8f2cf14af1
const SEARCH_ENGINE_ID = process.env['GOOGLE_SEARCH_ENGINE_MARKETS'];
const GEMINI_API_KEY = process.env['GEMINI_API_KEY'];

const customSearch = google.customsearch('v1');
const genAI = new GoogleGenerativeAI(GEMINI_API_KEY!);

const geminiFlashModel = genAI.getGenerativeModel({
  model: 'gemini-2.0-flash',
});
const geminiProModel = genAI.getGenerativeModel({
  model: 'gemini-1.5-pro-001',
});

interface SearchResultItem {
  title?: string;
  link?: string;
  snippet?: string;
}

interface SearchResult {
  items?: SearchResultItem[];
}

async function loadPageContent(results: SearchResultItem[]): Promise<string[]> {
  if (!results) {
    return [];
  }
  // TODO replace this service with local playwright
  /*const browser = await playwright.chromium.launch()
    const pageContents: string[] = [];

    for (const result of results) {
        if (result.link && result.snippet && result.title) {
            try {
                console.log('Connected! Navigating...');
                const page = await browser.newPage();
                await page.goto(result.link, { waitUntil: 'networkidle', timeout: 2 * 60 * 1000 });
                //console.log('Taking screenshot to page.png');
                // await page.screenshot({ path: './page.png', fullPage: true });
                console.log('Navigated! Scraping page content...');
                const textContent = await page.innerText('body', { timeout: 2 * 60 * 1000 }); // Extract text from the body element
                if (textContent) {
                    pageContents.push(textContent);
                }
            } catch (e) {
                console.log(e);
            }
        }
    }

    await browser.close();

    return pageContents;*/
  return new Promise((resolve) => resolve([]));
}

async function synthesizeAnswer(
  summaries: string[],
  originalQuery: string
): Promise<string> {
  if (!summaries || summaries.length === 0) {
    return 'No relevant information found.';
  }

  const prompt = `You are a helpful AI analyst tasked with helping users understand the current market conditions. You always format your responses per the users instructions and use tables to format key facts and figures. Using only the following information:\n\n${summaries.join(
    '\n\n'
  )} \n\n Generate a market report for the users query: "${originalQuery}"`;
  const geminiProResponse = await geminiProModel.generateContent(prompt);
  return (
    geminiProResponse.response?.text() ?? 'Could not synthesize an answer.'
  );
}

async function performSearch(
  query: string,
  numResults: number = 5
): Promise<SearchResult> {
  if (!SEARCH_API_KEY || !SEARCH_ENGINE_ID) {
    throw new Error('Search API key or Search Engine ID missing.');
  }

  try {
    const response = await customSearch.cse.list({
      cx: SEARCH_ENGINE_ID,
      q: query,
      auth: SEARCH_API_KEY,
      num: numResults,
      dateRestrict: 'd1', // Restricts results to the last 24 hours
      //siteSearch: 'finance.yahoo.com',
      //siteSearchFilter: 'i',
    });
    return response.data as SearchResult;
  } catch (error) {
    console.error('Error during search:', error);
    throw error;
  }
}

async function generateSearchQueries(userInput: string): Promise<string[]> {
  const prompt = `You are a helpful AI market analyst that specializes in writing search queries based on the user query.
    You carefully deconstruct keywords for the search queries to ensure the user gets valid search results
    Users tend to supply lots of information in their queries and passing this directly to the search engine will cause it to return null results
    Decompose the following user query into the required number of searches to cover their request while obtaining valid search results: 
    "${userInput}"
    You can only respond in JSON in the following format:
    {
        "queries": ["<QUERY_1>", "<QUERY_2>", "<QUERY_3>"...]
    }
    
    for example is the user asks: "what are the current market indices doing, who are the top movers"
    You respond with:
    {
        "queries": ["current VIX level", "what is the current QQQ Index Level", "What is the current SPX level", "top stock market winners today", "top stock market losers today", "top stock market sectors today"]
    }
    Explanation: They query is broken out into separate queries so the search engine will return valid results. There is timeliness to each query limiting the results to the last 24 hours.
    `;
  const geminiProResponse = await geminiFlashModel.generateContent(prompt);
  const result =
    geminiProResponse.response?.text() ?? 'Could not synthesize an answer.';
  const clean = JSON.parse(extractJsonFromBackticks(result)) as {
    queries: string[];
  };

  return clean.queries;
}

async function researchAssistant(userInput: string): Promise<string> {
  const queries = await generateSearchQueries(userInput);

  const searchPromises = queries.map((query) => performSearch(query));
  const searchResults = await Promise.all(searchPromises);

  const flattenedResults: SearchResultItem[] = searchResults.reduce(
    (acc: SearchResultItem[], curr) => {
      if (curr.items && curr.items.length > 0) {
        acc = [...acc, ...curr.items];
      }
      return acc;
    },
    [] as SearchResultItem[]
  );

  const summaries = await loadPageContent(flattenedResults);
  return synthesizeAnswer(summaries, userInput);
}

// Example Usage:
export async function gemeniStockMarketConditions(
  userInput: string
): Promise<string> {
  const answer = await researchAssistant(userInput);

  return answer;
}
````

## File: packages/services/google/src/lib/gsuiteClient.ts
````typescript
import { google } from 'googleapis';
import {
  CalendarContext,
  EmailContext,
  FindOptimalMeetingTimeOutput,
  OfficeServiceV1,
  MeetingRequest,
  ReadEmailHistoryContext,
  ScheduleMeetingOutput,
  SendEmailOutput,
  WatchEmailsInput,
} from '@codestrap/developer-foundations-types';
import { findOptimalMeetingTime } from './delegates/findOptimalMeetingTime';
import { scheduleMeeting } from './delegates/scheduleMeeting';
import { sendEmail } from './delegates/sendEmail';
import { readEmailHistory } from './delegates/readEmailHistory';
import { watchEmails } from './delegates/watchEmails';

export enum GSUITE_SCOPES {
  CALENDAR_READ = 'https://www.googleapis.com/auth/calendar.readonly',
  CALENDAR_WRITE = 'https://www.googleapis.com/auth/calendar.events',
  CALENDAR_FREEBUSY = 'https://www.googleapis.com/auth/calendar.freebusy',
  CALENDAR_ALL = 'https://www.googleapis.com/auth/calendar',
  GMAIL_SEND = 'https://www.googleapis.com/auth/gmail.send',
  GMAIL_READ = 'https://www.googleapis.com/auth/gmail.readonly',
  GMAIL_META = 'https://www.googleapis.com/auth/gmail.metadata',
  GMAIL_MODIFY = 'https://www.googleapis.com/auth/gmail.modify',
}

import { loadServiceAccountFromEnv, makeGoogleAuth } from '../helpers/googleAuth';

async function makeClient(user: string) {
  console.log(`Creating client for user: ${user}`);
  // load the service account one time
  const credentials = await loadServiceAccountFromEnv();

  const mailScopes: GSUITE_SCOPES[] = [
    GSUITE_SCOPES.GMAIL_SEND,
    GSUITE_SCOPES.CALENDAR_READ,
    GSUITE_SCOPES.GMAIL_READ,
  ];

  const calendarScopes: GSUITE_SCOPES[] = [
    GSUITE_SCOPES.CALENDAR_ALL,
    GSUITE_SCOPES.CALENDAR_FREEBUSY,
    GSUITE_SCOPES.CALENDAR_READ,
    GSUITE_SCOPES.CALENDAR_WRITE,
  ];

  const emailAuth = makeGoogleAuth(credentials, mailScopes, user);
  const calAuth = makeGoogleAuth(credentials, calendarScopes, user);

  const mailClient = await emailAuth.getClient();
  const calClient = await calAuth.getClient();

  if (!mailClient.getRequestHeaders || !calClient.getRequestHeaders) {
    throw new Error('Invalid auth client - missing methods');
  }

  const calendarClient = google.calendar({ version: 'v3', auth: calAuth });
  const emailClient = google.gmail({ version: 'v1', auth: emailAuth });
  
  return { emailClient, calendarClient };
}

export async function makeGSuiteClient(
  user: string
): Promise<OfficeServiceV1> {
  const { emailClient, calendarClient } = await makeClient(user);

  return {
    getAvailableMeetingTimes: async (
      meetingRequest: MeetingRequest
    ): Promise<FindOptimalMeetingTimeOutput> => {
      const result = await findOptimalMeetingTime(
        calendarClient,
        meetingRequest
      );

      return result;
    },
    scheduleMeeting: async (
      meeting: CalendarContext
    ): Promise<ScheduleMeetingOutput> => {
      const result = await scheduleMeeting(calendarClient, meeting);

      return result;
    },
    sendEmail: async (email: EmailContext): Promise<SendEmailOutput> => {
      const result = await sendEmail(emailClient, email);

      return result;
    },
    readEmailHistory: async (context: ReadEmailHistoryContext) => {
      const { emailClient } = await makeClient(context.email);
      const result = await readEmailHistory(emailClient, context);

      return {
        messages: result,
      };
    },
    watchEmails: async (context: WatchEmailsInput) => {
      // we pass makeClient because this operations requires scoped clients to the user's email!
      const result = await watchEmails(context, makeClient);

      return result;
    },
    getCalendarClient: () => calendarClient,
    getEmailClient: () => emailClient,
  };
}
````

## File: packages/services/google/src/lib/gsuiteClient.v2.test.ts
````typescript
import { makeGSuiteClientV2 } from './gsuiteClient.v2';
import { makeGSuiteClient } from './gsuiteClient';
import { searchDriveFiles } from './delegates/searchDriveFiles';
import { DriveSearchParams, DriveDateField } from '@codestrap/developer-foundations-types';

// Mock the v1 client
jest.mock('./gsuiteClient');
const mockMakeGSuiteClient = makeGSuiteClient as jest.MockedFunction<typeof makeGSuiteClient>;

// Mock the searchDriveFiles delegate
jest.mock('./delegates/searchDriveFiles');
const mockSearchDriveFiles = searchDriveFiles as jest.MockedFunction<typeof searchDriveFiles>;

// Mock console methods
const mockConsoleLog = jest.spyOn(console, 'log').mockImplementation();

describe('makeGSuiteClientV2', () => {
  const mockUser = 'test@example.com';
  const mockV1Client = {
    getCalendarClient: jest.fn().mockReturnValue({}),
    getEmailClient: jest.fn().mockReturnValue({}),
  } as any;

  beforeEach(() => {
    jest.clearAllMocks();
    mockMakeGSuiteClient.mockResolvedValue(mockV1Client);
    // Provide a minimal fake service account for v2 drive auth
    const fakeCreds = {
      type: 'service_account',
      project_id: 'test-project',
      private_key_id: 'test-key',
      private_key: 'dummy',
      client_email: 'service@test.iam.gserviceaccount.com',
      client_id: '1234567890',
      auth_uri: 'https://accounts.google.com/o/oauth2/auth',
      token_uri: 'https://oauth2.googleapis.com/token',
      auth_provider_x509_cert_url: 'https://www.googleapis.com/oauth2/v1/certs',
      client_x509_cert_url: 'https://www.googleapis.com/robot/v1/metadata/x509/service%40test.iam.gserviceaccount.com',
      universe_domain: 'googleapis.com',
    };
    process.env['GSUITE_SERVICE_ACCOUNT'] = Buffer.from(JSON.stringify(fakeCreds)).toString('base64');
  });

  afterAll(() => {
    mockConsoleLog.mockRestore();
  });

  describe('searchDriveFiles method', () => {
    it('should call searchDriveFiles delegate with correct parameters', async () => {
      const mockSearchResult = {
        files: [
          {
            id: 'file1',
            name: 'test.pdf',
            mimeType: 'application/pdf',
          },
        ],
        nextPageToken: 'next-token',
        incompleteSearch: false,
      };

      mockSearchDriveFiles.mockResolvedValue(mockSearchResult);

      const client = await makeGSuiteClientV2(mockUser);
      const searchParams: DriveSearchParams = {
        keywords: ['test'],
        mimeType: 'application/pdf',
      };

      const result = await client.searchDriveFiles(searchParams);

      expect(mockSearchDriveFiles).toHaveBeenCalledWith(expect.any(Object), searchParams);
      expect(result).toEqual({
        message: 'Found 1 files matching your search criteria',
        files: mockSearchResult.files,
        totalResults: 1,
        nextPageToken: 'next-token',
        incompleteSearch: false,
      });
    });

    it('should handle empty search results', async () => {
      const mockSearchResult = {
        files: [],
        nextPageToken: undefined,
        incompleteSearch: false,
      };

      mockSearchDriveFiles.mockResolvedValue(mockSearchResult);

      const client = await makeGSuiteClientV2(mockUser);
      const searchParams: DriveSearchParams = {
        keywords: ['nonexistent'],
      };

      const result = await client.searchDriveFiles(searchParams);

      expect(result).toEqual({
        message: 'Found 0 files matching your search criteria',
        files: [],
        totalResults: 0,
        nextPageToken: undefined,
        incompleteSearch: false,
      });
    });

    it('should handle multiple files in search results', async () => {
      const mockSearchResult = {
        files: [
          {
            id: 'file1',
            name: 'test1.pdf',
            mimeType: 'application/pdf',
          },
          {
            id: 'file2',
            name: 'test2.docx',
            mimeType: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
          },
          {
            id: 'file3',
            name: 'test3.xlsx',
            mimeType: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
          },
        ],
        nextPageToken: 'next-token',
        incompleteSearch: true,
      };

      mockSearchDriveFiles.mockResolvedValue(mockSearchResult);

      const client = await makeGSuiteClientV2(mockUser);
      const searchParams: DriveSearchParams = {
        keywords: ['test'],
      };

      const result = await client.searchDriveFiles(searchParams);

      expect(result).toEqual({
        message: 'Found 3 files matching your search criteria',
        files: mockSearchResult.files,
        totalResults: 3,
        nextPageToken: 'next-token',
        incompleteSearch: true,
      });
    });

    it('should propagate errors from searchDriveFiles delegate', async () => {
      const error = new Error('Search failed');
      mockSearchDriveFiles.mockRejectedValue(error);

      const client = await makeGSuiteClientV2(mockUser);
      const searchParams: DriveSearchParams = {
        keywords: ['test'],
      };

      await expect(client.searchDriveFiles(searchParams)).rejects.toThrow('Search failed');
    });

    it('should handle complex search parameters', async () => {
      const mockSearchResult = {
        files: [
          {
            id: 'file1',
            name: 'project-report.pdf',
            mimeType: 'application/pdf',
          },
        ],
        nextPageToken: undefined,
        incompleteSearch: false,
      };

      mockSearchDriveFiles.mockResolvedValue(mockSearchResult);

      const client = await makeGSuiteClientV2(mockUser);
      const searchParams: DriveSearchParams = {
        keywords: ['project', 'report'],
        dateRange: {
          startDate: new Date('2024-01-01'),
          endDate: new Date('2024-12-31'),
          field: DriveDateField.CREATED_TIME,
        },
        mimeType: 'application/pdf',
        owner: 'user@example.com',
        sharedWithMe: true,
        pageSize: 50,
        orderBy: 'createdTime desc',
      };

      const result = await client.searchDriveFiles(searchParams);

      expect(mockSearchDriveFiles).toHaveBeenCalledWith(expect.any(Object), searchParams);
      expect(result.message).toBe('Found 1 files matching your search criteria');
      expect(result.totalResults).toBe(1);
    });
    
  });

  describe('integration with v1 client', () => {
    it('should call makeGSuiteClient with correct user', async () => {
      await makeGSuiteClientV2(mockUser);

      expect(mockMakeGSuiteClient).toHaveBeenCalledWith(mockUser);
    });

    it('should return all v1 client methods plus searchDriveFiles', async () => {
      const client = await makeGSuiteClientV2(mockUser);

      // Check that v2 specific methods are available
      expect(client.searchDriveFiles).toBeDefined();
      expect(client.summarizeCalendars).toBeDefined();
      expect(client.getAvailableMeetingTimes).toBeDefined();
    });

    it('should preserve v1 client functionality', async () => {
      const client = await makeGSuiteClientV2(mockUser);

      // Test that v1 methods are available on the client
      expect(typeof client.getCalendarClient).toBe('function');
      expect(typeof client.getEmailClient).toBe('function');
      expect(typeof client.getDriveClient).toBe('function');
    });
  });

  describe('error handling', () => {
    it('should propagate errors from makeGSuiteClient', async () => {
      const error = new Error('Failed to create v1 client');
      mockMakeGSuiteClient.mockRejectedValue(error);

      await expect(makeGSuiteClientV2(mockUser)).rejects.toThrow('Failed to create v1 client');
    });
  });
});
````

## File: packages/services/google/src/lib/gsuiteClient.v2.ts
````typescript
import {
  MeetingRequest,
  OfficeServiceV2,
  Summaries,
  DriveSearchParams,
  DriveSearchOutput,
} from '@codestrap/developer-foundations-types';
import { makeGSuiteClient } from './gsuiteClient';

import { findOptimalMeetingTimeV2 } from './delegates/findOptimalMeetingTime.v2';
import { deriveWindowFromTimeframe } from './delegates/deriveWindowFromTimeframe';
import { summarizeCalendars } from './delegates/summerizeCalanders';
import { searchDriveFiles } from './delegates/searchDriveFiles';
import { wallClockToUTC, workingHoursUTCForDate } from '@codestrap/developer-foundations-utils';
import { google } from 'googleapis';
import { loadServiceAccountFromEnv, makeGoogleAuth } from '../helpers/googleAuth';

export async function makeGSuiteClientV2(
  user: string
): Promise<OfficeServiceV2> {
  const v1Client = await makeGSuiteClient(user);

  const credentials = await loadServiceAccountFromEnv();

  const driveScopes = [
    'https://www.googleapis.com/auth/drive.readonly',
    'https://www.googleapis.com/auth/drive.metadata.readonly',
  ];

  const driveAuth = makeGoogleAuth(credentials, driveScopes, user);

  const driveClient = google.drive({ version: 'v3', auth: driveAuth });

  return {
    ...v1Client,
    summarizeCalendars: async (args: {
      emails: string[];
      timezone: string;
      windowStartLocal: Date;
      windowEndLocal: Date;
    }): Promise<Summaries> => {
      const result = await summarizeCalendars({
        ...args,
        calendar: v1Client.getCalendarClient(),
      });

      return result;
    },
    getAvailableMeetingTimes: async (
      meetingRequest: MeetingRequest
    ): Promise<{
      message: string;
      suggested_times: { start: string; end: string; score: number }[];
    }> => {
      // TODO, get the TZ from the user profile
      const timezone = 'America/Los_Angeles';

      // "now" as an absolute UTC instant (portable across machines)
      const nowUTC = new Date();

      // Compute UTC working hours for *today in the target tz* (e.g., 08:0017:00 local)
      const workingHours = workingHoursUTCForDate(nowUTC, timezone, 8, 17);

      if (meetingRequest.timeframe_context === 'user defined exact date/time') {
        //localDateString
        meetingRequest.localDateString = wallClockToUTC(meetingRequest.localDateString!, timezone).toISOString();
      }

      // Ensure the request carries the UTC hours we just computed
      const req = { ...meetingRequest, working_hours: workingHours };

      console.log(`calling deriveWindowFromTimeframe`, { req, timezone, nowUTC: nowUTC.toISOString() });

      const { windowStartLocal, windowEndLocal, slotStepMinutes } =
        deriveWindowFromTimeframe(req);
      console.log(`deriveWindowFromTimeframe returned start time of ${windowStartLocal} and end time of ${windowEndLocal}`)

      const slots = await findOptimalMeetingTimeV2({
        calendar: v1Client.getCalendarClient(),
        attendees: meetingRequest.participants,
        timezone,
        windowStartUTC: windowStartLocal,
        windowEndUTC: windowEndLocal,
        durationMinutes: meetingRequest.duration_minutes,
        workingHours,
        slotStepMinutes,
        skipFriday: false,
      });

      const suggested_times = slots.map((s) => ({
        start: s.start,
        end: s.end,
        score: s.score ?? 0,
      }));

      return {
        message: `Found ${suggested_times.length} suggested times`,
        suggested_times,
      };
    },
    searchDriveFiles: async (params: DriveSearchParams): Promise<DriveSearchOutput> => {
      const result = await searchDriveFiles(driveClient, params);
      
      return {
        message: `Found ${result.files.length} files matching your search criteria`,
        files: result.files,
        totalResults: result.files.length,
        nextPageToken: result.nextPageToken,
        incompleteSearch: result.incompleteSearch,
      };
    },
    getDriveClient: () => driveClient,
  };
}
````

## File: packages/services/google/src/lib/README.gSuiteClient.v2.md
````markdown
# Meeting Time Finder v2  README

This document explains how **`getAvailableMeetingTimes` (v2)** works, what it returns, and how to use it. It wraps the new algorithm `findOptimalMeetingTimeV2` behind the same public interface you already use in v1.

---

## What it does

Given a **meeting request** (participants, duration, timeframe context, and PT working hours), the service:

1. Builds a **search window** in **Pacific Time** from your `timeframe_context` (ASAP / this week / next week / exact).
2. Calls Google Calendar **Free/Busy** for all participants inside that window.
3. Computes when **everyone is free** during **working hours** (MonThu + Fri; weekends are excluded).
4. Slices free time into fixedlength **slots** (default step 30 min).
5. **Scores** slots (earlier is better) and returns them as **PT ISO strings** with the correct **DST offset** (`-07:00` or `-08:00`).

---

## Quick start

```ts
import { makeGSuiteClientV2 } from './gsuiteClientV2';
import type { MeetingRequest } from '@xreason/types';

const office = await makeGSuiteClientV2('user@yourdomain.com');

const req: MeetingRequest = {
  participants: ['a@corp.com', 'b@corp.com', 'c@corp.com'],
  subject: 'Roadmap sync',
  timeframe_context: 'as soon as possible', // or 'this week' | 'next week' | 'user defined exact date/time'
  duration_minutes: 30,
  working_hours: { start_hour: 8, end_hour: 17 }, // PT business hours
  // localDateString: '2025-07-22T10:15:00' // only used for 'user defined exact date/time'
};

const result = await office.getAvailableMeetingTimes(req);

console.log(result);
/*
{
  message: "Found 6 suggested times",
  suggested_times: [
    { start: "2025-07-22T10:30:00-07:00", end: "2025-07-22T11:00:00-07:00", score: 98.7 },
    { start: "2025-07-22T11:00:00-07:00", end: "2025-07-22T11:30:00-07:00", score: 98.5 },
    ...
  ]
}
*/
```

**Return type**

```ts
{
  message: string;
  suggested_times: { start: string; end: string; score: number }[];
}
```

---

## Inputs

`MeetingRequest` (unchanged from v1):

```ts
type MeetingRequest = {
  participants: string[];                    // attendee emails (Google Calendar principals)
  subject: string;
  timeframe_context: 'user defined exact date/time' | 'as soon as possible' | 'this week' | 'next week';
  localDateString?: string;                  // required when timeframe_context is 'user defined exact date/time'
  duration_minutes: number;                  // e.g., 30
  working_hours: { start_hour: number; end_hour: number }; // PT hours, e.g. {8,17}
};
```

---

## How the timeframe is interpreted (PT)

We convert your `timeframe_context` into a **PT wallclock window**:

* **`'as soon as possible'`**
  From **now (clamped to business hours)** through **Friday 17:00** of the same work week.
  *Example:* If its Tuesday 10:05 PT, search window is `[Tue 10:05, Fri 17:00]`.

* **`'this week'`**
  From **now (clamped)** through **this Friday 17:00**. If youre **already past Friday 17:00**, it **rolls to next week** (Mon 08:00  Fri 17:00).

* **`'next week'`**
  **Monday 08:00  Friday 17:00** of the **next** week (PT).

* **`'user defined exact date/time'`**
  Build a **narrow window** `[localDateString, localDateString + duration]`, with **minute granularity** (no rounding), then **clamp** to working hours if needed.
  *Example:* `{ localDateString: "2025-07-22T10:10:00", duration_minutes: 30 }`  `[10:10, 10:40]`.

> **Weekends are excluded**. **Fridays are included** (no skip Friday unless you change that flag internally).

---

## Under the hood (how slots are found)

You dont have to call this directly, but heres what `findOptimalMeetingTimeV2` does:

1. **Convert the PT window to UTC** (DSTsafe) using `Intl.DateTimeFormat(...).formatToParts` to compute the true offset at each instant.
2. **Fetch Free/Busy** union for all attendees via `calendar.freebusy.query` in the UTC window.
3. **Merge** all busy intervals (planesweep).
4. Build **daily working windows** (PT hours), converted to **UTC**, and **skip weekends** (optionally Friday if enabled).
5. **Subtract** merged busy from working windows (twopointer sweep) to get global **free intervals**.
6. **Slice** free intervals into fixedlength **slots** (`duration_minutes`), advancing by `slotStepMinutes` (default 30), rounding **slot starts** up to the next step boundary.
7. **Score** (earlier  higher score), then **sort** descending.
8. Convert slot instants back to **PT ISO strings** with the **correct local offset** (`-07:00` in PDT, `-08:00` in PST).

---

## Time zone & DST behavior (Pacific Time)

* All userfacing strings are **PT ISO datetimes** such as `2025-07-22T16:30:00-07:00`.
* **No ambiguity** around DST changes:

  * **Spring forward**: there is no 02:0002:59 local hour; we never propose slots in that missing hour.
  * **Fall back**: the hour repeats; offset changes from `-07:00` to `-08:00` automatically.
* If `Intl` were to fail, we fall back to a safe offset (`fallbackOffsetMinutes`, default `-420`).

---

## What counts as working hours

* Provided by you in the request (`working_hours: { start_hour, end_hour }`) and applied **per business day** in PT.
* **Weekends** are **excluded**.
* **Fridays are included** by default (we do not set `skipFriday` in v2 client).

---

## Scoring

* Each slot gets a **simple heuristic score** that prefers **earlier** times.
* You can still sort or filter on your side (e.g., take top N)  the response contains a `score` for each.

---

## Error cases & validation

* If `timeframe_context = 'user defined exact date/time'` but `localDateString` is **missing** or **invalid**, you will get an error.
* If working hours are inverted (e.g., end  start) or duration is nonpositive, the search yields **no slots**.
* If participants have allday busy events (OOO), those are treated as **busy** by Free/Busy.

---

## Example scenarios

### 1) ASAP on a weekday, during business hours

* **Request:** Tuesday 10:05 PT, duration 30, 08:0017:00 PT.
* **Search window:** Tue 10:05  Fri 17:00.
* **Result:** First slot typically `10:3011:00` (rounded to the next 30min boundary), plus additional suggestions.

### 2) This week after Friday close

* **Request:** Friday 18:10 PT.
* **Behavior:** Rolls forward to **next week** (Mon 08:00  Fri 17:00).

### 3) Exact date/time

* **Request:** `"2025-07-22T10:10:00"` for 30 minutes.
* **Behavior:** Search just **10:1010:40** (clamped to business hours if outside).

---

## Performance notes

* Free/Busy call is a single batched request for all participants in the window.
* Interval math uses **merge** + **twopointer subtraction** for near **O(N)** traversal.
* For very long windows, consider limiting to the **first K slots** on your side.

---

## Required Google scopes & auth (unchanged)

* Calendar Free/Busy and Events scopes are used internally; you configure service account credentials via environment variables (same as v1).
* The v2 client reuses the v1 clients authenticated `calendar_v3.Calendar` under the hood.

---

## Testing

We ship unit tests that cover:

* **Rounding and step alignment**.
* **Multiday windows**, weekend skipping, and Friday handling.
* **DST boundaries** (fallback and springforward).
* **Fallback offset** behavior if `Intl` fails.

---

## FAQ

**Q: Why are the first slots slightly later than now?**
A: We **round up** to the next `slotStepMinutes` boundary to keep predictable scheduling (e.g., `10:05`  `10:30` when step is 30 min).

**Q: Can we exclude Fridays?**
A: The algorithm supports it (`skipFriday`), but the v2 client leaves it **off** by default to preserve v1 semantics.

**Q: Do results include lunch breaks or holidays?**
A: Lunch/holidays arent specialcased. You can subtract a holiday calendar or add a lunch busy block per attendee if needed.

---

## Summary

* **Same API**, better reliability: PT timezone correctness, DSTsafe, and robust slot generation across multiple days and attendees.
* You call `getAvailableMeetingTimes` **exactly like v1**, and receive:

  ```ts
  { message: string; suggested_times: { start: string; end: string; score: number }[] }
  ```
* If you need policy tweaks (buffers, lead time, skip Friday), we can enable them without breaking the API.
````

## File: packages/services/google/src/lib/researchAssistant.ts
````typescript
import { google } from 'googleapis';
import { GoogleGenAI } from '@google/genai';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import FirecrawlApp, { ScrapeResponse } from '@mendable/firecrawl-js';

// import playwright from 'playwright';

// Assuming you have API keys loaded from environment variables
const SEARCH_API_KEY = process.env['GOOGLE_SEARCH_API_KEY'];
// this search engine is specific to stock markets indices and current conditions
// https://programmablesearchengine.google.com/controlpanel/overview?cx=b7dc27c8f2cf14af1
const SEARCH_ENGINE_ID = process.env['GOOGLE_SEARCH_ENGINE_ID'];
const GEMINI_API_KEY = process.env['GEMINI_API_KEY'];
const FIRECRAWL_API_KEY = process.env['FIRECRAWL_API_KEY'];

const customSearch = google.customsearch('v1');
const ai = new GoogleGenAI({ apiKey: GEMINI_API_KEY });

interface SearchResultItem {
    title?: string;
    link?: string;
    snippet?: string;
}

interface SearchResult {
    items?: SearchResultItem[];
}

async function loadPageContent(results: SearchResultItem[], app: FirecrawlApp): Promise<string[]> {
    if (!results) {
        return [];
    }

    const pageContentsPromises = results
        .filter(result => typeof result.link === 'string' && result.link.trim() !== '')
        .map(result => {
            // Scrape a website
            return app.scrapeUrl(result.link!, {
                formats: ['markdown'],
            });
        });

    const scrapeResults = await Promise.allSettled(pageContentsPromises);

    const pageContents: string[] = scrapeResults
        .filter((r): r is PromiseFulfilledResult<ScrapeResponse> => r.status === 'fulfilled' && r.value.success)
        .map(r => r.value.markdown ?? '');

    return pageContents;
}


async function synthesizeAnswer(summaries: string[], originalQuery: string): Promise<string> {
    if (!summaries || summaries.length === 0) {
        return "No relevant information found.";
    }

    const contents = `You are a helpful AI analyst tasked with helping users understand the current market conditions. You always format your responses per the users instructions and use tables to format key facts and figures. Using only the following information:\n\n${summaries.join("\n\n")} \n\n Generate a market report for the users query: "${originalQuery}"`;
    const geminiProResponse = await ai.models.generateContent({
        model: 'gemini-2.0-flash-001',
        contents,
    });
    return geminiProResponse.text ?? "Could not synthesize an answer.";
}

async function performSearch(
    query: string,
    num = 5,
    dateRestrict?: string,
    siteSearch?: string,
    siteSearchFilter?: string,
    searchEngineId?: string
): Promise<SearchResult> {
    if (!SEARCH_API_KEY || !SEARCH_ENGINE_ID) {
        throw new Error("Search API key or Default Search Engine ID missing.");
    }

    try {
        const response = await customSearch.cse.list({
            cx: searchEngineId || SEARCH_ENGINE_ID,
            q: query,
            auth: SEARCH_API_KEY,
            num,
            dateRestrict,
            siteSearch,
            siteSearchFilter,

        });
        return response.data as SearchResult;
    } catch (error) {
        console.error("Error during search:", error);
        throw error
    }
}

async function generateSearchQueries(userInput: string): Promise<string[]> {
    const contents = `You are a helpful AI market analyst that specializes in writing search queries based on the user query.
    You carefully deconstruct keywords for the search queries to ensure the user gets valid search results
    Users tend to supply lots of information in their queries and passing this directly to the search engine will cause it to return null results
    Decompose the following user query into the required number of searches to cover their request while obtaining valid search results: 
    "${userInput}"
    You can only respond in JSON in the following format:
    {
        "queries": ["<QUERY_1>", "<QUERY_2>", "<QUERY_3>"...]
    }
    
    for example is the user asks: "what are the current market indices doing, who are the top movers"
    You respond with:
    {
        "queries": ["current VIX level", "what is the current QQQ Index Level", "What is the current SPX level", "top stock market winners today", "top stock market losers today", "top stock market sectors today"]
    }
    Explanation: They query is broken out into separate queries so the search engine will return valid results. There is timeliness to each query limiting the results to the last 24 hours.
    `;
    const geminiProResponse = await ai.models.generateContent({
        model: 'gemini-2.0-flash-001',
        contents,
    });
    const result = geminiProResponse.text ?? "Could not synthesize an answer.";
    const clean = JSON.parse(extractJsonFromBackticks(result)) as { queries: string[] };

    return clean.queries;
}

export async function researchAssistant(
    userInput: string,
    num = 5,
    dateRestrict?: string,
    siteSearch?: string,
    siteSearchFilter?: string,
    searchEngineId?: string

): Promise<string> {
    try {
        const app = new FirecrawlApp({ apiKey: FIRECRAWL_API_KEY });

        const queries = await generateSearchQueries(userInput);

        const searchPromises = queries.map(query => performSearch(
            query,
            num,
            dateRestrict,
            siteSearch,
            siteSearchFilter,
            searchEngineId,
        ));
        const searchResults = await Promise.all(searchPromises);

        const flattenedResults: SearchResultItem[] = searchResults.reduce((acc: SearchResultItem[], curr) => {
            if (curr.items && curr.items.length > 0) {
                acc = [...acc, ...curr.items]
            }
            return acc;
        }, [] as SearchResultItem[]);


        const summaries: string[] = [];
        // we are rate limited by firecrawl to two concurrent requests in the free tier
        for (let i = 0; i < flattenedResults.length; i += 2) {
            const batch = flattenedResults.slice(i, i + 2);
            const batchResults = await loadPageContent(batch, app);
            summaries.push(...batchResults.flat());
        }
        return synthesizeAnswer(summaries, userInput);
    } catch (e) {
        console.log((e as Error).message);
        console.log((e as Error).stack);
        return `Failed to scrape the webpage with FireCraw: ${(e as Error).message}`;
    }
}
````

## File: packages/services/google/src/index.ts
````typescript
export * from './lib/gsuiteClient';
export * from './lib/gsuiteClient.v2';
export * from './lib/gemeniStockMarketConditions';
export * from './lib/researchAssistant';
export { DRIVE_MIME_TYPES, DriveDateField } from '@codestrap/developer-foundations-types';
````

## File: packages/services/google/src/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            E2E: string;
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            FOUNDRY_TEST_USER: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            EIA_BASE_URL: string;
            EIA_API_KEY: string;
            CA_SERIES_ID: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: packages/services/google/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/services/google/jest.config.ts
````typescript
import * as dotenv from 'dotenv';

dotenv.config();

export default {
  displayName: 'google',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/services/google',
};
````

## File: packages/services/google/package.json
````json
{
  "name": "@codestrap/developer-foundations-services-google",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "@codestrap/developer-foundations-utils": "*",
    "@google/generative-ai": "^0.24.1",
    "googleapis": "^149.0.0",
    "tslib": "^2.3.0"
  },
  "devDependencies": {
    "@types/node": "^22.15.3"
  }
}
````

## File: packages/services/google/project.json
````json
{
  "name": "google-service",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/services/google/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:service"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/services/google",
        "main": "packages/services/google/src/index.ts",
        "tsConfig": "packages/services/google/tsconfig.lib.json",
        "assets": ["packages/services/google/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/services/google/jest.config.ts"
      }
    }
  }
}
````

## File: packages/services/google/README.md
````markdown
# google

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build google-service` to build the library.

## Running unit tests

Run `nx test google-service` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/services/google/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/services/google/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/services/google/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/services/palantir/src/lib/doa/communications/communications/read.ts
````typescript
import {
  FoundryClient,
  Communications,
} from '@codestrap/developer-foundations-types';

export async function readCommunications(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<Communications> {
  console.log(`readMachineExecution id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Communications/${id}`;
  const fetchResults = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await fetchResults.json()) as any;

  // NOT_FOUND errors are expected during polling operations. They are cluttering the console so I turned logging them off
  if (apiResponse.errorCode && apiResponse.errorCode !== 'NOT_FOUND') {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read communication errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(
    `the machine execution ontology returned: ${JSON.stringify(apiResponse)}`
  );

  return apiResponse as Communications;
}
````

## File: packages/services/palantir/src/lib/doa/communications/communications/upsert.ts
````typescript
import {
  Communications,
  FoundryClient,
} from '@codestrap/developer-foundations-types';
import { uuidv4 } from '@codestrap/developer-foundations-utils';

export async function upsertCommunications(
  channel: string,
  formattedMessage: string,
  status: string,
  taskList: string,
  comType: string,
  owner: string,
  token: string,
  ontologyRid: string,
  url: string,
  questionPrompt?: string,
  tokens?: number,
  id: string = uuidv4()
): Promise<Communications> {
  if (id.length === 0) {
    id = uuidv4();
  }

  console.log(`upsertCommunications id: ${id}`);

  const apiKey = token;

  const fullURl = `${url}/api/v2/ontologies/${ontologyRid}/actions/upsert-communication/apply`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      channel,
      formattedMessage,
      status,
      taskList,
      comType,
      owner,
      questionPrompt,
      tokens,
      id,
    },
    options: {
      returnEdits: 'ALL',
    },
  });

  const apiResult = await fetch(fullURl, {
    method: 'POST',
    headers,
    body,
  });

  const result = (await apiResult.json()) as any;

  if (!result.edits || result.edits.edits.length === 0) {
    throw new Error('Failed to upsert communications to the ontolgoy.');
  }

  console.log(
    `upsert communications action returned: ${result?.edits?.edits?.[0]}`
  );

  const commsId = result.edits.edits[0].primaryKey as string;

  const getUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Communications/${commsId}`;
  const fetchResults = await fetch(getUrl, {
    method: 'GET',
    headers: headers,
  });

  const comms = (await fetchResults.json()) as Communications;
  console.log(
    `the machine execution ontology returned: ${JSON.stringify(comms)}`
  );

  return comms;
}
````

## File: packages/services/palantir/src/lib/doa/communications/threads/read.ts
````typescript
import { FoundryClient, Threads } from '@codestrap/developer-foundations-types';

export async function readThread(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<Threads> {
  console.log(`readThread id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Threads/${id}`;
  const threadFetchResults = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await threadFetchResults.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read thread errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the threads ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse as Threads;
}
````

## File: packages/services/palantir/src/lib/doa/communications/threads/upsert.ts
````typescript
import { FoundryClient, Threads } from '@codestrap/developer-foundations-types';

export async function upsertThread(
  messages: string,
  appId: string,
  token: string,
  ontologyRid: string,
  url: string,
  id?: string
): Promise<Threads> {
  console.log(`upsertThread threadId: ${id}`);

  const apiKey = token;

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/actions/upsert-thread/apply`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      id,
      messages,
      appId,
    },
    options: {
      returnEdits: 'ALL',
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  if (!result.edits || result.edits.edits.length === 0) {
    throw new Error('Failed to upsert thread message to the ontology.');
  }

  console.log(`upsert thread action returned: ${result?.edits?.edits?.[0]}`);

  const threadId = result.edits.edits[0].primaryKey as string;

  const getUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Threads/${threadId}`;
  const machineFetchResults = await fetch(getUrl, {
    method: 'GET',
    headers: headers,
  });

  const thread = (await machineFetchResults.json()) as Threads;
  console.log(
    `the thread execution ontology returned: ${JSON.stringify(thread)}`
  );

  return thread;
}
````

## File: packages/services/palantir/src/lib/doa/communications/commsDao.test.ts
````typescript
describe('Communications DAO', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/palantir/src/lib/doa/communications/commsDao.ts
````typescript
import {
  SupportedFoundryClients,
  type CommsDao,
} from '@codestrap/developer-foundations-types';
import { readCommunications } from './communications/read';
import { upsertCommunications } from './communications/upsert';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeCommsDao(): CommsDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (
      channel: string,
      formattedMessage: string,
      status: string,
      taskList: string,
      comType: string,
      owner: string,
      questionPrompt?: string,
      tokens?: number,
      id?: string
    ) => {
      const token = await getToken();

      const comms = await upsertCommunications(
        channel,
        formattedMessage,
        status,
        taskList,
        comType,
        owner,
        token,
        ontologyRid,
        url,
        questionPrompt,
        tokens,
        id
      );

      return comms;
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting machines but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const token = await getToken();

      const comms = await readCommunications(id, token, ontologyRid, url);

      return comms;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/communications/threadsDao.ts
````typescript
import {
  SupportedFoundryClients,
  type ThreadsDao,
} from '@codestrap/developer-foundations-types';
import { upsertThread } from './threads/upsert';
import { readThread } from './threads/read';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeThreadsDao(): ThreadsDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (messages: string, appId: string, id?: string) => {
      const token = await getToken();

      const machine = await upsertThread(messages, appId, token, ontologyRid, url, id);

      return machine;
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting threads but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const token = await getToken();

      const machine = await readThread(id, token, ontologyRid, url);

      return machine;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/crm/delegates/contacts/read.ts
````typescript
import {
  FoundryClient,
  Contacts,
} from '@codestrap/developer-foundations-types';

export async function readContact(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<Contacts> {
  console.log(`readContact id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Contacts/${id}`;
  const contactFetchResults = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await contactFetchResults.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read machine errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(
    `the machine execution ontology returned: ${JSON.stringify(apiResponse)}`
  );

  return apiResponse as Contacts;
}
````

## File: packages/services/palantir/src/lib/doa/crm/delegates/contacts/search.ts
````typescript
import {
  Contacts,
  FoundryClient,
} from '@codestrap/developer-foundations-types';

export async function searchContacts(
  fullName: string,
  company: string,
  token: string,
  ontologyRid: string,
  url: string,
  pageSize = 10
): Promise<Contacts[]> {
  console.log(`searchContacts fullName: ${fullName} company: ${company}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Contacts/search`;

  const body = JSON.stringify({
    pageSize,
    where: {
      type: 'and',
      value: [
        {
          type: 'containsAnyTerm',
          field: 'fullName',
          value: fullName,
          fuzzy: true,
        },
        {
          type: 'containsAnyTerm',
          field: 'enterpriseName',
          value: company,
          fuzzy: true,
        },
      ],
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const apiResponse = (await apiResult.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling search Contacts errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the Contacts ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse.data as Contacts[];
}
````

## File: packages/services/palantir/src/lib/doa/crm/contactsDao.ts
````typescript
import {
  SupportedFoundryClients,
  type ContactsDao,
} from '@codestrap/developer-foundations-types';
import { readContact } from './delegates/contacts/read';
import { searchContacts } from './delegates/contacts/search';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeContactsDao(): ContactsDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (
      primaryKey_: string,
      email: string,
      firstName: string,
      lastName: string,
      codestrapPoc?: string[],
      company?: string,
      contactCategory?: string,
      countryOfResidence?: string,
      executiveAssistant?: string,
      fullName?: string,
      keyAccounts?: string,
      linkedIn?: string,
      notes?: string[],
      phoneNumberMain?: string,
      phoneNumberSecondary?: string,
      relationshipStatus?: string[],
      role?: string,
      talksTo?: string
    ) => {
      console.log(
        `stub upsert method for Contacts. We do not support upsert for this object type.`
      );
      return {
        primaryKey_,
        email,
        firstName,
        lastName,
        codestrapPoc,
        company,
        contactCategory,
        countryOfResidence,
        executiveAssistant,
        fullName,
        keyAccounts,
        linkedIn,
        notes,
        phoneNumberMain,
        phoneNumberSecondary,
        relationshipStatus,
        role,
        talksTo,
      };
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting RfpRequests but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const token = await getToken();
      const contact = await readContact(id, token, ontologyRid, url);

      return contact;
    },
    search: async (fullName: string, company: string, pageSize?: number) => {
      const token = await getToken();
      const result = await searchContacts(fullName, company, token, ontologyRid, url, pageSize);

      return result;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/crm/userDao.ts
````typescript
import {
  SupportedFoundryClients,
  type UserDao,
} from '@codestrap/developer-foundations-types';
import { Users } from '@osdk/foundry.admin';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeUserDao(): UserDao {
  const { getUser } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return async (userId?: string) => {
    const user = await getUser();
    console.log('OSDK makeUserDao returned:', user);

    return user;
  };
}
````

## File: packages/services/palantir/src/lib/doa/hello-world/worldDao.test.ts
````typescript
describe('World DAO', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/palantir/src/lib/doa/hello-world/worldDao.ts
````typescript
import {
  SupportedFoundryClients,
  type WorldDao,
} from '@codestrap/developer-foundations-types';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeWorldDao(): WorldDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return async ({ message, userId }) => {
    console.log(`makeWorldDao userId: ${userId}`);

    const apiKey = await getToken();

    const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/actions/say-hello/apply`;

    const headers = {
      Authorization: `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    };

    const body = JSON.stringify({
      parameters: {
        message,
      },
      options: {
        returnEdits: 'ALL',
      },
    });

    const apiResult = await fetch(fullUrl, {
      method: 'POST',
      headers: headers,
      body: body,
    });

    const result = (await apiResult.json()) as any;

    if (!result.edits || result.edits.edits.length === 0) {
      throw new Error('Failed to add hello message to the ontology.');
    }

    console.log(`create world action returned: ${result?.edits?.edits?.[0]}`);

    const worldId = result.edits.edits[0].primaryKey as string;

    const getUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/World/${worldId}`;
    const worldFetchResults = await fetch(getUrl, {
      method: 'GET',
      headers: headers,
    });

    const world = (await worldFetchResults.json()) as any;
    console.log(`the world ontology returned: ${JSON.stringify(world)}`);

    return { id: 'singleton', greeting: world.message };
  };
}
````

## File: packages/services/palantir/src/lib/doa/platform/delegates/machine/read.ts
````typescript
import {
  FoundryClient,
  MachineExecutions,
} from '@codestrap/developer-foundations-types';

export async function readMachineExecution(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<MachineExecutions> {
  console.log(`readMachineExecution id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/MachineExecutions/${id}`;
  const machineFetchResults = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await machineFetchResults.json()) as any;

  // NOT_FOUND errors are expected during polling operations. They are cluttering the console so I turned logging them off
  if (apiResponse.errorCode && apiResponse.errorCode !== 'NOT_FOUND') {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read machine errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  // trimming this out because the logs make these object massive
  // console.log(`the machine execution ontology returned: ${JSON.stringify(apiResponse)}`)

  return apiResponse as MachineExecutions;
}
````

## File: packages/services/palantir/src/lib/doa/platform/delegates/machine/upsert.ts
````typescript
import {
  FoundryClient,
  MachineExecutions,
} from '@codestrap/developer-foundations-types';

export async function upsertMachineExecution(
  id: string,
  stateMachine: string,
  state: string,
  logs: string,
  token: string,
  ontologyRid: string,
  url: string,
  lockOwner?: string,
  lockUntil?: number
): Promise<MachineExecutions> {
  console.log(`upsertMachineExecution machineId: ${id}`);

  const apiKey = token;

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/actions/upsert-machine/apply`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      id,
      stateMachine,
      state,
      logs,
      lockOwner,
      lockUntil,
    },
    options: {
      returnEdits: 'ALL',
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  if (!result.edits || result.edits.edits.length === 0) {
    throw new Error(`Failed to upsert machine message to the ontology with:
            ${JSON.stringify(result)}
            `);
  }

  console.log(`upsert machine action returned: ${result?.edits?.edits?.[0]}`);

  const machineId = result.edits.edits[0].primaryKey as string;

  const getUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/MachineExecutions/${machineId}`;
  const machineFetchResults = await fetch(getUrl, {
    method: 'GET',
    headers: headers,
  });

  const machine = (await machineFetchResults.json()) as MachineExecutions;
  // trimming this out because the logs make these object massive
  //console.log(`the machine execution ontology returned: ${JSON.stringify(machine)}`)

  return machine;
}
````

## File: packages/services/palantir/src/lib/doa/platform/delegates/memoryRecall/read.ts
````typescript
import {
  FoundryClient,
  MemoryRecall,
} from '@codestrap/developer-foundations-types';

export async function readMemoryRecall(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<MemoryRecall> {
  console.log(`readMemoryRecall id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/MemoryRecall/${id}`;
  const memoryRecallFetchResults = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await memoryRecallFetchResults.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read machine errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(
    `the machine execution ontology returned: ${JSON.stringify(apiResponse)}`
  );

  return apiResponse as MemoryRecall;
}
````

## File: packages/services/palantir/src/lib/doa/platform/delegates/memoryRecall/search.ts
````typescript
import {
  FoundryClient,
  MemoryRecall,
} from '@codestrap/developer-foundations-types';

// performs a vector search against the MemoryREcall objects using a proxy
// The OSDK does not support vector types yet.
// See https://www.palantir.com/docs/foundry/ontology-sdk/unsupported-types.
export async function searchMemoryRecall(
  input: string,
  kValue: number,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<MemoryRecall[]> {
  console.log(`searchMemoryRecall input search query: ${input}}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/queries/memoryRecalVectorSearch/execute`;

  const body = JSON.stringify({
    parameters: {
      input,
      kValue,
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const apiResponse = (await apiResult.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling memory recall search errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the threads ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse.value as MemoryRecall[];
}
````

## File: packages/services/palantir/src/lib/doa/platform/delegates/trainingData/read.ts
````typescript
import {
  FoundryClient,
  TrainingData,
} from '@codestrap/developer-foundations-types';

export async function readTrainingData(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<TrainingData> {
  console.log(`readTrainingData id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/XReasonTrainingData/${id}`;
  const fetchResult = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await fetchResult.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read Training Data errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the threads ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse as TrainingData;
}
````

## File: packages/services/palantir/src/lib/doa/platform/delegates/trainingData/search.ts
````typescript
import {
  FoundryClient,
  TrainingData,
} from '@codestrap/developer-foundations-types';

export async function searchTrainingData(
  xReason: string,
  type: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<TrainingData[]> {
  console.log(`searchTrainingData xReason: ${xReason} type: ${type}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/XReasonTrainingData/search`;

  const body = JSON.stringify({
    where: {
      type: 'and',
      value: [
        {
          type: 'eq',
          field: 'xReason',
          value: xReason,
        },
        {
          type: 'eq',
          field: 'type',
          value: type,
        },
      ],
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const apiResponse = (await apiResult.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read Training Data errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the threads ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse.data as TrainingData[];
}
````

## File: packages/services/palantir/src/lib/doa/platform/machineDao.test.ts
````typescript
describe('Machine DAO', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/palantir/src/lib/doa/platform/machineDao.ts
````typescript
import {
  SupportedFoundryClients,
  type MachineDao,
} from '@codestrap/developer-foundations-types';
import { upsertMachineExecution } from './delegates/machine/upsert';
import { readMachineExecution } from './delegates/machine/read';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeMachineDao(): MachineDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (
      id: string,
      stateMachine: string,
      state: string,
      logs: string,
      lockOwner?: string,
      lockUntil?: number
    ) => {
      const token = await getToken();

      const machine = await upsertMachineExecution(
        id,
        stateMachine,
        state,
        logs,
        token,
        ontologyRid,
        url,
        lockOwner,
        lockUntil
      );

      return machine;
    },
    delete: async (machineExecutionId: string) =>
      console.log(
        `stub delete method called for: ${machineExecutionId}. We do not support deleting machines but include the method as it is part of the interface.`
      ),
    read: async (machineExecutionId: string) => {
      const token = await getToken();

      const machine = await readMachineExecution(machineExecutionId, token, ontologyRid, url);

      return machine;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/platform/memoryRecallDao.ts
````typescript
import {
  SupportedFoundryClients,
  type MemoryRecallDao,
} from '@codestrap/developer-foundations-types';
import { searchMemoryRecall } from './delegates/memoryRecall/search';
import { readMemoryRecall } from './delegates/memoryRecall/read';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeMemoryRecallDao(): MemoryRecallDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (input: string) => {
      console.log(
        `stub upsert method for ${input}. We do not support upsert for this object type.`
      );
      return {
        createdOn: Date.now(),
        id: 'stubId',
        originalText: 'stub text',
        source: 'stubSource',
        userId: 'stubUserId',
      };
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting RfpRequests but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const token = await getToken();

      const memoryRecall = await readMemoryRecall(id, token, ontologyRid, url);

      return memoryRecall;
    },
    search: async (task: string, kValue: number = 1) => {
      const token = await getToken();

      const results = await searchMemoryRecall(task, kValue, token, ontologyRid, url);
      // there should be only one results based on the params
      return results;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/platform/trainingDataDao.ts
````typescript
import {
  SupportedFoundryClients,
  type TrainingDataDao,
} from '@codestrap/developer-foundations-types';
import { readTrainingData } from './delegates/trainingData/read';
import { searchTrainingData } from './delegates/trainingData/search';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeTrainingDataDao(): TrainingDataDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (
      id: string,
      isGood: boolean,
      type: string,
      xReason: string,
      machine?: string,
      solution?: string,
      humanReview?: string
    ) => {
      console.log(
        `stub upsert method for makeTrainingDataDao. We do not support upsert for this object type.`
      );
      return {
        isGood,
        type,
        xReason,
        machine,
        solution,
        humanReview,
        primaryKey_: id,
      };
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting RfpRequests but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const token = await getToken();

      const memoryRecall = await readTrainingData(id, token, ontologyRid, url);

      return memoryRecall;
    },
    search: async (xReason: string, type: string) => {
      const token = await getToken();

      const results = await searchTrainingData(xReason, type, token, ontologyRid, url);
      // there should be only one results based on the params
      return results;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/projects/delegates/tasks/read.ts
````typescript
import { FoundryClient, Tickets } from '@codestrap/developer-foundations-types';

export async function readTicket(
  id: string,
  token: string,
  ontologyRid: string,
  url: string,
): Promise<Tickets> {
  console.log(`readTicket id: ${id}`);

  const apiKey = token;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Tickets/${id}`;
  const machineFetchResults = await fetch(fullUrl, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await machineFetchResults.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read ticket errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(
    `the ticket execution ontology returned: ${JSON.stringify(apiResponse)}`
  );

  return apiResponse as Tickets;
}
````

## File: packages/services/palantir/src/lib/doa/projects/delegates/tasks/upsert.ts
````typescript
import { FoundryClient, Tickets } from '@codestrap/developer-foundations-types';

export async function upsertTicket(
  token: string,
  ontologyRid: string,
  url: string,
  id: string,
  alertTitle: string,
  alertType: string,
  description: string,
  severity: string = 'Low',
  status: string = 'Open',
  points?: number,
  assignees?: string
): Promise<Tickets> {
  console.log(`upsertTicket machineId: ${id}`);

  const apiKey = token;

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/actions/upsert-ticket/apply`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      id,
      alertTitle,
      alertType,
      description,
      severity,
      status,
      points,
      assignees,
    },
    options: {
      returnEdits: 'ALL',
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  if (!result.edits || result.edits.edits.length === 0) {
    throw new Error('Failed to upsert ticket message to the ontolgoy.');
  }

  console.log(`upsert ticket action returned: ${result?.edits?.edits?.[0]}`);

  const ticketId = result.edits.edits[0].primaryKey as string;

  const getUrl = `${url}/api/v2/ontologies/${ontologyRid}/objects/Tickets/${ticketId}`;
  const ticketFetchResults = await fetch(getUrl, {
    method: 'GET',
    headers: headers,
  });

  const ticket = (await ticketFetchResults.json()) as Tickets;
  console.log(
    `the ticket execution ontology returned: ${JSON.stringify(ticket)}`
  );

  return ticket;
}
````

## File: packages/services/palantir/src/lib/doa/projects/ticketsDao.test.ts
````typescript
describe('Tickets DAO', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/palantir/src/lib/doa/projects/ticketsDao.ts
````typescript
import {
  SupportedFoundryClients,
  type TicketsDao,
} from '@codestrap/developer-foundations-types';
import { upsertTicket } from './delegates/tasks/upsert';
import { readTicket } from './delegates/tasks/read';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeTicketsDao(): TicketsDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (
      id: string,
      alertTitle: string,
      alertType: string,
      description: string,
      severity: string = 'Low',
      status: string = 'Open',
      points?: number,
      assignees?: string
    ) => {
      const token = await getToken();

      const ticket = await upsertTicket(
        token,
        ontologyRid,
        url,
        id,
        alertTitle,
        alertType,
        description,
        severity,
        status,
        points,
        assignees
      );

      return ticket;
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting tickets but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const token = await getToken();

      const ticket = await readTicket(id, token, ontologyRid, url);

      return ticket;
    },
  };
}
````

## File: packages/services/palantir/src/lib/doa/telemetry/telemetryDao.ts
````typescript
import {
  SupportedFoundryClients,
  type TelemetryDao,
} from '@codestrap/developer-foundations-types';
import { foundryClientFactory } from '../../factory/foundryClientFactory';

export function makeTelemetryDao(): TelemetryDao {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  return async (inputJSON) => {
    console.log(`telemetryDao telemetryDao: ${inputJSON}`);

    const token = await getToken();
    const apiKey = token;

    const headers = {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`,
    };

    const body = JSON.stringify({
      parameters: {
        inputJSON,
      },
      options: {
        returnEdits: 'ALL',
      },
    });

    const apiResults = await fetch(
      `${url}/api/v2/ontologies/${ontologyRid}/actions/collect-telemetry/apply`,
      {
        method: 'POST',
        headers,
        body,
      }
    );

    const apiResponse = (await apiResults.json()) as any;

    if (apiResponse.errorCode) {
      console.log(
        `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
      );
      throw new Error(
        `An error occurred while writing telemetry data errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
      );
    }

    return JSON.stringify(apiResponse);
  };
}
````

## File: packages/services/palantir/src/lib/factory/foundryClientFactory.ts
````typescript
import { FoundryClient, SupportedFoundryClients } from '@codestrap/developer-foundations-types';
import { curry } from 'ramda';
import { getFoundryClient as getFoundryClientPrivate } from '../foundryClient';
import { getFoundryClient as getFoundryClientPublic } from '../foundryClientPublic';

// in your factor injection factory
const factory = curry((
    map: Record<SupportedFoundryClients, (config?: Record<string, any>) => FoundryClient>,
    key: SupportedFoundryClients,
    config?: Record<string, any>
) => {
    const supportedKeys = Object.keys(SupportedFoundryClients).map((item) =>
        item.toLowerCase()
    );

    if (!supportedKeys.includes(key)) {
        throw new Error('unsupported key ${key}');
    }

    return map[key](config);
});

const clients = {
    public: (config?: Record<string, any>) => {
        console.log(`config for getFoundryClientPublic is: ${config}`);
        return getFoundryClientPublic();
    },
    private: (config?: Record<string, any>) => {
        console.log(`config for getFoundryClientPrivate is: ${config}`);
        return getFoundryClientPrivate();
    }
}

export const foundryClientFactory = factory(clients) as (key: SupportedFoundryClients, config?: Record<string, any>) => FoundryClient;
````

## File: packages/services/palantir/src/lib/embeddingsService.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";
import { foundryClientFactory } from "./factory/foundryClientFactory";

export async function embeddingsService(input: string): Promise<[number[]]> {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  const apiKey = await getToken();

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/queries/textEmeddingSmall/execute`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      input,
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  return result.value as [number[]];
}
````

## File: packages/services/palantir/src/lib/foundryClient.test.ts
````typescript
describe('Foundry Client', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/palantir/src/lib/foundryClient.ts
````typescript
import { createClient } from '@osdk/client';
import { User, Users } from '@osdk/foundry.admin';
import { createConfidentialOauthClient } from '@osdk/oauth';
import { FoundryClient, Token } from '@codestrap/developer-foundations-types';
import { getRequestContext } from '@codestrap/developer-foundations-utils/src/lib/asyncLocalStorage';

// this is a utility method to manage usage of the Foundry Client and ensure we only get a singleton
// files in the palantir services package can't use the container to get the foundry client, nor should they really
// They are in the same package
let client: FoundryClient | undefined = undefined;

export function getFoundryClient(): FoundryClient {
  if (!client) {
    client = createFoundryClient();
  }

  return client;
}

function createFoundryClient(): FoundryClient {
  // log ENV vars
  console.log('Environment variable keys:');
  Object.keys(process.env).forEach((key) => {
    if (key.indexOf('FOUNDRY') >= 0 || key.indexOf('OSDK') >= 0) {
      console.log(`- ${key}`);
    }
  });

  if (!process.env['OSDK_CLIENT_ID'] || !process.env['OSDK_CLIENT_SECRET']) {
    throw new Error(
      'missing required env vars: OSDK_CLIENT_ID, OSDK_CLIENT_SECRET'
    );
  }

  // setup the OSDK
  const clientId: string = process.env['OSDK_CLIENT_ID']!;
  const url: string = process.env['FOUNDRY_STACK_URL']!;
  const ontologyRid: string = process.env['ONTOLOGY_RID']!;
  const clientSecret: string = process.env['OSDK_CLIENT_SECRET']!;
  const scopes: string[] = [
    'api:use-ontologies-read',
    'api:use-ontologies-write',
    'api:use-admin-read',
    'api:use-connectivity-read',
    'api:use-connectivity-execute',
    'api:use-orchestration-read',
    'api:use-mediasets-read',
    'api:use-mediasets-write',
  ];

  const auth = createConfidentialOauthClient(
    clientId,
    clientSecret,
    url,
    scopes
  );

  const client = createClient(url, ontologyRid, auth);

  const getUser = async () => {
    const context = getRequestContext();
    // check if a request has supplied a userId that this request should be grounded on
    if (context?.user?.id) {
      const user: User = await Users.get(client, context.user.id);
      return user;
    }

    const user: User = await Users.getCurrent(client);

    return user;
  };

  let token: Token | undefined;
  let tokenExpire: Date | undefined;
  let pendingRequest: Promise<Token> | undefined;

  auth.addEventListener('signIn', (evt) => {
    token = evt.detail; // Token
    tokenExpire = new Date(token.expires_at);
  });

  auth.addEventListener('signOut', (evt) => {
    token = undefined;
    tokenExpire = undefined;
  });

  const getToken = async function () {

    if (token && tokenExpire) {
      // add 60 seconds to account for processing time
      const skew = tokenExpire.getTime() + 60000;

      if (skew > new Date().getTime()) {
        return token.access_token;
      }
    }
    // avoid duplicate signin requests
    if (!pendingRequest) {
      pendingRequest = auth.signIn();
    }

    try {
      token = await pendingRequest;

      return token.access_token;
    } catch (e) {
      console.log(e);

      throw (e);
    } finally {
      pendingRequest = undefined;
    }

  }

  return { auth, ontologyRid, url, client, getUser, getToken };
}
````

## File: packages/services/palantir/src/lib/foundryClientPublic.ts
````typescript
import { FoundryClient } from '@codestrap/developer-foundations-types';
import { getRequestContext } from '@codestrap/developer-foundations-utils/src/lib/asyncLocalStorage';

// this is a utility method to manage usage of the Foundry Client and ensure we only get a singleton
// files in the palantir services package can't use the container to get the foundry client, nor should they really
// They are in the same package
let client: FoundryClient | undefined = undefined;

export function getFoundryClient(): FoundryClient {
  if (!client) {
    client = createFoundryClient();
  }

  return client;
}

function createFoundryClient(): FoundryClient {
  // log ENV vars
  console.log('Environment variable keys:');
  Object.keys(process.env).forEach((key) => {
    if (key.indexOf('NEXT_PUBLIC_') >= 0) {
      console.log(`- ${key}`);
    }
  });

  if (!process.env['NEXT_PUBLIC_OSDK_CLIENT_ID']
    || !process.env['NEXT_PUBLIC_REDIRECT_URL']
    || !process.env['NEXT_PUBLIC_FOUNDRY_STACK_URL']
    || !process.env['NEXT_PUBLIC_ONTOLOGY_RID']
  ) {
    throw new Error(
      'missing required env vars: NEXT_PUBLIC_OSDK_CLIENT_ID, NEXT_PUBLIC_REDIRECT_URL, NEXT_PUBLIC_FOUNDRY_STACK_URL, NEXT_PUBLIC_ONTOLOGY_RID'
    );
  }


  const getUser = async () => {
    const context = getRequestContext();

    console.log(`public getUser called, returning: ${context?.user?.username}`);


    return context?.user;
  };

  // IMPORTANT: the createPublicOauthClient method requires running client side
  // hence we return stubs here and use a global to retrieve the token
  // This global will get overwritten upon every API request and is managed client side
  // so we "assume" it's valid and that the client is using the OSDK client to get refresh tokens
  const getToken = async function () {
    const context = getRequestContext();

    console.log(`public getToken called, returning length: ${context?.token?.length}`);

    return context?.token;

  }

  const auth = {
    client: {},
    auth: {},
    ontologyRid: process.env['NEXT_PUBLIC_ONTOLOGY_RID'],
    url: process.env['NEXT_PUBLIC_FOUNDRY_STACK_URL'],
    getUser: () => 'undefined',
    getToken: () => 'undefined',
  }
  // @ts-expect-error we return a mock client since the actual auth is managed client side
  return { auth, ontologyRid: process.env['NEXT_PUBLIC_ONTOLOGY_RID'], url: process.env['NEXT_PUBLIC_FOUNDRY_STACK_URL'], client, getUser, getToken };
}
````

## File: packages/services/palantir/src/lib/geminiService.ts
````typescript
import {
  SupportedFoundryClients,
  type GeminiParameters,
} from '@codestrap/developer-foundations-types';
import { foundryClientFactory } from "./factory/foundryClientFactory";

export async function geminiService(
  user: string,
  system: string,
  params?: GeminiParameters
): Promise<string> {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  const apiKey = await getToken();

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/queries/gemniFlash20Proxy/execute`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      user,
      system,
      params,
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  return result.value as string;
}
````

## File: packages/services/palantir/src/lib/gpt4oService.ts
````typescript
import {
  SupportedFoundryClients,
  type Gpt40Parameters,
} from '@codestrap/developer-foundations-types';
import { foundryClientFactory } from './factory/foundryClientFactory';

export async function gpt4oService(
  user: string,
  system: string,
  gptParams?: Gpt40Parameters
): Promise<string> {
  const { getToken, url, ontologyRid } = foundryClientFactory(process.env.FOUNDRY_CLIENT_TYPE || SupportedFoundryClients.PRIVATE, undefined);

  const apiKey = await getToken();

  const fullUrl = `${url}/api/v2/ontologies/${ontologyRid}/queries/gpt4oProxy/execute`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      user,
      system,
      gptParams,
    },
  });

  const apiResult = await fetch(fullUrl, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  return result.value as string;
}
````

## File: packages/services/palantir/src/index.ts
````typescript
export * from './lib/foundryClient';
export * from './lib/embeddingsService';
export * from './lib/gpt4oService';
export * from './lib/geminiService';
export * from './lib/doa/communications/commsDao';
export * from './lib/doa/communications/threadsDao';
export * from './lib/doa/crm/contactsDao';
export * from './lib/doa/crm/userDao';
export * from './lib/doa/hello-world/worldDao';
export * from './lib/doa/platform/machineDao';
export * from './lib/doa/platform/memoryRecallDao';
export * from './lib/doa/platform/trainingDataDao';
export * from './lib/doa/projects/ticketsDao';
export * from './lib/doa/telemetry/telemetryDao';
export * from './lib/factory/foundryClientFactory';
````

## File: packages/services/palantir/src/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            FOUNDRY_TEST_USER: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: packages/services/palantir/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/services/palantir/jest.config.ts
````typescript
export default {
  displayName: 'palantir',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/services/palantir',
};
````

## File: packages/services/palantir/package.json
````json
{
  "name": "@codestrap/developer-foundations-services-palantir",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "@osdk/client": "^2.2.1",
    "@osdk/foundry.admin": "^2.22.0",
    "@osdk/oauth": "^1.1.2",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/services/palantir/project.json
````json
{
  "name": "palantir-service",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/services/palantir/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:service"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/services/palantir",
        "main": "packages/services/palantir/src/index.ts",
        "tsConfig": "packages/services/palantir/tsconfig.lib.json",
        "assets": ["packages/services/palantir/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/services/palantir/jest.config.ts"
      }
    }
  }
}
````

## File: packages/services/palantir/README.md
````markdown
# palantir

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build palantir-service` to build the library.

## Running unit tests

Run `nx test palantir-service` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/services/palantir/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/services/palantir/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/services/palantir/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/services/rangr/src/lib/doa/rfp/delegates/rangr/submit.ts
````typescript
import {
  RangrClient,
  RfpRequestResponse,
} from '@codestrap/developer-foundations-types';
import { uuidv4 } from '@codestrap/developer-foundations-utils';

export async function submitRangrRfp(
  rfp: string,
  machineExecutionId: string,
  client: RangrClient
): Promise<RfpRequestResponse> {
  console.log(`upsertRfpRequest machineExecutionId: ${machineExecutionId}`);

  const apiKey = await client.getToken();

  const url = `${client.url}/api/v2/ontologies/${client.ontologyRid}/actions/submit-rfp-request/apply`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      message: rfp,
      machineExecutionId,
    },
    options: {
      returnEdits: 'ALL',
    },
  });

  const apiResult = await fetch(url, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  // TODO implement error handling based on RANG spec
  // if (!result.edits || result.edits.edits.length === 0) {
  // throw new Error('Failed to submit RfpRequest to the ontology.');
  // }

  const message = JSON.stringify(result);

  return {
    // TODO replace with status and message from service
    status: 200,
    message,
    // TODO figure out a better way to manage vendorName and ID
    vendorName: 'RANGR',
    vendorId: 'rangrdata.com',
    received: false,
    // TODO add executionId to context
    machineExecutionId,
    // TODO replace with reciept from service
    receipt: {
      id: uuidv4(),
      timestamp: new Date(),
    },
  };
}
````

## File: packages/services/rangr/src/lib/doa/rfp/delegates/rfpRequests/read.ts
````typescript
import {
  RangrClient,
  RfpRequests,
} from '@codestrap/developer-foundations-types';

export async function readRfpRequest(
  id: string,
  client: RangrClient
): Promise<RfpRequests> {
  console.log(`readRfpRequest id: ${id}`);

  const apiKey = await client.getToken();

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const url = `${client.url}/api/v2/ontologies/${client.ontologyRid}/objects/RfpRequests/${id}`;
  const fetchResult = await fetch(url, {
    method: 'GET',
    headers: headers,
  });

  const apiResponse = (await fetchResult.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read RfpRequest errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the threads ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse as RfpRequests;
}
````

## File: packages/services/rangr/src/lib/doa/rfp/delegates/rfpRequests/search.ts
````typescript
import {
  RangrClient,
  RfpRequests,
} from '@codestrap/developer-foundations-types';

export async function searchRfpRequest(
  machineExecutionId: string,
  vendorId: string,
  client: RangrClient
): Promise<RfpRequests[]> {
  console.log(
    `searchRfpRequest machineExecutionId: ${machineExecutionId} vendorId: ${vendorId}`
  );

  const apiKey = await client.getToken();

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const url = `${client.url}/api/v2/ontologies/${client.ontologyRid}/objects/RfpRequests/search`;

  const body = JSON.stringify({
    where: {
      type: 'and',
      value: [
        {
          type: 'eq',
          field: 'machineExecutionId',
          value: machineExecutionId,
        },
        {
          type: 'eq',
          field: 'vendorId',
          value: vendorId,
        },
      ],
    },
  });

  const apiResult = await fetch(url, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const apiResponse = (await apiResult.json()) as any;

  if (apiResponse.errorCode) {
    console.log(
      `errorInstanceId: ${apiResponse.errorCode} errorName: ${apiResponse.errorName} errorCode: ${apiResponse.errorCode}`
    );
    throw new Error(
      `An error occurred while calling read RfpRequest errorInstanceId: ${apiResponse.errorInstanceId} errorCode: ${apiResponse.errorCode}`
    );
  }

  console.log(`the threads ontology returned: ${JSON.stringify(apiResponse)}`);

  return apiResponse.data as RfpRequests[];
}
````

## File: packages/services/rangr/src/lib/doa/rfp/delegates/rfpRequests/upsert.ts
````typescript
import {
  RangrClient,
  RfpRequests,
} from '@codestrap/developer-foundations-types';

export async function upsertRfpRequest(
  rfp: string,
  rfpVendorResponse: string,
  vendorId: string,
  machineExecutionId: string,
  client: RangrClient,
  id?: string,
  rfpResponseStatus?: number
): Promise<RfpRequests> {
  console.log(`upsertThread threadId: ${id}`);

  const apiKey = await client.getToken();

  const url = `${client.url}/api/v2/ontologies/${client.ontologyRid}/actions/upsert-rfp-requests/apply`;

  const headers = {
    Authorization: `Bearer ${apiKey}`,
    'Content-Type': 'application/json',
  };

  const body = JSON.stringify({
    parameters: {
      rfp,
      rfpVendorResponse,
      vendorId,
      machineExecutionId,
      id,
      rfpResponseStatus,
    },
    options: {
      returnEdits: 'ALL',
    },
  });

  const apiResult = await fetch(url, {
    method: 'POST',
    headers: headers,
    body: body,
  });

  const result = (await apiResult.json()) as any;

  if (!result.edits || result.edits.edits.length === 0) {
    throw new Error('Failed to upsert RfpRequest to the ontology.');
  }

  console.log(
    `upsert RfpRequest action returned: ${result?.edits?.edits?.[0]}`
  );

  const rfpId = result.edits.edits[0].primaryKey as string;

  const getUrl = `${client.url}/api/v2/ontologies/${client.ontologyRid}/objects/RfpRequests/${rfpId}`;
  const machineFetchResults = await fetch(getUrl, {
    method: 'GET',
    headers: headers,
  });

  const rfpRequest = (await machineFetchResults.json()) as RfpRequests;
  console.log(
    `the read RfpRequest request returned: ${JSON.stringify(rfpRequest)}`
  );

  return rfpRequest;
}
````

## File: packages/services/rangr/src/lib/doa/rfp/rangrRfpRequestsDao.ts
````typescript
import type {
  RangrRequestsDao,
} from '@codestrap/developer-foundations-types';
import { getRangrClient } from '../../rangrClient';
import { submitRangrRfp } from './delegates/rangr/submit';

export function makeRangrRfpRequestsDao(): RangrRequestsDao {
  const client = getRangrClient();

  return {
    // TODO code out all methods using OSDK API calls
    submit: async (rfp: string, machineExecutionId: string) => {
      const machine = await submitRangrRfp(rfp, machineExecutionId, client);

      return machine;
    },
  };
}
````

## File: packages/services/rangr/src/lib/doa/rfp/rfpRequestsDao.ts
````typescript
import type {
  RfpRequestsDao,
} from '@codestrap/developer-foundations-types';
import { getRangrClient } from '../../rangrClient';
import { upsertRfpRequest } from './delegates/rfpRequests/upsert';
import { readRfpRequest } from './delegates/rfpRequests/read';
import { searchRfpRequest } from './delegates/rfpRequests/search';

export function makeRfpRequestsDao(): RfpRequestsDao {
  const client = getRangrClient();

  return {
    // TODO code out all methods using OSDK API calls
    upsert: async (
      rfp: string,
      rfpVendorResponse: string,
      vendorId: string,
      machineExecutionId: string,
      id?: string,
      rfpResponseStatus?: number
    ) => {
      const machine = await upsertRfpRequest(
        rfp,
        rfpVendorResponse,
        vendorId,
        machineExecutionId,
        client,
        id,
        rfpResponseStatus
      );

      return machine;
    },
    delete: async (id: string) =>
      console.log(
        `stub delete method called for: ${id}. We do not support deleting RfpRequests but include the method as it is part of the interface.`
      ),
    read: async (id: string) => {
      const machine = await readRfpRequest(id, client);

      return machine;
    },
    search: async (machineExecutionId: string, vendorId: string) => {
      const results = await searchRfpRequest(
        machineExecutionId,
        vendorId,
        client
      );
      // there should be only one results based on the params
      return results[0];
    },
  };
}
````

## File: packages/services/rangr/src/lib/rangrClient.test.ts
````typescript
describe('Rangr Client', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/rangr/src/lib/rangrClient.ts
````typescript
import { createClient } from '@osdk/client';
import { User, Users } from '@osdk/foundry.admin';
import { createConfidentialOauthClient } from '@osdk/oauth';
import { RangrClient, Token } from '@codestrap/developer-foundations-types';

let client: RangrClient | undefined = undefined;

export function getRangrClient(): RangrClient {
  if (!client) {
    client = createRangrClient();
  }

  return client;
}

function createRangrClient(): RangrClient {
  // log ENV vars
  console.log('Environment variable keys:');
  Object.keys(process.env).forEach((key) => {
    if (key.indexOf('RANGR_FOUNDRY') >= 0 || key.indexOf('RANGR_OSDK') >= 0) {
      console.log(`- ${key}`);
    }
  });

  if (
    !process.env['RANGR_OSDK_CLIENT_ID'] ||
    !process.env['RANGR_OSDK_CLIENT_SECRET'] ||
    !process.env['RANGR_ONTOLOGY_RID'] ||
    !process.env['RANGR_OSDK_CLIENT_SECRET']
  ) {
    throw new Error('missing required env vars for RANGR');
  }

  // setup the OSDK
  const clientId: string = process.env['RANGR_OSDK_CLIENT_ID'] || '';
  const url: string = process.env['RANGR_FOUNDRY_STACK_URL'] || '';
  const ontologyRid: string = process.env['RANGR_ONTOLOGY_RID'] || '';
  const clientSecret: string = process.env['RANGR_OSDK_CLIENT_SECRET'] || '';
  const scopes: string[] = [
    'api:ontologies-read',
    'api:ontologies-write',
    'api:admin-read',
    'api:connectivity-read',
    'api:connectivity-write',
    'api:connectivity-execute',
    'api:mediasets-read',
    'api:mediasets-write',
  ];

  const auth = createConfidentialOauthClient(
    clientId,
    clientSecret,
    url,
    scopes
  );
  const client = createClient(url, ontologyRid, auth);

  const getUser = async () => {
    const user: User = await Users.getCurrent(client);

    return user;
  };

  let token: Token | undefined;
  let tokenExpire: Date | undefined;
  let pendingRequest: Promise<Token> | undefined;

  auth.addEventListener('signIn', (evt) => {
    token = evt.detail; // Token
    tokenExpire = new Date(token.expires_at);
  });

  auth.addEventListener('signOut', (evt) => {
    token = undefined;
    tokenExpire = undefined;
  });

  const getToken = async function () {

    if (token && tokenExpire) {
      // add 60 seconds to account for processing time
      const skew = tokenExpire.getTime() + 60000;

      if (skew > new Date().getTime()) {
        return token.access_token;
      }
    }
    // avoid duplicate signin requests
    if (!pendingRequest) {
      pendingRequest = auth.signIn();
    }

    try {
      token = await pendingRequest;

      return token.access_token;
    } catch (e) {
      console.log(e);

      throw (e);
    } finally {
      pendingRequest = undefined;
    }

  }

  return { auth, ontologyRid, url, client, getUser, getToken };
}
````

## File: packages/services/rangr/src/index.ts
````typescript
export * from './lib/rangrClient';
export * from './lib/doa/rfp/rangrRfpRequestsDao';
export * from './lib/doa/rfp/rfpRequestsDao';
````

## File: packages/services/rangr/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/services/rangr/jest.config.ts
````typescript
export default {
  displayName: 'rangr',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/services/rangr',
};
````

## File: packages/services/rangr/package.json
````json
{
  "name": "@codestrap/developer-foundations-services-rangr",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "@osdk/client": "^2.2.1",
    "@osdk/foundry.admin": "^2.22.0",
    "@osdk/oauth": "^1.1.2",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/services/rangr/project.json
````json
{
  "name": "rangr-service",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/services/rangr/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:service"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/services/rangr",
        "main": "packages/services/rangr/src/index.ts",
        "tsConfig": "packages/services/rangr/tsconfig.lib.json",
        "assets": ["packages/services/rangr/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/services/rangr/jest.config.ts"
      }
    }
  }
}
````

## File: packages/services/rangr/README.md
````markdown
# rangr

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build rangr-service` to build the library.

## Running unit tests

Run `nx test rangr-service` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/services/rangr/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/services/rangr/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/services/rangr/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/services/slack/src/lib/delegates/sendMessage.ts
````typescript
import {
  Message,
  MessageResponse,
} from '@codestrap/developer-foundations-types';

export async function sendSlackMessage(
  message: Message,
  baseUrl: string,
  botToken: string
): Promise<MessageResponse> {
  try {
    // Make the API call to Slack
    const response = await fetch(`${baseUrl}/chat.postMessage`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${botToken}`,
      },
      body: JSON.stringify({
        channel: message.channelId,
        text: message.message,
        unfurl_links: true,
        unfurl_media: true,
      }),
    });

    if (!response.ok) {
      return {
        ok: false,
        channel: message.channelId,
        ts: new Date().getTime(),
        error: `HTTP error: ${response.status} ${response.statusText}`,
      };
    }

    const result = (await response.json()) as {
      ok: boolean;
      error: string;
      channel: string;
    };

    if (!result.ok) {
      return {
        ok: false,
        channel: message.channelId,
        ts: new Date().getTime(),
        error: `Slack API error: ${result.error}`,
      };
    }

    return {
      ok: true,
      channel: result.channel,
      ts: new Date().getTime(),
    };
  } catch (error) {
    console.error('Error sending Slack message:', error);
    return {
      ok: false,
      channel: message.channelId,
      ts: new Date().getTime(),
      error: `Failed to send Slack message: ${
        error instanceof Error ? error.message : String(error)
      }`,
    };
  }
}
````

## File: packages/services/slack/src/lib/slack.test.ts
````typescript
describe('Slack Service', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/slack/src/lib/slack.ts
````typescript
import { sendSlackMessage } from './delegates/sendMessage';
import {
  Message,
  MessageService,
} from '@codestrap/developer-foundations-types';

export function makeSlackClient(
  baseUrl: string,
  botToken: string
): MessageService {
  return {
    sendMessage: async (message: Message) => {
      const response = await sendSlackMessage(message, baseUrl, botToken);

      return response;
    },
  };
}
````

## File: packages/services/slack/src/index.ts
````typescript
export * from './lib/slack';
````

## File: packages/services/slack/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/services/slack/jest.config.ts
````typescript
export default {
  displayName: 'slack',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/services/slack',
};
````

## File: packages/services/slack/package.json
````json
{
  "name": "@codestrap/developer-foundations-services-slack",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/services/slack/project.json
````json
{
  "name": "slack-service",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/services/slack/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:service"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/services/slack",
        "main": "packages/services/slack/src/index.ts",
        "tsConfig": "packages/services/slack/tsconfig.lib.json",
        "assets": ["packages/services/slack/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/services/slack/jest.config.ts"
      }
    }
  }
}
````

## File: packages/services/slack/README.md
````markdown
# slack

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build slack-service` to build the library.

## Running unit tests

Run `nx test slack-service` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/services/slack/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/services/slack/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/services/slack/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/services/weather/src/lib/weatherService.test.ts
````typescript
describe('Weather Service', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/services/weather/src/lib/weatherService.ts
````typescript
import { WeatherService } from '@codestrap/developer-foundations-types';

export const openWeatherService: WeatherService = async (city) => {
  const key = process.env['OPEN_WEATHER_API_KEY']!;
  const res = await fetch(
    `https://api.openweathermap.org/data/2.5/weather?q=${encodeURIComponent(
      city
    )}&appid=${key}&units=metric`
  );
  const result = (await res.json()) as {
    weather: { description: string }[];
    main: { temp: string };
  };
  return `${result.weather[0].description}, ${result.main.temp} C`;
};
````

## File: packages/services/weather/src/index.ts
````typescript
export * from './lib/weatherService';
````

## File: packages/services/weather/eslint.config.mjs
````
import baseConfig from '../../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/services/weather/jest.config.ts
````typescript
export default {
  displayName: 'weather',
  preset: '../../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../../coverage/packages/services/weather',
};
````

## File: packages/services/weather/package.json
````json
{
  "name": "@codestrap/developer-foundations-services-weather",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/services/weather/project.json
````json
{
  "name": "weather-service",
  "$schema": "../../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/services/weather/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:service"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/services/weather",
        "main": "packages/services/weather/src/index.ts",
        "tsConfig": "packages/services/weather/tsconfig.lib.json",
        "assets": ["packages/services/weather/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/services/weather/jest.config.ts"
      }
    }
  }
}
````

## File: packages/services/weather/README.md
````markdown
# weather

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build weather-service` to build the library.

## Running unit tests

Run `nx test weather-service` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/services/weather/tsconfig.json
````json
{
  "extends": "../../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/services/weather/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/services/weather/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/types/src/lib/x-reason/types.ts
````typescript
import { EventObject, StateNode } from "xstate";

export type ActionType = {
  type: string;
  value?: Record<string, unknown>;
  payload?: Record<string, unknown>;
  stateId?: string;
};

export type Context = {
  requestId: string;
  status: number;
  machineExecutionId?: string;
  stack?: string[];
  userId?: string,
  solution?: string; // holds the output from the solver which is the solution plan to execute. This is used by individual state functions to assemble their required input parameters
  // Index signature for additional properties
  [key: string]: any;
};

export type MachineEvent = {
  type: "PAUSE_EXECUTION" | "RESUME_EXECUTION" | "RETRY" | "INVOKE" | string;
  payload?: { [key: string]: any };
  stateId?: string;
  data?: { [key: string]: any };
} & EventObject;

export type Transition = Map<string, (context: Context, event: MachineEvent) => boolean>;

export type Task = {
  description: string;
  implementation: (context: Context, event?: MachineEvent, task?: string) => void;
  component?: (context: Context, event?: MachineEvent, task?: string) => any;
  transitions?: Transition;
};

export interface StateMachineConfig {
  [key: string]: StateNode<Context, any, MachineEvent>;
}

export type Solver = {
  // generates the instructions for solving the query
  solve(query: string, solver: Prompt): Promise<string>;
};

export type Programer = {
  // the input is the result of Solver.solve
  // generates the state machine config used by the interpreter
  program(query: string, functionCatalog: string, programmer: Prompt): Promise<StateConfig[]>;
};

export type EvaluationInput = {
  query?: string;
  instructions?: string;
  states: StateConfig[];
  tools?: Map<string, Task>,
};

export type EvaluatorResult = { rating: number; error?: Error, correct?: boolean, revised?: string };

export type Evaluator = {
  // takes the user's query with the generated instructions from the solver
  // and the output machine config from the programmer
  evaluate(input: EvaluationInput, evaluate: Prompt): Promise<EvaluatorResult>;
};

export type AiTransition = {
  // takes the task list returned by the solver, the id of the current state, 
  // and the value returned by the state's implementation function
  // returns true or false
  transition(taskList: string, currentState: string, stateValue: string, aiTransition: Prompt, executionId: string): Promise<string>;
};

export type Prompt = (...args: any[]) => Promise<{ user: string; system: string; }>

export type ReasoningEngine = {
  solver: Solver;
  programmer: Programer;
  evaluator: Evaluator;
  logic: AiTransition;
};

export interface ICallable {
  (...args: any[]): any;
}

export type InterpreterInput = {
  functions: Map<string, Task>;
  states: StateConfig[];
  context?: Context;
};

export type Interpreter = {
  interpret(input: InterpreterInput): void;
};

export type StateConfig = {
  id: string;
  parentId?: string;
  transitions?: Array<{
    on: string;
    target: string;
    cond?: string;
    actions?: string;
  }>;
  type?: "parallel" | "final";
  onDone?: string;
  states?: StateConfig[];
  task?: string;
  includesLogic?: boolean;
};

export interface Result {
  context: string;
  nextState: string;
  planId: string;
  machine: string;
}

export interface Workflow {
  context: string | undefined;
  nextState: string | undefined;
  planId: string;
  machine: string | undefined;
  implementation1: string | undefined;
}

export type Solutions = {
  input: string;
  id: string;
  plan: string;
};

export type SystemStatus = {
  status: number;
  message: string;
};
````

## File: packages/types/src/lib/types.test.ts
````typescript
describe('Types', () => {
  it('should be defined', () => {
    expect(true).toBe(true);
  });
});
````

## File: packages/types/src/lib/types.ts
````typescript
import { ComputeModule } from '@palantir/compute-module';
import type { Client } from '@osdk/client';
import { Type, Static } from '@sinclair/typebox';
import { StateValue } from 'xstate';
import { calendar_v3, gmail_v1, drive_v3 } from 'googleapis';
import { User as FoundryUser } from '@osdk/foundry.admin';

export const TYPES = {
  FoundryClient: Symbol.for('FoundryClient'),
  RangrClient: Symbol.for('RangrClient'),
  WeatherService: Symbol.for('WeatherService'),
  EnergyService: Symbol.for('EnergyService'),
  WorldDao: Symbol.for('WorldDao'),
  UserDao: Symbol.for('UserDao'),
  MachineDao: Symbol.for('MachineDao'),
  TicketDao: Symbol.for('TicketDao'),
  CommsDao: Symbol.for('CommsDao'),
  TelemetryDao: Symbol.for('TelemetryDao'),
  ThreadsDao: Symbol.for('ThreadsDao'),
  RfpRequestsDao: Symbol.for('RfpRequestsDao'),
  RangrRfpRequestsDao: Symbol.for('RangrRfpRequestsDao'),
  ResearchAssistant: Symbol.for('ResearchAssistant'),
  MemoryRecallDao: Symbol.for('MemoryRecallDao'),
  ContactsDao: Symbol.for('ContactsDao'),
  GeminiService: Symbol.for('GeminiService'),
  Gpt4oService: Symbol.for('Gpt4oService'),
  GeminiSearchStockMarket: Symbol.for('GeminiSearchStockMarket'),
  OfficeService: Symbol.for('OfficeService'),
  MessageService: Symbol.for('MessageService'),
  EmbeddingsService: Symbol.for('EmbeddingsService'),
  TrainingDataDao: Symbol.for('TrainingDataDao'),
  LoggingService: Symbol.for('LoggingService'),
};

// Schema Definitions for compute module
// IMPORTANT:  @sinclair/typebox is required!!!
// https://github.com/palantir/typescript-compute-module?tab=readme-ov-file#schema-registration
export const Schemas = {
  SendEmail: {
    input: Type.Object({
      recipients: Type.Array(Type.String()),
      subject: Type.String(),
      message: Type.String(),
    }),
    output: Type.Object({
      id: Type.String(),
      threadId: Type.String(),
      labelIds: Type.Array(Type.String()),
    }),
  },
  ReadEmailHistory: {
    input: Type.String(),
    output: Type.Object({
      messages: Type.Array(
        Type.Object({
          subject: Type.Optional(Type.String()),
          from: Type.Optional(Type.String()),
          body: Type.Optional(Type.String()),
          id: Type.Optional(Type.String()),
          threadId: Type.Optional(Type.String()),
        })
      ),
    }),
  },
  WatchEmails: {
    input: Type.Object({
      config: Type.Array(
        Type.Object({
          topicName: Type.String(),
          users: Type.Array(Type.String()),
          labelIds: Type.Array(Type.String()),
          labelFilterBehavior: Type.String(),
        })
      ),
    }),
    output: Type.Object({
      status: Type.Integer(),
      errors: Type.Optional(Type.Array(Type.String())),
      responses: Type.Optional(Type.Array(Type.String())),
    }),
  },
  ScheduleMeeting: {
    input: Type.Object({
      summary: Type.String(),
      description: Type.Optional(Type.String()),
      start: Type.String(),
      end: Type.String(),
      attendees: Type.Array(Type.String()),
    }),
    output: Type.Object({
      id: Type.String(),
      htmlLink: Type.String(),
      status: Type.String(),
    }),
  },
  FindOptimalMeetingTime: {
    input: Type.Object({
      participants: Type.Array(Type.String()),
      timeframe_context: Type.String(),
      duration_minutes: Type.Optional(Type.Number({ default: 30 })),
      working_hours: Type.Optional(
        Type.Object({
          start_hour: Type.Number({ default: 9 }),
          end_hour: Type.Number({ default: 17 }),
        })
      ),
      timezone: Type.String(),
    }),
    output: Type.Object({
      suggested_times: Type.Array(
        Type.Object({
          start: Type.String(),
          end: Type.String(),
          score: Type.Number(),
        })
      ),
      message: Type.String(),
    }),
  },
};

// Types from Schemas
export type ScheduleMeetingInput = Static<typeof Schemas.ScheduleMeeting.input>;
export type ScheduleMeetingOutput = Static<
  typeof Schemas.ScheduleMeeting.output
>;
export type SendEmailOutput = Static<typeof Schemas.SendEmail.output>;
export type SendEmailInput = Static<typeof Schemas.SendEmail.input>;
export type ReadEmailOutput = Static<typeof Schemas.ReadEmailHistory.output>;
export type ReadEmailInput = Static<typeof Schemas.ReadEmailHistory.input>;
export type WatchEmailsOutput = Static<typeof Schemas.WatchEmails.output>;
export type WatchEmailsInput = Static<typeof Schemas.WatchEmails.input>;
export type FindOptimalMeetingTimeInput = Static<
  typeof Schemas.FindOptimalMeetingTime.input
>;
export type FindOptimalMeetingTimeOutput = Static<
  typeof Schemas.FindOptimalMeetingTime.output
>;

export type UserProfile = {
  name: string | undefined;
  id: string | undefined;
  email: string | undefined;
  timezone: string | undefined;
};

export type MessageResponse = {
  ok: boolean;
  channel: string;
  ts: number;
  error?: string;
};

export type Message = {
  channelId: string;
  message: string;
};

export interface EmailConfig {
  recipients: string[];
  defaultSubject: string;
  defaultMessage: string;
}

export interface CalendarConfig {
  attendees: string[];
  defaultSummary: string;
  defaultDescription: string;
  defaultTimeframe: string;
  defaultDuration: number;
  defaultWorkingHours: WorkingHours;
}

export interface Config {
  email: EmailConfig;
  calendar: CalendarConfig;
}

export interface WorkingHours {
  start_hour: number;
  end_hour: number;
}

export interface TimeSlot {
  start: string;
  end: string;
  score?: number;
  attendees?: string;
  id?: string;
  startLocalDate?: string;
  endLocalDate?: string;
  duration?: number;
}

export interface EmailContext {
  from: string;
  recipients: string[];
  subject: string;
  message: string;
}

export interface ReadEmailHistoryContext {
  email: string;
  publishTime: string;
  labels?: string[];
}

export interface CalendarContext {
  summary: string;
  description?: string;
  start: string;
  end: string;
  attendees: string[];
}

export interface OptimalTimeContext {
  participants: string[];
  timeframe_context: string;
  duration_minutes?: number;
  working_hours?: WorkingHours;
  timezone?: string;
}

export interface TimeRange {
  startTime: Date;
  endTime: Date;
}

export interface BusyPeriod {
  start: string;
  end: string;
}

export type EmailMessage = {
  subject?: string;
  from?: string;
  body?: string;
  id?: string;
  threadId?: string;
};

export type AvailableTime = {
  start: string; // Available start time
  end: string; // IANA time zone (e.g., "America/New_York")
  availableAttendees: string[]; // Attendees available at this time
  unavailableAttendees: string[]; // Attendees unavailable at this time
};

export type ProposedTimes = {
  times: AvailableTime[]; // Array of available time slots
  subject: string; // Meeting subject or title
  agenda?: string; // Optional agenda
  durationInMinutes: number; // Meeting duration in minutes
  allAvailable: boolean; // are all required attendees available
};

export type MeetingRequest = {
  participants: Array<string>;
  subject: string;
  timeframe_context:
  | 'user defined exact date/time'
  | 'as soon as possible'
  | 'this week'
  | 'next week';
  localDateString?: string;
  duration_minutes: number;
  working_hours: {
    start_hour: number;
    end_hour: number;
  };
};

export type DerivedWindow = {
  windowStartLocal: Date;
  windowEndLocal: Date;
  slotStepMinutes: number;
};

export type Meeting = {
  id: string;
  status: string;
  htmlLink: string;
};

export interface GeminiParameters {
  stopSequences?: Array<string>;
  temperature?: number;
  maxTokens?: number;
  topP?: number;
  extractJsonString?: boolean;
}

export interface GeminiService {
  (user: string, system: string, params?: GeminiParameters): Promise<string>;
}

type GptSpecificToolChoice = {
  function?: { name: string } | undefined;
};

type GptTool = {
  function?:
  | {
    name: string;
    description?: string | undefined;
    strict?: boolean | undefined;
    parameters: Map<string, string>;
  }
  | undefined;
};

type GptToolChoice = {
  auto?: unknown | undefined;
  none?: unknown | undefined;
  specific?: GptSpecificToolChoice | undefined;
  required?: unknown | undefined;
};

type GptResponseFormat = {
  jsonSchema?: Map<string, string> | undefined;
  type: string;
};

export interface Gpt40Parameters {
  toolChoice?: GptToolChoice | undefined;
  presencePenalty?: number | undefined;
  stop?: Array<string> | undefined;
  seed?: number | undefined;
  temperature?: number | undefined;
  maxTokens?: number | undefined;
  logitBias?: Map<number, number> | undefined;
  responseFormat?: GptResponseFormat | undefined;
  topP?: number | undefined;
  frequencyPenalty?: number | undefined;
  tools?: Array<GptTool> | undefined;
  n?: number | undefined;
}

export interface Gpt4oService {
  (user: string, system: string, params?: Gpt40Parameters): Promise<string>;
}

export interface EmbeddingsService {
  (input: string): Promise<[number[]]>;
}

export interface Token {
  readonly access_token: string;
  readonly expires_in: number;
  readonly refresh_token?: string;
  readonly expires_at: number;
}

export interface BaseOauthClient {
  (): Promise<string>;
  getTokenOrUndefined: () => string | undefined;
  signIn: () => Promise<Token>;
  signOut: () => Promise<void>;
}

export interface FoundryClient {
  client: Client;
  auth: BaseOauthClient;
  ontologyRid: string;
  url: string;
  getUser: () => Promise<FoundryUser>;
  getToken: () => Promise<string>;
}

export interface RangrClient {
  client: Client;
  auth: BaseOauthClient;
  ontologyRid: string;
  url: string;
  getUser: () => Promise<User>;
  getToken: () => Promise<string>;
}

export interface GasScenarioResult {
  date: string;
  baselinePrice: number;
  scenarioPrice: number;
  deltaVsBaseline: number;
  annualIncrementalCostBn: number;
  pctOfCaGdp: number;
  impliedUsGdpDrag: number;
}

export interface EIAResponse {
  response?: {
    data?: Array<{
      period: string;
      value: string;
    }>;
  };
}

export interface VegaGasTrackerData {
  $schema: string;
  description: string;
  data: {
    name: string;
    values: Array<{
      date: string;
      scenario: number;
      delta: number;
      annualCost: number;
      pctOfCaGdp: number;
      usGdpDrag: number;
    }>;
  };
  mark: string;
  encoding: {
    x: {
      field: string;
      type: string;
      title: string;
    };
    y: {
      field: string;
      type: string;
      title: string;
    };
    tooltip: Array<{
      field: string;
      type: string;
      title: string;
    }>;
  };
}

// Basic example of calling other services besides Foundry.
export type EnergyService = {
  read: (
    scenarioPrices?: number[],
    caGallonsYearn?: number,
    caGdp?: number,
    caShareUsGdp?: number
  ) => Promise<GasScenarioResult[]>;
  getVegaChartData: (results: GasScenarioResult[]) => VegaGasTrackerData;
};

export interface WeatherService {
  (city: string): Promise<string>;
}

export interface GeminiSearchStockMarket {
  (userQuery: string): Promise<string>;
}

export interface APIError extends Error {
  response?: {
    data: any;
  };
}

export interface ModuleConfig {
  isTest?: boolean;
}

export interface TestModule {
  listeners: Record<string, any>;
  on(event: string, handler: Function): TestModule;
  register(operation: string, handler: Function): TestModule;
}

export type ComputeModuleType = TestModule | ComputeModule<any>;

export interface GreetingInput {
  message: string;
  userId: string;
}

export interface GreetingResult {
  id: string;
  greeting: string;
}

export interface User {
  id: string;
  username: string;
  givenName?: string;
  familyName?: string;
  email?: string;
  organization?: string;
  attributes: Record<string, any>;
}

export interface MachineExecutions {
  /** Current State */
  /** holds the current state of the state machine */
  currentState: string | undefined;
  /** Id */
  /** The uuid of the machine execution. It uniquely identifies the machine. */
  readonly id: string;
  /** Logs */
  /** Holds the execution logs from a machine execution. The logs are generated by the TypeScript functions */
  logs: string | undefined;
  /** Machine */
  /** Holds the state machine generated for the solution. The machine is a JSON string using the x-reason JSON schema. */
  machine: string | undefined;
  /** State */
  /** The current state of the state machine execution */
  state: string | undefined;
  /** The mutex used for distributed locks. This prevents things like infinite loops when resolving meeting conflicts */
  lockOwner?: string;
  /** The time expire of the lock */
  lockUntil?: number;
}

export interface Communications {
  /** Channel */
  channel: string | undefined;
  /** Completion Error Task List */
  completionErrorTaskList: string | undefined;
  /** Created On */
  createdOn: number | undefined;
  /** Formatted Message */
  formattedMessage: string | undefined;
  /** Id */
  readonly id: string;
  /** Machine */
  /** Holds the generated state machine for the given task list */
  machine: string | undefined;
  /** Owner */
  owner: string | undefined;
  /** Question Prompt */
  questionPrompt: string | undefined;
  /** Status */
  /** The current status of the tasks to perform. Must be one of Open, Accepted, or Rejected */
  status: string | undefined;
  /** Task List */
  taskList: string | undefined;
  /** Tokens */
  tokens: number | undefined;
  /** type */
  type: string | undefined;
}

export interface Threads {
  /** appId */
  appId: string | undefined;
  /** id */
  readonly id: string;
  /** messages */
  messages: string | undefined;
  /** userId */
  userId: string | undefined;
}

/** Holds rfp requests */
export interface RfpRequests {
  /** Created On */
  createdOn: number;
  /** id */
  readonly id: string;
  /** machineExecutionId */
  machineExecutionId: string | undefined;
  /** rfp */
  rfp: string | undefined;
  /** rfpResponse */
  rfpResponse: string | undefined;
  /** rfpResponseStatus Contains the response status, ie 200, 400, 401, 404, 500 etc*/
  rfpResponseStatus: number | undefined;
  /** vendorId */
  vendorId: string | undefined;
}

export interface Tickets {
  /** Ticket Id */
  readonly alertId: string;
  /** Ticket Title */
  alertTitle: string | undefined;
  /** Ticket Type */
  alertType: string | undefined;
  /** Assignee */
  assignees: string | undefined;
  /** createdOn */
  createdOn: number;
  /** Description */
  description: string | undefined;
  /** Machine */
  /** Holds the generated state machine based on the Task List */
  machine: string | undefined;
  /** modifiedOn */
  modifiedOn: number;
  /** points */
  points: number;
  /** Severity */
  severity: string | undefined;
  /** Status */
  status: string | undefined;
}

/** This is the object type for all names of partners, palantir and customers */
export interface Contacts {
  /** This is an array that stores the key CodeStrap contacts and aligns to the relationship status array. */
  codestrapPoc: ReadonlyArray<string> | undefined;
  /** Company */
  /** This property is the company the individual works at directly. This is the employer or the company they run/own. */
  company: string | undefined;
  /** Contact Category */
  /** This stores the values in three categories: Palantir, Partner, or Client. Palantir stores all objects for individuals who work at Palantir. Partner stores all objects for individuals who work at a partner organization (e.g., Northslope, PwC, Axis, Rangr). Client stores all objects for individuals who work at a client or customer. */
  contactCategory: string | undefined;
  /** Country Of Residence */
  /** This is where this person's home is located and where they are located. It can be used for scheduling for timezones as well. */
  countryOfResidence: string | undefined;
  /** Email */
  /** This is the individual's email address, used for direct communication. */
  email: string | undefined;
  /** Executive Assistant */
  /** This is someone who can help schedule meetings for this person */
  executiveAssistant: string | undefined;
  /** First Name */
  /** This is the individual's first name. */
  firstName: string | undefined;
  /** Full Name */
  /** This is the full name of the individual that combines the First Name and the Last Name of the individual. */
  fullName: string | undefined;
  /** Key Accounts */
  /** These are the key accounts we know these individuals work on and may lead from a relationship perspective */
  keyAccounts: string | undefined;
  /** Last Name */
  /** This is the individual's last name. */
  lastName: string | undefined;
  /** LinkedIn */
  /** This is the individual's profile on the social media site LinkedIn. */
  linkedIn: string | undefined;
  /** Notes */
  /** These are all the notes from everyone for this client. This will be the starting point for SalesForge, the notes were */
  notes: ReadonlyArray<string> | undefined;
  /** Phone Number Main */
  /** This is the phone number most used by the individual and should be used for the main reach out from calling and texting. */
  phoneNumberMain: string | undefined;
  /** Phone Number Secondary */
  /** This is the phone number used as a backup by the individual and should be used only when Phone Number Main is NOT successful */
  phoneNumberSecondary: string | undefined;
  /** Primary Key */
  /** This is the primary key derived from concatenating the full name of the individual and their email */
  readonly primaryKey_: string;
  /** Relationship Status */
  /** This is an array that stores the relationship status aligned to the CodeStrap poc stored in the same order. */
  relationshipStatus: ReadonlyArray<string> | undefined;
  /** Role */
  /** This is the individual's job title or role they hold at the Company they work for or manage */
  role: string | undefined;
  /** Talks To */
  /** These are the people the individual talks to and is the main point of contact */
  talksTo: string | undefined;
}

/** Used for retrieving relevant context for LLMs */
export interface MemoryRecall {
  /** Created On */
  createdOn: number;
  /** Id */
  readonly id: string;
  /** Original Text */
  originalText: string | undefined;
  /** Source */
  source: string | undefined;
  /** User Id */
  userId: string | undefined;
}

/** Holds the training data for all X-Reasons */
export interface TrainingData {
  /** Human Review */
  humanReview: string | undefined;
  /** Is Good */
  isGood: boolean | undefined;
  /** Machine */
  machine: string | undefined;
  /** Primary Key */
  readonly primaryKey_: string;
  /** Solution */
  solution: string | undefined;
  /** type */
  /** Either programmer or solver type. */
  type: string | undefined;
  /** X-Reason */
  xReason: string | undefined;
}

export type ListCalendarArgs = {
  calendar: calendar_v3.Calendar;
  emails: string[]; // calendars to query (primary)
  timezone: string; // e.g. "America/Los_Angeles"
  windowStartLocal: Date; // PT wall clock
  windowEndLocal: Date; // PT wall clock
};

export type EventSummary = {
  id: string;
  subject: string;
  description?: string;
  start: string; // local ISO with offset, e.g. 2025-07-22T10:30:00-07:00
  end: string; // same format
  durationMinutes: number;
  participants: string[]; // attendee email list
  meetingLink?: string; // Meet/Zoom/Teams link if found
};

export type CalendarSummary = {
  email: string;
  events: EventSummary[];
};

export type Summaries = {
  message: string;
  calendars: CalendarSummary[];
};

export type OfficeService = {
  getAvailableMeetingTimes: (
    meetingRequest: MeetingRequest
  ) => Promise<FindOptimalMeetingTimeOutput>;
  scheduleMeeting: (meeting: CalendarContext) => Promise<ScheduleMeetingOutput>;
  sendEmail: (email: EmailContext) => Promise<SendEmailOutput>;
  readEmailHistory: (
    context: ReadEmailHistoryContext
  ) => Promise<ReadEmailOutput>;
  watchEmails: (context: WatchEmailsInput) => Promise<WatchEmailsOutput>;
};

export type OfficeServiceV2 = {
  summarizeCalendars: (args: {
    emails: string[];
    timezone: string;
    windowStartLocal: Date;
    windowEndLocal: Date;
  }) => Promise<Summaries>;
  searchDriveFiles: (params: DriveSearchParams) => Promise<DriveSearchOutput>;
  getDriveClient: () => drive_v3.Drive;
} & OfficeServiceV1;

// V1 Google Workspace service surface (Calendar + Gmail operations and raw clients)
export type OfficeServiceV1 = {
  getCalendarClient: () => calendar_v3.Calendar;
  getEmailClient: () => gmail_v1.Gmail;
} & OfficeService;

// Backward-compatible alias (historical name kept to avoid breaking imports)
export type GSuiteCalendarService = OfficeServiceV1;

export type MessageService = {
  sendMessage: (message: Message) => Promise<MessageResponse>;
};

// Service Account Credentials for Google APIs
export type ServiceAccountCredentials = {
  type: string;
  project_id: string;
  private_key_id: string;
  private_key: string;
  client_email: string;
  client_id: string;
  auth_uri: string;
  token_uri: string;
  auth_provider_x509_cert_url: string;
  client_x509_cert_url: string;
  universe_domain: string;
};

// Google Drive Search Types

/**
 * Common MIME types for Google Drive files
 * Use these constants instead of file extensions for more accurate results
 */
export const DRIVE_MIME_TYPES = {
  // Documents
  PDF: 'application/pdf',
  DOCX: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  DOC: 'application/msword',
  TXT: 'text/plain',
  
  // Spreadsheets
  XLSX: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
  XLS: 'application/vnd.ms-excel',
  CSV: 'text/csv',
  
  // Presentations
  PPTX: 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
  PPT: 'application/vnd.ms-powerpoint',
  
  // Images
  JPG: 'image/jpeg',
  JPEG: 'image/jpeg',
  PNG: 'image/png',
  GIF: 'image/gif',
  SVG: 'image/svg+xml',
  
  // Google Workspace Files
  GOOGLE_DOC: 'application/vnd.google-apps.document',
  GOOGLE_SHEET: 'application/vnd.google-apps.spreadsheet',
  GOOGLE_SLIDE: 'application/vnd.google-apps.presentation',
  GOOGLE_FORM: 'application/vnd.google-apps.form',
  GOOGLE_DRAWING: 'application/vnd.google-apps.drawing',
  
  // Archives
  ZIP: 'application/zip',
  RAR: 'application/x-rar-compressed',
  
  // Audio/Video
  MP4: 'video/mp4',
  MP3: 'audio/mpeg',
  WAV: 'audio/wav',
} as const;

/**
 * Date field types for Google Drive search
 */
export enum DriveDateField {
  CREATED_TIME = 'createdTime',
  MODIFIED_TIME = 'modifiedTime',
}

/**
 * Safe ordering fields and formats for Drive file queries.
 */
export type DriveOrderField =
  | 'modifiedTime'
  | 'createdTime'
  | 'viewedByMeTime'
  | 'name';
export type SortDir = 'asc' | 'desc';
export type DriveOrderBy = DriveOrderField | `${DriveOrderField} ${SortDir}`;

// DriveFile interface 
export interface DriveFile {
  id: string;                    // Unique file ID
  name: string;                  // File name
  mimeType: string;              // File MIME type
  size?: string;                 // File size in bytes
  createdTime?: string;          // Creation timestamp
  modifiedTime?: string;         // Last modification timestamp
  webViewLink?: string;          // Link to view file in Drive
  webContentLink?: string;       // Direct download link
  owners?: Array<{               // File owners
    displayName?: string;
    emailAddress?: string;
  }>;
  lastModifyingUser?: {          // Last user who modified
    displayName?: string;
    emailAddress?: string;
  };
  parents?: string[];            // Parent folder IDs
  description?: string;          // File description
  starred?: boolean;             // Whether file is starred
  trashed?: boolean;             // Whether file is trashed
}

export interface DriveSearchParams {
  keywords?: string[];
  dateRange?: {
    startDate?: Date;
    endDate?: Date;
    field?: DriveDateField;
  };
  mimeType?: string;
  owner?: string;
  sharedWithMe?: boolean;
  trashed?: boolean;
  pageSize?: number;
  pageToken?: string;
  orderBy?: DriveOrderBy;
  fields?: string;
}

export interface DriveSearchResult {
  files: DriveFile[];
  nextPageToken?: string;
  incompleteSearch?: boolean;
}

export interface DriveSearchOutput {
  message: string;
  files: DriveFile[];
  totalResults: number;
  nextPageToken?: string;
  incompleteSearch?: boolean;
}

export type LoggingService = {
  getLog: (executionId: string) => string;
  log: (executionId: string, message: string) => void;
};

export type RfpResponsesResult = {
  allResponsesReceived: boolean;
  vendors: string[];
};

/** Holds rfp responses */
export type RfpRequestResponse = {
  status: number;
  message: string;
  machineExecutionId: string;
  vendorName: string;
  vendorId: string;
  received: boolean;
  response?: string;
  error?: string;
  receipt?: {
    id: string;
    timestamp: Date;
  };
};

// Receipt sent back to vendors when their response is recorded
export type RfpResponseReceipt = {
  status: number;
  message: string;
  machineExecutionId: string;
  error?: string;
  reciept?: {
    id: string;
    timestamp: number;
  };
};

export type TicketsDao = {
  upsert: (
    id: string,
    alertTitle: string,
    alertType: string,
    description: string,
    severity: string,
    status: string,
    points?: number,
    assignees?: string
  ) => Promise<Tickets>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<Tickets>;
};

export type WorldDao = (input: GreetingInput) => Promise<GreetingResult>;

export type UserDao = (userId?: string) => Promise<User>;

export type MachineDao = {
  upsert: (
    id: string,
    stateMachine: string,
    state: string,
    logs: string,
    lockOwner?: string,
    lockUntil?: number
  ) => Promise<MachineExecutions>;
  delete: (machineExecutionId: string) => Promise<void>;
  read: (machineExecutionId: string) => Promise<MachineExecutions>;
};

export type TelemetryDao = (inputJSON: string) => Promise<string>;

export type CommsDao = {
  upsert: (
    channel: string,
    formattedMessage: string,
    status: string,
    taskList: string,
    comType: string,
    owner: string,
    questionPrompt?: string,
    tokens?: number,
    id?: string
  ) => Promise<Communications>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<Communications>;
};

export type ThreadsDao = {
  upsert: (messages: string, appId: string, id?: string) => Promise<Threads>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<Threads>;
};

export type RfpRequestsDao = {
  upsert: (
    rfp: string,
    rfpVendorResponse: string,
    vendorId: string,
    machineExecutionId: string,
    id?: string,
    rfpResponseStatus?: number
  ) => Promise<RfpRequests>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<RfpRequests>;
  search: (
    machineExecutionId: string,
    vendorId: string
  ) => Promise<RfpRequests>;
};

export type RangrRequestsDao = {
  submit: (
    rfp: string,
    machineExecutionId: string
  ) => Promise<RfpRequestResponse>;
};

export type MemoryRecallDao = {
  upsert: (
    id: string,
    originalText: string,
    source: string,
    userId?: string
  ) => Promise<MemoryRecall>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<MemoryRecall>;
  search: (input: string, kValue: number) => Promise<MemoryRecall[]>;
};

export type TrainingDataDao = {
  upsert: (
    id: string,
    isGood: boolean,
    type: string,
    xReason: string,
    machine?: string,
    solution?: string,
    humanReview?: string
  ) => Promise<TrainingData>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<TrainingData>;
  search: (xReason: string, type: string) => Promise<TrainingData[]>;
};

export type ContactsDao = {
  upsert: (
    primaryKey_: string,
    email: string,
    firstName: string,
    lastName: string,
    codestrapPoc?: string[],
    company?: string,
    contactCategory?: string,
    countryOfResidence?: string,
    executiveAssistant?: string,
    fullName?: string,
    keyAccounts?: string,
    linkedIn?: string,
    notes?: string[],
    phoneNumberMain?: string,
    phoneNumberSecondary?: string,
    relationshipStatus?: string[],
    role?: string,
    talksTo?: string
  ) => Promise<Contacts>;
  delete: (id: string) => Promise<void>;
  read: (id: string) => Promise<Contacts>;
  search: (
    fullName: string,
    company: string,
    pageSize?: number
  ) => Promise<Contacts[]>;
};

export type GetNextStateResult = {
  value: StateValue;
  theResultOfEachTask: {
    taskName: string;
    taskOutput: any;
  }[];
  orderTheTasksWereExecutedIn: string[];
};

export enum SupportedFoundryClients {
  PUBLIC = 'public',
  PRIVATE = 'private',
}

export type RequestContext = {
  token?: string | null | undefined;
  user?: User | null | undefined;
  requestId?: string | null | undefined;
};
````

## File: packages/types/src/index.ts
````typescript
export * from './lib/types';
export * from './lib/x-reason/types';
````

## File: packages/types/eslint.config.mjs
````
import baseConfig from '../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/types/jest.config.ts
````typescript
export default {
  displayName: 'types',
  preset: '../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../coverage/packages/types',
};
````

## File: packages/types/package.json
````json
{
  "name": "@codestrap/developer-foundations-types",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "tslib": "^2.3.0",
    "@palantir/compute-module": "0.2.7",
    "@sinclair/typebox": "^0.34.33",
    "xstate": "4.37.2",
    "googleapis": "^149.0.0",
    "@osdk/client": "^2.2.1"
  },
  "devDependencies": {
    "@types/node": "^22.15.3"
  }
}
````

## File: packages/types/project.json
````json
{
  "name": "types",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/types/src",
  "projectType": "library",
  "rootDir": ".",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:utility"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc", 
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/types",
        "main": "packages/types/src/index.ts",
        "tsConfig": "packages/types/tsconfig.lib.json",
        "assets": ["packages/types/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/types/jest.config.ts"
      }
    }
  }
}
````

## File: packages/types/README.md
````markdown
# types

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build types` to build the library.

## Running unit tests

Run `nx test types` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/types/tsconfig.json
````json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    }
  ]
}
````

## File: packages/types/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/types/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/utils/src/lib/__fixtures__/DuplicateIdMachine.ts
````typescript
// this fixture is used to test deduplication of duplicate state ID values
export const simpleMachine = [
    {
        "id": "sendSlackMessage",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "sendSlackMessage"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "sendSlackMessage",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "sendSlackMessage"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "sendSlackMessage",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "success"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "success",
        "type": "final"
    },
    {
        "id": "failure",
        "type": "final"
    }
];

export const complexMachine = [
    {
        "id": "sendSlackMessage",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "sendSlackMessage"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "sendSlackMessage",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "parallelChecks"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        id: "parallelChecks",
        type: "parallel",
        states: [
            {
                id: "RegulatoryCheck",
                transitions: [
                    { on: "CONTINUE", target: "success" },
                    { on: "ERROR", target: "failure" },
                ],
            },
            {
                id: "ConcentrationEstimation",
                transitions: [
                    { on: "CONTINUE", target: "success" },
                    { on: "ERROR", target: "failure" },
                ],
            },
        ],
        onDone: "sendSlackMessage",
    },
    {
        "id": "sendSlackMessage",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "success"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "success",
        "type": "final"
    },
    {
        "id": "failure",
        "type": "final"
    }
];
````

## File: packages/utils/src/lib/asyncLocalStorage.ts
````typescript
import { RequestContext } from "@codestrap/developer-foundations-types";
import { AsyncLocalStorage } from "node:async_hooks";

const als = new AsyncLocalStorage<RequestContext>();

// sandboxes requests so we can access tokens and user profiles sent form the client
export function withRequestContext<T>(ctx: RequestContext, fn: () => Promise<T> | T) {
    return als.run(ctx, fn);
}

export function getRequestContext(): RequestContext | undefined {
    return als.getStore();
}
````

## File: packages/utils/src/lib/date.ts
````typescript
export function formatIsoDateStringForLocalDate (date: Date): string {
  const year = date.getFullYear();
  const month = String(date.getMonth() + 1).padStart(2, "0"); // Months are 0-based
  const day = String(date.getDate()).padStart(2, "0");

  return `${year}-${month}-${day}`;
};
````

## File: packages/utils/src/lib/Extractors.test.ts
````typescript
import { extractJsonFromBackticks } from './Extractors';
describe('Testing JSON extraction and clearning', () => {
  test('extracts JSON from a normal ```json fenced block (baseline)', () => {
    const input = "```json\n{\n  \"a\": 1\n}\n```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.a).toBe(1);
  });

  test('works when language tag is absent', () => {
    const input = "```\n{\n  \"ok\": true\n}\n```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.ok).toBe(true);
  });

  test('handles nested backticks inside JSON string (escaped), does not terminate early', () => {
    const input = "```json\n{\n  \"msg\": \"Here are backticks: \\`\\`\\` inside a string\"\n}\n```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.msg).toContain("`");
    expect(parsed.msg).toContain("```");
  });

  test('handles nested backticks inside JSON string (escaped, multiline)', () => {
    const input =
      "```json\r\n" +
      "{\r\n" +
      "  \"body\": \"Start line\\n\\`\\`\\`\\nEnd line\"\r\n" +
      "}\r\n" +
      "```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.body).toMatch(/Start line/);
    expect(parsed.body).toMatch(/```/);
  });

  test('extracts from the FIRST fenced block even if more blocks follow', () => {
    const input =
      "```json\n{\"first\": true}\n```\n" +
      "Some text...\n" +
      "```json\n{\"second\": true}\n```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.first).toBe(true);
    expect(() => JSON.parse(result)).not.toThrow();
  });

  test('ignores earlier non-JSON fences before the JSON one (extracts from the first fenced block overall)', () => {
    const input =
      "```txt\nthis is just text\n```\n" +
      "```json\n{\"ok\": 1}\n```";
    // NOTE: By design, extractor grabs the FIRST fenced block overall,
    // so this should parse the *txt* block which is NOT JSON and should throw.
    // This test documents current behavior.
    expect(() => extractJsonFromBackticks(input)).toThrow();
  });

  test('array root is supported ([ ... ])', () => {
    const input = "```json\n[1,2,3]\n```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(Array.isArray(parsed)).toBe(true);
    expect(parsed).toEqual([1, 2, 3]);
  });

  test('CRLF line endings are handled', () => {
    const input = "```json\r\n{\r\n  \"x\": 42\r\n}\r\n```";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.x).toBe(42);
  });

  test('leading/trailing noise outside fences is ignored', () => {
    const input = "noise before\n```json\n{\"n\": 9}\n```\nnoise after";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.n).toBe(9);
  });

  test('parses when no fences exist', () => {
    const input = "{ \"x\": 1 }";
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.x).toBe(1);
  });

  test('throws when opening fence exists but no closing fence', () => {
    const input = "```json\n{\"x\":1}";
    expect(() => extractJsonFromBackticks(input)).toThrow(/No valid closing fence/i);
  });

  test('throws when JSON start is not found between fences', () => {
    const input = "```json\nnot json\n```";
    expect(() => extractJsonFromBackticks(input)).toThrow(/JSON must start with either \{ or \[/i);
  });

  test('Fixes malformed JSON between fences', () => {
    const input = "```json\n{ \"x\": 1, }\n```"; // trailing comma
    const result = extractJsonFromBackticks(input);
    const parsed = JSON.parse(result);
    expect(parsed.x).toBe(1);
  });

  test('Should extract and clean JSON from a FUBAR string', () => {
    const inputJSON = `\`\`\`json
{
  "contacts": [],
  "currentUser": {
    "name": null,
    "email": "dsmiley@codestrap.me",
    "id": "cadf16c6-76c8-4ff2-8716-889f8797d547",
    "timezone": null
  },
  "messages": [
    "\\"# ** Daily Brief: Thursday, August 21, 2025 **\\\\n\\\\n## ** TL; DR **\\\\n1. ** Business-Related (CodeStrap) **: \\\\n   - ** Harshit Soni (CreativeGlu):** Proposed a meeting today (10:0010:30 AM PT) to discuss \\\\\\"X Reason\\\\\\" and Foundry. Confirm availability or reschedule if needed.\\\\n   - ** Kerry Sporkin:** Meeting scheduled for tomorrow (Friday, August 22, 2025, 10:0010:30 AM PT) to discuss Palantir implementations, Series A funding, and a strategic partnership with PWC. Confirm details today to avoid conflicts.\\\\n\\\\n2. ** Spam/Marketing Emails **: None detected.\\\\n\\\\n---\\\\n\\\\n## ** Business-Related Emails **\\\\n\\\\n### ** 1. Harshit Soni (CreativeGlu)  Meeting Proposal **\\\\n- ** Details **: \\\\n  - ** Topic **: CodeStrap inquiries regarding \\\\\\"X Reason\\\\\\" and Foundry.\\\\n  - ** Proposed Time **: Today, ** Thursday, August 21, 2025 **, from ** 10:00 AM to 10:30 AM PT **.\\\\n  - ** Attendees **:  \\\\n    - Dorian Smiley (<dsmiley@codestrap.me>)  \\\\n    - Harshit Soni (<harshit@creativeglu.ai>)\\\\n- ** Action Items **: \\\\n  1. Confirm availability of both attendees for the proposed time.\\\\n  2. If unavailable, propose alternative time slots and resolve scheduling conflicts.\\\\n  3. Send a follow-up email to Harshit to confirm the meeting or suggest rescheduling.  \\\\n     ** Email Draft **:  \\\\n     \\\`\\\`\\\`\\\\n     Hi Harshit,\\\\n\\\\n     I hope this message finds you well. I\\'ve checked for available times for our meeting on Thursday, August 21, 2025, from 10:00 AM to 10:30 AM (Pacific Time). Please let me know if this time works for you or if you\\'d like to reschedule.\\\\n\\\\n     Looking forward to your response.\\\\n\\\\n     Best regards,  \\\\n     Dorian Smiley\\\\n     \\\`\\\`\\\`\\\\n  4. Schedule the meeting in Google Calendar once confirmed: [Google Calendar Appointment Link](https://calendar.google.com/calendar/appointments/booking/AcZssZ0aYEsu_AL6fRFFwnjYP0cXwsbe36xOLKZWxqskikN22A3QXMRSyTW-HM-uiHtLSswtGz45Ga9x).\\\\n\\\\n---\\\\n\\\\n### **2. Kerry Sporkin  Meeting Scheduled for Tomorrow**\\\\n- **Details**: \\\\n  - **Topic**: Palantir implementations, Series A funding, and strategic partnership with PWC.\\\\n  - **Date/Time**: **Friday, August 22, 2025**, from **10:00 AM to 10:30 AM PT**.\\\\n  - **Attendees**: \\\\n    - Dorian Smiley (<dsmiley@codestrap.me>)  \\\\n    - Kerry Sporkin (<khsporkin@gmail.com>)\\\\n- **Key Discussion Points**: \\\\n  - Growing \\\\\\"cottage industry\\\\\\" around Palantir implementations.\\\\n  - CodeStrap LLC structure: exclusive partnerships, financial model, and investment strategy.\\\\n  - Transition to an ARR model and Series A funding plans.\\\\n  - Partnership with PWC to build AI-driven CFO solutions.\\\\n- **Action Items**: \\\\n  1. Confirm availability of all attendees today to avoid last-minute conflicts.\\\\n  2. Send a follow-up email to Kerry to confirm the meeting:  \\\\n     ** Email Draft **:  \\\\n     \\\`\\\`\\\`\\\\n     Hi Kerry,\\\\n\\\\n     I hope you\\'re doing well. Just confirming our meeting scheduled for Friday, August 22, 2025, from 10:00 AM to 10:30 AM (Pacific Time). Please let me know if this time still works or if there are any adjustments needed.\\\\n\\\\n     Looking forward to our discussion!\\\\n\\\\n     Best regards,  \\\\n     Dorian Smiley\\\\n     \\\`\\\`\\\`\\\\n  3. If conflicts arise, propose alternative times and reschedule promptly.\\\\n  4. Include a brief agenda in the calendar invite:  \\\\n     - Finalizing Series A strategy.  \\\\n     - Next steps for Palantir implementation opportunities.  \\\\n     - Operational details of the PWC partnership.\\\\n\\\\n**Additional Notes**: Full meeting notes from your previous discussion with Kerry are available [here](https://docs.google.com/document/d/1NwYRnCrQH3hAmdB5R_3mwhUF9wynzfPuLZbIb5AsRuo/edit?usp=meet_tnfm_email). Review them to prepare for tomorrows meeting.\\\\n\\\\n---\\\\n\\\\n## **Spam/Marketing Emails**\\\\nNo spam or marketing emails detected today. \\\\n\\\\n---\\\\n\\\\nThats it for todays brief! Let me know if you need help with any of the tasks above. Have a productive Thursday, and enjoy your coffee!\\\\n\\\\nWarm regards,  \\\\n**Vicki**   \\\\n*Your AI EA at CodeStrap*\\""
  ],
  "reasoning": "The message contains information about a meeting scheduled for tomorrow (August 22, 2025) with Kerry Sporkin. No contacts were found."
}
\`\`\``;

    const result = extractJsonFromBackticks(inputJSON);
    const parsed = JSON.parse(result);

    expect(parsed).toBeDefined();
    expect(parsed.contacts.length).toBe(0);
    expect(parsed.currentUser.email).toBe('dsmiley@codestrap.me');
  });

  test('Should extract and clean JSON from a FUBAR string with nested backticks', () => {
    const inputJSON = '```json' +
      '{' +
      '"contacts": [],' +
      '"currentUser": {' +
      '"name": null,' +
      '"email": "dsmiley@codestrap.me",' +
      '"id": "cadf16c6-76c8-4ff2-8716-889f8797d547",' +
      '"timezone": null' +
      '},' +
      '"messages": [' +
      '"\\"---\\\\n\\\\n### **Daily Brief: Wednesday, August 27, 2025**\\\\n\\\\n#### **TL;DR**  \\\\n- **Business-Related:** Prepare for and follow up on a scheduled meeting with Kerry Sporkin regarding CodeStrap inquiries.  \\\\n- **No spam or irrelevant marketing emails detected.**\\\\n\\\\n---\\\\n\\\\n#### **Business-Related Emails**\\\\n\\\\n1. **Meeting Confirmation: CodeStrap Inquiries with Kerry Sporkin**  \\\\n   - **Details:**  \\\\n     - **Date & Time:** Today, 12:30 PM - 1:00 PM (Pacific Time)  \\\\n     - **Attendees:** Dorian Smiley (you) and Kerry Sporkin  \\\\n     - **Platform:** Google Meet ([Join Link](https://meet.google.com/omd-ugvf-shm?hs=224))  \\\\n     - **Background:** Kerry learned about CodeStrap via Medium and has confirmed attendance.  \\\\n\\\\n   - **Action Items:**  \\\\n     - Prepare meeting materials, including agenda and discussion points.  \\\\n     - Test Google Meet link for technical readiness.\\\\n\\\\n---\\\\n\\\\n2. **Follow-Up Email to Kerry Sporkin**  \\\\n   - **Details:**  \\\\n     - Send a follow-up email to reconfirm meeting details and encourage Kerry to test the Google Meet setup.  \\\\n     - Use the provided draft email:  \\\\n       ```\\\\n       Hi Kerry, \\\\n       Thank you for accepting the invitation to discuss CodeStrap inquiries.As a reminder, the meeting is scheduled for Wednesday, August 27, 2025, from 12: 30 PM to 1:00 PM(Pacific Time).Please feel free to test the Google Meet setup beforehand using the provided link.Looking forward to our discussion.\\\\n\\\\n       Best regards, \\\\n       Dorian Smiley\\\\n       ```\\\\n\\\\n   - **Action Items:**  \\\\n     - Send this email by the end of the day.\\\\n\\\\n---\\\\n\\\\n#### **Task List to Tackle Today**\\\\n\\\\n1. **Prepare for the Meeting:**  \\\\n   - Review any background information or inquiries from Kerry.  \\\\n   - Draft an agenda or key talking points.  \\\\n   - Test the Google Meet link to ensure smooth connectivity.\\\\n\\\\n2. **Send Follow-Up Email:**  \\\\n   - Use the draft provided above to confirm details and assist Kerry with the meeting setup.\\\\n\\\\n3. **Post-Meeting Follow-Up Plan:**  \\\\n   - After the meeting, summarize key points and outline next steps for Kerry.  \\\\n\\\\n---\\\\n\\\\nEnjoy your coffee and lets make this Wednesday productive!  \\\\n\\\\nWarm regards,  \\\\nVicki\\""' +
      '],' +
      '"reasoning": "The message contains the details of a meeting scheduled for today with Kerry Sporkin."' +
      '}' +
      '```';

    const result = extractJsonFromBackticks(inputJSON);
    const parsed = JSON.parse(result);

    expect(parsed).toBeDefined();
    expect(parsed.contacts.length).toBe(0);
    expect(parsed.currentUser.email).toBe('dsmiley@codestrap.me');
  });
})
````

## File: packages/utils/src/lib/Extractors.ts
````typescript
export function extractJsonFromBackticks(text: string): string {
  text = cleanJsonString(text);

  const open = text.indexOf("```");
  if (open === -1) {
    return text;
  }

  const close = text.indexOf("```", open + 3);
  if (close === -1 || close <= open + 2) {
    throw new Error("No valid closing fence (```) found after opening fence");
  }

  // earliest of '{' or '[' after the opening fence
  const a = text.indexOf("{", open + 3);
  const b = text.indexOf("[", open + 3);
  const jsonStart = (a >= 0 && (b < 0 || a < b)) ? a : b;

  if (jsonStart === -1 || jsonStart >= close) {
    throw new Error("JSON must start with either { or [ after the opening fence (```) and before the closing fence");
  }

  const extractedJSONClean = text.substring(jsonStart, close);

  return extractedJSONClean;
}

export function extractHtmlFromBackticks(text: string): string {
  const regex = /```(?:html)?\s*([\s\S]+?)```/;
  const match = text.match(regex);
  return match ? match[1].trim() : text;
}

export function cleanJsonString(src: string): string {
  let s = src.trim();

  // 1) Remove BOM & zero-width chars
  s = s.replace(/^\uFEFF/, "").replace(/[\u200B-\u200D\u2060\uFEFF]/g, "");

  // 2) Normalize curly/smart quotes
  s = s.replace(/[]/g, '"').replace(/[]/g, "'");

  // 3) Strip // and /* */ comments (note: this is not string-aware)
  s = s.replace(/(^|\s)\/\/.*$/gm, "").replace(/\/\*[\s\S]*?\*\//g, "");

  // 4) Remove trailing commas before } or ]
  s = s.replace(/,\s*(?=[}\]])/g, "");

  // 5) Collapse backslashes before non-escape chars (keep valid escapes)
  s = s.replace(/\\(?!["\\/bfnrtu])/g, "");

  // 6) Neutralize inner ``` sequences INSIDE strings so they don't look like fences.
  //    Replace runs of >=3 backticks with \u0060\u0060\u0060 (still renders as ``` when parsed).
  {
    let out = "";
    let inStr = false;
    let esc = false;
    for (let i = 0; i < s.length; i++) {
      const ch = s[i];

      if (inStr) {
        if (esc) {
          out += "\\" + ch;      // preserve the escape as written
          esc = false;
          continue;
        }
        if (ch === "\\") {
          esc = true;
          continue;
        }
        if (ch === "`") {
          // count run of backticks
          let j = i;
          while (j < s.length && s[j] === "`") j++;
          const run = j - i;
          if (run >= 3) {
            // emit same count as \u0060
            for (let k = 0; k < run; k++) out += "\\u0060";
            i = j - 1;
            continue;
          }
          // single or double backtick in string: keep as-is
          out += ch;
          continue;
        }
        out += ch;
        if (ch === '"') inStr = false;
        continue;
      }

      // not in string
      out += ch;
      if (ch === '"') inStr = true;
    }
    s = out;
  }

  // 7) Trim again
  return s.trim();
}
````

## File: packages/utils/src/lib/logCollector.README.md
````markdown
# Logging Service  Developer README

**TL;DR**
Inmemory logger with **perexecution ring buffers** and a **global LRU cap**.

* **Hard memory ceilings:** `perExecBytes`, `globalBytes`.
* **LRU eviction:** O(logn) minheap by last access.
* **Semantics:** keep newest entry on global pressure; drop oversized single entry when theres no global pressure.
* **Great for:** request/job/agent runs; dump logs on error/completion.

---

## Install / Import

```ts
// ESM/TS
import { createLoggingService } from '@xreason/services/loggingService';
```

*No external deps.*

---

## API

```ts
function createLoggingService(
  perExecBytes = 256 * 1024,
  globalBytes = 64 * 1024 * 1024,
  now: () => number = Date.now
): {
  log: (executionId: string, message: string) => void;
  getLog: (executionId: string) => string;     // joined by '\n'
  __debug: () => {
    executionIds: string[];
    totalBytes: number;                        // sum of all buffers
    bufferBytes: (id: string) => number;       // 0 if missing
  };
}
```

### Methods

* `log(executionId, message)`

  * Appends `message` to that executions buffer.
  * Enforces caps:

    * **Preeviction**: Evicts oldest executions until `totalBytes + size <= globalBytes`.
    * **Perexec**: Trims oldest entries of that execution until  `perExecBytes` **but** keeps at least the newest entry if there was global pressure.
    * **Oversized single message**: If there was **no** global pressure and the single entry still exceeds `perExecBytes`, it is **dropped**.
* `getLog(executionId)`

  * Returns the executions entries joined by `'\n'`, or `''` if none.
* `__debug()`

  * For tests/telemetry. Do not rely on as a stable public API.

---

## Memory Accounting

* Size is `Buffer.byteLength(msg, 'utf8') + 1` (the `+1` is for the newline when joining).
* **Unicode safe**: multibyte chars are counted correctly via `Buffer.byteLength`.
* Nodeonly note: if you must run in the browser, swap to `new TextEncoder().encode(msg).length`.

---

## Eviction Semantics (precise)

1. **Global LRU (O(logn))**

   * Minheap on `lastAccess`.
   * Evict **entire** oldest executions until `totalBytes + incomingSize <= globalBytes`.
2. **Perexecution ring buffer**

   * While `byteSize > perExecBytes` and `entries.length > 1`, drop oldest entries.
   * If **no global pressure** and a single entry still exceeds `perExecBytes`, **drop it**.
3. **Edge caps**

   * `globalBytes = 0`  nothing is retained.
   * `perExecBytes = 0`  execution buffers retain nothing.

---

## Complexity

* `log()`:

  * Heap push/pop: **O(logn)** (n = active execution IDs).
  * Perexec trimming: proportional to removed entries (amortized OK under cap).
* `getLog()`:

  * Join of that buffers strings (O(bytes in that exec)).

---

## Usage Patterns

### Request/job/agent scoped logs

```ts
const logs = createLoggingService(64 * 1024, 64 * 1024 * 1024);
const id = ctx.requestId; // or jobId/execId

logs.log(id, 'starting step A');
// ...
logs.log(id, 'A done');
// on error or completion:
const text = logs.getLog(id);
// attach to response, persist selectively, or emit on error only
```

### Sidecar logger with your existing stack (pino/winston/etc.)

Keep your normal streaming logger; also `log()` to this service using a **correlation ID**. On failure, fetch `getLog(id)` and attach to error reports/UI.

---

## Testing & Determinism

* **Inject clock**: `createLoggingService(per, global, () => ++t)` for precise LRU order.
* **Invariants** (dev only): checks that `totalBytes ===  buffer.byteSize` and each `buffer.byteSize` matches recomputed entry sizes. Throws on mismatch.

---

## Guarantees & Caveats

* **Isolation**: perID buffers are independent.
* **No I/O**: inmemory only; add your own export/flush hook if needed.
* **Singlethreaded**: designed for JS event loop (no crossthread sync).
* **Join separator**: `'\n'`. If you need exact original bytes, store entries externally.

---

## Examples

**Basic**

```ts
const svc = createLoggingService(32 * 1024, 128 * 1024 * 1024);

svc.log('exec-1', 'step 1');
svc.log('exec-1', 'step 2');
console.log(svc.getLog('exec-1')); // "step 1\nstep 2"
```

**Oversized single message (no global pressure)**

```ts
const svc = createLoggingService(32, 4096);
svc.log('x', 'X'.repeat(100)); // dropped (too big, no global pressure)
console.log(svc.getLog('x')); // ""
```

**Global pressure keeps newest**

```ts
const svc = createLoggingService(64, 100);
svc.log('old', 'O'.repeat(30));
svc.log('old', 'O'.repeat(30));
svc.log('new', 'N'.repeat(80)); // evicts 'old', keeps 'new'
```

---

## Extension Ideas (if needed)

* Structured entries: `{ ts, level, fields, msg }`.
* Export hooks: on completion/error, flush a buffer to a sink.
* Metrics: counts of evictions, drops, bytes per exec.
* Severityaware eviction (prefer dropping lowlevel logs first).

---

## FAQ

* **Why `+1` byte per entry?**
  To account for the newline during `join('\n')`. Keeps accounting exact vs `getLog()` output.

* **Why keep newest message under global pressure?**
  Latest state is often most valuable for debugging; older entries get trimmed first.

* **Why evict before writing?**
  Simpler invariants and avoids temporary overcap states; earlyreturn if it still cant fit.

---

Thats itbounded, perID logs with deterministic eviction you can ship today.
````

## File: packages/utils/src/lib/logCollector.ts
````typescript
let log = '';
export function getLogger() {
    return {
        getLog: () => log,
        log: (message: string) => log = `${log}\n${message}\n`,
    }
}
````

## File: packages/utils/src/lib/loggingService.ts
````typescript
// perExecBytes defaults to 256 KB
// globalBytes defaults to 64 MB
export function createLoggingService(
  perExecBytes = 256 * 1024,
  globalBytes = 64 * 1024 * 1024,
  now: () => number = Date.now // injectable clock for deterministic tests
) {
  type Buf = { entries: string[]; byteSize: number; lastAccess: number };

  const buffers = new Map<string, Buf>();
  let totalBytes = 0;

  // --- O(log n) LRU heap (lazy-delete) ---
  const lruHeap: Array<{ ts: number; id: string }> = [];

  const heapPush = (item: { ts: number; id: string }) => {
    lruHeap.push(item);
    let i = lruHeap.length - 1;
    while (i > 0) {
      const p = (i - 1) >> 1; // parent index
      if (lruHeap[p].ts <= lruHeap[i].ts) break;
      [lruHeap[p], lruHeap[i]] = [lruHeap[i], lruHeap[p]];
      i = p;
    }
  };

  const heapPop = (): { ts: number; id: string } | undefined => {
    if (lruHeap.length === 0) return undefined;
    const top = lruHeap[0];
    const last = lruHeap.pop()!;
    if (lruHeap.length > 0) {
      lruHeap[0] = last;
      // siftDown
      let i = 0;
      while (true) {
        const l = 2 * i + 1;
        const r = 2 * i + 2;
        let m = i;
        if (l < lruHeap.length && lruHeap[l].ts < lruHeap[m].ts) m = l;
        if (r < lruHeap.length && lruHeap[r].ts < lruHeap[m].ts) m = r;
        if (m === i) break;
        [lruHeap[i], lruHeap[m]] = [lruHeap[m], lruHeap[i]];
        i = m;
      }
    }
    return top;
  };

  const approxBytes = (msg: string) => Buffer.byteLength(msg, 'utf8') + 1;

  function ensureBuffer(executionId: string) {
    if (!buffers.has(executionId)) {
      buffers.set(executionId, { entries: [], byteSize: 0, lastAccess: now() });
      heapPush({ ts: buffers.get(executionId)!.lastAccess, id: executionId });
    }
    return buffers.get(executionId)!;
  }

  function __debug() {
    return {
      executionIds: Array.from(buffers.keys()),
      totalBytes,
      bufferBytes: (id: string) => buffers.get(id)?.byteSize ?? 0,
    };
  }

  function evictGlobally(extraBytes = 0) {
    // Evict until (totalBytes + what-we-want-to-add) fits under globalBytes
    while (totalBytes + extraBytes > globalBytes && buffers.size > 0) {
      const top = heapPop();
      if (!top) break;

      const buf = buffers.get(top.id);
      // lazy delete: skip if heap entry is stale
      if (!buf || buf.lastAccess !== top.ts) continue;

      totalBytes -= buf.byteSize;
      buffers.delete(top.id);
    }
  }

  function assertInvariants() {
    if (process.env['NODE_ENV'] === 'production') return;
    let sum = 0;
    for (const [, b] of buffers) {
      const recomputed = b.entries.reduce((acc, m) => acc + approxBytes(m), 0);
      if (recomputed !== b.byteSize) {
        throw new Error(`Invariant violated: buffer.byteSize mismatch`);
      }
      sum += b.byteSize;
    }
    if (sum !== totalBytes) {
      throw new Error(`Invariant violated: totalBytes mismatch`);
    }
  }

  function log(executionId: string, message: string) {
    let buf = ensureBuffer(executionId);
    const size = approxBytes(message);

    const willExceedGlobal = totalBytes + size > globalBytes;

    // PRE-eviction
    evictGlobally(size);

    // If our own buffer was evicted while making room, recreate it.
    if (!buffers.has(executionId)) {
      buf = ensureBuffer(executionId);
    }

    // Still cannot fit? Drop the message.
    if (totalBytes + size > globalBytes) {
      assertInvariants();
      return;
    }

    // Write
    totalBytes += size;
    buf.byteSize += size;
    buf.entries.push(message);
    buf.lastAccess = now();
    heapPush({ ts: buf.lastAccess, id: executionId });

    // Per-exec trimming (keep newest single entry if needed)
    while (buf.byteSize > perExecBytes && buf.entries.length > 1) {
      const removed = buf.entries.shift()!;
      const removedSize = approxBytes(removed);
      buf.byteSize -= removedSize;
      totalBytes -= removedSize;
    }

    // If no global pressure and single entry is still oversized, drop it
    if (
      !willExceedGlobal &&
      buf.entries.length === 1 &&
      buf.byteSize > perExecBytes
    ) {
      const removed = buf.entries.pop()!;
      const removedSize = approxBytes(removed);
      buf.byteSize -= removedSize;
      totalBytes -= removedSize;
    }

    assertInvariants();
  }

  function getLog(executionId: string) {
    const buf = buffers.get(executionId);
    return buf ? buf.entries.join('\n') : '';
  }

  return { log, getLog, __debug };
}
````

## File: packages/utils/src/lib/loggingServices.test.ts
````typescript
import { createLoggingService } from './loggingService';

describe('createLoggingService', () => {
  test('isolates logs by executionId', () => {
    const svc = createLoggingService(1024, 4096);
    svc.log('execA', 'A1');
    svc.log('execB', 'B1');
    svc.log('execA', 'A2');

    expect(svc.getLog('execA')).toBe('A1\nA2');
    expect(svc.getLog('execB')).toBe('B1');
    expect(svc.__debug().executionIds.sort()).toEqual(['execA', 'execB']);
  });

  test('per-execution ring buffer trims when exceeding perExecBytes', () => {
    const perExecBytes = 32;
    const svc = createLoggingService(perExecBytes, 4096);

    const id = 'exec-ring';
    const m1 = '1234567890'; // 10 bytes
    const m2 = 'abcdefghij'; // 10 bytes
    const m3 = 'KLMNOPQRST'; // 10 bytes

    svc.log(id, m1);
    svc.log(id, m2);
    svc.log(id, m3);

    const log = svc.getLog(id);
    expect(log).not.toContain(m1);
    expect(log).toContain(m2);
    expect(log).toContain(m3);

    const expectedSize =
      Buffer.byteLength(m2, 'utf8') + 1 + Buffer.byteLength(m3, 'utf8') + 1;
    expect(svc.__debug().bufferBytes(id)).toBe(expectedSize);
  });

  test('global LRU eviction removes oldest execution logs', () => {
    const perExecBytes = 64;
    const globalBytes = 100;
    const svc = createLoggingService(perExecBytes, globalBytes);

    const oldMsg = 'O'.repeat(30);
    svc.log('old', oldMsg);
    svc.log('old', oldMsg);

    const newMsg = 'N'.repeat(80);
    svc.log('new', newMsg);

    expect(svc.getLog('old')).toBe('');
    expect(svc.getLog('new')).toContain(newMsg);

    const expectedSize = Buffer.byteLength(newMsg, 'utf8') + 1;
    expect(svc.__debug().totalBytes).toBe(expectedSize);
  });

  test('oversized single message is trimmed (ignored)', () => {
    const perExecBytes = 32;
    const svc = createLoggingService(perExecBytes, 1024);

    const id = 'oversized';
    const bigMsg = 'X'.repeat(100);

    svc.log(id, bigMsg);
    // It should be trimmed down by ring buffer
    const log = svc.getLog(id);
    expect(log.length).toBeLessThanOrEqual(perExecBytes);
    expect(svc.__debug().bufferBytes(id)).toBeLessThanOrEqual(perExecBytes);
  });

  test('buffer sizes match the exact message sizes', () => {
    const svc = createLoggingService(128, 256);

    const msgA1 = 'AAA';
    const msgB1 = 'BBBBBB';
    const msgB2 = 'B2';

    svc.log('A', msgA1);
    svc.log('B', msgB1);
    svc.log('B', msgB2);

    const debug = svc.__debug();
    const aExpected = Buffer.byteLength(msgA1, 'utf8') + 1;
    const bExpected =
      Buffer.byteLength(msgB1, 'utf8') +
      1 +
      Buffer.byteLength(msgB2, 'utf8') +
      1;

    expect(debug.bufferBytes('A')).toBe(aExpected);
    expect(debug.bufferBytes('B')).toBe(bExpected);
    expect(debug.totalBytes).toBe(aExpected + bExpected);
  });

  // -----------------------------
  // New tests (your requested fixes)
  // -----------------------------

  test('deterministic LRU using injected clock', () => {
    let t = 0;
    const now = () => ++t;
    const svc = createLoggingService(64, 70, now); // 70 so only 'a' is evicted

    svc.log('a', 'AAAA'); // t=1
    svc.log('b', 'BBBB'); // t=2

    // Force eviction on next insert
    const big = 'X'.repeat(60);
    svc.log('c', big); // t=3, should evict 'a' (oldest)

    expect(svc.getLog('a')).toBe('');
    expect(svc.getLog('b')).toContain('BBBB');
    expect(svc.getLog('c')).toContain(big);
  });

  test('stress/fuzz: invariants always hold', () => {
    const now = (() => {
      let t = 0;
      return () => ++t;
    })();
    const svc = createLoggingService(256, 4 * 1024, now);

    const ids = Array.from({ length: 50 }, (_, i) => `id-${i}`);
    const rand = (n: number) => Math.floor(Math.random() * n);

    for (let i = 0; i < 2000; i++) {
      const id = ids[rand(ids.length)];
      const len = rand(200); // 0..199
      const msg = ''.repeat(len); // multibyte payload too
      svc.log(id, msg);
    }

    const dbg = svc.__debug();
    const sum = dbg.executionIds.reduce(
      (acc, id) => acc + dbg.bufferBytes(id),
      0
    );
    expect(sum).toBe(dbg.totalBytes);
  });

  test('edge: perExecBytes = 0 drops everything for that exec', () => {
    const svc = createLoggingService(0, 1024);
    svc.log('x', 'hi');
    expect(svc.getLog('x')).toBe('');
    expect(svc.__debug().bufferBytes('x')).toBe(0);
  });

  test('edge: globalBytes = 0 evicts everything immediately', () => {
    const svc = createLoggingService(1024, 0);
    svc.log('x', 'hi');
    expect(svc.getLog('x')).toBe('');
    expect(svc.__debug().totalBytes).toBe(0);
  });

  test('edge: unicode/multibyte sizing', () => {
    const per = 32;
    const svc = createLoggingService(per, 4096);
    const msg = ''; // each is multi-byte in UTF-8
    svc.log('u', msg);
    const expected = Buffer.byteLength(msg, 'utf8') + 1;
    expect(svc.__debug().bufferBytes('u')).toBe(expected);
  });
});
````

## File: packages/utils/src/lib/Markdown.ts
````typescript
export function generateMarkdownTable(jsonData: Record<string, any>[]) {
    if (!jsonData.length) return "";

    // Extract headers from the first object
    const headers = Object.keys(jsonData[0]);

    // Generate header row
    let markdownTable = `| ${headers.join(" | ")} |\n`;
    markdownTable += `| ${headers.map(() => "---").join(" | ")} |\n`;

    // Generate data rows
    for (const row of jsonData) {
        const values = headers.map(header => row[header]);
        markdownTable += `| ${values.join(" | ")} |\n`;
    }

    return markdownTable;
}
````

## File: packages/utils/src/lib/sanitizers.ts
````typescript
export function sanitizeJSONString(input: string): string {
  // Replace double quotes with escaped double quotes
  let sanitized = input.replace(/"/g, '\\"');

  // Replace line feeds with escaped newline characters
  sanitized = sanitized.replace(/\n/g, '\\n');

  // Replace carriage returns (if any) with escaped characters
  sanitized = sanitized.replace(/\r/g, '\\r');

  return sanitized;
}
````

## File: packages/utils/src/lib/StateMachines.test.ts
````typescript
import {
  simpleMachine,
  complexMachine,
} from './__fixtures__/DuplicateIdMachine';
import { StateConfig } from '@codestrap/developer-foundations-types';
import { getUniqueStateIds } from './StateMachines';
let counter = 0;

jest.mock('./uuid', () => ({
  ...jest.requireActual('./uuid'),
  uuidv4: jest.fn(() => (++counter).toString()),
}));

afterAll(() => {
  jest.clearAllMocks();
});

beforeEach(() => (counter = 0));

describe('Testing the getUniqueStateIds function', () => {
  test('Testing Deuplication of a state machines without parellel states', async () => {
    const inputStates = simpleMachine as StateConfig[];
    const deduplicatedStates = getUniqueStateIds(inputStates);
    const serializedResults = JSON.stringify(deduplicatedStates);

    expect(serializedResults).toBe(
      '[{"id":"sendSlackMessage|1","transitions":[{"on":"CONTINUE","target":"sendSlackMessage|2"},{"on":"ERROR","target":"failure"}]},{"id":"sendSlackMessage|2","transitions":[{"on":"CONTINUE","target":"sendSlackMessage|3"},{"on":"ERROR","target":"failure"}]},{"id":"sendSlackMessage|3","transitions":[{"on":"CONTINUE","target":"success"},{"on":"ERROR","target":"failure"}]},{"id":"success","type":"final"},{"id":"failure","type":"final"}]'
    );
  });

  test('Testing Deuplication of a state machines with parellel states', async () => {
    const inputStates = complexMachine as StateConfig[];
    const deduplicatedStates = getUniqueStateIds(inputStates);
    const serializedResults = JSON.stringify(deduplicatedStates);

    expect(serializedResults).toBe(
      '[{"id":"sendSlackMessage|1","transitions":[{"on":"CONTINUE","target":"sendSlackMessage|2"},{"on":"ERROR","target":"failure"}]},{"id":"sendSlackMessage|2","transitions":[{"on":"CONTINUE","target":"parallelChecks|3"},{"on":"ERROR","target":"failure"}]},{"id":"parallelChecks|3","type":"parallel","states":[{"id":"RegulatoryCheck|5","transitions":[{"on":"CONTINUE","target":"success"},{"on":"ERROR","target":"failure"}],"parentId":"parallelChecks|3"},{"id":"ConcentrationEstimation|6","transitions":[{"on":"CONTINUE","target":"success"},{"on":"ERROR","target":"failure"}],"parentId":"parallelChecks|3"}],"onDone":"sendSlackMessage|4"},{"id":"sendSlackMessage|4","transitions":[{"on":"CONTINUE","target":"success"},{"on":"ERROR","target":"failure"}]},{"id":"success","type":"final"},{"id":"failure","type":"final"}]'
    );
  });
});
````

## File: packages/utils/src/lib/StateMachines.ts
````typescript
import { StateConfig } from '@codestrap/developer-foundations-types';
import { uuidv4 } from './uuid';

export function getUniqueStateIds(
  inputArray: StateConfig[],
  parent?: StateConfig
): StateConfig[] {
  let statesArray = [...inputArray];

  // the presence of the | character means we've already deduplicated this states
  // Skip if already deduplicated
  if (statesArray[0]?.id.indexOf('|') >= 0) {
    return statesArray;
  }

  // first rewrite all the state id values in the top level states
  statesArray = statesArray.map((state, index) => {
    switch (state.id) {
      // these states only hve one occurrence in all machines
      case 'success':
      case 'failure':
      case 'pause':
        break;
      default:
        // generate unique ID for each state. Without this states that share the same function will collapse to a single one
        // if a parent is supplied append the parent ID so the send to event
        state.id = `${state.id}|${uuidv4()}`;
        if (parent) state.parentId = parent.id;
        break;
    }
    return state;
  });

  // next rewrite the id of transitions by slicing the states array from the current index and finding the first occurrence of that transition
  statesArray = statesArray.map((state, index) => {
    switch (state.id) {
      // these states only hve one occurrence in all machines
      case 'success':
      case 'failure':
      case 'pause':
        break;
      default:
        // transition states can be ahead of the current state or behind in the states array, ahead is more common thus proffered
        // so we slice the array to find all possible candidates
        const futureStates = statesArray.slice(index + 1);
        const pastStates = statesArray.slice(0, index).reverse();

        // Helper function to find target in future first, then past
        const findTargetState = (target: string) => {
          return (
            futureStates.find((s) => s.id.includes(target)) ||
            pastStates.find((s) => s.id.includes(target))
          );
        };

        // Update transitions
        state.transitions = state.transitions?.map((transition) => {
          const targetState = findTargetState(transition.target);
          transition.target = targetState ? targetState.id : transition.target;
          return transition;
        });

        // Update onDone
        if (state.onDone) {
          // sometimes the programmer model fucks up and send back an object array instead of a string
          if ((state.onDone as any) instanceof Array) {
            state.onDone = (state.onDone as any)[0].target;
          }
          // sometimes the programmer model fucks up and send back an object instead of a string
          if ((state.onDone as any) instanceof Object) {
            state.onDone = (state.onDone as any).target;
          }
          // set the transition target to the new ID or default back to the original
          const targetState = findTargetState(state.onDone as string);
          state.onDone = targetState ? targetState.id : state.onDone;
        }

        // Handle parallel states recursively
        if (state.states) {
          getUniqueStateIds(state.states, state);
        }
        break;
    }
    return state;
  });

  return statesArray;
}
````

## File: packages/utils/src/lib/utc.ts
````typescript
/** Extract Y/M/D/h/m/s as seen in `tz` for a given UTC instant. */
export function partsInTZ(d: Date, tz: string) {
    const dtf = new Intl.DateTimeFormat('en-US', {
        timeZone: tz,
        year: 'numeric', month: '2-digit', day: '2-digit',
        hour: '2-digit', minute: '2-digit', second: '2-digit',
        hour12: false,
    });
    const p = Object.fromEntries(dtf.formatToParts(d).map((x) => [x.type, x.value]));
    return {
        year: +p['year'], month: +p['month'], day: +p['day'],
        hour: +p['hour'], minute: +p['minute'], second: +p['second'],
    };
}

const pad = (n: number, len = 2) => String(n).padStart(len, '0');

/** Render the SAME UTC instant as local time in `tz` with HH:MM suffix. */
export function toZonedISOString(utc: Date, tz: string): string {
    const p = partsInTZ(utc, tz); // local Y/M/D H:M:S in tz
    // Offset minutes = (local-as-UTC ms) - (true UTC ms)
    const asIfUTC = Date.UTC(p.year, p.month - 1, p.day, p.hour, p.minute, p.second);
    const offMin = Math.round((asIfUTC - utc.getTime()) / 60000);
    const sign = offMin >= 0 ? '+' : '-';
    const abs = Math.abs(offMin);
    return `${pad(p.year, 4)}-${pad(p.month)}-${pad(p.day)}T${pad(p.hour)}:${pad(p.minute)}:${pad(p.second)}${sign}${pad(Math.floor(abs / 60))}:${pad(abs % 60)}`;
}

/** Build "YYYY-MM-DDTHH:mm:ss" from a wall-clock Date and convert to the UTC instant for `tz`. */
export function toUTCFromWallClockLocal(wallClock: Date, tz: string): Date {
    const s =
        `${pad(wallClock.getFullYear(), 4)}-${pad(wallClock.getMonth() + 1)}-${pad(wallClock.getDate())}` +
        `T${pad(wallClock.getHours())}:${pad(wallClock.getMinutes())}:${pad(wallClock.getSeconds())}`;
    return wallClockToUTC(s, tz);
}


/** Convert a wall-clock string in `tz` to a UTC instant.
 * Supports:
 *  - ISO no-offset:  "YYYY-MM-DDTHH:mm[:ss]"   interpret as wall-clock in `tz`
 *  - Explicit offset/Z (e.g., "...Z", "...+02:00", "GMT-0700 (...)")  parsed as real instant
 */
export function wallClockToUTC(isoOrOffsetStr: string, tz: string): Date {
    const s = isoOrOffsetStr.trim();

    // Case A: ISO without offset (wall-clock in tz)
    const m = s.match(/^(\d{4})-(\d{2})-(\d{2})[T\s](\d{2}):(\d{2})(?::(\d{2}))?$/);
    if (m) {
        const Y = +m[1], Mo = +m[2], D = +m[3], h = +m[4], mi = +m[5], ssec = +(m[6] || '0');

        // First guess as UTC, then adjust by the tz offset at that instant.
        let ms = Date.UTC(Y, Mo - 1, D, h, mi, ssec);
        for (let i = 0; i < 3; i++) {
            const got = partsInTZ(new Date(ms), tz); // your existing helper (Intl-based)
            const gotMs = Date.UTC(got.year, got.month - 1, got.day, got.hour, got.minute, got.second);
            const wantMs = Date.UTC(Y, Mo - 1, D, h, mi, ssec);
            const delta = wantMs - gotMs;
            if (delta === 0) break;
            ms += delta;
        }
        return new Date(ms);
    }

    // Case B: Anything with an explicit offset or Z  real instant already
    // Examples: "2025-09-09T10:30:00Z", "2025-09-09T10:30:00-07:00",
    //           "Tue Sep 09 2025 10:30:00 GMT-0700 (Pacific Daylight Time)"
    const parsed = new Date(s);
    if (!isNaN(parsed.getTime())) return parsed;

    throw new Error(`Bad wall-clock string: ${isoOrOffsetStr}`);
}

/** Return UTC-hour numbers for the intended local working hours on the given date. */
export function workingHoursUTCForDate(
    baseUTC: Date, tz: string, localStartHour: number, localEndHour: number
): { start_hour: number; end_hour: number } {
    const p = partsInTZ(baseUTC, tz);
    const y = p.year, m = p.month, d = p.day;

    const startUTC = wallClockToUTC(
        `${y}-${String(m).padStart(2, '0')}-${String(d).padStart(2, '0')}T${String(localStartHour).padStart(2, '0')}:00:00`,
        tz
    );
    const endUTC = wallClockToUTC(
        `${y}-${String(m).padStart(2, '0')}-${String(d).padStart(2, '0')}T${String(localEndHour).padStart(2, '0')}:00:00`,
        tz
    );

    // Use the UTC hour fields for clamping on that UTC date.
    return {
        start_hour: startUTC.getUTCHours(),
        end_hour: endUTC.getUTCHours(),
    };
}

/** Day-of-week index (0=Sun..6=Sat) for a UTC instant as seen in `tz`. */
export function dowInTZ(dUTC: Date, tz: string): number {
    const fmt = new Intl.DateTimeFormat('en-US', { timeZone: tz, weekday: 'short' });
    const w = fmt.format(dUTC);
    return ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'].indexOf(w);
}

/** Monday at LOCAL start-hour for the week containing `dUTC` in `tz`  UTC instant. */
export function mondayOfWeek(dUTC: Date, tz: string): Date {
    // Intended LOCAL business hours in the target tz:
    const LOCAL_START = 8;
    const p = partsInTZ(dUTC, tz);
    const dow = dowInTZ(dUTC, tz);
    const delta = dow === 0 ? -6 : 1 - dow; // to Monday
    const Y = p.year, Mo = p.month, D = p.day + delta;
    return wallClockToUTC(
        `${Y}-${String(Mo).padStart(2, '0')}-${String(D).padStart(2, '0')}T${String(LOCAL_START).padStart(2, '0')}:00:00`,
        tz
    );
}

/** Friday at LOCAL end-hour for the week containing `dUTC` in `tz`  UTC instant. */
export function fridayOfWeek(dUTC: Date, tz: string): Date {
    const LOCAL_END = 17;
    const monUTC = mondayOfWeek(dUTC, tz);
    const mp = partsInTZ(monUTC, tz);
    const Y = mp.year, Mo = mp.month, D = mp.day + 4;
    return wallClockToUTC(
        `${Y}-${String(Mo).padStart(2, '0')}-${String(D).padStart(2, '0')}T${String(LOCAL_END).padStart(2, '0')}:00:00`,
        tz
    );
}

export function dayInTZ(isoWithOffset: string, tz: string): number {
    const d = new Date(isoWithOffset); // instant is correct
    const fmt = new Intl.DateTimeFormat('en-US', { timeZone: tz, weekday: 'short' });
    const w = fmt.format(d); // weekday as seen in `tz`
    return ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'].indexOf(w);
}

export function detectIanaTimeZone(): string {
    // Works in modern Node and browsers with ICU data:
    const tz = Intl.DateTimeFormat().resolvedOptions().timeZone;
    return tz;
}
````

## File: packages/utils/src/lib/uuid.ts
````typescript
export function uuidv4() {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'
    .replace(/[xy]/g, function (c) {
        const r = Math.random() * 16 | 0, 
            v = c == 'x' ? r : (r & 0x3 | 0x8);
        return v.toString(16);
    });
}
````

## File: packages/utils/src/lib/Vectors.ts
````typescript
export function dotProduct<K extends number>(arr1: K[], arr2: K[]): number {
    if (arr1.length !== arr2.length) {
        throw EvalError("Two vectors must be of the same dimensions");
    }
    return arr1.map((x, i) => arr1[i] * arr2[i]).reduce((m, n) => m + n);
}
````

## File: packages/utils/src/index.ts
````typescript
export * from './lib/Extractors';
export * from './lib/date';
export * from './lib/logCollector';
export * from './lib/sanitizers';
export * from './lib/StateMachines';
export * from './lib/uuid';
export * from './lib/Markdown';
export * from './lib/Vectors';
export * from './lib/loggingService';
export * from './lib/utc';
````

## File: packages/utils/eslint.config.mjs
````
import baseConfig from '../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/utils/jest.config.ts
````typescript
export default {
  displayName: 'utils',
  preset: '../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': ['ts-jest', { tsconfig: '<rootDir>/tsconfig.spec.json' }],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../coverage/packages/utils',
};
````

## File: packages/utils/package.json
````json
{
  "name": "@codestrap/developer-foundations-utils",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "@codestrap/developer-foundations-types": "*",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/utils/project.json
````json
{
  "name": "utils",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/utils/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:utility"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/utils",
        "main": "packages/utils/src/index.ts",
        "tsConfig": "packages/utils/tsconfig.lib.json",
        "assets": ["packages/utils/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/utils/jest.config.ts"
      }
    }
  }
}
````

## File: packages/utils/README.md
````markdown
# utils

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build utils` to build the library.

## Running unit tests

Run `nx test utils` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/utils/tsconfig.json
````json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": true
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/utils/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/utils/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: packages/x-reason/src/lib/__fixtures__/Email.ts
````typescript
import { Context } from '@codestrap/developer-foundations-types';

const date = new Date();
// get tomorrow
date.setDate(date.getDate() + 1);

// Helper to generate ISO strings with specified hour and minute in UTC
function getISOTime(date: Date, hour: number, minute: number): string {
  const d = new Date(
    Date.UTC(date.getFullYear(), date.getMonth(), date.getDate(), hour, minute)
  );
  return d.toISOString();
}

// Mock email response data
export const mockEmailResponse = {
  data: {
    id: '8675309',
    threadId: '2468',
    labelIds: ['labels', 'schmabels'],
  },
};

export const validEmailData = {
  message: 'Hello World',
  subject: 'Test Subject',
  recipients: ['test@example.com'],
  modelDialog: 'sample dialog',
  ts: 1234567890,
};

export const validContext = {
  stack: ['emailData', 'bullshit'],
  emailData: validEmailData,
} as any as Context;

export const missingRecipientContext = {
  stack: ['emailData', 'bullshit'],
  emailData: {
    // message is missing
    subject: 'Test',
    modelDialog: 'sample dialog',
    ts: 1234567890,
  },
} as any as Context;

const THREAD_ID = 'mock-thread-id-1';

/*  messages.get  */
export const mockMessageGetResponse = {
  data: {
    id: 'mock-email-id-1',
    threadId: THREAD_ID,
    payload: {
      headers: [
        {
          name: 'Subject',
          value:
            'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        },
      ],
    },
    snippet: 'Mock message snippet',
  },
};

/*  messages.list (noresolution)  */
export const mockEmailHistoryNoResolution = {
  data: {
    messages: [
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'vici@codestrap.me',
        body: `Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time. Could you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  Thanks!  Best Vickie`,
        id: 'mock-email-id',
      },
    ],
  },
};

/*  messages.list (with resolution)  */
export const mockEmailHistoryWithResolution = {
  data: {
    messages: [
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'vici@codestrap.me',
        body: `Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time. Could you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  Thanks!  Best Vickie`,
        id: 'mock-email-id-1',
      },
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'dsmiley@codestrap.me',
        body: `Hey Connor what about tomorrow at 4 PM?`,
        id: 'mock-email-id-2',
      },
      {
        subject:
          'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
        threadId: THREAD_ID,
        from: 'connor.deeks@codestrap.me',
        body: `That works.`,
        id: 'mock-email-id-3',
      },
    ],
  },
};

/*  threads.get  */
export const mockMessageGetThreadsResponse = {
  data: {
    id: THREAD_ID,
    messages: [
      {
        id: mockEmailHistoryWithResolution.data.messages[0].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'vici@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryWithResolution.data.messages[0].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
      {
        id: mockEmailHistoryWithResolution.data.messages[1].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'dsmiley@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryWithResolution.data.messages[1].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
      {
        id: mockEmailHistoryWithResolution.data.messages[2].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'connor.deeks@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryWithResolution.data.messages[2].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
    ],
  },
};

export const mockMessageGetThreadsResponseNoResolution = {
  data: {
    id: THREAD_ID,
    messages: [
      {
        id: mockEmailHistoryNoResolution.data.messages[0].id,
        threadId: THREAD_ID,
        payload: {
          headers: [
            {
              name: 'Subject',
              value:
                'Resolve Meeting Conflicts - ID f41b004c-c032-4f3a-b7b8-be831804cb03',
            },
            { name: 'From', value: 'vici@codestrap.me' },
          ],
          body: {
            data: Buffer.from(
              mockEmailHistoryNoResolution.data.messages[0].body,
              'utf8'
            ).toString('base64'),
          },
        },
        snippet: 'Mock thread snippet',
      },
    ],
  },
};

export const mockCalendarList = {
  data: {
    items: [
      {
        id: 'mockEventId',
        summary: 'Meet with Komatsu',
        start: { dateTime: getISOTime(date, 20, 0) },
        end: { dateTime: getISOTime(date, 21, 0) },
      },
      {
        id: 'mockEventId2',
        summary: 'Stand Up',
        start: { dateTime: getISOTime(date, 21, 0) },
        end: { dateTime: getISOTime(date, 21, 30) },
      },
    ],
    nextPageToken: null,
    // other Schema$Events fields can be added if your code reads them
  },
};

export const mockCalendarInsert = {
  data: {
    id: 'mockEventId',
    hangoutLink: 'https://meet.google.com/mock-link', // direct Meet link
    conferenceData: {
      // redundant but harmless
      entryPoints: [
        {
          entryPointType: 'video',
          uri: 'https://meet.google.com/mock-link',
        },
      ],
    },
  },
};

export function getMockFreeBusyResponse(timeMin: any, timeMax: any) {
  return {
    data: {
      kind: 'calendar#freeBusy',
      timeMin,
      timeMax,
      calendars: {
        // each email requested in params.requestBody.items[*].id gets an entry:
        'dsmiley@codestrap.me': {
          busy: [
            {
              start: { dateTime: getISOTime(date, 20, 0) },
              end: { dateTime: getISOTime(date, 21, 0) },
            },
            {
              start: { dateTime: getISOTime(date, 21, 0) },
              end: { dateTime: getISOTime(date, 21, 30) },
            },
          ],
        },
      },
    },
  };
}
````

## File: packages/x-reason/src/lib/__fixtures__/Gemini.ts
````typescript
// Set up the mock response
export const mockProgrammerResponse1 = `[
    {
        "id": "sendEmail|13",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "success"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "success",
        "type": "final"
    },
    {
        "id": "failure",
        "type": "final"
    }
]`;
````

## File: packages/x-reason/src/lib/__fixtures__/MachineExecutions.ts
````typescript
export const machineId = 'mock-execution-id';
export const machineId2 = 'mock-execution-id2';

export const mockExecution = {
    id: machineId,
    state: `{
            "actions":[{"type":"entry"}],
            "activities":{},
            "meta":{},
            "events":[],
            "value":"pause",
            "context":{
                "status":0,
                "requestId":"test",
                "stack":["sendEmail|2"],
                "sendEmail|2": {
                    "message": "Test message",
                    "channelId": "test-channel"
                }
            },
            "_event":{
                "name":"xstate.init",
                "data":{"type":"xstate.init"},
                "$$type":"scxml",
                "type":"external"
            },
            "_sessionid":"x:1",
            "event":{"type":"xstate.init"},
            "children":{},
            "done":false,
            "tags":[]
        }`,
    machine: `[
            {
                "id": "sendEmail|2",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendSlackMessage|3"
                    },
                    {
                        "on": "pause",
                        "target": "pause"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendSlackMessage|3",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendEmail|4"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendEmail|4",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "success"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "success",
                "type": "final"
            },
            {
                "id": "failure",
                "type": "final"
            }
        ]`
};

const date = new Date();
// get tomorrow
date.setDate(date.getDate() + 1);
const dayName = date.toLocaleDateString('en-US', { weekday: 'long' });

// this is the second state in the machine
export const mockExecution2 = {
    id: machineId2,
    state: `{
    "actions": [
        {
            "type": "entry"
        }
    ],
    "activities": {},
    "meta": {},
    "events": [],
    "value": "success",
    "context": {
        "requestId": "2117368a-3119-44dd-878b-d9ff886ae7f5",
        "status": 0,
        "childToParentStateMap": {},
        "machineExecutionId": "2618bc50-d865-4aaf-8625-a05eb608e4e3",
        "solution": "1. **Get available times for meeting attendees** - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Proposed date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour    If all attendees are not available, resolve unavailable attendees  2. **Schedule a meeting** - Subject: Meeting with Dorian and Connor. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour",
        "stack": [
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
            "success"
        ],
        "stateId": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
        "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
            "times": [
                {
                    "start": "2025-08-04T16:30:00.000Z",
                    "end": "2025-08-04T17:30:00.000Z",
                    "availableAttendees": [
                        "dsmiley@codestrap.me",
                        "connor.deeks@codestrap.me"
                    ],
                    "unavailableAttendees": []
                }
            ],
            "subject": "Meeting with Dorian and Connor",
            "durationInMinutes": 60,
            "allAvailable": true,
            "agenda": "Found 1 optimal time slots."
        },
        "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42": {
            "emailId": "1984e2ae93f40a57",
            "message": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
            "meetingSubject": "Meeting with Dorian and Connor.",
            "meetingDuration": 60,
            "dayTimes": "                  start: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         end: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
            "modelDialog": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
            "ts": 1753658092064,
            "resolution": "${dayName} at 4",
            "processEmail": true
        },
        "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533": {
            "id": "pccjsddgde4kjalihqb6pnsohs",
            "htmlLink": "https://www.google.com/calendar/event?eid=cGNjanNkZGdkZTRramFsaWhxYjZwbnNvaHMgdmljaUBjb2Rlc3RyYXAubWU",
            "status": "confirmed"
        },
        "success": {
            "resolution": "${dayName} at 4",
            "processEmail": true
        }
    },
    "_event": {
        "name": "CONTINUE",
        "data": {
            "type": "CONTINUE",
            "payload": {
                "stateId": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
                "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533": {
                    "id": "pccjsddgde4kjalihqb6pnsohs",
                    "htmlLink": "https://www.google.com/calendar/event?eid=cGNjanNkZGdkZTRramFsaWhxYjZwbnNvaHMgdmljaUBjb2Rlc3RyYXAubWU",
                    "status": "confirmed"
                }
            }
        },
        "$$type": "scxml",
        "type": "external"
    },
    "_sessionid": "x:9",
    "event": {
        "type": "CONTINUE",
        "payload": {
            "stateId": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
            "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533": {
                "id": "pccjsddgde4kjalihqb6pnsohs",
                "htmlLink": "https://www.google.com/calendar/event?eid=cGNjanNkZGdkZTRramFsaWhxYjZwbnNvaHMgdmljaUBjb2Rlc3RyYXAubWU",
                "status": "confirmed"
            }
        }
    },
    "historyValue": {
        "current": "success",
        "states": {}
    },
    "history": {
        "actions": [
            {
                "type": "entry"
            }
        ],
        "activities": {},
        "meta": {},
        "events": [],
        "value": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
        "context": {
            "requestId": "2117368a-3119-44dd-878b-d9ff886ae7f5",
            "status": 0,
            "childToParentStateMap": {},
            "machineExecutionId": "2618bc50-d865-4aaf-8625-a05eb608e4e3",
            "solution": "1. **Get available times for meeting attendees** - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Proposed date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour    If all attendees are not available, resolve unavailable attendees  2. **Schedule a meeting** - Subject: Meeting with Dorian and Connor. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me>    Date: 2025-7-25    Start Time: 3:00 PM    Duration: 1 hour",
            "stack": [
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
                "success"
            ],
            "stateId": "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
            "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
                "times": [
                    {
                        "start": "2025-08-04T16:30:00.000Z",
                        "end": "2025-08-04T17:30:00.000Z",
                        "availableAttendees": [
                            "dsmiley@codestrap.me",
                            "connor.deeks@codestrap.me"
                        ],
                        "unavailableAttendees": []
                    }
                ],
                "subject": "Meeting with Dorian and Connor",
                "durationInMinutes": 60,
                "allAvailable": true,
                "agenda": "Found 1 optimal time slots."
            },
            "resolveUnavailableAttendees|c47a4244-979e-4090-a325-89447368fd42": {
                "emailId": "1984e2ae93f40a57",
                "message": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
                "meetingSubject": "Meeting with Dorian and Connor.",
                "meetingDuration": 60,
                "dayTimes": "                  start: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         end: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
                "modelDialog": "Hi Dorian and Connor, Happy Sunday! I'm having trouble finding an available day/time that works for the both of you for our meeting about task list items 1 and 2. I have the following time as available but it looks like both of you are unavailable: Tue Jul 29 2025 10:00:00 GMT-0700 (Pacific Daylight Time). Please respond to this message with a proposed day/time that works. If you can move any existing meetings around to make the unavailable time work, that would be preferred. Thanks, Vickie.",
                "ts": 1753658092064,
                "resolution": "${dayName} at 4",
                "processEmail": true
            }
        },
        "_event": {
            "name": "CONTINUE",
            "data": {
                "type": "CONTINUE",
                "payload": {
                    "stateId": "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                    "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
                        "times": [
                            {
                                "start": "2025-08-04T16:30:00.000Z",
                                "end": "2025-08-04T17:30:00.000Z",
                                "availableAttendees": [
                                    "dsmiley@codestrap.me",
                                    "connor.deeks@codestrap.me"
                                ],
                                "unavailableAttendees": []
                            }
                        ],
                        "subject": "Meeting with Dorian and Connor",
                        "durationInMinutes": 60,
                        "allAvailable": true,
                        "agenda": "Found 1 optimal time slots."
                    }
                }
            },
            "$$type": "scxml",
            "type": "external"
        },
        "_sessionid": "x:1",
        "event": {
            "type": "CONTINUE",
            "payload": {
                "stateId": "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152",
                "getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152": {
                    "times": [
                        {
                            "start": "2025-08-04T16:30:00.000Z",
                            "end": "2025-08-04T17:30:00.000Z",
                            "availableAttendees": [
                                "dsmiley@codestrap.me",
                                "connor.deeks@codestrap.me"
                            ],
                            "unavailableAttendees": []
                        }
                    ],
                    "subject": "Meeting with Dorian and Connor",
                    "durationInMinutes": 60,
                    "allAvailable": true,
                    "agenda": "Found 1 optimal time slots."
                }
            }
        },
        "historyValue": {
            "current": "scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533",
            "states": {}
        },
        "children": {},
        "done": false,
        "changed": true,
        "tags": []
    },
    "children": {},
    "done": true,
    "tags": []
}`,
    machine: `
        [
            {
                "id": "sendEmail",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendSlackMessage"
                    },
                    {
                        "on": "pause",
                        "target": "pause"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendSlackMessage",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "getAvailableMeetingTimes"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "getAvailableMeetingTimes",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "scheduleMeeting"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "scheduleMeeting",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendEmail"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendEmail",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "success"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "success",
                "type": "final"
            },
            {
                "id": "failure",
                "type": "final"
            }
        ]
        `
};

export const mockModifyFetchResponse = {
    validation: {
        result: "VALID",
        submissionCriteria: [],
        parameters: {}
    },
    edits: {
        type: "edits",
        edits: [
            {
                type: "modifyObject",
                primaryKey: "310e5c75-9ccf-4b01-8d0b-f4bf9bf6667e",
                objectType: "MachineExecutions"
            }
        ],
        addedObjectCount: 0,
        modifiedObjectsCount: 1,
        deletedObjectsCount: 0,
        addedLinksCount: 0,
        deletedLinksCount: 0
    }
};

export const mockModifyApiResponse = (): Response =>
({
    ok: true,
    status: 200,
    statusText: "OK",
    headers: {},
    json: () => Promise.resolve(mockModifyFetchResponse)
} as Response);

export const text2ActionTestMachineExecution = {
    machine: `
        [
            {
                "id": "sendEmail|1",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "sendEmail|5"
                    },
                    {
                        "on": "pause",
                        "target": "pause"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "sendEmail|5",
                "transitions": [
                    {
                        "on": "CONTINUE",
                        "target": "success"
                    },
                    {
                        "on": "ERROR",
                        "target": "failure"
                    }
                ]
            },
            {
                "id": "success",
                "type": "final"
            },
            {
                "id": "failure",
                "type": "final"
            }
        ]
        `,
    state: `{"actions":[{"type":"entry"}],"activities":{},"meta":{},"events":[],"value":"sendEmail|1","context":{"status":0,"requestId":"test","stack":["sendEmail|1"], "sendEmail|1": {"message": "test", "subject": "test subject", "recipients": ["test@example.com"],"modelDialog": "sample dialog", "ts": "1234567890"}},"_event":{"name":"xstate.init","data":{"type":"xstate.init"},"$$type":"scxml","type":"external"},"_sessionid":"x:1","event":{"type":"xstate.init"},"children":{},"done":false,"tags":[]}`,
};

export const mockProcessEmailEventExecution = {
    id: 'f41b004c-c032-4f3a-b7b8-be831804cb03',
    currentState: 'pause',
    logs: '',
    state: `
    {
    "actions": [],
    "activities": {},
    "meta": {},
    "events": [],
    "value": "pause",
    "context": {
        "requestId": "5eea54ea-0f14-4afa-9f89-7b2913fa8e54",
        "status": 0,
        "childToParentStateMap": {},
        "machineExecutionId": "f41b004c-c032-4f3a-b7b8-be831804cb03",
        "solution": "Get available times for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM nIf all attendees are not available, resolve unavailable attendees nSchedule a meeting - Subject: Meeting with Dorian Smiley and Connor Deeks. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nStart Time: 2:00 PM nEnd Time: 3:00 PM nRead Emails - Read emails for Dorian Smiley <dsmiley@codestrap.me> from the last 15 minutes",
        "stack": [
            "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
            "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1"
        ],
        "stateId": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
        "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
            "times": [
                {
                    "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                    "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                    "availableAttendees": [],
                    "unavailableAttendees": [
                        "dsmiley@codestrap.me",
                        "connor.deeks@codestrap.me"
                    ]
                }
            ],
            "subject": "Meeting with Dorian Smiley and Connor Deeks.",
            "durationInMinutes": 60,
            "allAvailable": false
        },
        "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1": {
            "emailId": "1981ab81fe57c933",
            "message": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
            "meetingSubject": "Meeting with Dorian Smiley and Connor Deeks.",
            "meetingDuration": 60,
            "dayTimes": "                  start: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         end: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
            "modelDialog": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
            "ts": 1752794931444
        }
    },
    "_event": {
        "name": "pause",
        "data": {
            "type": "pause",
            "payload": {
                "stateId": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
                "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1": {
                    "emailId": "1981ab81fe57c933",
                    "message": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                    "meetingSubject": "Meeting with Dorian Smiley and Connor Deeks.",
                    "meetingDuration": 60,
                    "dayTimes": "                  start: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         end: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
                    "modelDialog": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                    "ts": 1752794931444
                }
            }
        },
        "$$type": "scxml",
        "type": "external"
    },
    "_sessionid": "x:7",
    "event": {
        "type": "pause",
        "payload": {
            "stateId": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
            "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1": {
                "emailId": "1981ab81fe57c933",
                "message": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                "meetingSubject": "Meeting with Dorian Smiley and Connor Deeks.",
                "meetingDuration": 60,
                "dayTimes": "                  start: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         end: Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time),         available: ,         unavailable: dsmiley@codestrap.me, connor.deeks@codestrap.me         ",
                "modelDialog": "Hey Dorian and Connor  nHappy Thursday! I'm Vickie, Code's AI EA. I'm having trouble scheduling a meeting for you both on July 18, 2025, between 2:00 PM and 3:00 PM. It looks like neither of you are available at that time.  nCould you please let me know if there's any chance you could move things around to make that time work? Knowing whether that slot is flexible would really help in finding a suitable time.  nThanks!  nBest nVickie",
                "ts": 1752794931444
            }
        }
    },
    "historyValue": {
        "current": "pause",
        "states": {}
    },
    "history": {
        "actions": [
            {
                "type": "entry"
            }
        ],
        "activities": {},
        "meta": {},
        "events": [],
        "value": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
        "context": {
            "requestId": "5eea54ea-0f14-4afa-9f89-7b2913fa8e54",
            "status": 0,
            "childToParentStateMap": {},
            "machineExecutionId": "f41b004c-c032-4f3a-b7b8-be831804cb03",
            "solution": "Get available times for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM nIf all attendees are not available, resolve unavailable attendees nSchedule a meeting - Subject: Meeting with Dorian Smiley and Connor Deeks. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nStart Time: 2:00 PM nEnd Time: 3:00 PM nRead Emails - Read emails for Dorian Smiley <dsmiley@codestrap.me> from the last 15 minutes",
            "stack": [
                "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
                "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1"
            ],
            "stateId": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
            "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
                "times": [
                    {
                        "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                        "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                        "availableAttendees": [],
                        "unavailableAttendees": [
                            "dsmiley@codestrap.me",
                            "connor.deeks@codestrap.me"
                        ]
                    }
                ],
                "subject": "Meeting with Dorian Smiley and Connor Deeks.",
                "durationInMinutes": 60,
                "allAvailable": false
            }
        },
        "_event": {
            "name": "CONTINUE",
            "data": {
                "type": "CONTINUE",
                "payload": {
                    "stateId": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
                    "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
                        "times": [
                            {
                                "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                                "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                                "availableAttendees": [],
                                "unavailableAttendees": [
                                    "dsmiley@codestrap.me",
                                    "connor.deeks@codestrap.me"
                                ]
                            }
                        ],
                        "subject": "Meeting with Dorian Smiley and Connor Deeks.",
                        "durationInMinutes": 60,
                        "allAvailable": false
                    }
                }
            },
            "$$type": "scxml",
            "type": "external"
        },
        "_sessionid": "x:7",
        "event": {
            "type": "CONTINUE",
            "payload": {
                "stateId": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
                "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67": {
                    "times": [
                        {
                            "start": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                            "end": "Fri Jul 18 2025 14:00:00 GMT-0700 (Pacific Daylight Time)",
                            "availableAttendees": [],
                            "unavailableAttendees": [
                                "dsmiley@codestrap.me",
                                "connor.deeks@codestrap.me"
                            ]
                        }
                    ],
                    "subject": "Meeting with Dorian Smiley and Connor Deeks.",
                    "durationInMinutes": 60,
                    "allAvailable": false
                }
            }
        },
        "historyValue": {
            "current": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
            "states": {}
        },
        "children": {},
        "done": false,
        "changed": true,
        "tags": []
    },
    "children": {},
    "done": true,
    "changed": true,
    "tags": []
}
    `,
    machine: `
    [
    {
        "id": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67",
        "task": "Get available times for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM",
        "includesLogic": true,
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "scheduleMeeting|ddb8ee4f-72a2-4198-8547-06816fa0de77"
            },
            {
                "on": "CONTINUE",
                "target": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "resolveUnavailableAttendees|ee6a31dc-48d2-4cd9-9481-fafc8b2635c1",
        "task": "Resolve meeting conflicts for meeting attendees - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nProposed date: 2025-07-18 nStart Time: 2:00 PM nEnd Time: 3:00 PM. If an agreed upon time has been reached target the find available times state. Do not continue or target schedule meeting!",
        "includesLogic": true,
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "scheduleMeeting|ddb8ee4f-72a2-4198-8547-06816fa0de77"
            },
            {
                "on": "CONTINUE",
                "target": "getAvailableMeetingTimes|cdd45abd-d759-4b8f-9341-a8852d8dde67"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "scheduleMeeting|ddb8ee4f-72a2-4198-8547-06816fa0de77",
        "task": "Schedule a meeting - Subject: Meeting with Dorian Smiley and Connor Deeks. - Attendees: Dorian Smiley <dsmiley@codestrap.me>, Connor Deeks <connor.deeks@codestrap.me> nStart Time: 2:00 PM nEnd Time: 3:00 PM",
        "includesLogic": false,
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "readEmails|d0b61e3d-9603-429d-9e3b-f1b614b19c0e"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "readEmails|d0b61e3d-9603-429d-9e3b-f1b614b19c0e",
        "task": "Read Emails - Read emails for Dorian Smiley <dsmiley@codestrap.me> from the last 15 minutes",
        "transitions": [
            {
                "on": "CONTINUE",
                "target": "success"
            },
            {
                "on": "ERROR",
                "target": "failure"
            }
        ]
    },
    {
        "id": "success",
        "type": "final"
    },
    {
        "id": "failure",
        "type": "final"
    }
]
    `};
````

## File: packages/x-reason/src/lib/__fixtures__/Programmer.ts
````typescript
import {
  StateConfig,
  Context,
  MachineEvent,
  Task,
} from '@codestrap/developer-foundations-types';

export const stateConfigArray: StateConfig[] = [
  {
    id: 'RecallSolutions',
    transitions: [
      { on: 'CONTINUE', target: 'GenerateIngredientsList' },
      { on: 'ERROR', target: 'failure' },
    ],
  },
  {
    id: 'GenerateIngredientsList',
    transitions: [
      { on: 'CONTINUE', target: 'IngredientDatabase' },
      { on: 'ERROR', target: 'failure' },
    ],
  },
  {
    id: 'IngredientDatabase',
    transitions: [
      { on: 'CONTINUE', target: 'parallelChecks' },
      { on: 'ERROR', target: 'failure' },
    ],
  },
  {
    id: 'parallelChecks',
    type: 'parallel',
    states: [
      {
        id: 'RegulatoryCheck',
        transitions: [
          { on: 'CONTINUE', target: 'success' },
          { on: 'ERROR', target: 'failure' },
        ],
      },
      {
        id: 'ConcentrationEstimation',
        transitions: [
          { on: 'CONTINUE', target: 'success' },
          { on: 'ERROR', target: 'failure' },
        ],
      },
    ],
    onDone: 'FormulationSimulation',
  },
  {
    id: 'FormulationSimulation',
    transitions: [
      { on: 'CONTINUE', target: 'success' },
      { on: 'ERROR', target: 'failure' },
    ],
  },
  {
    id: 'success',
    type: 'final',
  },
  {
    id: 'failure',
    type: 'final',
  },
];

export const stateConfigResolvePastStates = JSON.parse(`[
  {
    "id": "getAvailableMeetingTimes",
    "task": "Get available times for meeting attendees - Attendees: Connor Deeks <connor.deeks@codestrap.me>, Dorian Smiley <dsmiley@codestrap.me>. Proposed date: 2025-07-25 at 3pm PDT. Duration: 1 hour. If all attendees are not available, resolve unavailable attendees.",
    "includesLogic": true,
    "transitions": [
      {
        "on": "CONTINUE",
        "target": "scheduleMeeting"
      },
      {
        "on": "CONTINUE",
        "target": "resolveUnavailableAttendees"
      },
      {
        "on": "ERROR",
        "target": "failure"
      }
    ]
  },
  {
    "id": "resolveUnavailableAttendees",
    "task": "Resolve unavailable attendees for the meeting - Attendees: Connor Deeks <connor.deeks@codestrap.me>, Dorian Smiley <dsmiley@codestrap.me>. If an agreed upon time has been reached target the get available meeting times state. Else target the pause state.",
    "includesLogic": true,
    "transitions": [
      {
        "on": "CONTINUE",
        "target": "getAvailableMeetingTimes"
      },
      {
        "on": "PAUSE",
        "target": "pause"
      },
      {
        "on": "ERROR",
        "target": "failure"
      }
    ]
  },
  {
    "id": "scheduleMeeting",
    "task": "Schedule a meeting - Subject: Discuss changes to Vicki - Attendees: Connor Deeks <connor.deeks@codestrap.me>, Dorian Smiley <dsmiley@codestrap.me>. Start time: 2025-07-25 at 3pm PDT. Duration: 1 hour.",
    "includesLogic": false,
    "transitions": [
      {
        "on": "CONTINUE",
        "target": "success"
      },
      {
        "on": "ERROR",
        "target": "failure"
      }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]`) as StateConfig[];

export function getFunctionCatalog(dispatch: (action: any) => void) {
  return new Map<string, Task>([
    [
      'readEmails',
      {
        description:
          'Retrieves the users email messages for a given time period.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('readEmails implementation in function catalog called');
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'researchReport',
      {
        description:
          'Creates a research report based on the users instructions.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'researchReport implementation in function catalog called'
          );
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'createTask',
      {
        description:
          'Creates task assigments in our ticketing system. This tool should never be used for follow up communication such as reminder messages, emails, project reports etc. This tool is used to assign a bug report, feature, research task, chore, etc.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('createTask implementation in function catalog called');
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'getAvailableMeetingTimes',
      {
        description:
          'Gets the available times for all required and optional meeting attendees',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'getAvailableMeetingTimes implementation in function catalog called'
          );
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'resolveUnavailableAttendees',
      {
        description:
          'Resolves unavailable attendees for meeting requests where not all attendees are available.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'resolveUnavailableAttendees implementation in function catalog called'
          );
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'scheduleMeeting',
      {
        description:
          'Schudules a meeting using the provided time at which all attendees are available.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('scheduleMeeting function catalog implementation called');
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'getProjectFiles',
      {
        description: 'Retrieves project files.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('getProjectFiles function catalog implementation called');
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'getProjectStatusReport',
      {
        description:
          'Retrieves a cull project status report including estimated completion date, task lists, and timeline.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'getProjectStatusReport function catalog implementation called'
          );
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'sendEmail',
      {
        description: 'Sends an email.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('sendEmail function catalog implementation called');
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'writeEmail',
      {
        description: 'Writes a draft email for review.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('writeEmail function catalog implementation called');
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'writeSlackMessage',
      {
        description: 'Writes a draft slack message for review.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'writeSlackMessage function catalog implementation called'
          );
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'sendSlackMessage',
      {
        description: 'Sends a Slack Message',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'sendSlackMessage function catalog implementation called'
          );
          dispatch({ type: 'CONTINUE' });
        },
      },
    ],
    [
      'UnsafeQuestion',
      {
        description: 'Default state to display for unsafe questions',
        implementation: (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('UnsafeQuestion implementation called');
          dispatch({ type: 'success' });
        },
      },
    ],
    [
      'UnsupportedQuestion',
      {
        description: 'Default state to display for unsupported questions',
        implementation: (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('UnsupportedQuestion implementation called');
          dispatch({ type: 'success' });
        },
      },
    ],
  ]);
}
````

## File: packages/x-reason/src/lib/factory/index.ts
````typescript
export {
  default as xReasonFactory,
  SupportedEngines,
  SupportTrainingDataTypes,
} from './XreasonFactory';
export type { XReasonEngine } from './XreasonFactory';
````

## File: packages/x-reason/src/lib/factory/XreasonFactory.test.ts
````typescript
import { default as factory, SupportedEngines } from './XreasonFactory';
import {
  comsProgrammer,
  comsAiTrasition,
  comsEvaluate,
  comsFunctionCatalog,
  comsSolver,
  contextAiTrasition,
  contextEvaluate,
  contextFunctionCatalog,
  contextProgrammer,
  contextSolver,
  salesProgrammer,
  salesAiTrasition,
  salesEvaluate,
  salesFunctionCatalog,
  salesSolver,
} from '../reasoning';

describe('Factory Function Tests', () => {
  it("should return the correct engine implementation for 'coms'", () => {
    const engine = factory(SupportedEngines.COMS)({});

    // Validate the structure of the returned object
    expect(engine).toHaveProperty('programmer', comsProgrammer);
    expect(engine).toHaveProperty('aiTransition', comsAiTrasition);
    expect(engine).toHaveProperty('evaluate', comsEvaluate);
    expect(engine).toHaveProperty('functionCatalog', comsFunctionCatalog);
    expect(engine).toHaveProperty('solver', comsSolver);
  });

  it("should return the correct engine implementation for 'context'", () => {
    const engine = factory(SupportedEngines.CONTEXT)({});

    // Validate the structure of the returned object
    expect(engine).toHaveProperty('programmer', contextProgrammer);
    expect(engine).toHaveProperty('aiTransition', contextAiTrasition);
    expect(engine).toHaveProperty('evaluate', contextEvaluate);
    expect(engine).toHaveProperty('functionCatalog', contextFunctionCatalog);
    expect(engine).toHaveProperty('solver', contextSolver);
  });

  it("should return the correct engine implementation for 'sales'", () => {
    const engine = factory(SupportedEngines.SALES)({});

    // Validate the structure of the returned object
    expect(engine).toHaveProperty('programmer', salesProgrammer);
    expect(engine).toHaveProperty('aiTransition', salesAiTrasition);
    expect(engine).toHaveProperty('evaluate', salesEvaluate);
    expect(engine).toHaveProperty('functionCatalog', salesFunctionCatalog);
    expect(engine).toHaveProperty('solver', salesSolver);
  });

  it('should throw an error if an unsupported engine is provided', () => {
    const invalidKey = 'invalid_engine' as SupportedEngines;

    // Wrap the call in a function to test errors
    expect(() => factory(invalidKey)({})).toThrowError();
  });
});
````

## File: packages/x-reason/src/lib/factory/XreasonFactory.ts
````typescript
import { curry } from 'ramda';

import {
  comsProgrammer,
  comsAiTrasition,
  comsEvaluate,
  comsFunctionCatalog,
  comsSolver,
  contextAiTrasition,
  contextEvaluate,
  contextFunctionCatalog,
  contextProgrammer,
  contextSolver,
  salesProgrammer,
  salesAiTrasition,
  salesEvaluate,
  salesFunctionCatalog,
  salesSolver,
} from '../reasoning';

// Define the shape of the clients map
export type XReasonEngine = (config: Record<string, any>) => {
  programmer: typeof comsProgrammer;
  aiTransition: typeof comsAiTrasition;
  evaluate: typeof comsEvaluate;
  functionCatalog: typeof comsFunctionCatalog;
  solver: typeof comsSolver;
};

export enum SupportedEngines {
  COMS = 'coms',
  CONTEXT = 'context',
  SALES = 'sales',
}

export enum SupportTrainingDataTypes {
  SOLVER = 'solver',
  PROGRAMMER = 'programmer',
}

// in your factor injectionb factory
const factory = curry((map, key, config) => {
  const supportedKeys = Object.keys(SupportedEngines).map((item) =>
    item.toLowerCase()
  );

  if (!supportedKeys.includes(key)) {
    throw new Error('unsupported key ${key}');
  }

  return map[key](config);
});

// in your config
const clients = {
  coms: (config: Record<string, any>) => {
    console.log(`config for comms xreason is: ${config}`);

    return {
      programmer: comsProgrammer,
      aiTransition: comsAiTrasition,
      evaluate: comsEvaluate,
      functionCatalog: comsFunctionCatalog,
      solver: comsSolver,
    };
  },
  context: (config: Record<string, any>) => {
    console.log(`config for context xreason is: ${config}`);

    return {
      programmer: contextProgrammer,
      aiTransition: contextAiTrasition,
      evaluate: contextEvaluate,
      functionCatalog: contextFunctionCatalog,
      solver: contextSolver,
    };
  },
  sales: (config: Record<string, any>) => {
    console.log(`config for sales xreason is: ${config}`);

    return {
      programmer: salesProgrammer,
      aiTransition: salesAiTrasition,
      evaluate: salesEvaluate,
      functionCatalog: salesFunctionCatalog,
      solver: salesSolver,
    };
  },
  // TODO add more implementations
};

export default factory(clients) as (key: SupportedEngines) => XReasonEngine;
````

## File: packages/x-reason/src/lib/functions/comsFunctions/CreateTask.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import {
  extractJsonFromBackticks,
  uuidv4,
} from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';
import {
  GeminiService,
  TicketsDao,
  TYPES,
} from '@codestrap/developer-foundations-types';

enum Users {
  Connor_Deeks = '147c63f3-69c1-4576-88a2-49e2cb6421c7',
  Dorian_Smiley = 'cadf16c6-76c8-4ff2-8716-889f8797d547',
}

// TODO finish this type
export type TaskDetails = {
  id: string;
  description: string;
  status: 'Open' | 'In Progress' | 'Resolved';
  assignee: Users;
  taskType: 'Task' | 'Bug' | 'Chore';
  severity: 'Critical' | 'High' | 'Low';
  title: string;
  points: 1 | 2 | 3 | 5;
};

export async function createTask(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<TaskDetails> {
  const system = `You are a helpful virtual project manager in charge of task creation and assignments.
    You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Viki, Code's AI EA" or similar. 
    You can get creative on your greeting, taking into account the day of the week. Today is ${new Date().toLocaleDateString(
    'en-US',
    { weekday: 'long' }
  )}. 
    You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
    The current month is ${new Date().toLocaleDateString('en-US', {
    month: 'long',
  })}. 
    When creating a task you always create a task title, description, and point estimation.
    You also careful decide on the severity based on the ask from the end user.`;

  const user = `
    Using the ask from the end user below create a ticket. You must:
    1. Create a title
    2. Create descirption
    3. Determine the points which can be 1,2,3 or 5 based on the time and complexity which you must estimate
    4. The ticket type which cab be either Task, Bug, or Chore
    5. Determine who to assign the ticket to. To determine who to assign the ticket to use this following information:

    Connor_Deeks - Connor Deeks in the CEO and board memeber in charge of platform leads, business strategy, and investor relations.
    Dorian_Smiley - Dorian is the CTO who manages the software engineers and is responsible for technology strategy, execution, and the lead applied AI engineer.

    If the task explicitly contains a name pick the most likely person from the list above based on the supplied name and role. 
    Otherwise just pick the most likely person based on role.

    The ask from the end user:
    ${task}

    You can only respond in JSON in the following format:
    {
        description: string,
        assignee: string,
        taskType: "Task" | "Bug" | "Chore",
        // Critical is reserved for system outages, customer service issues, legal, or tax problems
        // High is reserved for achieving a business outcome
        // low is for everything else
        severity: "Critical" | "High" | "Low",
        title: string,
        points: 1 | 2 | 3 | 5,
    }

    For example if the ask from the user is:
    "Dorian needs to figure out how we are going to apply DSpy to help automate prompt and model alignment"
    
    An accetable response is:
    {
        "description": "Hello Dorian, Viki here. Can you please explore how we can apply DSpy to help automate prompt and model alignment.",
        "assignee": "Dorian_Smiley",
        "taskType": "Task",
        "severity": "Low",
        "title": "Research DSpy",
        "points": 3,
    }

    If you know additional information that might be helpful context for the task based on your training data you can include it.
    Some additional context that might be helpful:
    Our tech stack is built on Palantir Foundry
    Our primary programming languages are TypeSrript, React, Javascript, Node, and Python. 
    We use Python for data science and data engineering. We use TypeScript, React, and Node for applications
    We are an AI services startup that specializes in delivers consulting services as software products.
    Sometimes we like to joke around so if someone takes vacation and leaves us doing a bunch of work will
    might ask you to "mess with so and so" by assinging them a mountain of work. Something really hard like engineer a new transformer architecture
    with a bunch of research work. You can have when the ask is prefixed with "mess with", "fuck with", etc. It is innosent fun. Just be sure to say just kidding at the end.
    `;

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);

  const response = await geminiService(user, system);

  const clean = extractJsonFromBackticks(response);

  const parsedResult = JSON.parse(clean);
  // TODO handle retried if we fail to parse the result

  const description = parsedResult.description;
  // eslint-disable-next-line @typescript-eslint/ban-ts-comment
  // @ts-expect-error
  const assignee = Users[parsedResult.assignee];
  const taskType = parsedResult.taskType;
  const severity = parsedResult.severity;
  const title = parsedResult.title;
  const points = parsedResult.points;

  const ticketDoa = container.get<TicketsDao>(TYPES.TicketDao);
  const upsertResult = await ticketDoa.upsert(
    uuidv4(),
    title,
    taskType,
    description,
    severity,
    'Open',
    points,
    assignee
  );

  const parameters: TaskDetails = {
    id: upsertResult.alertId,
    status: upsertResult.status as 'Open' | 'In Progress' | 'Resolved',
    title,
    description,
    assignee,
    taskType,
    severity,
    points,
  };

  return parameters;
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/GetAvailableMeetingTimes.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import {
    extractJsonFromBackticks,
} from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';
import {
    GeminiService,
    ProposedTimes,
    TYPES,
    MeetingRequest,
    OfficeService,
} from '@codestrap/developer-foundations-types';
import { DraftAtendeeEmailResponse } from './ResolveUnavailableAttendees';


// This function gets the attendees from the input context and then
// uses Google Calendar APIs to find available meeting times for anyone with a codestrap.me (we should make the home domain configurable) email address
// For external emails it will send an email asking for available time slots if it can not find them on the input context
// The calling function in the function catalog will then determine whether or not to pause machine execution waiting for a response of continue forward
export async function getAvailableMeetingTimes(context: Context, event?: MachineEvent, task?: string): Promise<ProposedTimes> {
    try {
        const options = {
            timeZone: "America/Los_Angeles",
            timeZoneName: "short" // This will produce "PST" or "PDT"
        };
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        //@ts-expect-error
        const formatter = new Intl.DateTimeFormat("en-US", options);
        const formatted = formatter.format(new Date());

        console.log(`formatted int date: ${formatted}`);
        const isPDT = formatted.includes("PDT");

        const getAvailableStateId = context.stack?.slice().reverse().find(item => item.includes('getAvailableMeetingTimes'));
        // find the last instance of a resolveUnavailableAttendees state in the stack
        const resolveStateId = context.stack?.slice().reverse().find(item => item.includes('resolveUnavailableAttendees'));

        const { resolution } = resolveStateId && context[resolveStateId] ? context[resolveStateId] as DraftAtendeeEmailResponse : { resolution: undefined };
        const { allAvailable } = getAvailableStateId && context[getAvailableStateId] ? context[getAvailableStateId] as ProposedTimes : { allAvailable: false };
        let resolutionClause = '';
        if (!allAvailable && resolution) {
            resolutionClause = `# Conflict Resolution
All the attendees were previously not available at the proposed time.
The resolution for the conflict that has been agreed upon by al parties is: ${resolution}. 
Update the meeting time to use this resolution. Output local date string in Pacific Time. 
The current day/time in Pacific Time is: ${new Date().toString()}
PDT in effect (indicated if Pacific Daylight Time is in effect): ${isPDT}`;
        }
        // we are all on the west coast so we hard code our time zone for now
        const system = `You are a helpful virtual assistant tasked with meeting scheduling.
    You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Vickie, Code's AI EA" or similar. 
    You can get creative on your greeting, taking into account the day of the week. Today is ${new Date().toLocaleDateString('en-US', { weekday: 'long' })}. 
    You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
    The current local date/time is ${new Date().toLocaleString("en-US", { timeZone: "America/Los_Angeles" })}. 
    When scheduling meetings you always extract the key details from the input task.`;

        const user = `
# Task
Using the meeting request from the end user extract the key details. You must extract:
1. The participants
2. the meeting subject
3. The meeting duration
4. The time frame
5. The local date string for the proposed day/time if any

# The meeting request from the end user is:
${task}

${resolutionClause}

The complete task list which may contain additional information about the meeting such as the subject or agenda:
${context.solution}

Let's take this step by step.
1. First determine if any people mentioned in the input task most likely match the people below. If so return the matching participant(s) in the participant array
Connor Deeks <connor.deeks@codestrap.me> - Connor Deeks in the CEO and board member in charge of platform leads, business strategy, and investor relations.
Dorian Smiley <dsmiley@codestrap.me> - Dorian is the CTO who manages the software engineers and is responsible for technology strategy, execution, and the lead applied AI engineer.
2. Insert any explicit email addresses into the participants array
3. Extract the meting subject based on the meeting request from the end user. Most meeting requests from the ens user include Subject: THE_MEETING_SUBJECT
4. If the meeting request from the end user does not contain a subject, use the provided complete task list to extract it. 
If not subject can be extracted for this meeting request use "Circle Up"
5. Extract the meeting duration in minutes. If the duration can not be inferred return 30.
6. Determine the time frame as one of the following: "user defined exact date/time", "as soon as possible", "this week", or "next week". If the user specifies "today" without an exact time use "as soon as possible". If the user did not specify a timeframe you must use "as soon as possible".
        6.5 If the user specifies a date 2025-04-11 without a time use 9 AM Pacific Time "Fri Apr 11 2025 09:00:00 GMT-0700 (Pacific Daylight Time)"
7. If the time frame is "user defined exact date/time" output local date string in Pacific Time.
The current day/time in Pacific Time is: ${new Date().toString()}
PDT in effect (indicated if Pacific Daylight Time is in effect): ${isPDT}

You can only respond in JSON in the following format:
{
    participants: Array<string>;
    subject: string;
    timeframe_context: 'user defined exact date/time' | 'as soon as possible' | 'this week' | 'next week';
    localDateString: string,
    duration_minutes: number;
}

For example:
If the ask from the user is:
"Schedule a meeting with Connor and Dorian for next week to discuss new Palantir features from DevCon"

Your response is:
{
    "participants:" ["dsmiley@codestrap.me", "connor.deeks@codestrap.me"],
    "subject": "DevCon Feature Recap",
    "timeframe_context": "next week",
    "duration_minutes": 30;
}

If the ask from the user is:
"Schedule a meeting with Connor, Dorian, and keith@eriestreet.com to discuss investment ask"

Your response is:
{
    "participants": ["connor.deeks@codestrap.me", "dsmiley@codestrap.me", "keith@eriestreet.com"],
    "subject": "Investment Ask",
    "timeframe_context": "as soon as possible",
    "duration_minutes": 30;
}

"Schedule a meeting for today with Connor, Dorian, and keith@eriestreet.com to discuss investment ask"

Your response is:
{
    "participants": ["connor.deeks@codestrap.me", "dsmiley@codestrap.me", "keith@eriestreet.com"],
    "subject": "Investment Ask",
    "timeframe_context": "as soon as possible",
    "duration_minutes": 30;
}

Note a request for a meeting today translates to "as soon as possible" not an exact day time! This will automatically include time slots for today.

If the ask from the user is (assuming the current local day/time in your time zone is 'Tue Apr 08 2025 08:26:19 GMT-0700 (Pacific Daylight Time))':
"Schedule a meeting with Connor and Dorian to discuss to internal projects this Friday at 9 AM MT for 1 hour"

Your response is:
{
    "participants": ["connor.deeks@codestrap.me", "dsmiley@codestrap.me"],
    "subject": "Internal Projects",
    "timeframe_context": "user defined exact date/time",
    "localDateString": "Fri Apr 11 2025 09:00:00 GMT-0600 (Mountain Daylight Time)"
    "duration_minutes": 60;
}
`;

        const geminiService = container.get<GeminiService>(TYPES.GeminiService);

        const response = await geminiService(user, system);

        const clean = extractJsonFromBackticks(response);

        const parsedResult = JSON.parse(clean) as MeetingRequest;
        console.log(`the model returned the following meeting time proposal:\n${clean}`);
        const timeFrame = (parsedResult.timeframe_context === 'user defined exact date/time') ? parsedResult.localDateString! : parsedResult.timeframe_context;
        const participants = Array.from(new Set(parsedResult.participants));
        //remove external email addresses since we can't check them
        const codeStrapParticipants = participants.filter(participant => participant.indexOf('codestrap.me') >= 0 || participant.indexOf('codestrap.com') >= 0);
        const inputs = {
            participants: codeStrapParticipants,
            localDateString: timeFrame,
            timeframe_context: parsedResult.timeframe_context,
            subject: parsedResult.subject,
            duration_minutes: parsedResult.duration_minutes,
            working_hours: {
                start_hour: 8,
                end_hour: 17,
            },
            timezone: "America/Los_Angeles", // hard code for now, should be the organizer's time zone
        } as MeetingRequest;



        const officeService = await container.getAsync<OfficeService>(TYPES.OfficeService);

        let availableTimes = await officeService.getAvailableMeetingTimes(inputs);

        // no times found, retry when the user has not specified a time frame
        if (availableTimes.suggested_times.length === 0 && inputs.timeframe_context === 'as soon as possible') {
            // first try this week, then next week
            inputs.timeframe_context = 'this week';
            availableTimes = await officeService.getAvailableMeetingTimes(inputs);
            if (availableTimes.suggested_times.length === 0) {
                inputs.timeframe_context = 'next week';
                availableTimes = await officeService.getAvailableMeetingTimes(inputs);
            }
        }

        // still nothing, return allAvailable false to resolve manually
        if (availableTimes.suggested_times.length === 0) {
            return {
                times: [
                    {
                        start: timeFrame,
                        end: timeFrame,
                        availableAttendees: [],
                        unavailableAttendees: participants,
                    }
                ],
                subject: parsedResult.subject,
                durationInMinutes: inputs.duration_minutes,
                allAvailable: false,
            }
        }
        // the array is presorted based on score, 
        // we return all the times for use cases there people want the explore the times themselves
        const times = availableTimes.suggested_times.map(time => ({
            start: time.start,
            end: time.end,
            availableAttendees: participants,
            unavailableAttendees: [],
        }));
        const message = availableTimes.message;

        const returnValue: ProposedTimes = {
            times, // Array of available time slots
            agenda: message,
            subject: parsedResult.subject, // Meeting subject or title
            durationInMinutes: inputs.duration_minutes, // Meeting duration in minutes
            allAvailable: true, // findOptimalMeetingTime will always find a timeslot currently since it does not allow you to specify an exact day/time yet
        }

        console.log('findOptimalMeetingTime response:', JSON.stringify(availableTimes));

        return returnValue;
    } catch (e) {
        console.log((e as Error).message);
        throw e;
    }
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/GetProjectFiles.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';

export type File = {
  kind: string;
  id: string;
  name: string;
  mimeType: string;
  modifiedDate: Date;
};

// This function will eventually retrieves the most recent versions of files from Google Drive using the input prompt and sends back as a list
// This is useful for sending emails and status reports where files need to be referenced
// For now it's just stubbed out
export async function getProjectFiles(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<File[]> {
  return new Promise((resolve) => {
    // TODO use LLM to extract the input parameters from the context.solution parameter
    // IE "construct the query parameter for Google Drive API find files ${context.solution}"
    setTimeout(() => {
      resolve([
        {
          kind: 'drive#file',
          id: '1234567890abcdef',
          name: 'important_document.pdf',
          mimeType: 'application/pdf',
          modifiedDate: new Date('2023-12-20T15:30:00Z'),
        },
      ]);
    }, 500);
  });
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/GetProjectStatusReport.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';

// TODO finish this type
export type ProjectStatusReport = {
  id: string;
  estimatedCompletionDate: Date;
  sprintsRemaining: number;
};

// This function will eventually work with our Foundry Native project management system
// For now it's just stubbed out
export async function getProjectStatusReport(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<ProjectStatusReport> {
  return new Promise((resolve) => {
    setTimeout(() => {
      resolve({
        id: '1234sdf',
        estimatedCompletionDate: new Date(),
        sprintsRemaining: 5,
      });
    }, 500);
  });
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/index.ts
````typescript
export * from './SendSlackMessage';
export * from './GetAvailableMeetingTimes';
export * from './ScheduleMeeting';
export * from './SendEmail';
export * from './GetProjectFiles';
export * from './GetProjectStatusReport';
export * from './WriteSlackMessage';
export * from './CreateTask';
export * from './ResolveUnavailableAttendees';
export * from './WriteEmail';
export * from './ResearchReport';
export * from './ReadEmails';
export * from './ReadWebPage';
export * from './SummerizeCalendars';
````

## File: packages/x-reason/src/lib/functions/comsFunctions/ReadEmails.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import {
    extractJsonFromBackticks,
} from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';
import {
    GeminiService,
    OfficeService,
    ReadEmailOutput,
    TYPES,
} from '@codestrap/developer-foundations-types';

export async function readEmails(context: Context, event?: MachineEvent, task?: string): Promise<ReadEmailOutput> {
    const system = `You are a helpful virtual ai assistant tasked with extracting the time frame in minutes for an email query.`;

    const userPrompt = `
    Using the task from the end user below classify the time frame for the email query into one of the following:
    1. past 15 minutes (also the default if no time from is specified)
    2. past hour
    3. past day (this is the farthest supported look back)

    The task from the end user:
    ${task}

    You can only respond in JSON in the following format:
    {
        timeframe: string,
        email: string
    }

    For example if the ask from the user is:
    Q: "1. **Read Emails** - Read emails for Bob Jones <bob@codestrap.me>"
    A: {
        "timeframe": "past 15 minutes",
        "email": "bob@codestrap.me"
    }

    Q: "1. **Read Emails** - Read emails for Bob Jones <bob@codestrap.me> for the previous hour"
    A: {
        "timeframe": "past hour",
        "email": "bob@codestrap.me"
    }

    Q: "1. **Read Emails** - Read emails for Bob Jones <bob@codestrap.me> for today"
    A: {
        "timeframe": "past day",
        "email": "bob@codestrap.me"
    }
    `;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(userPrompt, system);

    const clean = extractJsonFromBackticks(response);

    const { timeframe, email } = JSON.parse(clean) as { timeframe: string, email: string };

    let parsedTime = 15;

    switch (timeframe) {
        case 'past hour':
            parsedTime = 60
            break;
        case 'past day':
            parsedTime = 720; // we use 12 hours instead of 24 as it's probably the most relevant window.

    }

    const officeService = await container.getAsync<OfficeService>(TYPES.OfficeService);

    const publishTime = new Date((new Date().getTime() - parsedTime * 60 * 1000)).toISOString();

    const result = await officeService.readEmailHistory({
        email,
        publishTime, // TODO construct the published time from the extracted timeframe parameter
    });

    return result;
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/ReadWebPage.ts
````typescript
import { Context, MachineEvent } from "@codestrap/developer-foundations-types";
import { extractJsonFromBackticks } from "@codestrap/developer-foundations-utils";
import { container } from "@codestrap/developer-foundations-di";
import { GeminiService, TYPES } from "@codestrap/developer-foundations-types";
import FirecrawlApp from "@mendable/firecrawl-js";

/**
 * Returns `true` only when `input` is a syntactically valid
 * HTTP or HTTPS URL (must include the protocol).
 */
function isValidWebUrl(input: string): boolean {
    try {
        const u = new URL(input);
        const valid = u.protocol === "http:" || u.protocol === "https:"
        return valid;
    } catch {
        return false;
    }
}

export async function readWebPage(context: Context, event?: MachineEvent, task?: string): Promise<{ result: string }> {
    const system = `You are a helpful virtual ai assistant tasked with extracting the url from user queries.`;

    const userPrompt = `
    Using the user query below output the URL contained in the user query. If the URL does not include the protocol (https://) use must include it

    The user query is:
    ${task}

    You can only respond in JSON in the following format:
    {
        url: string,
    }

    For example if the ask from the user is:
    Q: "1. **Read Web Page** - Read the following web page: codestrap.com
    A: {
        "url": "https://codestrap.com"
    }

    Q: "1. **Read Web Page** - Read the following web page: https://codestrap.com
    A: {
        "url": "https://codestrap.com"
    }
    `;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(userPrompt, system);

    const clean = extractJsonFromBackticks(response);

    let { url } = JSON.parse(clean) as { url: string };

    if (!isValidWebUrl(url)) {
        // ask Gemini to fix the bad URL
        const retryPrompt = `
The URL you just returned (${url}) is invalid.  
Please correct it.  Respond **only** with JSON in the form:

{
  "url": "https://example.com"
}

Original user query:
${task}
`;

        const retryRaw = await geminiService(retryPrompt, system);

        const clean = extractJsonFromBackticks(retryRaw);

        url = (JSON.parse(clean) as { url: string }).url;

        if (!isValidWebUrl(url)) {
            throw new Error(`Invalid URL after retry: ${url}`);
        }
    }

    const FIRECRAWL_API_KEY = process.env.FIRECRAWL_API_KEY;

    if (!FIRECRAWL_API_KEY) {
        throw new Error('FIRECRAWL_API_KEY is not defined!');
    }

    try {
        const app = new FirecrawlApp({ apiKey: FIRECRAWL_API_KEY });

        const pageContents = await app.scrapeUrl(url, {
            formats: ['markdown'],
        });

        if (pageContents.success && pageContents.markdown) {
            return { result: pageContents.markdown };
        }

        return { result: `Failed to load ${url}\n${pageContents.error}` };
    } catch (e) {
        console.log((e as Error).message);
        console.log((e as Error).stack);

        return { result: `Failed to scrape the webpage with FireCraw: ${(e as Error).message}` };
    }

}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/ResearchReport.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import { uuidv4 } from '@codestrap/developer-foundations-utils';

// TODO finish this type
export type ResearchReport = {
  id: string;
  content: string;
};

export async function researchReport(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<ResearchReport> {
  const response = await fetch('https://api.openai.com/v1/responses', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.OPEN_AI_KEY}`,
    },
    body: JSON.stringify({
      model: 'gpt-4o',
      input: [
        {
          role: 'system',
          content: [
            {
              type: 'input_text',
              text: 'You are an AI consultant who is regularly tasked with research for a wide variety of research activities. You specialize in business and technology. You always organize your response in a well-formatted manner, using tables to present key facts and information and lists to outline key points. You carefully listen to the amount of detail the user is looking for in their research report. You always search the internet for updated key facts and figures and to cross-check your work.',
            },
          ],
        },
        {
          role: 'user',
          content: [
            {
              type: 'input_text',
              text: task,
            },
          ],
        },
      ],
      text: {
        format: {
          type: 'text',
        },
      },
      reasoning: {},
      tools: [
        {
          type: 'web_search_preview',
          user_location: {
            type: 'approximate',
            country: 'US',
          },
          search_context_size: 'high',
        },
      ],
      temperature: 1,
      max_output_tokens: 4096,
      top_p: 1,
      store: true,
    }),
  });

  const data = (await response.json()) as any;
  const content = data.output?.filter(
    (message: { type: string }) => message.type === 'message'
  )?.[0]?.content?.[0]?.text;

  return {
    id: uuidv4(),
    content,
  };
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/ResolveUnavailableAttendees.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import {
    GeminiService,
    ProposedTimes,
    TYPES,
    OfficeService,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

export type DraftAtendeeEmailResponse = {
    emailId: string,
    message: string,
    modelDialog: string,
    dayTimes: string;
    meetingSubject: string;
    meetingDuration: number;
    meetingAgenda?: string;
    resolution?: string;
    ts: number,
}

// This function extracts the channel ID and recepients from the input context and sends a slack message
export async function resolveUnavailableAttendees(context: Context, event?: MachineEvent, task?: string): Promise<DraftAtendeeEmailResponse> {
    // find the last occurrence of a getAvailableMeetingTimes execution which had to proceed this state transition
    const stateId = context.stack?.slice().reverse().find(item => item.indexOf('getAvailableMeetingTimes') >= 0);

    console.log(`resolveUnavailableAttendees found stateId: ${stateId}`);

    if (!stateId || stateId.length === 0) {
        throw new Error('Unable to find associated getAvailableMeetingTimes state in the machine stack.')
    }

    let emails: string[] = [];
    const resultOfMeetingSchedulingAttempt = context[stateId] as ProposedTimes;
    console.log(`resultOfMeetingSchedulingAttempt is: 
        ${JSON.stringify(resultOfMeetingSchedulingAttempt, null, 2)}`);
    const dayTimes = resultOfMeetingSchedulingAttempt.times.reduce((acc, cur) => {
        emails = [...emails, ...cur.unavailableAttendees, ...cur.availableAttendees]
        acc = `${acc}
        
        start: ${cur.start},
        end: ${cur.start},
        available: ${cur.availableAttendees.join(', ')},
        unavailable: ${cur.unavailableAttendees.join(', ')}
        `;
        return acc;
    }, '');

    console.log(`resolveUnavailableAttendees found the resultOfMeetingSchedulingAttempt: ${JSON.stringify(resultOfMeetingSchedulingAttempt || {})}`);
    console.log(`resolveUnavailableAttendees emails is: ${JSON.stringify(emails || [])}`);

    if (emails.length === 0) {
        throw new Error('resolveUnavailableAttendees did not find any email addresses to send and email to!')
    }

    const user = `
    Draft an email message asking all attendees asking if anyone can move blockers to make any of the day/time work:
    Required attendees: 
    ${Array.from(new Set(emails).values()).join(', ')}

    Available Day/Time:
    ${dayTimes}

    the task list used to generate the meeting request. This can provide context for the meeting such as attendee names and what will be discussed.
    ${context.solution}

    You can only respond in JSON in the following format:
    {
        message: string,
        recipients: string[],
    }

    For example if the attendees are times are:
    Required attendees:
    "jane.doe@example.com>", "john.doe@example.com"

    Available Day/Time:
    start: Mon Mar 10 2025 01:00:00 GMT-0700 (Pacific Daylight Time),
    end: Mon Mar 10 2025 01:30:00 GMT-0700 (Pacific Daylight Time),
    available: jane.doe@example.com,
    unavailable: john.doe@example.com,

    Your response is:
    {
        "recipients": ["jane.doe@example.com", "john.doe@example.com"],
        "message": "Hi Jane and John, Happy Friday! I'm having trouble finding an available day/time that works for the both of you. Jane is available at Mon Mar 10 2025 01:00:00 GMT-0700 (Pacific Daylight Time) but John is not. Please respond to this email with a proposed day time that works. If you can make any of the unavailable times work that would be preferred. Best, Viki.",
    }
    `;

    const system = `You are a helpful AI assistant tasked with authoring Slack messages. 
    You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Vickie, Code's AI EA" or similar. 
    You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString('en-US', { weekday: 'long' })}. 
    You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
    The current month is ${new Date().toLocaleDateString('en-US', { month: 'long' })}.`;

    const geminiService = container.get<GeminiService>(TYPES.GeminiService);

    const response = await geminiService(user, system);

    const clean = extractJsonFromBackticks(response);

    const parsedResult = JSON.parse(clean);
    const message = parsedResult.message;
    const modelDialog = parsedResult.message;

    const officeService = await container.getAsync<OfficeService>(TYPES.OfficeService);

    const emailResponse = await officeService.sendEmail(
        {
            from: process.env.OFFICE_SERVICE_ACCOUNT,
            recipients: parsedResult.recipients,
            subject: `Resolve Meeting Conflicts - ID ${context.machineExecutionId}`,
            message,
        }
    );

    // TODO: implement email threading with event listeners
    // This will involve saving this initial email to a "threads" ontology object
    // then having the event listener monitor the Gmail inbox, then when it fins an email from Vicki
    // lookup the corresponding email thread on the ontology based on the emailResponse.id (should math the PK field of the ontology object)
    return {
        emailId: emailResponse.id,
        message,
        meetingSubject: resultOfMeetingSchedulingAttempt.subject,
        meetingDuration: resultOfMeetingSchedulingAttempt.durationInMinutes,
        meetingAgenda: resultOfMeetingSchedulingAttempt.agenda,
        dayTimes,
        modelDialog,
        ts: new Date().getTime(),
    };
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/ScheduleMeeting.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import {
  Meeting,
  ProposedTimes,
  TYPES,
  OfficeService,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

// This function extracts the proposed time slot found on the input context and the attendees and schedules a meeting with Google Calander API
export async function scheduleMeeting(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<Meeting> {
  try {
    const { subject, times }: ProposedTimes = context[context.stateId];

    const inputs = {
      summary: subject,
      description: subject,
      start: times[0].start,
      end: times[0].end,
      attendees: times[0].availableAttendees,
    };

    const officeService = await container.getAsync<OfficeService>(
      TYPES.OfficeService
    );

    const schedulingResult = await officeService.scheduleMeeting(inputs);

    console.log('schedulingResult response:', JSON.stringify(schedulingResult));

    return schedulingResult;
  } catch (e) {
    console.log((e as Error).message);
    throw e;
  }
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/SendEmail.test.ts
````typescript
import {
  mockEmailResponse,
  missingRecipientContext,
  validContext,
} from '../../__fixtures__/Email';
import { google } from 'googleapis';

import { sendEmail } from './SendEmail';
import { Context } from '@codestrap/developer-foundations-types';

jest.mock('googleapis', () => ({
  ...jest.requireActual('googleapis'), // Keep other actual exports

  google: {
    // Mock the 'gmail' function as before
    gmail: jest.fn((version: string, auth: any) => {
      return {
        users: {
          messages: {
            send: jest.fn((request: any) => {
              console.log(`Gmail mock called with: ${request}`);
              return Promise.resolve(mockEmailResponse);
            }),
          },
        },
      };
    }),

    // Mock the 'calendar' function as before
    calendar: jest.fn((version: string, auth: any) => {
      return {
        events: {
          insert: jest.fn((request: any) => {
            console.log(`Calendar mock called with: ${request}`);
            return Promise.resolve({ data: { id: 'mockEventId' } });
          }),
        },
      };
    }),

    // Mock the 'customsearch' function as before
    customsearch: jest.fn((version: string) => {
      return {
        cse: {
          list: jest.fn((params: any) => {
            console.log(`Custom Search mock called with: ${params}`);
            return Promise.resolve({
              data: {
                items: [
                  { title: 'Mock Result 1', link: 'http://mock.com/1' },
                  { title: 'Mock Result 2', link: 'http://mock.com/2' },
                ],
              },
            });
          }),
        },
      };
    }),

    // Add a mock for the 'auth' object and its 'GoogleAuth' constructor
    auth: {
      GoogleAuth: jest.fn().mockImplementation((config) => {
        console.log('Mocked GoogleAuth constructor called');

        // Return a mock object that mimics the behavior of a GoogleAuth instance
        return {
          // Mock methods that are called on the GoogleAuth instance
          getClient: jest.fn().mockResolvedValue({
            getRequestHeaders: jest.fn().mockResolvedValue({
              /* mock headers */
            }), // Mock getRequestHeaders if used
          }),
        };
      }),
    },
  },
}));

describe('sendEmail', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  afterAll(() => {
    jest.clearAllMocks();
  });

  it('calls sendEmail and returns the expected response', async () => {
    const response = await sendEmail(validContext);
    expect(response).toEqual(mockEmailResponse.data);
  }, 30000);

  it('throws an error when no email data is found in context', async () => {
    const invalidContext = { stack: [] } as any as Context;
    await expect(sendEmail(invalidContext)).rejects.toThrow(
      'No email data found in context'
    );
  });

  it('throws an error when required email fields are missing', async () => {
    await expect(sendEmail(missingRecipientContext)).rejects.toThrow(
      'Invalid email data format in context'
    );
  });
});
````

## File: packages/x-reason/src/lib/functions/comsFunctions/SendEmail.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import { extractHtmlFromBackticks } from '@codestrap/developer-foundations-utils';
import {
  TYPES,
  GeminiService,
  MessageService,
  OfficeService,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

// Types for Email functionality
export type EmailThread = {
  id: string;
  threadId: string;
  labelIds?: string[];
};

// Email-specific types and utilities
export interface EmailContext {
  message: string;
  subject: string;
  recipients: string[];
  modelDialog: string;
  ts: number;
}

export interface ContextData {
  status: number;
  requestId: string;
  stack: string[];
  [key: string]: any;
}

export function parseEmailContext(context: ContextData): EmailContext | null {
  if (!context?.stack?.length) {
    return null;
  }

  // Get the previous state which must be write email
  // we use - 2 because the state machine has already trasitioned to the next state state
  // at this point, which is SendEmail;
  const lastStackKey = context.stack[context.stack.length - 2];
  if (!lastStackKey || !context[lastStackKey]) {
    return null;
  }

  const emailData = context[lastStackKey];
  if (!emailData?.message || !emailData?.subject || !emailData?.recipients) {
    throw new Error('Invalid email data format in context');
  }

  return emailData;
}

async function parseResearchReport(
  context: Context,
  task?: string
): Promise<string | undefined> {
  const user = `
# Task
Extract any research reports in the state machine DSL that may be related to this task:
${task}

# State Machine DSL:
The stack property let's you know which states have been visited. Each state has a property on the context
which includes the output from that state. There is where you may find a research report that should be returned.
Extract any relevant report(s)
${JSON.stringify(context)}

# Output
Seperate each report by a section heading. Convert the markdown to HTML. Do not output the JSON, only the HTML conversion of the markdown.
If no reports are found output N/A
    `;

  const system = `You are a helpful AI assistant tasked with looking for any relevant research report(s).
    You understand common state machine DSL's like x-state.`;

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);

  const response = await geminiService(user, system);

  return extractHtmlFromBackticks(response ?? 'N/A');
}

const EMAIL_FOOTER = `
<br/>
<div style="border-top: 1px solid #ddd; margin-top: 20px; padding-top: 20px; font-family: Arial, sans-serif;">
    <strong>Vicki</strong><br/>
    Executive AI Assistant | Codestrap<br/>
    <a href="mailto:vicki@codestrap.me">vicki@codestrap.me</a>
</div>
`;

// Main email sending function
export async function sendEmail(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<EmailThread> {
  console.log('[EMAIL] Starting email send process...');
  const emailData = parseEmailContext(context as unknown as ContextData);
  if (!emailData) {
    throw new Error('No email data found in context');
  }
  const researchReports = await parseResearchReport(context, task);
  // if there are any attached reports incude int in the email
  const message =
    researchReports !== 'N/A'
      ? `${emailData.message}\n\n${researchReports}`
      : emailData.message;

  console.log('sending email via compute module:', {
    recipients: emailData.recipients,
    subject: emailData.subject,
    message,
  });

  const messageService = await container.getAsync<OfficeService>(
    TYPES.OfficeService
  );

  const response = await messageService.sendEmail({
    from: process.env.OFFICE_SERVICE_ACCOUNT!,
    recipients: emailData.recipients,
    subject: emailData.subject,
    message,
  });

  console.log('[EMAIL] Constructed email thread response:', response);

  return response;
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/SendSlackMessage.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import {
  Message,
  MessageResponse,
  MessageService,
  TYPES,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

// This function is called by the state machine and uses the connection already established in Text2Action
export async function sendSlackMessage(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<MessageResponse> {
  // Get the state ID for the writeSlackMessage step that preceded this
  const writeSlackStateId = context.stack?.[context.stack?.length - 2];
  if (!writeSlackStateId) {
    throw new Error(
      'Unable to find writeSlackMessage state in the machine stack.'
    );
  }

  // Get the drafted message from the previous state
  const draftMessage = context[writeSlackStateId] as Message;
  if (!draftMessage?.message) {
    throw new Error('No message found in context from writeSlackMessage step.');
  }

  const messageService = container.get<MessageService>(TYPES.MessageService);

  const result = await messageService.sendMessage(draftMessage);

  if (!result.ok) {
    throw new Error(result.error);
  }

  return result;
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/SummerizeCalendars.ts
````typescript
import {
  Context,
  MachineEvent,
  OfficeServiceV2,
  Summaries,
} from '@codestrap/developer-foundations-types';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';
import { GeminiService, TYPES } from '@codestrap/developer-foundations-types';

function nowInTZ(tz: string, ref: Date): Date {
  const dtf = new Intl.DateTimeFormat('en-US', {
    timeZone: tz,
    year: 'numeric',
    month: '2-digit',
    day: '2-digit',
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit',
    hour12: false,
  });
  const p = Object.fromEntries(
    dtf.formatToParts(ref).map((x) => [x.type, x.value])
  );
  return new Date(
    Number(p.year),
    Number(p.month) - 1,
    Number(p.day),
    Number(p.hour),
    Number(p.minute),
    Number(p.second),
    0
  );
}

function startOfDay(d: Date): Date {
  const x = new Date(d);
  x.setHours(0, 0, 0, 0);
  return x;
}

function addDays(d: Date, days: number): Date {
  const x = new Date(d);
  x.setDate(x.getDate() + days);
  return x;
}

function startOfWeekMonday(d: Date): Date {
  const x = startOfDay(d);
  const dow = x.getDay(); // Sun=0..Sat=6
  const delta = dow === 0 ? -6 : 1 - dow;
  return startOfDay(addDays(x, delta));
}

export async function summarizeCalendars(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<Summaries> {
  const TZ = 'America/Los_Angeles';
  const nowPT = nowInTZ(TZ, new Date()); // wall-clock PT now

  const system = `You are a helpful virtual ai assistant tasked with extracting the time frame for a calendar queries.`;

  const userPrompt = `
    Using the task from the end user below classify the time frame for the calendar query into one of the following:
    1. today (default)
    2. tomorrow
    3. this week
    4. next week

    The task from the end user:
    ${task}

    The current day/time in the user's time zone (${TZ}) is:
    ${nowPT}

    You can only respond in JSON in the following format:
    {
        timeframe: string,
        emails: string[]
    }

    For example if the ask from the user is:
    Q: "1. **Summarize Calendars** - Summarize calendars for Bob Jones <bob@codestrap.me>"
    A: {
        "timeframe": "today",
        "emails": ["bob@codestrap.me"]
    }

    Q: "1. **Summarize Calendars** - Summarize calendars for Bob Jones <bob@codestrap.me> and Jane Doe <jane@codestrap.me> for tomorrow"
    A: {
        "timeframe": "tomorrow",
        "emails": ["bob@codestrap.me", "jane@codestrap.me"]
    }

    Q: "1. **Summarize Calendars** - Summarize calendars for Bob Jones <bob@codestrap.me> for the week"
    A: {
        "timeframe": "this week",
        "emails": ["bob@codestrap.me"]
    }

    Q: "1. **Summarize Calendars** - Summarize calendars for Bob Jones <bob@codestrap.me> for next week"
    A: {
        "timeframe": "next week",
        "emails": ["bob@codestrap.me"]
    }
    `;

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);

  const response = await geminiService(userPrompt, system);

  const clean = extractJsonFromBackticks(response);

  const { timeframe, emails } = JSON.parse(clean) as {
    timeframe: string;
    emails: string[];
  };

  /* ---------- build PT window ---------- */

  let windowStartLocal: Date;
  let windowEndLocal: Date;

  switch (timeframe) {
    case 'tomorrow': {
      windowStartLocal = startOfDay(addDays(nowPT, 1)); // tomorrow 00:00
      windowEndLocal = startOfDay(addDays(nowPT, 2)); // day after tomorrow 00:00
      break;
    }
    case 'this week': {
      windowStartLocal = startOfDay(nowPT); // today 00:00
      const nextMon = startOfWeekMonday(addDays(nowPT, 7)); // next weeks Monday 00:00
      windowEndLocal = nextMon;
      break;
    }
    case 'next week': {
      const nextMon = startOfWeekMonday(addDays(nowPT, 7)); // next Monday 00:00
      windowStartLocal = nextMon;                           // start of next week
      windowEndLocal = startOfDay(addDays(nextMon, 7));     // following Monday 00:00
      break;
    }
    case 'today':
    default: {
      windowStartLocal = startOfDay(nowPT); // today 00:00
      windowEndLocal = startOfDay(addDays(nowPT, 1)); // tomorrow 00:00
    }
  }

  const officeService = await container.getAsync<OfficeServiceV2>(
    TYPES.OfficeService
  );

  const result = await officeService.summarizeCalendars({
    emails,
    timezone: TZ,
    windowStartLocal,
    windowEndLocal,
  });

  return result;
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/WriteEmail.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';
import { GeminiService, TYPES } from '@codestrap/developer-foundations-types';

export type DraftEmailResponse = {
  message: string;
  subject: string;
  recipients: string[];
  modelDialog: string;
  ts: number;
};

// This function extracts the channel ID and recepients from the input context and sends a slack message
export async function writeEmail(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<DraftEmailResponse> {
  const user = `
    Draft an email message based on this task:
    ${task}

    Below us some additional context as a JSON blob. It includes any work that has been done leading up to drafring this email. 
    For example it may contains deails on files or project status reports that are referenced in your task.
    ${JSON.stringify(context)}

    You can only respond in JSON in the following format:
    {
        message: <THE_EMAIL_MESSAGE_IN_HTML>,
        recipients: <THE_EXTRACTED_EMAIL_ADDRESSES_FROM_THE_TASK>,
        subject: <THE_EXTRACTED_SUBJECT_FROM_THE_TASK>
    }

     The email message should be formatted with HTML to include:
        - Bullet points for any lists
        - Paragraph spacing for readability
        - <a href='...'> links for elements such as email addresses and hyperlinks
        - A professional tone

    For example if the task is:
    1. **Send Email** - **To**: Mike Johnson <mike.johnson@example.com>, Jane Doe <jane.doe@example.com> - **Subject**: Follow-up on Marketing Plan - **Body**: "Hi Mike and Jane, following up on the recent discussion about the marketing plan. Please review the points raised by Sarah Lee <sarah.lee@example.com> and David Brown <david.brown@example.com>. Let me know if you need any further input. Best, Cody the AI Assistant"
    
    Your response is:
    {
        "recipients": ["mike.johnson@example.com", "jane.doe@example.com"],
        "subject": "Follow-up on Marketing Plan",
        "message": "<p>Hi Mike and Jane,</p><p>Happy Friday! Just following up on the recent discussion about the marketing plan. Please review the points raised by:</p><ul><li>Sarah Lee &lt;sarah.lee@example.com&gt;</li><li>David Brown &lt;david.brown@example.com&gt;</li></ul><p>Let me know if you need any further input.</p><p>Best,</p><p>Viki</p>"
    }
    `;

  const system = `You are a helpful AI assistant tasked with authoring Slack messages. 
    You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Viki, Code's AI EA" or similar. 
    You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString(
    'en-US',
    { weekday: 'long' }
  )}. 
    You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
    The current month is ${new Date().toLocaleDateString('en-US', {
    month: 'long',
  })}.`;

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);

  const response = await geminiService(user, system);

  const clean = extractJsonFromBackticks(response);

  const parsedResult = JSON.parse(clean);
  const message = parsedResult.message;
  const subject = parsedResult.subject;
  const recipients = parsedResult.recipients;
  const modelDialog = parsedResult.message;

  return {
    message,
    subject,
    recipients,
    modelDialog,
    ts: new Date().getTime(),
  };
}
````

## File: packages/x-reason/src/lib/functions/comsFunctions/WriteSlackMessage.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import { TYPES, GeminiService } from '@codestrap/developer-foundations-types';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';

export type DraftMessageResponse = {
  message: string;
  modelDialog: string;
  channelId: string;
  ts: number;
};

// This function extracts the channel ID and recepients from the input context and sends a slack message
export async function writeSlackMessage(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<DraftMessageResponse> {
  const user = `
    Draft a slack message based on this task:
    ${task}

    You can only respond in JSON in the following format:
    {
        message: <THE_SLACK_MESSAGE>,
        channelId: <THE_EXTRACTED_CHANNELID_FROM_THE_TASK>
    }

    For example if the task is:
    2. **Send a Slack message** - Channel ID: C1234567890 - Recipients: Team members - Message: Please review the project milestones and provide feedback by EOD Friday.

    Your response is:
    {
        "channelId": "C1234567890",
        "message": "Hey team, it's Viki, Code's AI EA. Happy Humpday! Don't forget to review the project milestones and provide feedback by EOD Friday.",
    }
    `;

  const system = `You are a helpful AI assistant tasked with authoring Slack messages. 
    You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Viki, Code's AI EA" or similar. 
    You can get creative on your greeting, taking into account the day of the week. Today is ${new Date().toLocaleDateString(
    'en-US',
    { weekday: 'long' }
  )}. 
    You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
    The current month is ${new Date().toLocaleDateString('en-US', {
    month: 'long',
  })}.`;

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);

  const response = await geminiService(user, system);

  const clean = extractJsonFromBackticks(response);

  const parsedResult = JSON.parse(clean);
  const message = parsedResult.message;
  const modelDialog = parsedResult.message;
  const channelId = parsedResult.channelId;

  return {
    message,
    modelDialog,
    channelId,
    ts: new Date().getTime(),
  };
}
````

## File: packages/x-reason/src/lib/functions/context/dateTime.ts
````typescript
import { UserProfile } from '@codestrap/developer-foundations-types';
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';

export type CurrentDateTime = {
  currentLocalDateTime: string;
  currentGMTDateTme: string;
  isPacificDaylightTime: boolean;
};

export async function dateTime(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<CurrentDateTime> {
  console.log(
    `dateTime called with context ${context} event ${event} task ${task}`
  );

  // find the user profile state
  const lastStackKey = context?.stack?.find(
    (stackItem) => stackItem.indexOf('userProfile') >= 0
  );
  const userDetails: UserProfile = {
    name: undefined,
    id: undefined,
    email: undefined,
    timezone: 'America/Los_Angeles',
  };
  // if we found a state that retrieved a user profile grab it
  if (lastStackKey) {
    const retrievedUser = context[lastStackKey] as UserProfile;
    userDetails.name = retrievedUser.name;
    userDetails.id = retrievedUser.id;
    userDetails.email = retrievedUser.email;
    userDetails.timezone = retrievedUser.timezone;
  }

  // Figure out of PDT is in effect
  const options = {
    timeZone: userDetails.timezone ?? 'America/Los_Angeles',
    timeZoneName: 'short', // This will produce "PST" or "PDT"
  };

  const formatter = new Intl.DateTimeFormat(
    'en-US',
    options as Intl.DateTimeFormatOptions
  );
  const formatted = formatter.format(new Date());

  console.log(`formatted int date: ${formatted}`);
  const isPacificDaylightTime = formatted.includes('PDT');
  const currentLocalDateTime = new Date().toLocaleString('en-US', {
    timeZone: userDetails.timezone,
  });
  const currentGMTDateTme = new Date().toISOString();

  return {
    isPacificDaylightTime,
    currentLocalDateTime,
    currentGMTDateTme,
  };
}
````

## File: packages/x-reason/src/lib/functions/context/index.ts
````typescript
export * from './userProfile';
export * from './recall';
export * from './dateTime';
````

## File: packages/x-reason/src/lib/functions/context/recall.ts
````typescript
import {
  Context,
  MachineEvent,
  ContactsDao,
  GeminiService,
  MemoryRecallDao,
  TYPES,
  UserDao,
  UserProfile,
} from '@codestrap/developer-foundations-types';
import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';

export type ModelMemory = {
  contacts: {
    name: string;
    email: string;
  }[];
  currentUser: {
    name: string;
    email: string;
    id: string;
    timezone: string;
  };
  messages: string[];
  reasoning: string;
};

export async function recall(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<ModelMemory> {
  const memoryRecallDao = container.get<MemoryRecallDao>(TYPES.MemoryRecallDao);
  const contactsDao = container.get<ContactsDao>(TYPES.ContactsDao);
  const userDao = container.get<UserDao>(TYPES.UserDao);

  // find the user profile state
  const lastStackKey = context?.stack?.find(
    (stackItem) => stackItem.indexOf('userProfile') >= 0
  );
  const userDetails: UserProfile = {
    name: undefined,
    id: undefined,
    email: undefined,
    timezone: undefined,
  };

  // prefer the user profile loaded as a result of the previous state being executed
  if (lastStackKey) {
    const retrievedUser = context[lastStackKey] as UserProfile;
    userDetails.name = retrievedUser.name;
    userDetails.id = retrievedUser.id;
    userDetails.email = retrievedUser.email;
    userDetails.timezone = retrievedUser.timezone;
  } else if (context.userId) {
    // use the context as a fallback
    const user = await userDao(context.userId);
    userDetails.name = `${user.givenName} ${user.familyName}`;
    userDetails.id = user.id;
    userDetails.email = user.email;
    userDetails.timezone = 'America/Los_Angeles'; // hard code for now, will need some way to look this up in the future
  }

  // find any daily briefs that are relevant here
  const matchedMessages = await memoryRecallDao.search(task!, 1);

  // match any relevant contacts based on name and the task
  const matchedContacts = await contactsDao.search(task!, task!);

  const messagesString = JSON.stringify(
    matchedMessages.map((message) => ({
      messageText: JSON.stringify(message.originalText),
      taskOwnerIfAny: message.userId,
      source: message.source,
    }))
  );

  const contactsString = JSON.stringify(
    matchedContacts.map((contact) => ({
      name: contact.fullName,
      email: contact.email,
      talksTo: contact.talksTo,
      contextOfTheRelatioship: contact.notes,
      account: contact.keyAccounts,
      company: contact.company,
      notes: contact.notes,
    }))
  );

  const user = `
    Extract the exact contact and messages that are relvant to the task below using the provided recalled conversations and contact information.
    Include your reasoning.

    # Task
    ${task}

    # User Executing This Request
    ${JSON.stringify(userDetails)}

    # Contacts retrieved using fuzzy matching based on the task. 
    Pick the best possible contact(s) to return based on task, if any
    If the user has not specified a name but instead a role description or company name determine which persons(s) are the best possible match
    If no contacts are are relevant to the task return an empty array
    ${contactsString}

    # Messages retrieved using vector search:
    Only return messages relevant to the task at hand, if any
    If not messages are relevant to the task return an empty array
    ${messagesString}

    You can only respond in JSON in the following format:
    {
        contacts: {
            name: string,
            email: string,
        }[],
        currentUser: {
            name: string,
            email: string,
            id: string,
            timezone: string,
        },
        messages: string [];
        reasoning: string;
    }

    For example if you are provided:
    # Task
    Schedule a meeting with Bob for Monday to discuss Ford as a possible customer in 2026

    # User Executing This Request
    {
        name: 'Dorian Smiley',
        id: '1234',
        email: 'dsmiley@codestrap.me',
        timezone: 'America/Los_Angeles',
    }

    # Contacts retrieved using fuzzy matching based on the task. 
    Only return contacts where you are 90% sure or more they are the ones refered to in the task, if any. 
    Use the provided message, if any, to give you more context on which contact is the most relevant
    If not contacts are are relevant to the task return an empty array
    ${JSON.stringify([
    {
      name: 'Bob Seager',
      email: 'bob.seager@ford.com',
      talksTo: 'DORIAN',
      contextOfTheRelatioship: [
        'Met a few times at AIP/DevCon, See each other at every event, Worked with him on several bootcamps, small sessions, and AIPcon prep',
      ],
      account: 'Ford',
    },
    {
      name: 'Bob Baymon',
      email: 'bob.baymon@gmail.com',
      talksTo: 'CONNOR',
      contextOfTheRelatioship: ['Friend of mine that works at IBM'],
      account: 'Personal',
    },
  ])}

    # Messages retrieved using vector search:
    Only return messages where you are 90% sure or more they are relevant to the task at hand, if any
    If not messages are relevant to the task return an empty array
    ${JSON.stringify([])}
    
    
    Your response is:
    {
        "contacts": [
            {
                "name": "Bob Seager",
                "email": "bob.seager@ford.com"
            }
        ],
        "currentUser": {
            "name": "Dorian Smiley",
            "id": "1234",
            "email": "dsmiley@codestrap.me",
            "timezone": "America/Los_Angeles"
        },
        "messages": [],
        "reasoning": "Bob Seager works at Ford as is likely the Bob being reffered to."
    }
    `;

  const system = `You are a helpful AI assistant tasked with extracting relevant context details for user tasks. 
    You always obey the user instructions and pay close attention to detail. You are not chatty and always respond in the requested JSON structure, nothing else.`;

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);

  let parsedResult;
  let response;
  let result

  try {
    response = await geminiService(user, system);

    result = extractJsonFromBackticks(response);

    parsedResult = JSON.parse(result) as ModelMemory;
  } catch (e) {
    console.log(e);
    console.log(`the model returned the following invalid JSON: ${response}`);
    // god I hate my life
    response = await geminiService(`
      ${user} 
      
      Your response of:
      ${response}
      
      Is not fucking valid JSON!!! It produce the following error:
      ${(e as Error).message}
      Stop sending me dog shit responses and send me valid fucking JSON!!!!!!!
      `, system);

    result = extractJsonFromBackticks(response);

    parsedResult = {
      contacts: [],
      currentUser: userDetails,
      messages: [],
      reasoning: 'this model returned an empty response for the grounding context',
    } as ModelMemory;
  }

  return parsedResult;
}
````

## File: packages/x-reason/src/lib/functions/context/userProfile.ts
````typescript
import {
  Context,
  MachineEvent,
  UserProfile,
  TYPES,
  UserDao,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

// This function enriches the context with the most likely user profiles relevant to the user's request
// This is usefule for sending emails and status reports where files need to be referenced
export async function userProfile(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<UserProfile> {
  const userProfile: UserProfile = {
    name: undefined,
    id: undefined,
    email: undefined,
    timezone: undefined,
  };

  if (context.userId) {
    const currentUser = await container.get<UserDao>(TYPES.UserDao)(
      context.userId
    );
    userProfile.name = `${currentUser?.givenName} ${currentUser?.familyName}`;
    userProfile.email = currentUser?.email;
    userProfile.id = currentUser?.id;
    userProfile.timezone = 'America/Los_Angeles'; // hard code for now, will need some way to look this up in the future
  }

  return userProfile;
}
````

## File: packages/x-reason/src/lib/functions/sales/awaitRfpResponses.ts
````typescript
import {
  Context,
  MachineEvent,
  RfpResponsesResult,
} from '@codestrap/developer-foundations-types';

export async function awaitRfpResponses(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<RfpResponsesResult> {
  /*
    find all request rfp nodes.
    If all are marked as received allResponsesReceived = true
    */
  const allResponses = Object.keys(context)
    .filter((key) => key.indexOf('requestRfp') >= 0)
    .map((key) => context[key]);

  // all received if there had been a response and the status is 200
  const allResponsesReceived = allResponses.every(
    (item) => item.received && item.status === 200
  );
  const vendors = allResponses.map((item) => item.vendorId);

  return {
    allResponsesReceived,
    vendors,
  };
}
````

## File: packages/x-reason/src/lib/functions/sales/incompleteQuestion.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';

export type IncompleteQuestionResponse = {
  summary: string;
  rawResponse: string;
};

export async function incompleteQuestion(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<IncompleteQuestionResponse> {
  // use an LLM to summerize the missing infromation and return the result
  return {
    summary: 'you fucked up, fix your shit',
    rawResponse:
      'Incomplete Question - you are missing the objectives, deliverables, and timeline required for an RFP',
  };
}
````

## File: packages/x-reason/src/lib/functions/sales/index.ts
````typescript
export * from './requestRfp';
export * from './incompleteQuestion';
export * from './awaitRfpResponses';
````

## File: packages/x-reason/src/lib/functions/sales/requestRfp.ts
````typescript
import { Context, MachineEvent } from '@codestrap/developer-foundations-types';
import { uuidv4 } from '@codestrap/developer-foundations-utils';
import {
  RangrRequestsDao,
  RfpRequestsDao,
  TYPES,
  RfpRequestResponse,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

function extractDomain(input: string) {
  const match = input.match(/<([^>]+)>/);
  return match ? match[1] : null;
}

function extractVendorName(input: string) {
  const match = input.match(/:\s*([\w\s]+)\s*</);
  return match ? match[1].trim() : null;
}

export async function requestRfp(
  context: Context,
  event?: MachineEvent,
  task?: string
): Promise<RfpRequestResponse> {
  const vendorName = extractVendorName(task!);
  const vendorId = extractDomain(task!);
  const message = 'We have received your RFP and will respond shortly';

  if (!vendorName || !vendorId) {
    throw new Error('Vendor name or id not found!');
  }

  // TODO handle all vendors. The only thing that should change in the code below is the four params for url, certs, etc
  // maybe just create a factory to get the clientId, clientSecret, ontologyRid, and url
  if (
    vendorId === 'axisdata.com' ||
    vendorId === 'rangrdata.com' ||
    vendorId === 'rangr.com' ||
    vendorId.indexOf('rangr.com') >= 0
  ) {
    // TODO inject ranger dao and execute
    const rangrRfpDao = container.get<RangrRequestsDao>(
      TYPES.RangrRfpRequestsDao
    );
    // submit to RANGR
    const rangrRfpResult = rangrRfpDao.submit(
      task!,
      context.machineExecutionId!
    );

    console.log(`RANGR returned the following response: ${rangrRfpResult}`);
  }

  // record the request in our system, this is useful for demos and for our records
  const rfpDao = container.get<RfpRequestsDao>(TYPES.RfpRequestsDao);
  await rfpDao.upsert(task!, message, vendorId, context.machineExecutionId!);

  return {
    // TODO replace with status and message from service
    status: 200,
    message,
    // Note: vendor name and ID are extract via the LLM above
    vendorName,
    vendorId,
    received: false,
    // TODO add executionId to context
    machineExecutionId: context.executionId,
    // TODO replace with reciept from service
    receipt: {
      id: uuidv4(),
      timestamp: new Date(),
    },
  };
}
````

## File: packages/x-reason/src/lib/functions/index.ts
````typescript
export * from './comsFunctions';
export * from './context';
export * from './sales';
````

## File: packages/x-reason/src/lib/reasoning/context/coms/functionCatalog.ts
````typescript
import {
    Context,
    MachineEvent,
    Task,
    ActionType,
} from '@codestrap/developer-foundations-types';
import {
    readEmails,
    writeEmail,
    researchReport,
    resolveUnavailableAttendees,
    createTask,
    getAvailableMeetingTimes,
    getProjectFiles,
    getProjectStatusReport,
    scheduleMeeting,
    summarizeCalendars,
    sendEmail,
    readWebPage,
    sendSlackMessage,
    writeSlackMessage,
} from '../../../functions';


function getPayload(context: Context, result: Record<string, any>) {
    const stateId = context.stack?.[context.stack?.length - 1]
    if (!stateId) {
        throw new Error('Unable to find associated state in the machine stack.')
    }
    const payload = {
        stateId,
        [stateId]: {
            // we destructure to preserve other keys like result which holds values from user interaction
            ...context[stateId],
            ...result
        }
    };

    return payload;
}
export function getFunctionCatalog(dispatch: (action: ActionType) => void) {
    return new Map<string, Task>([
        [
            "summarizeCalendars",
            {
                description:
                    "Use this tool to summarize the upcoming calendar events for the specified email addresses",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('summarizeCalendars implementation in function catalog called');
                    const result = await summarizeCalendars(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`summarizeCalendars returned: ${JSON.stringify(result)}`);
                    console.log('dispatching CONTINUE from summarizeCalendars');

                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "readWebPage",
            {
                description:
                    "Use this tool to for requests to read the contents of a web page or other artifact as a web URL",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('readWebPage implementation in function catalog called');
                    const result = await readWebPage(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`readWebPage returned: ${JSON.stringify(result)}`);
                    console.log('dispatching CONTINUE from readWebPage');

                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "readEmails",
            {
                description:
                    "Retrieves the users email messages for a given time period.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('readEmails implementation in function catalog called');
                    const result = await readEmails(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`readEmails returned: ${JSON.stringify(result)}`);
                    console.log('dispatching CONTINUE from readEmails');

                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "researchReport",
            {
                description:
                    "Creates a research report based on the users instructions.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('researchReport implementation in function catalog called');
                    const result = await researchReport(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`researchReport returned: ${JSON.stringify(result)}`);
                    console.log('dispatching CONTINUE from researchReport');

                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "createTask",
            {
                description:
                    "Creates task assigments in our ticketing system. This tool should never be used for follow up communication such as reminder messages, emails, project reports etc. This tool is used to assign a bug report, feature, research task, chore, etc.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('createTask implementation in function catalog called');
                    const result = await createTask(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`createTask returned: ${JSON.stringify(result)}`);
                    /**
                    * to perform and AI transition use the following
                    import { engineV1 as engine } from "../../";
                    import { SupportedEngines, xReasonFactory } from "../../factory";
                    
                    const { aiTransition } = xReasonFactory(SupportedEngines.COMS)({});
                    const nextState = await engine.logic.transition(
                        context.solution!,
                        payload.stateId,
                        JSON.stringify({ ...context, ...payload }),
                        aiTransition
                    )
                    
                    dispatch({
                        type: nextState,
                        payload,
                    });
                     */
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "getAvailableMeetingTimes",
            {
                description:
                    "Gets the available times for all required and optional meeting attendees",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('getAvailableMeetingTimes implementation in function catalog called');
                    const result = await getAvailableMeetingTimes(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`getAvailableMeetingTimes returned: ${JSON.stringify(result)}`);

                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
                // this is an example of how to perform a determinstic gaurd on a tranistion
                // if it returns false the next state in the machine's trasnistions array is evaulauted
                transitions: new Map<string, (context: Context, event: MachineEvent) => boolean>([
                    [
                        // if everyone is available schedule
                        "CONTINUE|resolveUnavailableAttendees",
                        (context: Context, event: MachineEvent) => {
                            console.log(`evaluating pause transition logic for state: ${event.payload?.stateId}`);
                            if (event.payload && event.payload?.stateId) {
                                // if all are available return false and move to schedule meeting
                                return !(event.payload[event.payload.stateId].allAvailable as boolean);
                            }
                            return true;
                        }
                    ]
                ]),
            },
        ],
        [
            "resolveUnavailableAttendees",
            {
                description:
                    "Resolves unavailable attendees for meeting requests where not all attendees are available.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('resolveUnavailableAttendees implementation in function catalog called');
                    const result = await resolveUnavailableAttendees(context, event, task);
                    const payload = getPayload(context, result);
                    console.log(`resolveUnavailableAttendees returned: ${JSON.stringify(result)}`);
                    console.log('dispatching CONTINUE from resolveUnavailableAttendees');
                    // this will pause the state machine execution
                    dispatch({
                        type: 'pause',
                        payload,
                    });
                },
            },
        ],
        [
            "scheduleMeeting",
            {
                description:
                    "Schudules a meeting using the provided time at which all attendees are available.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('scheduleMeeting function catalog implementation called');
                    const result = await scheduleMeeting(context, event, task);

                    const payload = getPayload(context, result);
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "getProjectFiles",
            {
                description:
                    "Retrieves project files.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('getProjectFiles function catalog implementation called');
                    const result = await getProjectFiles(context, event, task);
                    const payload = getPayload(context, result);
                    // This will continue to the next state
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "getProjectStatusReport",
            {
                description:
                    "Retrieves a cull project status report including estimated completion date, task lists, and timeline.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('getProjectStatusReport function catalog implementation called');
                    const result = await getProjectStatusReport(context, event, task);
                    const payload = getPayload(context, result);
                    // This will continue to the next state
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "sendEmail",
            {
                description:
                    "Sends an email.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('sendEmail function catalog implementation called');
                    const result = await sendEmail(context, event, task);
                    const payload = getPayload(context, result);

                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "writeEmail",
            {
                description:
                    "Writes a draft email for review.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('writeEmail function catalog implementation called');
                    const result = await writeEmail(context, event, task);
                    const payload = getPayload(context, result);
                    // Change the type to pause to allow the user to review the email in the UI before send
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "writeSlackMessage",
            {
                description:
                    "Writes a draft slack message for review.",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('writeSlackMessage function catalog implementation called');
                    const result = await writeSlackMessage(context, event, task);
                    const payload = getPayload(context, result);
                    // Change the type to pause to allow the user to review the email in the UI before send
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "sendSlackMessage",
            {
                description:
                    "Sends a Slack Message",
                implementation: async (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('sendSlackMessage function catalog implementation called');
                    const result = await sendSlackMessage(context, event, task);
                    const payload = getPayload(context, result);
                    dispatch({
                        type: 'CONTINUE',
                        payload,
                    });
                },
            },
        ],
        [
            "UnsafeQuestion",
            {
                description:
                    "Default state to display for unsafe questions",
                implementation: (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('UnsafeQuestion implementation called');
                    dispatch({ type: 'success' });
                },
            },
        ],
        [
            "UnsupportedQuestion",
            {
                description:
                    "Default state to display for unsupported questions",
                implementation: (context: Context, event?: MachineEvent, task?: string) => {
                    console.log('UnsupportedQuestion implementation called');
                    dispatch({ type: 'success' });
                },
            },
        ]
    ]);
}
````

## File: packages/x-reason/src/lib/reasoning/context/coms/implementation.v1.ts
````typescript
import { solver, programmer, aiTransition, evaluate } from "./prompts";
import { getFunctionCatalog } from "./functionCatalog";
import { getMetaData } from "./metadata";

export {
    solver as comsSolver, 
    programmer as comsProgrammer, 
    aiTransition as comsAiTrasition, 
    evaluate as comsEvaluate,
    getFunctionCatalog as comsFunctionCatalog,
    getMetaData as metadata,
}
````

## File: packages/x-reason/src/lib/reasoning/context/coms/index.ts
````typescript
export * from './implementation.v1';
````

## File: packages/x-reason/src/lib/reasoning/context/coms/metadata.ts
````typescript
export function getMetaData() {
    return {
        title: 'I am Vickie, the AI powered back office assistant.',
        description: 'Vickie is detail oriented, pays close attention to task order, ensuring tasks are always executed on the correct order with all the required details.',
    }
}
````

## File: packages/x-reason/src/lib/reasoning/context/coms/prompts.ts
````typescript
import {
  SupportedEngines,
  xReasonFactory,
  SupportTrainingDataTypes,
} from '../../../factory';
import {
  ActionType,
  TrainingDataDao,
  TYPES,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

// TODO get this data from the ontology
async function getProgrammingTrainingData() {
  const trainingDataDao = container.get<TrainingDataDao>(TYPES.TrainingDataDao);
  const searchResults = await trainingDataDao.search(SupportedEngines.COMS, SupportTrainingDataTypes.PROGRAMMER);
  const trainingExamples = searchResults
    .reduce((acc, cur) => {
      acc = `${acc}
      If the task list is:
      ${cur.solution}

      Your response is:
      ${cur.machine}

      Explination:
      ${cur.humanReview}
      `;

      return acc;
    }, '');

  const data = `
  ${trainingExamples}
  If the task list is:
  1. Unsupported question

  Your response is:
  [
  {
    "id": "UnsupportedQuestion",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]

If the task list is:
1. Unsafe question

  Your response is:
  [
  {
    "id": "UnsafeQuestion",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]

`;

  return data;
}

// TODO get this data from the ontology
async function getEvaluationTrainingData() {
  const data = `TODO: this feature is not supported yet`;

  return data;
}

async function getSolverTrainingData() {
  const trainingDataDao = container.get<TrainingDataDao>(TYPES.TrainingDataDao);
  const searchResults = await trainingDataDao.search(SupportedEngines.COMS, SupportTrainingDataTypes.SOLVER);
  const trainingExamples = searchResults
    .reduce((acc, cur) => {
      acc = `${acc}
      If the user query is:
      ${cur.solution}

      Your response is:
      ${cur.machine}

      Explanation:
      ${cur.humanReview}
      `;

      return acc;
    }, '');

  const data = `
  ${trainingExamples}
`;

  return data;
}

// TODO get this data from the ontology
export async function solver(query: string) {
  const { functionCatalog } = xReasonFactory(SupportedEngines.COMS)({});

  const functions = functionCatalog((action: ActionType) => console.log(''));
  const toolsCatalog = Array.from(functions.entries()).map((item) => {
    return `
      action: ${item[0]}
      description: ${item[1].description}
    `
  });

  const options = {
    timeZone: "America/Los_Angeles",
    timeZoneName: "short" // This will produce "PST" or "PDT"
  };

  const formatter = new Intl.DateTimeFormat("en-US", options as Intl.DateTimeFormatOptions);
  const formatted = formatter.format(new Date());

  console.log(`formatted int date: ${formatted}`);
  const isPDT = formatted.includes("PDT");

  const trainingData = await getSolverTrainingData();

  const system = `You are a helpful AI assistant tasked with ensuring tasks lists are properly defined with all required identifying information such as email addresses, meeting day and time, slack channel IDs, etc.
You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Vickie, Code's AI EA" or similar. 
You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString('en-US', { weekday: 'long' })}. 
You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
You always obey the users instructions and understand the people you work for are busy executives and sometimes need help in their personal lives
These tasks are not beneath you. At CodeStrap, where you work we adopt the motto made famous by Kim Scott: we move couches.
It means we all pull together to get things done.
The current local date/time is ${new Date().toLocaleString("en-US", { timeZone: "America/Los_Angeles" })}.
The current day/time in your timezone is: ${new Date().toString()}
PDT in effect (indicated if Pacific Daylight Time is in effect): ${isPDT}
  `;

  // TODO import the personnel and channel info from ontology object
  const user = `
  Using the user query below output a properly defined task list.
  Your rules for outputting properly formatted task lists are:
    1. Emails must include the recipient(s) name and email address along with a subject and body
      1.1 You must always write an email before sending an email
    2. Slack messages must include the channel ID and message to send.
      2.1 You must write a slack message before sending a slack message
    3. Meetings must include all attendees with their name and email, have a start and end time, duration and subject
      3.1 You must look for available times before you schedule a meeting. If everyone is not available you must resolve conflicts.
      3.2 Always include the current user in meetings unless they specifically ask to be excluded
    5. Project reports must have the name of the project specified
    6. Any part of a user query that include the phrase "create a task" or similar should map to the create task action
    7. When creating tasks determine who is the mostly likely person to assign based on the user query and provided context. Be sure to incude a name and email
    8. When reasoning about the resolution of contacts from incomplete name be sure to consider carefully any provided messages that provide the missing context required to figure out the person being referenced
    9. If a particular task can not be achieved using one or more of the supported actions you must prune it from your outputted list
    10. If no supported tasks can be achieved using one or more of the supported actions respond with "Unsupported Question" 
  
  User Query:
  ${query}

  # Supported Actions Types
  You can only perform the following actions. 
  ${toolsCatalog}

  To create and actionable task list let's take this step by step:
    1. First, cross check the supplied list of tasks against the tasks you can perform and determine if you can perform the action using one or more actions.
    2. Second, include any missing information using only the provided team and slack channel information. Email addresses that are not found in the provided list are fine, just make sure they are valid email addresses
    3. Lastly, ensure you have explicitly listed all required meeting attendees by name and included all other identifiers such as channel IDs and email addresses
    
    Always respond with an ordered list in markdown format.
    
    For example:
    ${trainingData}
  `;

  return { user, system };
}

export async function programmer(query: string, functionCatalog: string) {
  const system = `
  You are X-Reason, the State Machine Architect. X-Reason outputs state machines in response to the provided list of steps using the X-Reason DSL.
  Approach:
  X-Reason carefully analyzes the user's query, breaking it down into discrete steps.
  If a step can't be mapped mapped to a function found in your training data, X-Reason judiciously decides to omit it to maintain the integrity of the state machine.
  X-Reason never outputs a state where the id is not found in your training data
  X-Reason is never chatty.
  X-Reason always respond in JSON that conforms to the the X-Reason DSL.
  ### Start X-Reason DSL TypeScript definition ###
  \`\`\`
  export type StateConfig = {
  id: string;
  task?: string;
  transitions?: Array<{
    on: string;
    target: string;
    actions?: string;
  }>;
  type?: 'parallel' | 'final';
  onDone?: Array<{
    target: string;
    actions?: string;
  }>;
  states?: StateConfig[];
  includesLogic?: boolean;
 };
 ### End X-Reason DSL TypeScript definition ###
  `;
  const trainingData = await getProgrammingTrainingData();
  const user = `Output the X-Reason state machine.

Let's take this step by step:
1. Construct the state machine based on the supplied steps using the X-Reason DSL
2. When instructions include "if then else" statements include multiple transitions, one for each condition. 
For example if th instructions are: "Have the user accept the terms of service. If the user accepts the TOS go to age confirmation else exit." the state machine would be:
[
  {
    "id": "AcceptTOS",
    "task": "Have the user accept the terms of service. If the user accepts the TOS go to age confirmation else exit.",
    "includesLogic": true,
    "transitions": [
      { "on": "CONTINUE", "target": "AgeConfirmation" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "AgeConfirmation",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]
In this solution "If the user accepts the TOS go to age confirmation" is represented by the { "on": "CONTINUE", "target": "AgeConfirmation" } transition and "else exit." is represented by the { "on": "CONTINUE", "target": "success" } transition. 
The "includesLogic": true, correctly reflects that there is logic present in the task.
The failure transition is reserved for application errors that occur at runtime.

Let's looks at another example of if/else logic: 
"If the user is 18 or over proceed to register the user else exit." would result in the following state config:
{
    "id": "AgeConfirmation",
    "includesLogic": true,
    "transitions": [
      { "on": "CONTINUE", "target": "RegisterUser" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
}
In this solution "If the user is 18 or over proceed to register" is represented by the { "on": "CONTINUE", "target": "RegisterUser" } transition and "else exit" is represented by the { "on": "CONTINUE", "target": "success" } transition
The "includesLogic": true, correctly reflects that there is logic present in the task.
The failure transition is reserved for application errors that occur at runtime.
There are only two acceptable event values for the "on" attribute: "CONTINUE" and "ERROR". The "ERROR" event can only target the "failure" state
4. Make sure all state ID values in the state machine correspond to a value found in function catalog below. DO NOT INVENT YOUR OWN STATES!!!
Function Catalog:
${functionCatalog}

${trainingData}

If steps are
${query}

The state machine is?
`;

  return { user, system };
}

// TODO add training data for transitions
export async function aiTransition(
  taskList: string,
  currentState: string,
  context: string
) {
  const system = `
  You are an AI based reasoning engine called Transit. Transit determines if state machine transitions should take place.
  Transit only returns a valid transition target and is never chatty.
  Transit only considered the information provided by the user to determine which transition target to return
  You always receive three input parameter to determine which state to transition to:
  1. The task list - this is the list of tasks to perform
  2. The current state - this is the current state of the application performing the task list
  3. The context - the context contains all the work performed so far. The stack array attribute denotes which states have been executed and in what order.
  `;

  const user = `
  ### Start training data ###
  Q: Based on the following task list:
  1. Recall solution for sku #1234 face cream.
  2. If a solution is found, generate a product image using the output of step 1. If the solution is not found, exit.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall solution for sku #1234 face cream.",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateProductImage" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":"No solution found"}

  Return the target for the next state.
  A: success

  Q: Based on the following task list:
  1. Recall solution for sku #1234 face cream.
  2. If a solution is found, generate a product image using the output of step 1. If the solution is not found, exit.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall solution for sku #1234 face cream.",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateProductImage" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":{"phases": 
  {"A": [...phases], "B": [...]}
  "Manufacturing Procedure": "1. Mix phase (A) and (B)"...,
  ...more solution attributes
}}

  Return the target for the next state.
  A: GenerateProductImage

  Q: Based on the following task list:
  1. Recall an existing solutions
  2. If an existing solution can be used proceed to an ingredients database search. Else generate the ingredients list.
  3. Perform an ingredients database search for relevant ingredients.
  4. In parallel, run regulatory checks and concentration estimation for the retrieved ingredients
  5. Once those steps are complete, perform a formula simulation.
  6. Have an expert review the generated formula.
  7. Perform lab testing.
  8. Evaluate the complete tested formula.
  9. Generate the manufacturing instructions.
  10. Have an expert review the generated manufacturing instructions.
  11. Generate the manufacturing instructions.
  12. Conduct market research.
  13. Generate marketing claims using the output of step 11
  14. Generate a product image.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall an existing solutions",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateIngredientsList" },
      { "on": "CONTINUE", "target": "IngredientDatabase" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":{"phases":
  {"A": [...phases], "B": [...]}
  "Manufacturing Procedure": "1. Mix phase (A) and (B)"...,
  ...more solution attributes
}}

  Return the target for the next state.
  A: IngredientDatabase

  ### End training data ###

  Based on the following task list:
  ${taskList}

 The current state of the application is:
  ${currentState}
  
  The current context is:
  ${context}

  Return the target for the next state. Let's take this step by step:
  1. Determine which step in the task list the user in on based on the current state and context.
  2. Determine which transition logic from the task to apply based on the results of each state contained in the context.
    2.1 When resolving meeting conflicts, if a resolution has been found, you must reenter the find available times state!
  3. Determine the target to return. Show your work as an enumerated markdown list.
  `;

  return { system, user };
}

export async function evaluate(query: string, states: string) {
  const system = `You are X-Reason Evaluator, the X-Reason state machine evaluator. Your job os to rate the quality of AI generated state machines.`;
  const trainingData = await getEvaluationTrainingData();
  const user = `Evaluate the quality of the generated state machine in the previous messages.
Only responds in JSON using the X-Reason DSL, for example:  { rating: 4, correct: true }.
`;

  return { user, system };
}
````

## File: packages/x-reason/src/lib/reasoning/context/context/functionCatalog.ts
````typescript
import {
  Context,
  MachineEvent,
  Task,
  ActionType,
} from '@codestrap/developer-foundations-types';
import { userProfile, recall, dateTime } from '../../../functions';

function getPayload(context: Context, result: Record<string, any>) {
  const stateId = context.stack?.[context.stack?.length - 1];
  if (!stateId) {
    throw new Error('Unable to find associated state in the machine stack.');
  }
  const payload = {
    stateId,
    [stateId]: {
      // we destructure to preserve other keys like result which holds values from user interaction
      ...context[stateId],
      ...result,
    },
  };

  return payload;
}
export function getFunctionCatalog(dispatch: (action: ActionType) => void) {
  return new Map<string, Task>([
    [
      'userProfile',
      {
        description:
          "Enriches the context with user details that include the current user's email and timezone. This information is always required",
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('userProfile implementation in function catalog called');
          const result = await userProfile(context, event, task);
          const payload = getPayload(context, result);
          console.log(`userProfile returned: ${JSON.stringify(result)}`);
          console.log('dispatching CONTINUE from userProfile');
          // this will pause the state machine execution
          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'dateTime',
      {
        description:
          'Enriches the context with details about the current date/time. This information is always required.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('dateTime implementation in function catalog called');
          const result = await dateTime(context, event, task);
          const payload = getPayload(context, result);
          console.log(`dateTime returned: ${JSON.stringify(result)}`);
          console.log('dispatching CONTINUE from dateTime');
          // this will pause the state machine execution
          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'recall',
      {
        description:
          'Recalls contact infromation, slack channel IDs, and meeting context. This is usefu for sending meeting requests, emails, and slack messages',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('recall implementation in function catalog called');
          const result = await recall(context, event, task);
          const payload = getPayload(context, result);
          console.log(`recall returned: ${JSON.stringify(result)}`);
          console.log('dispatching CONTINUE from recall');
          // this will pause the state machine execution
          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'UnsafeQuestion',
      {
        description: 'Default state to display for unsafe questions',
        implementation: (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('UnsafeQuestion implementation called');
          dispatch({ type: 'success' });
        },
      },
    ],
    [
      'UnsupportedQuestion',
      {
        description: 'Default state to display for unsupported questions',
        implementation: (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('UnsupportedQuestion implementation called');
          dispatch({ type: 'success' });
        },
      },
    ],
  ]);
}
````

## File: packages/x-reason/src/lib/reasoning/context/context/implementation.v1.ts
````typescript
import { solver, programmer, aiTransition, evaluate } from "./prompts";
import { getFunctionCatalog } from "./functionCatalog";
import { getMetaData } from "./metadata";

export {
    solver as contextSolver, 
    programmer as contextProgrammer, 
    aiTransition as contextAiTrasition, 
    evaluate as contextEvaluate,
    getFunctionCatalog as contextFunctionCatalog,
    getMetaData as contextMetadata,
}
````

## File: packages/x-reason/src/lib/reasoning/context/context/index.ts
````typescript
export * from './implementation.v1';
````

## File: packages/x-reason/src/lib/reasoning/context/context/metadata.ts
````typescript
export function getMetaData() {
    return {
        title: 'I am Vickie, the AI powered back office assistant.',
        description: 'Vickie is detail oriented, pays close attention to task order, ensuring tasks are always executed on the correct order with all the required details.',
    }
}
````

## File: packages/x-reason/src/lib/reasoning/context/context/prompts.ts
````typescript
import {
  SupportedEngines,
  xReasonFactory,
  SupportTrainingDataTypes,
} from '../../../factory';
import {
  ActionType,
  TrainingDataDao,
  TYPES,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';
import { dateTime } from '../../../functions';

// TODO get this data from the ontology
async function getProgrammingTrainingData() {
  const trainingDataDao = container.get<TrainingDataDao>(TYPES.TrainingDataDao);
  const searchResults = await trainingDataDao.search(
    SupportedEngines.CONTEXT,
    SupportTrainingDataTypes.PROGRAMMER
  );
  const trainingExamples = searchResults.reduce((acc, cur) => {
    acc = `${acc}
      If the task list is:
      ${cur.solution}

      Your response is:
      ${cur.machine}

      Explination:
      ${cur.humanReview}
      `;

    return acc;
  }, '');

  const data = `
  ${trainingExamples}
  If the task list is:
  1. Unsupported question

  Your response is:
  [
  {
    "id": "UnsupportedQuestion",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]

If the task list is:
1. Unsafe question

  Your response is:
  [
  {
    "id": "UnsafeQuestion",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]

`;

  return data;
}

// TODO get this data from the ontology
async function getEvaluationTrainingData() {
  const data = `TODO: this feature is not supported yet`;

  return data;
}

// TODO get this data from the ontology
export async function solver(query: string) {
  const { functionCatalog } = xReasonFactory(SupportedEngines.COMS)({});

  const functions = functionCatalog((action: ActionType) => console.log(''));
  const toolsCatalog = Array.from(functions.entries()).map((item) => {
    return `
      action: ${item[0]}
      description: ${item[1].description}
    `;
  });

  const dateTimeResult = await dateTime({ requestId: '1234', status: 0 });

  const system = `You are a helpful AI assistant tasked with ensuring user quires are enriched with the appropriate context.
You thoughtfully assemble the prerequire information retrieval steps in the correct order to ensure the user query can be answered with all appropriate context such as user prole data, contacts, and message history.
You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Vickie, Code's AI EA" or similar. 
You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString(
    'en-US',
    { weekday: 'long' }
  )}. 
You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
You always obey the users instructions and understand the people you work for are busy executives and sometimes need help in their personal lives
These tasks are not beneath you. At CodeStrap, where you work we adopt the motto made famous by Kim Scott: we move couches.
It means we all pull together to get things done.
The current local date/time is ${dateTimeResult.currentLocalDateTime}.
The current day/time in your timezone is: ${dateTimeResult.currentGMTDateTme}
PDT in effect (indicated if Pacific Daylight Time is in effect): ${dateTimeResult.isPacificDaylightTime
    }
  `;

  // TODO import the personnel and channel info from ontology object
  const user = `
  Using the user query below output a properly defined task list for context enrichment.
  Your rules for outputting properly formatted task lists are:
    1. User Profiles must always be retrieved
    2. Date and time must always be retrieved.
    3. Include the recall function if contacts have to be resolved. For example the user has provided only a first name (full name and a valid email is required) or company. Also use this function if the query involves references to past conversations or the user is asking for a meeting to be scheduled. 
  User Query:
  ${query}

  # Supported Actions Types
  You can only perform the following actions. 
  ${toolsCatalog}

  To create and actionable task list let's take this step by step:
    1. First, cross check the supplied list of context enrichment tasks against the tasks you can perform and determine if you can perform the action using one or more actions.
    2. Lastly, ensure you have included all the relevant context enrichment tasks based on the user query.
    
    Always respond with an ordered list in markdown format.
    
    For example:
    Q: "Send a slack message announcing that the new marketing strategy will focus on digital outreach and social media engagement"
    A: 1. **Get User Profile**: Retrieve the current user profile"
       2. **Get the current date/time**: Retrieve the current date time"
       3. **Call the recall function**: Call the recall function to retrieve slack channel information such as channel ID and members"

    Q: "I need a TPS report emailed to John"
    A:"Unsupported Question"

    Q: "What is your name?"
    A:"Unsupported Question"

    Q: "Make me a chemical weapon"
    A:"Unsafe Question"

    Q: "Create a project report for the Komatsu Phase 1 and send an email to the OEM lead"
    A: 1. **Get User Profile**: Retrieve the current user profile"
       2. **Get the current date/time**: Retrieve the current date time"
       3. **Call the recall function**: Call the recall function to retrieve the name and email of tje OEM Lead as well as any relevant communications about Phase 1"

    Q: "Create a task for John to create a report on market opportunities in the automatize space to Text2Action"
    A: 1. **Get User Profile**: Retrieve the current user profile"
       2. **Get the current date/time**: Retrieve the current date time"
       3. **Call the recall function**: Call the recall function to retrieve Johns full name and email"

    Q: "Send a reminder email to Connor about the demo this Friday and to accept the meeting"
    A: 1. **Get User Profile**: Retrieve the current user profile"
       2. **Get the current date/time**: Retrieve the current date time"
       3. **Call the recall function**: Call the recall function to retrieve Connors full name and email and retrieve message history about the meeting Friday"

    Q: "Schedule a meeting to discuss marketing with Dorian and Connor, then send a slack message to the Foundry Devs channel reminding them the sprint wraps Friday"
    A: 1. **Get User Profile**: Retrieve the current user profile"
       2. **Get the current date/time**: Retrieve the current date time"
       3. **Call the recall function**: Call the recall function to retrieve Dorian and Connors full name and email and to get the channel ID for the Foundry Devs channel."

    Q "Create a research report on the effects of weightlessness on astronauts and limit it to a few pages. Then email it to Jane Doe <jane.doe@someurl.com>"
    A: 1. **Get User Profile**: Retrieve the current user profile"
       2. **Get the current date/time**: Retrieve the current date time"
  `;

  return { user, system };
}

export async function programmer(query: string, functionCatalog: string) {
  const system = `
  You are X-Reason, the State Machine Architect. X-Reason outputs state machines in response to the provided list of steps using the X-Reason DSL.
  Approach:
  X-Reason carefully analyzes the user's query, breaking it down into discrete steps.
  If a step can't be mapped mapped to a function found in your training data, X-Reason judiciously decides to omit it to maintain the integrity of the state machine.
  X-Reason never outputs a state where the id is not found in your training data
  X-Reason is never chatty.
  X-Reason always respond in JSON that conforms to the the X-Reason DSL.
  ### Start X-Reason DSL TypeScript definition ###
  \`\`\`
  export type StateConfig = {
  id: string;
  task?: string;
  transitions?: Array<{
    on: string;
    target: string;
    actions?: string;
  }>;
  type?: 'parallel' | 'final';
  onDone?: Array<{
    target: string;
    actions?: string;
  }>;
  states?: StateConfig[];
  includesLogic?: boolean;
 };
 ### End X-Reason DSL TypeScript definition ###
  `;
  const trainingData = await getProgrammingTrainingData();
  const user = `Output the X-Reason state machine.

Let's take this step by step:
1. Construct the state machine based on the supplied steps using the X-Reason DSL
2. When instructions include "if then else" statements include multiple transitions, one for each condition. 
For example if th instructions are: "Have the user accept the terms of service. If the user accepts the TOS go to age confirmation else exit." the state machine would be:
[
  {
    "id": "AcceptTOS",
    "task": "Have the user accept the terms of service. If the user accepts the TOS go to age confirmation else exit.",
    "includesLogic": true,
    "transitions": [
      { "on": "CONTINUE", "target": "AgeConfirmation" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "AgeConfirmation",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]
In this solution "If the user accepts the TOS go to age confirmation" is represented by the { "on": "CONTINUE", "target": "AgeConfirmation" } transition and "else exit." is represented by the { "on": "CONTINUE", "target": "success" } transition. 
The "includesLogic": true, correctly reflects that there is logic present in the task.
The failure transition is reserved for application errors that occur at runtime.

Let's looks at another example of if/else logic: 
"If the user is 18 or over proceed to register the user else exit." would result in the following state config:
{
    "id": "AgeConfirmation",
    "includesLogic": true,
    "transitions": [
      { "on": "CONTINUE", "target": "RegisterUser" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
}
In this solution "If the user is 18 or over proceed to register" is represented by the { "on": "CONTINUE", "target": "RegisterUser" } transition and "else exit" is represented by the { "on": "CONTINUE", "target": "success" } transition
The "includesLogic": true, correctly reflects that there is logic present in the task.
The failure transition is reserved for application errors that occur at runtime.
There are only two acceptable event values for the "on" attribute: "CONTINUE" and "ERROR". The "ERROR" event can only target the "failure" state
4. Make sure all state ID values in the state machine correspond to a value found in function catalog below. DO NOT INVENT YOUR OWN STATES!!!
Function Catalog:
${functionCatalog}

${trainingData}

If steps are
${query}

The state machine is?
`;

  return { user, system };
}

// TODO add training data for transitions
export async function aiTransition(
  taskList: string,
  currentState: string,
  context: string
) {
  const system = `
  You are an AI based reasoning engine called Transit. Transit determines if state machine transitions should take place.
  Transit only returns a valid transition target and is never chatty.
  Transit only considered the information provided by the user to determine which transition target to return
  You always receive three input parameter to determine which state to transition to:
  1. The task list - this is the list of tasks to perform
  2. The current state - this is the current state of the application performing the task list
  3. The context - the context contains all the work performed so far. The stack array attribute denotes which states have been executed and in what order.
  `;

  const user = `
  ### Start training data ###
  Q: Based on the following task list:
  1. Recall solution for sku #1234 face cream.
  2. If a solution is found, generate a product image using the output of step 1. If the solution is not found, exit.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall solution for sku #1234 face cream.",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateProductImage" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":"No solution found"}

  Return the target for the next state.
  A: success

  Q: Based on the following task list:
  1. Recall solution for sku #1234 face cream.
  2. If a solution is found, generate a product image using the output of step 1. If the solution is not found, exit.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall solution for sku #1234 face cream.",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateProductImage" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":{"phases": 
  {"A": [...phases], "B": [...]}
  "Manufacturing Procedure": "1. Mix phase (A) and (B)"...,
  ...more solution attributes
}}

  Return the target for the next state.
  A: GenerateProductImage

  Q: Based on the following task list:
  1. Recall an existing solutions
  2. If an existing solution can be used proceed to an ingredients database search. Else generate the ingredients list.
  3. Perform an ingredients database search for relevant ingredients.
  4. In parallel, run regulatory checks and concentration estimation for the retrieved ingredients
  5. Once those steps are complete, perform a formula simulation.
  6. Have an expert review the generated formula.
  7. Perform lab testing.
  8. Evaluate the complete tested formula.
  9. Generate the manufacturing instructions.
  10. Have an expert review the generated manufacturing instructions.
  11. Generate the manufacturing instructions.
  12. Conduct market research.
  13. Generate marketing claims using the output of step 11
  14. Generate a product image.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall an existing solutions",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateIngredientsList" },
      { "on": "CONTINUE", "target": "IngredientDatabase" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":{"phases":
  {"A": [...phases], "B": [...]}
  "Manufacturing Procedure": "1. Mix phase (A) and (B)"...,
  ...more solution attributes
}}

  Return the target for the next state.
  A: IngredientDatabase

  ### End training data ###

  Based on the following task list:
  ${taskList}

 The current state of the application is:
  ${currentState}
  
  The current context is:
  ${context}

  Return the target for the next state. Let's take this step by step:
  1. Determine which step in the task list the user in on based on the current state and context.
  2. Determine which tradition logic from the task to apply based on the results of each state contained in the context.
  3. Determine the target to return. Show your work as an enumerated markdown list.
  `;

  return { system, user };
}

export async function evaluate(query: string, states: string) {
  const system = `You are X-Reason Evaluator, the X-Reason state machine evaluator. Your job os to rate the quality of AI generated state machines.`;
  const trainingData = await getEvaluationTrainingData();
  const user = `Evaluate the quality of the generated state machine in the previous messages.
Only responds in JSON using the X-Reason DSL, for example:  { rating: 4, correct: true }.
`;

  return { user, system };
}
````

## File: packages/x-reason/src/lib/reasoning/context/sales/functionCatalog.ts
````typescript
import {
  Context,
  MachineEvent,
  Task,
  ActionType,
} from '@codestrap/developer-foundations-types';
import {
  incompleteQuestion,
  requestRfp,
  awaitRfpResponses,
  writeEmail,
  sendEmail,
  sendSlackMessage,
  writeSlackMessage,
} from '../../../functions';

function getPayload(context: Context, result: Record<string, any>) {
  const stateId = context.stack?.[context.stack?.length - 1];
  if (!stateId) {
    throw new Error('Unable to find associated state in the machine stack.');
  }

  const payload = {
    stateId,
    [stateId]: {
      // we destructure to preserve other keys like result which holds values from user interaction
      ...context[stateId],
      ...result,
    },
  };

  return payload;
}
export function getFunctionCatalog(dispatch: (action: ActionType) => void) {
  return new Map<string, Task>([
    [
      'incompleteQuestion',
      {
        description: 'Sends a request for proposal to a vendor.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'incompleteQuestion function catalog implementation called'
          );
          const result = await incompleteQuestion(context, event, task);
          const payload = getPayload(context, result);

          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'requestRfp',
      {
        description: 'Sends a request for proposal to a vendor.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('requestRfp function catalog implementation called');
          const result = await requestRfp(context, event, task);
          const payload = getPayload(context, result);
          console.log(
            'requestRfp function response received, calling dispatch'
          );
          const parentId = context.childToParentStateMap[payload.stateId];

          if (!parentId) {
            // if the state has a parent, meaning it's executed as part of a parallel state
            // do not dispatch continue. I haven't figured out how to get the targeting to work correctly
            // ie send('CONTINUE', {to: id}) to send the event to a specific state
            // so I used invoke for parallel states as a hack. This means we do not want to trigger
            // a transition here as the onDone handler of invoke will take care of it
            dispatch({
              type: 'CONTINUE',
              payload,
            });
            return undefined;
          } else {
            return result;
          }
        },
      },
    ],
    [
      'awaitRfpResponses',
      {
        description:
          'Waits until all rfp responses are received before proceeding.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'awaitRfpResponses function catalog implementation called'
          );
          const result = await awaitRfpResponses(context, event, task);
          const payload = getPayload(context, result);
          if (result.allResponsesReceived) {
            return dispatch({
              type: 'CONTINUE',
              payload,
            });
          }
          // pause untill all responses received
          dispatch({
            type: 'pause',
            payload,
          });
        },
      },
    ],
    [
      'sendEmail',
      {
        description: 'Sends an email.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('sendEmail function catalog implementation called');
          const result = await sendEmail(context, event, task);
          const payload = getPayload(context, result);

          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'writeEmail',
      {
        description: 'Writes a draft email for review.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('writeEmail function catalog implementation called');
          const result = await writeEmail(context, event, task);
          const payload = getPayload(context, result);
          // Change the type to pause to allow the user to review the email in the UI before send
          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'writeSlackMessage',
      {
        description: 'Writes a draft slack message for review.',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'writeSlackMessage function catalog implementation called'
          );
          const result = await writeSlackMessage(context, event, task);
          const payload = getPayload(context, result);
          // Change the type to pause to allow the user to review the email in the UI before send
          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'sendSlackMessage',
      {
        description: 'Sends a Slack Message',
        implementation: async (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log(
            'sendSlackMessage function catalog implementation called'
          );
          const result = await sendSlackMessage(context, event, task);
          const payload = getPayload(context, result);
          dispatch({
            type: 'CONTINUE',
            payload,
          });
        },
      },
    ],
    [
      'UnsafeQuestion',
      {
        description: 'Default state to display for unsafe questions',
        implementation: (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('UnsafeQuestion implementation called');
          dispatch({ type: 'success' });
        },
      },
    ],
    [
      'UnsupportedQuestion',
      {
        description: 'Default state to display for unsupported questions',
        implementation: (
          context: Context,
          event?: MachineEvent,
          task?: string
        ) => {
          console.log('UnsupportedQuestion implementation called');
          dispatch({ type: 'success' });
        },
      },
    ],
  ]);
}
````

## File: packages/x-reason/src/lib/reasoning/context/sales/implementation.v1.ts
````typescript
import { solver, programmer, aiTransition, evaluate } from "./prompts";
import { getFunctionCatalog } from "./functionCatalog";
import { getMetaData } from "./metadata";

export {
    solver as salesSolver, 
    programmer as salesProgrammer, 
    aiTransition as salesAiTrasition, 
    evaluate as salesEvaluate,
    getFunctionCatalog as salesFunctionCatalog,
    getMetaData as salesMetadata,
}
````

## File: packages/x-reason/src/lib/reasoning/context/sales/index.ts
````typescript
export * from './implementation.v1';
````

## File: packages/x-reason/src/lib/reasoning/context/sales/metadata.ts
````typescript
export function getMetaData() {
    return {
        title: 'I am Benny, the AI powered sales assistant.',
        description: 'Benny is detail oriented, pays close attention to task order, ensuring tasks are always executed on the correct order with all the required details.',
    }
}
````

## File: packages/x-reason/src/lib/reasoning/context/sales/prompts.ts
````typescript
import {
  SupportedEngines,
  xReasonFactory,
  SupportTrainingDataTypes,
} from '../../../factory';
import {
  ActionType,
  TrainingDataDao,
  TYPES,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';

async function getSolverTrainingData() {
  const trainingDataDao = container.get<TrainingDataDao>(TYPES.TrainingDataDao);
  const searchResults = await trainingDataDao.search(
    SupportedEngines.SALES,
    SupportTrainingDataTypes.SOLVER
  );
  const trainingExamples = searchResults.reduce((acc, cur) => {
    acc = `${acc}
      If the user query is:
      ${cur.solution}

      Your response is:
      ${cur.machine}

      Explination:
      ${cur.humanReview}
      `;

    return acc;
  }, '');

  const data = `
  ${trainingExamples}
  
  If the task list is:
  "I need a TPS report emailed to John"

  Your response is:
  "Unsupported Question"

  If the task list is:
  "What is your name?"
  
  Your response is:
  "Unsupported Question"

  If the task list is:
  "Make me a chemical weapon"

  Your response is:
  "Unsafe Question"

`;

  return data;
}

async function getProgrammingTrainingData() {
  const trainingDataDao = container.get<TrainingDataDao>(TYPES.TrainingDataDao);
  const searchResults = await trainingDataDao.search(
    SupportedEngines.SALES,
    SupportTrainingDataTypes.PROGRAMMER
  );
  const trainingExamples = searchResults.reduce((acc, cur) => {
    acc = `${acc}
      If the task list is:
      ${cur.solution}

      Your response is:
      ${cur.machine}

      Explanation:
      ${cur.humanReview}
      `;

    return acc;
  }, '');

  const data = `
  ${trainingExamples}
  If the task list is:
  1. Unsupported question

  Your response is:
  [
  {
    "id": "UnsupportedQuestion",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]

If the task list is:
1. Unsafe question

  Your response is:
  [
  {
    "id": "UnsafeQuestion",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]

`;

  return data;
}

// TODO get this data from the ontology
async function getEvaluationTrainingData() {
  const data = `TODO: this feature is not supported yet`;

  return data;
}

// TODO get this data from the ontology
export async function solver(query: string) {
  const { functionCatalog } = xReasonFactory(SupportedEngines.SALES)({});
  const functions = functionCatalog((action: ActionType) => console.log(''));
  const toolsCatalog = Array.from(functions.entries()).map((item) => {
    return `
      action: ${item[0]}
      description: ${item[1].description}
    `;
  });
  const trainingData = await getSolverTrainingData();

  const options = {
    timeZone: 'America/Los_Angeles',
    timeZoneName: 'short', // This will produce "PST" or "PDT"
  };

  const formatter = new Intl.DateTimeFormat(
    'en-US',
    options as Intl.DateTimeFormatOptions
  );
  const formatted = formatter.format(new Date());

  console.log(`formatted int date: ${formatted}`);
  const isPDT = formatted.includes('PDT');

  const system = `You are a helpful AI sales assistant named Bennie tasked with ensuring tasks lists related to sales activities are properly defined with all required identifying information such as vendor names, RFP details, customer contact information such as email addresses, slack channel IDs, etc.
You are professional in your tone, personable, and always start your messages with the phrase, "Hi, I'm Bennie, Code's AI Sales Associate" or similar. 
You can get creative on your greeting, taking into account the dat of the week. Today is ${new Date().toLocaleDateString(
    'en-US',
    { weekday: 'long' }
  )}. 
You can also take into account the time of year such as American holidays like Halloween, Thanksgiving, Christmas, etc. 
You always obey the users instructions and understand the people you work for are busy executives and sometimes need help in their personal lives
These tasks are not beneath you. At CodeStrap, where you work we adopt the motto made famous by Kim Scott: we move couches.
It means we all pull together to get things done.
The current local date/time is ${new Date().toLocaleString('en-US', {
    timeZone: 'America/Los_Angeles',
  })}.
The current day/time in your timezone is: ${new Date().toString()}
PDT in effect (indicated if Pacific Daylight Time is in effect): ${isPDT}
  `;

  // TODO import the personnel and channel info from ontology object
  const user = `
  Using the user query below output a properly defined task list.
  Your rules for outputting properly formatted task lists are:
    1. Emails must include the recipient(s) name and email address along with a subject and body
      1.1 You must always write an email before sending an email
    2. Slack messages must include the channel ID and message to send.
      2.1 You must write a slack message before sending a slack message
    3. Requests for proposals must have
      3.1 A list of vendor names and IDs who will be submitting and RFP
      3.2 Objectives
      3.3 Deliverables
      3.4 Timeline
    4. When creating a request for proposal, to determine mostly likely vendor(s) to assign based on the user query and provided context. Be sure to include a vendor name and ID in the format VENDOR_NAME <VENDOR_ID> where VENDOR_ID is the domain name. For example Northslope <northslopetech.com>
      4.1 To infer the VENDOR_ID from the context find the most likely matching emails and extract the domain name. For example if the task is referencing an RFP for Northslope and in the provided context you find bill@northslopetech.com and that is the only north slope found you can assume the VENDOR_ID is northslopetech.com
    5. When reasoning about the resolution of contacts, slack channelIDs, or RFP details such as vendor name from incomplete information be sure to consider carefully any provided messages that provide the missing context required to figure out the person being referenced
    6. If a particular task can not be achieved using one or more of the supported actions you must prune it from your outputted list
    7. If no supported tasks can be achieved using one or more of the supported actions respond with "Unsupported Question" 
  
  User Query:
  ${query}

  # Supported Actions Types
  You can only perform the following actions. 
  ${toolsCatalog}

  To create and actionable task list let's take this step by step:
    1. First, cross check the supplied list of tasks against the tasks you can perform and determine if you can perform the action using one or more actions.
    2. Second, include any missing information using only the provided vendor, team and slack channel information. Email addresses that are not found in the provided list are fine, just make sure they are valid email addresses
    3. Lastly, when requesting proposals ensure you have explicitly listed all required vendors with the correct vendor name and ID int he form VENDOR_NAME <VENDOR_ID>
    
    Always respond with an ordered list in markdown format.
    
    For example:
    ${trainingData}
    `;

  return { user, system };
}

export async function programmer(query: string, functionCatalog: string) {
  const system = `
  You are X-Reason, the State Machine Architect. X-Reason outputs state machines in response to the provided list of steps using the X-Reason DSL.
  Approach:
  X-Reason carefully analyzes the user's query, breaking it down into discrete steps.
  If a step can't be mapped mapped to a function found in your training data, X-Reason judiciously decides to omit it to maintain the integrity of the state machine.
  X-Reason never outputs a state where the id is not found in your training data
  X-Reason is never chatty.
  X-Reason always respond in JSON that conforms to the the X-Reason DSL.
  ### Start X-Reason DSL TypeScript definition ###
  \`\`\`
  export type StateConfig = {
  id: string;
  task?: string;
  transitions?: Array<{
    on: string;
    target: string;
    actions?: string;
  }>;
  type?: 'parallel' | 'final';
  onDone?: Array<{
    target: string;
    actions?: string;
  }>;
  states?: StateConfig[];
  includesLogic?: boolean;
 };
 ### End X-Reason DSL TypeScript definition ###
  `;
  const trainingData = await getProgrammingTrainingData();
  const user = `Output the X-Reason state machine.

Let's take this step by step:
1. Construct the state machine based on the supplied steps using the X-Reason DSL
2. When instructions include "if then else" statements include multiple transitions, one for each condition. 
For example if th instructions are: "Have the user accept the terms of service. If the user accepts the TOS go to age confirmation else exit." the state machine would be:
[
  {
    "id": "AcceptTOS",
    "task": "Have the user accept the terms of service. If the user accepts the TOS go to age confirmation else exit.",
    "includesLogic": true,
    "transitions": [
      { "on": "CONTINUE", "target": "AgeConfirmation" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "AgeConfirmation",
    "transitions": [
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  },
  {
    "id": "success",
    "type": "final"
  },
  {
    "id": "failure",
    "type": "final"
  }
]
In this solution "If the user accepts the TOS go to age confirmation" is represented by the { "on": "CONTINUE", "target": "AgeConfirmation" } transition and "else exit." is represented by the { "on": "CONTINUE", "target": "success" } transition. 
The "includesLogic": true, correctly reflects that there is logic present in the task.
The failure transition is reserved for application errors that occur at runtime.

Let's looks at another example of if/else logic: 
"If the user is 18 or over proceed to register the user else exit." would result in the following state config:
{
    "id": "AgeConfirmation",
    "includesLogic": true,
    "transitions": [
      { "on": "CONTINUE", "target": "RegisterUser" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
}
In this solution "If the user is 18 or over proceed to register" is represented by the { "on": "CONTINUE", "target": "RegisterUser" } transition and "else exit" is represented by the { "on": "CONTINUE", "target": "success" } transition
The "includesLogic": true, correctly reflects that there is logic present in the task.
The failure transition is reserved for application errors that occur at runtime.
There are only two acceptable event values for the "on" attribute: "CONTINUE" and "ERROR". The "ERROR" event can only target the "failure" state
4. Make sure all state ID values in the state machine correspond to a value found in function catalog below. DO NOT INVENT YOUR OWN STATES!!!
Function Catalog:
${functionCatalog}

${trainingData}

If steps are
${query}

The state machine is?
`;

  return { user, system };
}

// TODO add training data for transitions
export async function aiTransition(
  taskList: string,
  currentState: string,
  context: string
) {
  const system = `
  You are an AI based reasoning engine called Transit. Transit determines if state machine transitions should take place.
  Transit only returns a valid transition target and is never chatty.
  Transit only considered the information provided by the user to determine which transition target to return
  You always receive three input parameter to determine which state to transition to:
  1. The task list - this is the list of tasks to perform
  2. The current state - this is the current state of the application performing the task list
  3. The context - the context contains all the work performed so far. The stack array attribute denotes which states have been executed and in what order.
  
  When handling RFP responses you always wait for all responses to be received before transitioning to another state.
  If all rfp responses are not received return the current await state. For example awaitRfpResponses|902fe5f3-d84c-459d-af4c-af82cede5b8d. It must be the exact stateId including the pipe and GUID! This allows the machine to continue to wait for responses.
  If all rfp responses are received but some are missing information, you must target the await state. For example awaitRfpResponses|902fe5f3-d84c-459d-af4c-af82cede5b8d. Again, the full state ID must be returned including the pipe and GUID.
  If all rfp responses are received and valid you must target the CONTINUE state. 
  `;

  const user = `
  ### Start training data ###
  Q: Based on the following task list:
  1. **Create RFP** - **Vendor**: TeamB <teamb.com>, TeamA <teama.com> **Objectives**: Create a contracts and pricing solution in Foundry that includes support for Cournot models, simulations, and A/B testing of the outcomes., **Timeline**: 8 weeks starting June 1st 2025 with a team of 1 Python engineer, 1 TypeScript engineer, and 1 SME on developing Cournot pricing models
  2. **Write Email** - **To**: Bryce Leszczynski <bryce@codestrap.me> - **Subject**: RFP Pricing Module Responses - **Body**: "Hey Bryce, Bennie here. Hope you are enjoying your Saturday. Below is the RFP responses. Best, Bennie"
  3. **Send Email** - **To**: Bryce Leszczynski <bryce@codestrap.me> - **Subject**: RFP Pricing Module Responses - **Body**: "Hey Bryce, Bennie here. Hope you are enjoying your Saturday. Below is the RFP responses. Best, Bennie"

  The current state of the application is:
  {
    "id": "awaitRfpResponses|4bc74786-12e6-4cef-83f4-be4af505fb29",
    "task": "**Await RFP Responses** - **Vendors**: TeamB <teamb.com>, TeamA <teama.com>",
    "includesLogic": true,
    "transitions": [
      {
        "on": "CONTINUE",
        "target": "writeEmail|0a64031a-c0a1-439e-8bfb-69b189228009"
      },
      {
        "on": "ERROR",
        "target": "failure"
      }
    ]
  }
  And the current context is:
  {
        "requestId": "c15e116a-73be-449c-9ffb-f489813ee40a",
        "status": 0,
        "childToParentStateMap": {
            "requestRfp|1cebc011-42fa-410e-a540-72155fe74a3d": "parallelRfpRequests|0a64031a-c0a1-439e-8bfb-69b189228009",
            "requestRfp|d3bddc2d-3cdd-40f9-b1a8-a90ce5551959": "parallelRfpRequests|0a64031a-c0a1-439e-8bfb-69b189228009"
        },
        "machineExecutionId": "4bc74786-12e6-4cef-83f4-be4af505fb29",
        "stack": [
            "requestRfp|1cebc011-42fa-410e-a540-72155fe74a3d",
            "requestRfp|d3bddc2d-3cdd-40f9-b1a8-a90ce5551959",
            "awaitRfpResponses|802fe5f2-d84c-459d-af4c-af82cede5b9b"
        ],
        "stateId": "awaitRfpResponses|802fe5f2-d84c-459d-af4c-af82cede5b9b",
        "requestRfp|1cebc011-42fa-410e-a540-72155fe74a3d": {
            "status": 200,
            "message": "TODO add the actual response message",
            "vendorName": "TeamA",
            "vendorId": "teama.com",
            "received": false,
            "reciept": {
                "id": "149ab267-a3ec-4f40-90f6-00e178d08907",
                "timestamp": "2025-05-25T17:32:15.183Z"
            }
        },
        "requestRfp|d3bddc2d-3cdd-40f9-b1a8-a90ce5551959": {
            "status": 200,
            "message": "{"validation":{"result":"VALID","submissionCriteria":[],"parameters":{}}}",
            "vendorName": "TeamB",
            "vendorId": "teamB.com",
            "received": true,
            "reciept": {
                "id": "f69d5a47-75c1-47ed-a967-8bb88d760edf",
                "timestamp": "2025-05-25T17:32:25.040Z"
            },
            "response": "###  Proposed Staffing Plan\n\n- **Engagement Director**: 0.25 FTE\n- **Solutions Engineer  Senior**: 0.5 FTE\n- **Solutions Engineer  Junior**: 1.0 FTE\n\n** Available Start Date**: June 17, 2025  \n** Estimated Weekly Cost**: $3,842.50  \n** Estimated Total Cost (8 weeks)**: $30,740.00\nThe earliest date when all required roles are simultaneously available is June 17, 2025, based on the provided availability information.\n\nThe weekly blended cost is calculated as follows:\n\nEngagement Director: 0.25 FTE x $3,192 = $798\nSolutions Engineer - Senior: 0.5 FTE x $3,192 = $1,596\nSolutions Engineer - Junior: 1.0 FTE x $1,942 = $1,942\nTotal weekly cost: $798 + $1,596 + $1,942 = $3,842.50\nMultiplying the weekly blended cost of $3,842.50 by the project duration of 8 weeks results in an estimated total cost of $30,740.00."
        },
        "awaitRfpResponses|4bc74786-12e6-4cef-83f4-be4af505fb29": {
            "allResponsesRecieved": false,
            "vendors": [
                "teamb.com",
                "teamb.com",
            ]
        }
    }
  The Return the target for the next state is:
  A: awaitRfpResponses|4bc74786-12e6-4cef-83f4-be4af505fb29

  Q: Based on the following task list:
  1. Recall solution for sku #1234 face cream.
  2. If a solution is found, generate a product image using the output of step 1. If the solution is not found, exit.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall solution for sku #1234 face cream.",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateProductImage" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":"No solution found"}

  Return the target for the next state.
  A: success

  Q: Based on the following task list:
  1. Recall solution for sku #1234 face cream.
  2. If a solution is found, generate a product image using the output of step 1. If the solution is not found, exit.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall solution for sku #1234 face cream.",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateProductImage" },
      { "on": "CONTINUE", "target": "success" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":{"phases": 
  {"A": [...phases], "B": [...]}
  "Manufacturing Procedure": "1. Mix phase (A) and (B)"...,
  ...more solution attributes
}}

  Return the target for the next state.
  A: GenerateProductImage

  Q: Based on the following task list:
  1. Recall an existing solutions
  2. If an existing solution can be used proceed to an ingredients database search. Else generate the ingredients list.
  3. Perform an ingredients database search for relevant ingredients.
  4. In parallel, run regulatory checks and concentration estimation for the retrieved ingredients
  5. Once those steps are complete, perform a formula simulation.
  6. Have an expert review the generated formula.
  7. Perform lab testing.
  8. Evaluate the complete tested formula.
  9. Generate the manufacturing instructions.
  10. Have an expert review the generated manufacturing instructions.
  11. Generate the manufacturing instructions.
  12. Conduct market research.
  13. Generate marketing claims using the output of step 11
  14. Generate a product image.

  The current state of the application is:
  {
    "id": "RecallSolutions",
    "task": "Recall an existing solutions",
    "transitions": [
      { "on": "CONTINUE", "target": "GenerateIngredientsList" },
      { "on": "CONTINUE", "target": "IngredientDatabase" },
      { "on": "ERROR", "target": "failure" }
    ]
  }
  The result of that state is:
  {"RecallSolutions":{"phases":
  {"A": [...phases], "B": [...]}
  "Manufacturing Procedure": "1. Mix phase (A) and (B)"...,
  ...more solution attributes
}}

  Return the target for the next state.
  A: IngredientDatabase

  ### End training data ###

  Based on the following task list:
  ${taskList}

 The current state of the application is:
  ${currentState}
  
  The current context is:
  ${context}

  Return the target for the next state. Let's take this step by step:
  1. Determine which step in the task list the user in on based on the current state and context.
  2. Determine which transition logic from the task to apply based on the results of each state contained in the context.
  3. Determine the target to return. Show your work as an enumerated markdown list.
  `;

  return { system, user };
}

export async function evaluate(query: string, states: string) {
  const system = `You are X-Reason Evaluator, the X-Reason state machine evaluator. Your job os to rate the quality of AI generated state machines.`;
  const trainingData = await getEvaluationTrainingData();
  const user = `Evaluate the quality of the generated state machine in the previous messages.
Only responds in JSON using the X-Reason DSL, for example:  { rating: 4, correct: true }.
`;

  return { user, system };
}
````

## File: packages/x-reason/src/lib/reasoning/context/index.ts
````typescript
export * from "./coms";
export * from './context';
export * from './sales';
````

## File: packages/x-reason/src/lib/reasoning/index.ts
````typescript
export * from './context'
````

## File: packages/x-reason/src/lib/engineV1.ts
````typescript
import { interpret } from 'xstate';

import {
  StateConfig,
  EvaluationInput,
  EvaluatorResult,
  ReasoningEngine,
  Prompt,
} from '@codestrap/developer-foundations-types';
import programV1 from './programmerV1';

import { extractJsonFromBackticks } from '@codestrap/developer-foundations-utils';
import { container } from '@codestrap/developer-foundations-di';
import {
  GeminiService,
  LoggingService,
  TYPES,
} from '@codestrap/developer-foundations-types';

async function solve(query: string, solver: Prompt): Promise<string> {
  // TODO remove the use of the threads API and go with completions
  const { user, system } = await solver(query);

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);
  const response = await geminiService(user, system);

  const result = response ?? '';
  return result;
}

async function program(
  query: string,
  functionCatalog: string,
  programmer: Prompt
): Promise<StateConfig[]> {
  const { user, system } = await programmer(query, functionCatalog);

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);
  const response = await geminiService(user, system);

  const value = response ?? '';
  let unwrapped = extractJsonFromBackticks(value) || value;

  console.log(
    `programmer generated the following unchecked solution: ${unwrapped}`
  );

  // check the quality of the result
  try {
    JSON.parse(unwrapped);
  } catch (e) {
    const updatedUserMessage = `${user}
your generated solution:
${unwrapped}
generated the following error:
${(e as Error).message}
Ensure the JSON is valid and does not contain any trailing commas, correct quotes, etc
Only respond with the updated JSON! Your response will be sent to JSON.parse
`;
    const response = await geminiService(updatedUserMessage, system);

    const value = response ?? '';
    unwrapped = extractJsonFromBackticks(value) || value;
  }
  const states: StateConfig[] = JSON.parse(unwrapped);

  // make sure the state ID's are valid, including transition targets
  const notFoundTransitions: string[] = [];
  const notFound = states
    .map((state) => {
      if (
        state.type !== 'parallel' &&
        state.id !== 'success' &&
        state.id !== 'failure' &&
        functionCatalog.indexOf(state.id) < 0
      ) {
        return state;
      }
      // sometimes the model will return a state in a transition that is not a valid state node
      state.transitions?.forEach((transition) => {
        if (
          transition.target !== 'success' &&
          transition.target !== 'failure' &&
          functionCatalog.indexOf(transition.target) < 0
        ) {
          notFoundTransitions.push(transition.target);
        }
      });

      return undefined;
    })
    .filter((item) => item !== undefined)
    .map((item) => item?.id);
  if (notFound.length > 0) {
    console.log(
      `Unknown state ID encountered: ${notFound.join(
        ','
      )}. Calling GPT4o to fix.`
    );
    //console.log(`functionCatalog:\n${functionCatalog}`);
    const notFoundTransitionsMessage =
      notFoundTransitions.length > 0
        ? `The following transitions triggered an unknown state ID error: ${notFoundTransitions.join(
          ','
        )}. Please ensure all targets are referencing a valid state node. If these state nodes are invalid replace them with valid ones.`
        : undefined;
    console.log(
      `Unknown transition target encountered: ${notFoundTransitionsMessage}. Calling GPT4o to fix.`
    );
    // TODO, return a recursive call to program if max count has not been exceeded
    const updatedUserMessage = `${user}
your previous answer generated the following errors:
Unknown state ID encountered: ${notFound.join(',')}
${notFoundTransitionsMessage}
Replace the unknown state IDs with valid IDs found in the function catalog below:
###### start function catalog ######
${functionCatalog}
###### end function catalog ######
Do not modify the state machine in any other way!
Only respond with the updated JSON and don't be chatty! Your response will be sent to JSON.parse
`;
    const response = await geminiService(updatedUserMessage, system);

    const value = response ?? '';
    // TODO retest valid states by moving logic to a util function
    unwrapped = extractJsonFromBackticks(value) || value;
    console.log(
      `model returned the following updated state machine to correct errors:\n${unwrapped}`
    );
  }

  return JSON.parse(unwrapped) as StateConfig[];
}

async function evaluate(
  input: EvaluationInput,
  evaluate: Prompt
): Promise<EvaluatorResult> {
  let evaluation = {
    rating: 0,
    correct: false,
  };
  try {
    const machine = programV1(input.states, input.tools!);
    const { user, system } = await evaluate(
      input.query,
      JSON.stringify(input.states)
    );

    // see if the machine compiles
    const withContext = machine.withContext({
      status: 0,
      requestId: 'test',
      stack: [],
    });

    const machineExecution = interpret(withContext);

    evaluation = {
      rating: 5,
      correct: true,
    };
    /* TODO we need to fix this by allowing it to receive the message history so the model can evaluate the conversation
        then the model can evaluate the conversation
        // Now have the evaluator evaluate the result
        const result = await chatCompletion({
            messages: [
                { role: 'system', contents: [{ text: system }] },
                { role: 'user', contents: [{ text: user }] },
            ],
            model: "gpt-4", // gpt-4-0125-preview, gpt-4
            //response_format: { type: "json_object" } gpt-4-0125-preview
        });
        const value = result || '';
        let unwrapped = extractJsonFromBackticks(value) || value;

        // check the quality of the result
        try {
            evaluation = JSON.parse(unwrapped);
        } catch (e) {
            const result = await chatCompletion({
                messages: [
                    { role: 'system', contents: [{ text: system }] },
                    { role: 'user', contents: [{ text: user }] },
                    {
                        role: 'user', content: `your generated evaluation:
                ${unwrapped}
                generated the following error:
                ${(e as Error).message}
                Ensure the JSON is valid and does not contain any trailing commas, correct quotes, etc
                Only respond with the updated JSON! Your response will be sent to JSON.parse
                ` },
                ],
                model: "gpt-4",
                //response_format: { type: "json_object" }
            });
            const value = result || '';
            unwrapped = extractJsonFromBackticks(value) || value;
            evaluation = JSON.parse(unwrapped);
        }
        */
  } catch (e) {
    return {
      rating: 0,
      error: e as Error,
    };
  }
  // TODO better evaluation. For now if it compiles we are good. When we have evaluator models we'll expand
  console.log(`evaluator responded with: ${JSON.stringify(evaluation)}`);
  return evaluation;
}

async function transition(
  taskList: string,
  currentState: string,
  payload: string,
  aiTransition: Prompt,
  executionId: string
): Promise<string> {
  const { user, system } = await aiTransition(taskList, currentState, payload);
  const { log } = container.get<LoggingService>(TYPES.LoggingService);

  const geminiService = container.get<GeminiService>(TYPES.GeminiService);
  const response = await geminiService(user, system);

  let value = response.trim() ?? '';

  console.log(`engine.v2.ts.transition result is: ${value}`);
  log(executionId, value);

  // coerce the reasoning step into a state ID
  const updatedUserMessage = `${user}
Extract the target state ID and only the target state id from your previous response:
${value}
Do not be chatty!
`;
  const coercedResponse = await geminiService(updatedUserMessage, system);

  value = coercedResponse ?? '';
  value = value.trim();

  // TODO improve retry mechanism
  if (currentState.indexOf(value) < 0) {
    const updatedUserMessage = `${user}
your generated solution:
${value}
does not include a valid transition ID! Make sure your are picking a transition ID from the provided state's transitions array
Do not be chatty!
`;
    const result = await geminiService(updatedUserMessage, system);

    value = result ?? '';
    value = value.trim();
    if (
      currentState.indexOf(value) < 0 &&
      value !== 'CONTINUE' &&
      value !== 'success' &&
      value !== 'failure'
    ) {
      throw new Error(`Invalid model response: ${value}`);
    }
  }

  return value;
}

const implementation: ReasoningEngine = {
  solver: { solve },
  programmer: { program },
  evaluator: { evaluate },
  logic: { transition },
};

export default implementation;
````

## File: packages/x-reason/src/lib/interpreterV1Headless.ts
````typescript
import { StateMachine, interpret, State } from 'xstate';

import {
  ActionType,
  MachineEvent,
  Context,
  StateConfig,
  Task,
} from '@codestrap/developer-foundations-types';
import programV1 from './programmerV1';

export default function headlessInterpreter(
  states: StateConfig[],
  functions: Map<string, Task>,
  // callback function to revieve notifications on state change
  dispatch: (action: ActionType) => void,
  context?: Context,
  state?: State<Context, MachineEvent>,
  retriggerEntryFunction: boolean = false
) {
  const result: StateMachine<Context, any, MachineEvent> = programV1(
    states,
    functions
  );
  const returnedContext = result.context;

  const initialContext = context || {
    status: 0,
    requestId: 'test',
    stack: [],
  };
  // make sure initialContext overwrites anything on the input context
  const contextToSupply = { ...returnedContext, ...initialContext };
  const machine = result.withContext(contextToSupply);

  const instance = interpret(machine).onTransition((state) => {
    console.log(
      `onTransition called: machine: ${machine.id} state: ${state.value}`
    );
    dispatch({
      type: 'SET_STATE',
      value: {
        currentState: state,
        context: state.context,
      },
    });
    if (state.done) {
      console.log('Final state reached, stopping the interpreter.');
      instance.stop(); // Stop the interpreter when the final state is reached
    }
  });
  const done = () => {
    return instance?.getSnapshot().done;
  };
  const serialize = (state: State<Context, MachineEvent> | undefined) =>
    state ? JSON.stringify(state) : '{}';
  const stop = () => instance.stop();
  const send = (event: MachineEvent, id?: string) => {
    if (id) {
      instance.send(event, { to: id });
    } else {
      instance.send(event);
    }
  };
  // if state is defined the machine will hydrate from where it left off as defined by the supplied state
  // for more an persisting state visit: https://xstate.js.org/docs/guides/states.html#persisting-state
  const start = () => {
    instance.start(state);
    if (state && retriggerEntryFunction) {
      // Manually invoke the entry actions for the starting state
      // The entry actions are not executed because XState interpreters treat instance.start()
      // when the next state to execute is determined by an LLM we need to manually invoke entry
      const startingStateConfig =
        machine.config?.states?.[state.value as string];
      if (
        startingStateConfig?.entry &&
        typeof startingStateConfig?.entry === 'function'
      ) {
        console.log(startingStateConfig.entry);
        (
          startingStateConfig.entry as (
            context: Context,
            event: MachineEvent
          ) => void
        )(state.context!, { type: 'xstate.init' });
      }
    }
  };
  const getContext = () => instance.getSnapshot().context;

  // TODO define an actual interface and think about what to expose
  return { done, serialize, stop, send, start, getContext };
}
````

## File: packages/x-reason/src/lib/orchestrator.v1.test.ts
````typescript
import { mockProgrammerResponse1 } from './__fixtures__/Gemini';
import { getState } from './orchestratorV1';
import { SupportedEngines, SupportTrainingDataTypes } from './factory';

import {
  machineId,
  machineId2,
  mockExecution,
  mockExecution2,
} from './__fixtures__/MachineExecutions';

jest.mock('@codestrap/developer-foundations-services-palantir', () => ({
  ...jest.requireActual('@codestrap/developer-foundations-services-palantir'),
  makeMemoryRecallDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeTrainingDataDao: jest.fn(() => ({
    upsert: jest.fn(),
    delete: jest.fn(),
    read: jest.fn((id: string) => {
      return {
        humanReview: 'this anser is good',
        isGood: true,
        machine: mockProgrammerResponse1,
        primaryKey_: '1234',
        solution: 'The task list',
        type: SupportTrainingDataTypes.PROGRAMMER,
        xReason: SupportedEngines.COMS,
      };
    }),
    search: jest.fn((xReason: string, type: string) => {
      return [
        {
          humanReview: 'this anser is good',
          isGood: true,
          machine: mockProgrammerResponse1,
          primaryKey_: '1234',
          solution: 'The task list',
          type: SupportTrainingDataTypes.PROGRAMMER,
          xReason: SupportedEngines.COMS,
        },
      ];
    }),
  })),
  makeMachineDao: jest.fn(() => ({
    upsert: jest.fn(),
    delete: jest.fn(),
    read: jest.fn((machineExecutionId: string) => {
      if (machineExecutionId === 'mock-execution-id') {
        return Promise.resolve(mockExecution);
      } else if (machineExecutionId === 'mock-execution-id2') {
        return Promise.resolve(mockExecution2);
      } else {
        return Promise.resolve(null); // or throw if you want stricter tests
      }
    }),
  })),
  makeContactsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
  })),
  makeUserDao: jest.fn(() => ({
    read: jest.fn(),
  })),
  makeCommsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeThreadsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeTicketsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeWorldDao: jest.fn(() => ({
    read: jest.fn(),
  })),
  geminiService: jest.fn(() => {
    return mockProgrammerResponse1;
  }),
}));

jest.mock('@codestrap/developer-foundations-services-rangr', () => ({
  createRangrClient: jest.fn(() => ({
    someMethod: jest.fn(),
  })),
  makeRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
  makeRangrRfpRequestsDao: jest.fn(() => ({
    search: jest.fn(),
    read: jest.fn(),
    upsert: jest.fn(),
  })),
}));

let counter = 0;

jest.mock('@codestrap/developer-foundations-utils', () => ({
  ...jest.requireActual('@codestrap/developer-foundations-utils'),
  uuidv4: jest.fn(() => (++counter).toString()),
}));

jest.mock('./functions', () => ({
  ...jest.requireActual('./functions'),
  sendEmail: jest.fn().mockImplementation(() => {
    const { mockEmailResponse } = require('./__fixtures__/Email');
    return Promise.resolve(mockEmailResponse);
  }),
}));

// Mock fetch globally since it's used in SendSlackMessage
global.fetch = jest.fn().mockImplementation(() =>
  Promise.resolve({
    ok: true,
    json: () =>
      Promise.resolve({
        ok: true,
        channel: 'test-channel',
        ts: '1234567890.123456',
      }),
  })
) as jest.Mock;

describe('testing orchestrator', () => {
  afterAll(() => {
    jest.clearAllMocks();
  });

  it('it should rehydrate an existing execution, move forward, and save', async () => {
    const solution = {
      input: '', //not relevant for this
      id: machineId || '',
      plan: '', //not relevant for retrieving an execution
    };

    //we don't need to test interpolation in this test case, but leaving here to help facilitate testing that
    const valuesToInterpolateOntoContext = {};

    const result = await getState(
      solution,
      true,
      valuesToInterpolateOntoContext,
      SupportedEngines.COMS
    );
    const state = JSON.parse(result.jsonState);

    expect(state.value).toBe('success');
    expect(state.context.stack).toHaveLength(4);
    expect(state.context.stack[0]).toBe('sendEmail|2');
  });

  it('it should rehydrate an existing execution, move backward, and save', async () => {
    const solution = {
      input: '', //not relevant for this
      // note machineId2 starts on the second state: sendSlackMessage
      id: machineId2 || '',
      plan: '', //not relevant for retrieving an execution
    };

    //we don't need to test interpolation in this test case, but leaving here to help facilitate testing that
    const valuesToInterpolateOntoContext = {};

    const result = await getState(
      solution,
      false,
      valuesToInterpolateOntoContext,
      SupportedEngines.COMS
    );
    const state = JSON.parse(result.jsonState);

    expect(state.value).toBe(
      'scheduleMeeting|7f8824d7-bb8e-4bb3-a820-5ab9e7dc6533'
    );
    expect(state.context.stack).toHaveLength(16);
    expect(state.context.stack[0]).toBe(
      'getAvailableMeetingTimes|ba26e192-9a5c-4c34-8a9c-c4a7a4567152'
    );
  });

  it('it should create a new machine, move forward, and save', async () => {
    const solution = {
      input: '', //not relevant for this
      id: '',
      plan: `1. **Send Email** - **To**: Mike Johnson <mike.johnson@example.com> - **Subject**: Follow-up on Marketing Plan - **Body**: "Hi Mike, following up on the recent discussion about the marketing plan. Please review the points raised by Sarah Lee <sarah.lee@example.com> and David Brown <david.brown@example.com>. Let me know if you need any further input. Best, Cody the AI Assistant"`, //not relevant for retrieving an execution
    };

    //we don't need to test interpolation in this test case, but leaving here to help facilitate testing that
    const valuesToInterpolateOntoContext = {};

    const result = await getState(
      solution,
      true,
      valuesToInterpolateOntoContext,
      SupportedEngines.COMS
    );
    const state = JSON.parse(result.jsonState);
    expect(state.value).toBe('success');
    expect(state.context.stack).toHaveLength(2);
    expect(state.context.stack[0]).toBe('sendEmail|13');
    expect(state.context.stack[1]).toBe('success');
  });
});
````

## File: packages/x-reason/src/lib/orchestratorV1.ts
````typescript
import { State } from 'xstate';

import { xReasonFactory, SupportedEngines } from './factory';
import {
  headlessInterpreter,
  engineV1 as engine,
} from '@codestrap/developer-foundations-x-reason';
import {
  sanitizeJSONString,
  uuidv4,
} from '@codestrap/developer-foundations-utils';
import {
  Solutions,
  ActionType,
  Context,
  MachineEvent,
  LoggingService,
  MachineDao,
  MachineExecutions,
  TYPES,
  StateConfig,
} from '@codestrap/developer-foundations-types';
import { container } from '@codestrap/developer-foundations-di';


export async function getState(
  solution: Solutions,
  forward = true,
  workflow?: Record<string, any>,
  xreason: SupportedEngines = SupportedEngines.COMS
) {
  const { programmer, aiTransition, evaluate, functionCatalog } = xReasonFactory(xreason)({});
  let currentState: State<Context, MachineEvent> | undefined;

  const dispatch = (action: ActionType) => {
    console.log(`route dispatch callback called`);
    switch (action.type) {
      case "SET_STATE":
        currentState = action.value?.currentState as State<
          Context,
          MachineEvent
        >;
        break;
    }
  };

  const sendProxy = (action: ActionType) => {
    send(action, action.payload?.stateId as string);
  };

  const functions = functionCatalog(sendProxy);

  const toolsCatalog = Array.from(functions.entries()).map((item) => {
    return [item[0], { description: item[1].description }];
  });

  const { getLog, log } = container.get<LoggingService>(TYPES.LoggingService);

  // retrieve previous execution if there was one
  const machineDao = container.get<MachineDao>(TYPES.MachineDao);
  let execution: undefined | MachineExecutions = undefined;

  try {
    execution = await machineDao.read(solution.id);
  } catch (e) {
    const error = (e as Error);

    log(solution.id, `machineDao.read returned the following error:\n${error.message}\n${error.stack}`);
    console.log(e);
  }

  const machine: StateConfig[] =
    execution && execution.machine ? JSON.parse(execution.machine) : undefined;
  const stateDefinition =
    execution && execution.state ? JSON.parse(execution.state) : undefined;
  // setup a default context
  let inputContext: Context = {
    requestId: uuidv4(),
    machineExecutionId: solution.id,
    status: 0,
    solution: sanitizeJSONString(solution.plan),
    stack: [],
    ...workflow,//capture any incoming updates from the UI Layer
  };

  // if a state definition is defined we want to use it and transfer the updated state to it
  if (stateDefinition) {
    inputContext = stateDefinition.context;
    // Map the values passed by the consumer onto the context.
    if (workflow) {
      const keys = Object.keys(workflow);
      keys.forEach((key) => {
        // we use destructing to preserve existing values not in the workflow params
        stateDefinition.context[key] = { ...stateDefinition.context[key], ...workflow[key] };
      });
    }
  }

  // get the last state visited in the stack to find where we left off on the previous run
  //stateDefinition?.context?.stack?.[stateDefinition.context.stack.length-1]
  const savePoint =
    stateDefinition?.context?.stack?.[
    stateDefinition?.context?.stack.length - 1
    ];
  const previousState =
    stateDefinition?.context?.stack?.[
    stateDefinition?.context?.stack.length - 2
    ];

  if (forward && savePoint && stateDefinition && savePoint !== stateDefinition.value) {
    log(solution.id, `resetting stateDefinition.value from ${stateDefinition.value} to ${savePoint}`);
    console.log(
      `resetting stateDefinition.value from ${stateDefinition.value} to ${savePoint}`
    );

    stateDefinition.value = savePoint;
  } else if (
    !forward &&
    previousState &&
    stateDefinition &&
    previousState !== stateDefinition.value
  ) {
    console.log(
      `resetting stateDefinition.value from ${stateDefinition.value} to ${previousState}`
    );
    log(solution.id, `resetting stateDefinition.value from ${stateDefinition.value} to ${previousState}`);

    stateDefinition.value = previousState;
    // remove the last element of the stack
    stateDefinition?.context?.stack?.pop();
  }

  if (!forward && stateDefinition) {
    // stateDefinition must be defined in these cases or you should get an error
    const targetState: State<Context, MachineEvent> = State.create<Context, MachineEvent>(stateDefinition);

    // if we are not moving forward we do not want to rerun the machine or effect its state
    // we just want to return the previous state and let the consumer execute by calling next
    const context = targetState.context;
    const jsonState = JSON.stringify(targetState);

    log(solution.id, `moving backward, returning previous state of ${targetState.value}`);
    console.log(`moving backward, returning previous state of ${targetState.value}`);

    return {
      stateMachine: machine,
      // hard code the evaluation result since this is for a previous execution
      evaluationResult: { rating: 5, correct: true },
      context,
      jsonState,
    };
  }

  let startingState: State<Context, MachineEvent> | undefined = stateDefinition ? State.create<Context, MachineEvent>(stateDefinition) : undefined;

  const programmedState = machine?.find(
    (value) => value.id === startingState?.value
  );

  if (stateDefinition && startingState) {
    startingState = State.create<Context, MachineEvent>(stateDefinition)

    if (programmedState?.includesLogic) {
      // Use an LLM to figure out what the next state should be based on the login in the last list and the current state of the machine
      // Structured outputs could be very useful here to restrict acceptable state output values to a enum based on the functions catalog id values
      // not sure if Foundry supports structured outputs yet or not
      const nextState = await engine.logic.transition(
        solution.plan,
        JSON.stringify(programmedState),
        JSON.stringify(stateDefinition.context),
        aiTransition,
        solution.id
      );

      log(solution.id, `The AI transition returned the target state of: ${nextState}`);
      console.log(`resetting the starting state to: ${nextState}`);
      // Create a new State object with the updated value
      startingState = State.create<Context, MachineEvent>({
        value: nextState, // The new state value returned by the AI model
        context: stateDefinition.context, // Preserve the existing context
        history: startingState.history, // Preserve history if needed
        actions: startingState.actions, // Preserve actions if needed
        activities: startingState.activities, // Preserve activities if needed
        meta: startingState.meta, // Preserve meta if needed
        events: startingState.events, // Preserve events if needed
        configuration: startingState.configuration, // Preserve configuration if needed
        // Required properties for StateConfig
        _event: startingState._event || { type: '' }, // Default _event if not available
        _sessionid: startingState._sessionid || null, // Default _sessionid if not available
        transitions: startingState.transitions || [], // Default transitions if not available
        children: startingState.children || {}, // Default children if not available
      });
    }
  }

  // generate the program
  const result: StateConfig[] = machine
    ? machine
    : await engine.programmer.program(
      solution.plan,
      JSON.stringify(Array.from(toolsCatalog.entries())),
      programmer
    );
  // evaluate the generated program. Currently, this just checks if the machine compiles
  // in the future we will use specially trained evaluation models
  const evaluationResult = await engine.evaluator.evaluate(
    {
      query: `${solution.plan}\n${result}`,
      states: result,
      tools: functions,
    },
    evaluate
  );
  if (!evaluationResult.correct) {
    throw (
      evaluationResult.error ||
      new Error("The provided solution failed evaluation")
    );
  }

  const { done, start, send, getContext, serialize } = headlessInterpreter(
    result,
    functions,
    dispatch,
    inputContext,
    startingState,
    // if the programmed state includes logic we need to manually trigger state execution
    programmedState?.includesLogic ?? false
  );

  log(solution.id, `calling start on the machine with starting state of: ${startingState?.value}`);
  console.log(`calling start on the machine with starting state of: ${startingState?.value}`);

  start();

  if (stateDefinition && startingState && (programmedState?.includesLogic ?? false) === false) {
    // manually advance the machine if we did not use an LLM to advance the machine to a target state
    // if we don't do this the machine will stay stuck on the current state 
    send({ type: 'CONTINUE' });
  }

  let iterations = 0;
  // this effectively acts as a timeout. Be sure to adjust if you have long running functions in your states!
  const MAX_ITERATIONS = 60;
  while (!done() && iterations < MAX_ITERATIONS) {
    await new Promise((resolve) => setTimeout(resolve, 1000));

    log(solution.id, `awaiting results`);
    console.log("awaiting results");

    iterations++;
  }

  if (iterations >= MAX_ITERATIONS) {
    console.warn("Exceeded maximum iterations while awaiting results.");
  }

  const context = getContext();
  const jsonState = serialize(currentState);

  return {
    stateMachine: result,
    evaluationResult,
    context,
    jsonState,
    logs: getLog(solution.id),
  };
}
````

## File: packages/x-reason/src/lib/programmer.test.ts
````typescript
import { interpret } from 'xstate';
import {
  Context,
  MachineEvent,
  Task,
} from '@codestrap/developer-foundations-types';
import programV1 from './programmerV1';
import {
  getFunctionCatalog,
  stateConfigArray,
  stateConfigResolvePastStates,
} from './__fixtures__/Programmer';

let counter = 0;

// Mock the uuid utility to prevent issues with uuid generation
jest.mock('@codestrap/developer-foundations-utils', () => {
  const actualUtils = jest.requireActual(
    '@codestrap/developer-foundations-utils'
  );
  return {
    ...actualUtils,
    uuidv4: jest.fn(() => (++counter).toString()),
    // Let getUniqueStateIds use the actual implementation but with mocked uuidv4
    getUniqueStateIds: actualUtils.getUniqueStateIds,
  };
});

describe('Testing Programmer', () => {
  afterAll(() => {
    jest.clearAllMocks();
  });

  test('Test the programV1 function passing state nodes array', async () => {
    // TODO refactor this to use the headless interpreter when it's done
    return new Promise((resolve, reject) => {
      const sampleCatalog = new Map<string, Task>([
        [
          'RecallSolutions',
          {
            description:
              'Recalls a smilar solution to the user query. If a solution is found it will set the existingSolutionFound attribute of the event params to true: `event.payload?.params.existingSolutionFound`',
            implementation: (context: Context, event?: MachineEvent) => {
              console.log('RecallSolutions implementation called');
              machineExecution.send({
                type: 'CONTINUE',
                payload: { RecallSolutions: undefined },
              });
            },
          },
        ],
        [
          'GenerateIngredientsList',
          {
            description:
              'Generates a list of ingredients for a product formula',
            // this is an example of how you can render a component while the implementation function executes
            implementation: (context: Context, event?: MachineEvent) => {
              console.log('GenerateIngredientsList implementation called');
              machineExecution.send({
                type: 'CONTINUE',
                payload: { GenerateIngredientsList: [] },
              });
            },
          },
        ],
        [
          'IngredientDatabase',
          {
            description:
              'Maintain a comprehensive database of cosmetic ingredients, their properties, potential combinations, and effects. This database includes natural and synthetic ingredients, their usual concentrations in products, and regulatory information.',
            implementation: (context: Context, event?: MachineEvent) => {
              const currentList = context.GenerateIngredientsList || [];
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  IngredientDatabase: [
                    ...currentList,
                    ['Bee Wax 1234 Special Proprietary', '30%', 'A'],
                  ],
                },
              });
            },
            transitions: new Map<
              'CONTINUE' | 'ERROR',
              (context: Context, event: MachineEvent) => boolean
            >([
              [
                'CONTINUE',
                // this is an example of a deterministic function that is invoked as part of evaluating transitions
                // it can do whatever you like and take into account the current state of the world found on the context
                // The results of the implementation function should be include included in the payload of the incoming event
                // in this case payload.IngredientDatabase
                (context: Context, event: MachineEvent) =>
                  event.payload?.IngredientDatabase?.length > 0,
              ],
            ]),
          },
        ],
        [
          'RegulatoryCheck',
          {
            description:
              'Ensure that the predicted formula adheres to relevant cosmetic regulations and standards. If this function has an error it will set `context.regulatoryChecksSuccess` to false.',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: { RegulatoryCheck: 'no regulatory issues were found' },
              });
            },
          },
        ],
        [
          'ConcentrationEstimation',
          {
            description:
              'Estimate the concentration of each ingredient based on standard industry practices, known effects, and regulatory limits. If this function has an error it will set `context.concentrationEstimationSuccess` to false.',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  ConcentrationEstimation: [
                    ['ingredient', 'tolerance%'],
                    ['Bee Wax', '30-31%'],
                    ['Coconut Oil', '40-45%'],
                    ['Tree Resin', '20-21%%'],
                  ],
                },
              });
            },
          },
        ],
        [
          'FormulationSimulation',
          {
            description:
              'Use simulation models to predict how different ingredients interact. This includes stability, texture, and efficacy simulations.',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  FormulationSimulation: 'no available simulations were found',
                },
              });
            },
          },
        ],
        [
          'ExpertReview',
          {
            description:
              'Have cosmetic chemists review the proposed formula for feasibility and safety.',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  ExpertReview: 'Certified by Dorian Smiley on 2/2/24',
                },
              });
            },
          },
        ],
        [
          'LabTesting',
          {
            description:
              'Test the proposed formula in a laboratory setting to verify its properties and efficacy.',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: { LabTesting: 'Certified by Dorian Smiley on 2/2/24' },
              });
            },
          },
        ],
        [
          'Evaluation',
          {
            description:
              'Evaluates a generated product formula and rates the result',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: { Evaluation: 0.95 },
              });
            },
          },
        ],
        [
          'ManufacturingInstructions',
          {
            description:
              'Generate the manufacturing steps for a tested and evaluated formula',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: { ManufacturingInstructions: 'The steps are...' },
              });
            },
          },
        ],
        [
          'MarketResearch',
          {
            description: 'Performs market research for the new product',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: { MarketResearch: 'You market is as follows...' },
              });
            },
          },
        ],
        [
          'CreateMarketing',
          {
            description: 'Generates a product description for target customers',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  CreateMarketing: 'Here is your marketing claims...',
                },
              });
            },
          },
        ],
        [
          'GenerateProductImage',
          {
            description:
              'generates a product image using the generated product description',
            implementation: (context: Context, event?: MachineEvent) => {
              machineExecution.send({
                type: 'CONTINUE',
                payload: { GenerateProductImage: 'https://someurl.com' },
              });
            },
          },
        ],
        [
          'UnsupportedQuestion',
          {
            description: 'Default state to display for unsupported questions',
            implementation: (context: Context, event?: MachineEvent) => {
              console.log('UnsupportedQuestion implementation called');
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  UnsupportedQuestion:
                    'UnsupportedQuestion implementation called',
                },
              });
            },
          },
        ],
        [
          'UnsafeQuestion',
          {
            description: 'Default state to display for unsafe questions',
            implementation: (context: Context, event?: MachineEvent) => {
              console.log('UnsafeQuestion implementation called');
              machineExecution.send({
                type: 'CONTINUE',
                payload: {
                  UnsafeQuestion: 'UnsafeQuestion implementation called',
                },
              });
            },
          },
        ],
      ]);

      const result = programV1(stateConfigArray, sampleCatalog);

      const withContext = result.withContext({
        status: 0,
        requestId: 'test',
        stack: [],
      });

      const machineExecution = interpret(withContext).onTransition((state) => {
        const type =
          machineExecution.machine.states[state.value as string]?.meta?.type;

        switch (state.value) {
          case 'success': {
            // Test the structure and key properties instead of exact UUID values
            expect(state.context.status).toBe(0);
            expect(state.context.requestId).toBe('test');
            expect(state.context.stack?.length).toBe(7);
            expect(state.context.stack?.[6]).toBe('success');
            expect(state.context.GenerateIngredientsList).toEqual([]);
            expect(state.context.IngredientDatabase).toEqual([
              ['Bee Wax 1234 Special Proprietary', '30%', 'A'],
            ]);
            expect(state.context.FormulationSimulation).toBe(
              'no available simulations were found'
            );

            // Verify that stack contains expected state names (ignoring UUIDs)
            const stackStateNames = state.context.stack?.map(
              (item) => item.split('|')[0]
            );
            expect(stackStateNames).toEqual([
              'RecallSolutions',
              'GenerateIngredientsList',
              'IngredientDatabase',
              'RegulatoryCheck',
              'ConcentrationEstimation',
              'FormulationSimulation',
              'success',
            ]);

            resolve('success');
            break;
          }
          case 'failure':
            // TODO error reporting
            reject(state.context);
            break;
        }
      });

      machineExecution.start();
    });
  });

  test('Test the programV1 function passing state nodes array that requires resolving a transition target that occurred in the past, in this case getAvailableMeetingTimes', async () => {
    return new Promise((resolve, reject) => {
      const dispatch = (action: any) => {
        console.log(`dispatch called with: ${action}`);
        machineExecution.send({
          type: 'CONTINUE',
          payload: {},
        });
      };

      const functionCatalog = getFunctionCatalog(dispatch);

      const result = programV1(stateConfigResolvePastStates, functionCatalog);

      const withContext = result.withContext({
        status: 0,
        requestId: 'test',
        stack: [],
      });

      const machineExecution = interpret(withContext).onTransition((state) => {
        const type =
          machineExecution.machine.states[state.value as string]?.meta?.type;

        switch (state.value) {
          case 'success': {
            // note our stub functions do not do anything for this test but call continue, hence the much simpler results
            expect(state.context.status).toBe(0);
            expect(state.context.requestId).toBe('test');
            expect(state.context.stack?.length).toBe(3);
            expect(state.context.stack?.[2]).toBe('success');

            // Verify that stack contains expected state names (ignoring UUIDs)
            const stackStateNames = state.context.stack?.map(
              (item) => item.split('|')[0]
            );
            expect(stackStateNames).toEqual([
              'getAvailableMeetingTimes',
              'scheduleMeeting',
              'success',
            ]);

            resolve('success');
            break;
          }
          case 'failure':
            // TODO error reporting
            reject(state.context);
            break;
        }
      });

      machineExecution.start();
    });
  });
  // TODO add more tests including testing for conditionals
});
````

## File: packages/x-reason/src/lib/programmerV1.ts
````typescript
import { createMachine, assign, StateNode, MachineConfig } from 'xstate';
import {
  getUniqueStateIds,
  uuidv4,
} from '@codestrap/developer-foundations-utils';

import {
  Context,
  MachineEvent,
  StateConfig,
  Task,
  Transition,
} from '@codestrap/developer-foundations-types';

function getTransition(
  transition: { target: string; cond?: string; actions?: string },
  task: Task,
  transitionEvent: 'CONTINUE' | 'ERROR'
) {
  const transitionConfig: any = {
    target: transition.target,
    actions: transition.actions || 'saveResult',
  };
  const genericStateId = transition.target.split('|')[0];
  // if there is a transition guard defined to this Task add a condition for the transition
  // guards can either be generic, ie for all CONTINUE or ERROR events, or for specific targets delineated cia a |
  // for example CONTINUE which would be triggered for all CONTINUE events
  // or CONTINUE|scheduleMeeting which would be specific to transition.target === 'scheduleMeeting'
  if (task.transitions?.get(transitionEvent)) {
    transitionConfig.cond = (context: Context, event: MachineEvent) => {
      // TODO improve this by using a function supplied by the function catalog which can either be
      // a classical algorithm or a call to an LLM that returns true or false
      return (task.transitions as Transition).get(transitionEvent)!(
        context,
        event
      );
    };
  } else if (task.transitions?.get(`${transitionEvent}|${genericStateId}`)) {
    transitionConfig.cond = (context: Context, event: MachineEvent) => {
      // TODO improve this by using a function supplied by the function catalog which can either be
      // a classical algorithm or a call to an LLM that returns true or false
      return (task.transitions as Transition).get(
        `${transitionEvent}|${genericStateId}`
      )!(context, event);
    };
  }

  return transitionConfig;
}

function generateStateConfig(
  state: StateConfig,
  functionCatalog: Map<string, Task>,
  context: Context,
  parallel = false,
  isNestedState = false
): Partial<StateNode<Context, any, MachineEvent>> {
  if (parallel) {
    const stateConfig: any = {};
    stateConfig.type = 'parallel';
    stateConfig.states = {};
    stateConfig.id = state.id;
    stateConfig.onDone = state.onDone; // TODO have to find the target
    state.states?.forEach((state) => {
      if (
        state.id !== 'success' &&
        state.id !== 'failure' &&
        state.id !== 'pause'
      ) {
        stateConfig.states[state.id] = {
          initial: 'pending',
          id: state.id,
          states: {
            pending: generateStateConfig(
              state,
              functionCatalog,
              context,
              false,
              true
            ),
            success: {
              type: 'final',
            },
            failure: {
              type: 'final',
            },
            pause: {
              type: 'final',
            },
          },
        };
      }
    });

    return stateConfig;
  }

  if (state.parentId) {
    context.childToParentStateMap[state.id] = state.parentId;
  }

  const functionName = state.id.split('|')?.[0];
  if (state.type === 'final') {
    return {
      // for some reason the entry property is not defined when we return here
      // we have to manuall push the final state onto the stack so the next state is correctly returned
      // TODO: fix me
      // eslint-disable-next-line @typescript-eslint/ban-ts-comment
      // @ts-expect-error
      entry: (context: Context, event: MachineEvent) => {
        console.log('Received Event:', event.type);
        context.stack?.push(state.id);
      },
      type: state.type,
    };
  }

  const retrievedFunction = functionCatalog.get(functionName);
  if (!retrievedFunction) {
    throw new Error(
      `function implementation for stateId: ${state.id} functionName: ${functionName} not found`
    );
  }

  const stateConfig: any = !isNestedState
    ? {
        entry: (context: Context, event: MachineEvent) => {
          console.log('Received Event:', event.type);
          context.stack?.push(state.id);
          // if the function is async, we ignore the promise as this is fire and forget.
          // it's up to the function to dispatch the CONTINUE event on the machine to capture results
          // in the vent payload and continue execution
          console.log('Executing function:', functionName);
          retrievedFunction.implementation(context, event, state.task);
        },
      }
    : {
        invoke: {
          src: async (context: Context, event: MachineEvent) => {
            console.log('Received Event:', event.type);
            context.stack?.push(state.id);
            // if the function is async, we ignore the promise as this is fire and forget.
            // it's up to the function to dispatch the CONTINUE event on the machine to capture results
            // in the vent payload and continue execution
            console.log('Executing nested state function:', functionName);
            const result = await retrievedFunction.implementation(
              context,
              event,
              state.task
            );
            console.log(
              `received result from nested state function: ${result}`
            );
            const returnValue = {
              stateId: state.id,
              [state.id]: {
                // we destructure to preserve other keys like result which holds values from user interaction
                ...context[state.id],
                ...(result as any),
              },
            };
            return returnValue;
          },
          onDone: {
            target: 'success',
            actions: 'saveResult',
          },
          onError: {
            target: 'failure',
          },
        },
      };

  stateConfig.id = state.id;
  // TODO augment with retrievedFunction.transitions.
  if (state.transitions && !isNestedState) {
    // we add these transtiions for states that require callbacks
    // ie sagas, wait for external system to call back in and resume excecution
    // in these cases a state with distach success or failure
    stateConfig.on = {
      pause: {
        target: 'pause',
        actions: 'saveResult',
      },
      success: {
        target: 'success',
        actions: 'saveResult',
      },
      failure: {
        target: 'failure',
        actions: 'saveResult',
      },
    };
    // we add stateConfig.on[transition.target] to support dynamic transitions added by the LLM
    // The LLM will determine which event to dispatch
    state.transitions
      .filter((transition) => transition.on === 'CONTINUE')
      .forEach((transition) => {
        stateConfig.on[transition.target] = {
          target: transition.target,
          actions: transition.actions || 'saveResult',
        };
      });
    // we add these transitions so than non dynamic transitions still work
    stateConfig.on.CONTINUE = state.transitions
      .filter((transition) => transition.on === 'CONTINUE')
      .map((transition) =>
        getTransition(transition, retrievedFunction, 'CONTINUE')
      );
    stateConfig.on.ERROR = state.transitions
      .filter((transition) => transition.on === 'ERROR')
      .map((transition) =>
        getTransition(transition, retrievedFunction, 'ERROR')
      );
  }

  // sort the array such that any transition with a conditional statement appears first
  // this ensures logic is evaulauted
  stateConfig.on?.CONTINUE?.sort((a: any, b: any) => {
    const aHasCond = typeof a.cond !== 'undefined';
    const bHasCond = typeof b.cond !== 'undefined';

    if (aHasCond && !bHasCond) return -1;
    if (!aHasCond && bHasCond) return 1;
    return 0;
  });

  return stateConfig;
}

function generateStateMachineConfig(
  statesArray: StateConfig[],
  functionCatalog: Map<string, Task>
) {
  const states: {
    [key: string]: Partial<StateNode<Context, any, MachineEvent>>;
  } = {
    // pause is a special state that allows functions to dispatch pause event that will not show up in the stack
    // this allows for the machine to progress through the states and pause when needed
    pause: { type: 'final' },
  };

  const context = {
    requestId: uuidv4(), // Replace with actual uniqueId function
    status: 0,
    childToParentStateMap: {},
    // ... other context properties
  };

  // deduplicate the states and trasitions
  const deduplicatedStates = getUniqueStateIds(statesArray);

  deduplicatedStates.forEach((state) => {
    states[state.id] = generateStateConfig(
      state,
      functionCatalog,
      context,
      state.type === 'parallel'
    );
  });

  return {
    id: uuidv4(),
    predictableActionArguments: true,
    initial: deduplicatedStates[0]?.id,
    context,
    states,
  };
}

function program(
  statesArray: StateConfig[],
  functionCatalog: Map<string, Task>
) {
  const states = generateStateMachineConfig(
    statesArray,
    functionCatalog
  ) as MachineConfig<Context, any, MachineEvent>;
  return createMachine<Context, MachineEvent>(states, {
    actions: {
      saveResult: assign((context, event) => {
        const data = event.payload ?? event.data;
        // IMPORTANT: it's up to the caller to set status to -1 to trigger errors
        // we can work on improving this in the future
        return {
          ...context,
          ...data,
        };
      }),
    },
  });
}

export default program;
````

## File: packages/x-reason/src/index.ts
````typescript
export { default as engineV1 } from './lib/engineV1';
export { default as programV1 } from './lib/programmerV1';
export { default as headlessInterpreter } from './lib/interpreterV1Headless';
export * from './lib/orchestratorV1';
export * from './lib/factory';
export * from './lib/functions';
export * from './lib/reasoning';
````

## File: packages/x-reason/src/process-env.d.ts
````typescript
import { SupportedFoundryClients } from "@codestrap/developer-foundations-types";

// process-env.d.ts
declare global {
    namespace NodeJS {
        interface ProcessEnv {
            FOUNDRY_STACK_URL: string;
            FOUNDRY_TOKEN: string;
            FOUNDRY_TEST_USER: string;
            OSDK_CLIENT_ID: string;
            OSDK_CLIENT_SECRET: string;
            OPEN_WEATHER_API_KEY: string;
            LOG_PREFIX: string;
            ONTOLOGY_RID: string;
            ONTOLOGY_ID: string;
            GOOGLE_SEARCH_API_KEY: string;
            GOOGLE_SEARCH_ENGINE_ID: string;
            GOOGLE_SEARCH_ENGINE_MARKETS: string;
            GEMINI_API_KEY: string;
            BROWSERFY_KEY: string;
            BROWSERFY_BROWSER_URL: string;
            RANGR_OSDK_CLIENT_ID: string;
            RANGR_OSDK_CLIENT_SECRET: string;
            RANGR_FOUNDRY_STACK_URL: string;
            RANGR_ONTOLOGY_RID: string;
            OFFICE_SERVICE_ACCOUNT: string;
            OPEN_AI_KEY: string;
            SLACK_CLIENT_ID: string;
            SLACK_CLIENT_SECRET: string;
            SLACK_SIGNING_SECRET: string;
            SLACK_BOT_TOKEN: string;
            SLACK_APP_TOKEN: string;
            SLACK_BASE_URL: string;
            REDIRECT_URL: string;
            FOUNDRY_CLIENT_TYPE: SupportedFoundryClients;
        }
    }
}
export { };
````

## File: packages/x-reason/.env.sample
````
FOUNDRY_STACK_URL=https://someurl.palantirfoundry.com
FOUNDRY_TEST_USER=someUserId
OSDK_CLIENT_SECRET=someSecretId
OSDK_CLIENT_ID=someClientId
OPEN_WEATHER_API_KEY=84910d444fb81a1ee9d48dd75ff5819e
LOG_PREFIX=foundry-developer-foundations-x-reason
ONTOLOGY_RID=ri.ontology.main.ontology.89c90752-177d-45ee-baf9-f4f2d2660316
ONTOLOGY_ID=ontology-a0c8a327-cd0a-4f69-a575-b0398c04b74c
GOOGLE_SEARCH_API_KEY=someSearchKey
GOOGLE_SEARCH_ENGINE_ID=someEngineId
GOOGLE_SEARCH_ENGINE_MARKETS=someMarketIds
GEMINI_API_KEY=someKey
RANGR_OSDK_CLIENT_ID=someId
RANGR_OSDK_CLIENT_SECRET=someSecret
RANGR_FOUNDRY_STACK_URL=https://someUrl.palantirfoundry.com
RANGR_ONTOLOGY_RID=ri.ontology.main.ontology.a47cc7f3-2b7b-4be8-b8b9-e57fe78af24c
OFFICE_SERVICE_ACCOUNT='email@someUrl'
OPEN_AI_KEY=someKey
SLACK_CLIENT_ID=someKey
SLACK_CLIENT_SECRET=someKey
SLACK_SIGNING_SECRET=someKey
SLACK_BOT_TOKEN=someKey
SLACK_APP_TOKEN=someKey
SLACK_BASE_URL=https://slack.com/api
GSUITE_SERVICE_ACCOUNT="eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwicHJvamVjdF9pZCI6ImZvdW5kcnktY29tcy1mb3VuZGF0aW9ucyIsInByaXZhdGVfa2V5X2lkIjoiMTIzNCIsInByaXZhdGVfa2V5IjoiLS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tXG41Njc4XG4tLS0tLUVORCBQUklWQVRFIEtFWS0tLS0tXG4iLCJjbGllbnRfZW1haWwiOiJtZUBtZS5pYW0uZ3NlcnZpY2VhY2NvdW50LmNvbSIsImNsaWVudF9pZCI6IjEyOTM4OTMiLCJhdXRoX3VyaSI6Imh0dHBzOi8vYWNjb3VudHMuZ29vZ2xlLmNvbS9vL29hdXRoMi9hdXRoIiwidG9rZW5fdXJpIjoiaHR0cHM6Ly9vYXV0aDIuZ29vZ2xlYXBpcy5jb20vdG9rZW4iLCJhdXRoX3Byb3ZpZGVyX3g1MDlfY2VydF91cmwiOiJodHRwczovL3d3dy5nb29nbGVhcGlzLmNvbS9vYXV0aDIvdjEvY2VydHMiLCJjbGllbnRfeDUwOV9jZXJ0X3VybCI6Imh0dHBzOi8vd3d3Lmdvb2dsZWFwaXMuY29tL3JvYm90L3YxL21ldGFkYXRhL3g1MDkvZm91bmRyeS1jb21zLWZvdW5kYXRpb25zJTQwZm91bmRyeS1jb21zLWZvdW5kYXRpb25zLmlhbS5nc2VydmljZWFjY291bnQuY29tIiwidW5pdmVyc2VfZG9tYWluIjoiZ29vZ2xlYXBpcy5jb20ifQ=="
EIA_API_KEY="4bCgBshgInqayafNBbq70iHuRRwMYMmEtNdC9tTx"
EIA_BASE_URL="https://api.eia.gov/v2/petroleum/pri/gnd/data/"
CA_SERIES_ID="EMM_EPMR_PTE_SCA_DPG"
FIRECRAWL_API_KEY=<api_key>
````

## File: packages/x-reason/eslint.config.mjs
````
import baseConfig from '../../eslint.config.mjs';

export default [
  ...baseConfig,
  {
    files: ['**/*.json'],
    rules: {
      '@nx/dependency-checks': [
        'error',
        {
          ignoredFiles: ['{projectRoot}/eslint.config.{js,cjs,mjs,ts,cts,mts}'],
        },
      ],
    },
    languageOptions: {
      parser: await import('jsonc-eslint-parser'),
    },
  },
];
````

## File: packages/x-reason/jest.config.ts
````typescript
export default {
  displayName: 'x-reason',
  preset: '../../jest.preset.js',
  testEnvironment: 'node',
  transform: {
    '^.+\\.[tj]s$': [
      'ts-jest',
      {
        tsconfig: '<rootDir>/tsconfig.spec.json',
        useESM: true,
      },
    ],
  },
  moduleFileExtensions: ['ts', 'js', 'html'],
  coverageDirectory: '../../coverage/packages/x-reason',
  transformIgnorePatterns: ['/node_modules/(?!(?:@osdk|@codestrap)/)'],
  extensionsToTreatAsEsm: ['.ts'],
  testPathIgnorePatterns: ['<rootDir>/dist/'],
  moduleNameMapper: {
    // Strip `.js` from your TS imports so ESM paths resolve
    '^(\\.{1,2}/.*)\\.js$': '$1',
    '^@osdk/shared\\.client$':
      '<rootDir>/../../node_modules/@osdk/shared.client/index.js',
    '^@osdk/shared\\.client2$':
      '<rootDir>/../../node_modules/@osdk/shared.client2/index.js',
  },
};
````

## File: packages/x-reason/package.json
````json
{
  "name": "@codestrap/developer-foundations-x-reason",
  "version": "0.0.1",
  "type": "commonjs",
  "main": "./src/index.js",
  "types": "./src/index.d.ts",
  "publishConfig": {
    "access": "public"
  },
  "dependencies": {
    "xstate": "4.37.2",
    "@codestrap/developer-foundations-types": "*",
    "@codestrap/developer-foundations-utils": "*",
    "@codestrap/developer-foundations-di": "*",
    "@osdk/client": "^2.2.1",
    "@osdk/foundry.admin": "^2.22.0",
    "@osdk/oauth": "^1.1.2",
    "tslib": "^2.3.0"
  }
}
````

## File: packages/x-reason/project.json
````json
{
  "name": "x-reason",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "sourceRoot": "packages/x-reason/src",
  "projectType": "library",
  "release": {
    "version": {
      "manifestRootsToUpdate": ["dist/{projectRoot}"],
      "currentVersionResolver": "git-tag",
      "fallbackCurrentVersionResolver": "disk"
    }
  },
  "tags": ["type:platform"],
  "targets": {
    "build": {
      "executor": "@nx/js:tsc",
      "outputs": ["{options.outputPath}"],
      "options": {
        "outputPath": "dist/packages/x-reason",
        "main": "packages/x-reason/src/index.ts",
        "tsConfig": "packages/x-reason/tsconfig.lib.json",
        "assets": ["packages/x-reason/*.md"]
      }
    },
    "nx-release-publish": {
      "options": {
        "packageRoot": "dist/{projectRoot}"
      }
    },
    "test": {
      "executor": "@nx/jest:jest",
      "outputs": ["{workspaceRoot}/coverage/{projectRoot}"],
      "options": {
        "jestConfig": "packages/x-reason/jest.config.ts"
      }
    }
  }
}
````

## File: packages/x-reason/README.md
````markdown
# x-reason

This library was generated with [Nx](https://nx.dev).

## Building

Run `nx build x-reason` to build the library.

## Running unit tests

Run `nx test x-reason` to execute the unit tests via [Jest](https://jestjs.io).
````

## File: packages/x-reason/tsconfig.json
````json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "module": "commonjs",
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "importHelpers": true,
    "noImplicitOverride": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noPropertyAccessFromIndexSignature": false
  },
  "files": [],
  "include": [],
  "references": [
    {
      "path": "./tsconfig.lib.json"
    },
    {
      "path": "./tsconfig.spec.json"
    }
  ]
}
````

## File: packages/x-reason/tsconfig.lib.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "declaration": true,
    "types": ["node"]
  },
  "include": ["src/**/*.ts"],
  "exclude": ["jest.config.ts", "src/**/*.spec.ts", "src/**/*.test.ts"]
}
````

## File: packages/x-reason/tsconfig.spec.json
````json
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "outDir": "../../dist/out-tsc",
    "module": "commonjs",
    "moduleResolution": "node10",
    "types": ["jest", "node"]
  },
  "include": [
    "jest.config.ts",
    "src/**/*.test.ts",
    "src/**/*.spec.ts",
    "src/**/*.d.ts"
  ]
}
````

## File: scripts/fix-npm-install.sh
````bash
#!/bin/bash

echo " Fixing npm install issues..."

# Check Node.js version
echo " Checking Node.js version..."
node_version=$(node -v)
echo "Current Node.js version: $node_version"

if [[ ! "$node_version" =~ ^v22\. ]]; then
    echo "  Warning: Node.js version should be 22.x for this project"
    echo "   Consider using nvm: nvm use 22"
fi

# Check npm version
echo " Checking npm version..."
npm_version=$(npm -v)
echo "Current npm version: $npm_version"

# Clean up existing installations
echo " Cleaning up existing node_modules and lock files..."
rm -rf node_modules
rm -rf .nx/installation
rm -f package-lock.json

# Clear npm cache
echo "  Clearing npm cache..."
npm cache clean --force

# Configure npm for better reliability
echo "  Configuring npm..."
npm config set fund false
npm config set audit false
npm config set progress false
npm config set loglevel error
npm config set prefer-offline true

# Install dependencies with nx wrapper skipped to prevent hanging
echo " Installing dependencies (skipping nx postinstall)..."
export NX_WRAPPER_SKIP_INSTALL=true
npm install --no-fund --no-audit --prefer-offline

if [ $? -eq 0 ]; then
    echo " npm install completed successfully!"
    
    # Now manually initialize nx
    echo " Initializing nx installation..."
    npx nx --version
    
    if [ $? -eq 0 ]; then
        echo " Setup completed successfully!"
    else
        echo "  nx initialization had issues but dependencies are installed"
    fi
else
    echo " npm install failed. Try running this script again or check your internet connection."
    exit 1
fi
````

## File: .actrc
````
# Use Node.js 20
-P ubuntu-latest=node:20-buster-slim

# Workflow Path
-W .github/workflows

# Reuse Containers
--reuse

# Secrets File
--secret-file .secrets

#skip download if we have already got it
--pull=false 

--input base-ref=master
````

## File: .gitignore
````
.secrets
node_modules/
.env/
.env
buildAndPublish.sh
.DS_Store/
.DS_Store
testGitWorklows.sh
.vscode
.nx/installation
.nx/cache
.nx/workspace-data
/packages/**/.env

# dev TLS certs/keys
apps/**/certificates/*.pem
*.key
*.p12
*.pfx
*.crt

.cursor/rules/nx-rules.mdc
.github/instructions/nx.instructions.md
/dist
.verdaccio/
/tmp

# Next.js
.next
out
````

## File: .npmrc
````
fund=false
audit=false
progress=false
loglevel=error
registry=https://registry.npmjs.org/
prefer-offline=true
cache-max=86400000

# Prevent nx wrapper from hanging during npm install
# The nx installation will be handled manually after npm install completes
````

## File: .nvmrc
````
22.13.0
````

## File: .nxignore
````
.github/**
hello-world/**
.vercel/**
````

## File: .prettierignore
````
# Add files here to ignore them from prettier formatting
/dist
/coverage
/.nx/cache
/.nx/workspace-data
````

## File: .prettierrc
````
{
  "singleQuote": true
}
````

## File: CHANGELOG.md
````markdown
## 1.2.5 (2025-08-06)

This was a version bump only, there were no code changes.

## 1.2.4 (2025-08-06)

This was a version bump only, there were no code changes.

## 1.3.0 (2025-08-05)

This was a version bump only, there were no code changes.
````

## File: eslint.config.mjs
````
import nx from '@nx/eslint-plugin';

export default [
  ...nx.configs['flat/base'],
  ...nx.configs['flat/typescript'],
  ...nx.configs['flat/javascript'],
  {
    ignores: ['**/dist'],
  },
  {
    files: ['**/*.ts', '**/*.tsx', '**/*.js', '**/*.jsx'],
    rules: {
      '@nx/enforce-module-boundaries': [
        'error',
        {
          enforceBuildableLibDependency: true,
          allow: ['^.*/eslint(\\.base)?\\.config\\.[cm]?[jt]s$'],
          depConstraints: [
            {
              sourceTag: '*',
              onlyDependOnLibsWithTags: ['*'],
            },
          ],
        },
      ],
    },
  },
  {
    files: [
      '**/*.ts',
      '**/*.tsx',
      '**/*.cts',
      '**/*.mts',
      '**/*.js',
      '**/*.jsx',
      '**/*.cjs',
      '**/*.mjs',
    ],
    // Override or add rules here
    rules: {},
  },
];
````

## File: jest.config.ts
````typescript
import type { Config } from 'jest';
import { getJestProjectsAsync } from '@nx/jest';

export default async (): Promise<Config> => ({
  projects: await getJestProjectsAsync(),
});
````

## File: jest.preset.js
````javascript
const nxPreset = require('@nx/jest/preset').default;

module.exports = { ...nxPreset };
````

## File: LICENSE
````
MIT License

Copyright (c) 2025 Dorian Smiley

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
````

## File: nx
````
#!/bin/bash
command -v node >/dev/null 2>&1 || { echo >&2 "Nx requires NodeJS to be available. To install NodeJS and NPM, see: https://nodejs.org/en/download/ ."; exit 1; }
command -v npm >/dev/null 2>&1 || { echo >&2 "Nx requires npm to be available. To install NodeJS and NPM, see: https://nodejs.org/en/download/ ."; exit 1; }
path_to_root=$(dirname $BASH_SOURCE)
node $path_to_root/.nx/nxw.js $@
````

## File: nx.bat
````
@ECHO OFF
SETLOCAL
SET path_to_root=%~dp0
WHERE node >nul 2>nul
IF %ERRORLEVEL% NEQ 0 (ECHO Nx requires NodeJS to be available. To install NodeJS and NPM, see: https://nodejs.org/en/download/ . & GOTO exit)
WHERE npm >nul 2>nul
IF %ERRORLEVEL% NEQ 0 (ECHO Nx requires npm to be available. To install NodeJS and NPM, see: https://nodejs.org/en/download/ . & GOTO exit)
node %path_to_root%\.nx\nxw.js %*
:exit
  cmd /c exit /b %ERRORLEVEL%
````

## File: nx.json
````json
{
  "exclude": ["hello-world"],
  "installation": {
    "version": "21.3.10",
    "plugins": {
      "@nx/eslint": "21.3.10",
      "@nx/jest": "21.3.10"
    }
  },
  "$schema": "./node_modules/nx/schemas/nx-schema.json",
  "defaultBase": "master",
  "targetDefaults": {
    "@nx/js:tsc": {
      "cache": true,
      "dependsOn": ["^build"],
      "inputs": ["default", "^default"]
    }
  },
  "release": {
    "projects": ["packages/**/*"],
    "version": {
      "preVersionCommand": "npx nx run-many -t build --parallel=3 --skip-nx-cache=false"
    }
  },
  "plugins": [
    {
      "plugin": "@nx/eslint/plugin",
      "options": {
        "targetName": "eslint:lint"
      }
    },
    {
      "plugin": "@nx/jest/plugin",
      "options": {
        "targetName": "jest:test"
      }
    },
    {
      "plugin": "@nx/next/plugin",
      "options": {
        "startTargetName": "start",
        "buildTargetName": "build",
        "devTargetName": "dev",
        "serveStaticTargetName": "serve-static",
        "buildDepsTargetName": "build-deps",
        "watchDepsTargetName": "watch-deps"
      }
    },
    {
      "plugin": "@nx/playwright/plugin",
      "options": {
        "targetName": "e2e"
      }
    }
  ],
  "generators": {
    "@nx/next": {
      "application": {
        "style": "css",
        "linter": "eslint"
      }
    }
  }
}
````

## File: package.json
````json
{
  "name": "@codestrap/foundry-developer-foundations",
  "version": "1.0.0",
  "description": "Foundry Developer Foundations - A reference implementation of the Foundrybacked / GitHubnative collaboration pattern",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/doriansmiley/foundry-developer-foundations.git"
  },
  "bugs": {
    "url": "https://github.com/doriansmiley/foundry-developer-foundations/issues"
  },
  "homepage": "https://github.com/doriansmiley/foundry-developer-foundations",
  "keywords": [
    "foundry",
    "palantir",
    "typescript",
    "nx",
    "monorepo",
    "ai",
    "reasoning",
    "tracing",
    "telemetry"
  ],
  "author": "Dorian Smiley <dsmiley@codestrap.me>",
  "private": true,
  "workspaces": {
    "packages": [
      "packages/*",
      "packages/*/*",
      "foundry-tracing-foundations"
    ],
    "ignore": [
      ".github/**"
    ]
  },
  "packageManager": "npm@10.9.0",
  "scripts": {
    "nx": "nx",
    "build": "nx run-many --target=build",
    "test": "nx run-many --target=test",
    "lint": "nx run-many --target=lint",
    "clean": "nx reset && rm -rf node_modules",
    "prebuild": "nx run-many --target=clean"
  },
  "dependencies": {
    "@codestrap/developer-foundations.foundry-tracing-foundations": "^1.2.3",
    "@elevenlabs/react": "^0.1.7",
    "@google/generative-ai": "^0.24.1",
    "@mendable/firecrawl-js": "^1.29.3",
    "@osdk/client": "^2.2.1",
    "@osdk/foundry.admin": "^2.22.0",
    "@osdk/oauth": "^1.1.2",
    "@palantir/compute-module": "0.2.7",
    "@playwright/test": "^1.52.0",
    "@radix-ui/react-icons": "^1.3.1",
    "@radix-ui/react-slot": "^1.1.0",
    "@sinclair/typebox": "^0.34.33",
    "@types/node-fetch": "^2.6.12",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.1",
    "cors": "^2.8.5",
    "eslint-plugin-import": "^2.31.0",
    "googleapis": "^149.0.0",
    "inversify": "^7.5.1",
    "lucide-react": "^0.454.0",
    "next": "~15.2.4",
    "node-fetch": "^3.3.2",
    "openai": "^4.92.1",
    "ramda": "^0.30.1",
    "react": "19.0.0",
    "react-dom": "19.0.0",
    "tailwind-merge": "^2.5.4",
    "tailwindcss-animate": "^1.0.7",
    "vega-embed": "^7.0.2",
    "xstate": "4.37.2"
  },
  "devDependencies": {
    "@eslint/compat": "^1.2.9",
    "@eslint/eslintrc": "^3.3.1",
    "@eslint/js": "^9.26.0",
    "@google/genai": "1.12.0",
    "@next/eslint-plugin-next": "^15.2.4",
    "@nx/devkit": "21.3.10",
    "@nx/esbuild": "21.3.10",
    "@nx/eslint": "21.3.10",
    "@nx/eslint-plugin": "21.3.10",
    "@nx/jest": "21.3.10",
    "@nx/js": "21.3.10",
    "@nx/next": "21.3.10",
    "@nx/playwright": "21.3.10",
    "@swc-node/register": "~1.9.1",
    "@swc/cli": "~0.6.0",
    "@swc/core": "~1.5.7",
    "@swc/helpers": "^0.5.17",
    "@testing-library/dom": "10.4.0",
    "@testing-library/react": "16.1.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^22.15.3",
    "@types/ramda": "^0.30.2",
    "@types/react": "19.0.0",
    "@types/react-dom": "19.0.0",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "babel-jest": "^30.0.2",
    "cross-env": "^7.0.3",
    "dotenv": "^16.5.0",
    "eslint": "^9.26.0",
    "eslint-config-next": "^15.2.4",
    "eslint-config-prettier": "^10.0.0",
    "eslint-import-resolver-typescript": "^4.3.4",
    "eslint-plugin-jsx-a11y": "6.10.1",
    "eslint-plugin-playwright": "^1.6.2",
    "eslint-plugin-react": "7.35.0",
    "eslint-plugin-react-hooks": "5.0.0",
    "globals": "^16.0.0",
    "install": "0.13.0",
    "jest": "^29.7.0",
    "jest-environment-jsdom": "^30.0.2",
    "jest-environment-node": "^30.0.2",
    "jest-util": "^30.0.2",
    "jsonc-eslint-parser": "^2.1.0",
    "npm": "11.5.2",
    "nx": "21.3.10",
    "prettier": "^2.6.2",
    "ts-jest": "^29.3.2",
    "ts-node": "^10.9.2",
    "tsconfig-paths": "^4.2.0",
    "tslib": "^2.3.0",
    "tsup": "^8.5.0",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5.8.3",
    "typescript-eslint": "^8.29.0",
    "verdaccio": "^6.0.5"
  },
  "engines": {
    "node": ">=22.13.0"
  },
  "nx": {
    "includedScripts": []
  }
}
````

## File: project.json
````json
{
  "name": "@codestrap/foundry-developer-foundations",
  "$schema": "node_modules/nx/schemas/project-schema.json",
  "targets": {
    "local-registry": {
      "executor": "@nx/js:verdaccio",
      "options": {
        "port": 4873,
        "config": ".verdaccio/config.yml",
        "storage": "tmp/local-registry/storage"
      }
    }
  }
}
````

## File: PUBLISHING.md
````markdown
# Pubslishing with Nx

Run

`nx release version`

then

`nx release publish --otp=<one_time_password>`

More info: https://nx.dev/reference/core-api/nx/documents/release
````

## File: README.md
````markdown
# WiP: Foundry Developer Foundations

### IMPORTANT: This project is under active development and refactoring in preparation for v0

# If you are a developer and want to learn and contribute to this project email me at dsmiley@codestrap.me and I will train you. This is a limited time offer while we build our core user and contributor base.

### IMPORTANT: This README is also under active development and not ready for use.

Do not use this code in your applications. We are looking for contributors. You can participate without a Foundry stack by following the contributor guide. We expect a v0 release in June 2025.

## Introduction

Foundry Developer Foundations is a reference implementation of the **Foundrybacked / GitHubnative** collaboration pattern created by CodeStrap, LLC.
The goal: let any JavaScript/TypeScript engineer contribute business logic to a PalantirFoundry deployment **without needing direct Foundry expertise or access**.

- **Foundry holds the data model and actions**  i.e. a `HelloWorldFunction` action updates the `World` ontology object.
- **GitHub holds all application code**  i.e. services, data access objects (DAO), logic, tests, CI/CD, APIs, and containers.
- **Clean implementation abstraction (DAO + ComputeModule)** isolates Foundry specifics behind a function interface, so the rest of the codebase behaves like a normal Node project (using dependency injection via Inversify).
- **Foundry Mocks** an included mock Foundry instance exposes the API routes required for the application with mock responses so developers don't have to supply a Foundry stack. Simple updated the `FOUNDRY_STACK_URL` to point to your `localhost` where the mocks are running. Jest mocks are also used for unit tests.

By following this pattern you can:

1. **Unblock external teams**  they develop, run tests, and ship PRs with no Foundry account.
2. **Enforce clear contracts**  DAOs expose _entities in  entities out_; meaning you can swap backends with something like a MongoDB instance or whatever persistence store you like.
3. **Reuse familiar tooling**  npm workspaces, eslint, GitHub Actions, container builds.
4. **Deploy predictably**  a single Docker image pushed to Foundrys registry and released via pipeline.

## Getting Started

### Prerequisites

- Node.js 22.13.0 or higher (use `nvm use` if you have nvm installed)
- npm 10.9.0 or higher

### Installation

**Common Issue**: npm install may hang during nx postinstall setup. If you're experiencing npm install issues (hanging or timeouts), run our fix script:

```bash
./scripts/fix-npm-install.sh
```

Or manually:

```bash
# Use the correct Node.js version
nvm use 22

# Clean install (skip nx postinstall to prevent hanging)
rm -rf node_modules package-lock.json .nx/installation
npm cache clean --force
export NX_WRAPPER_SKIP_INSTALL=true
npm install --no-fund --no-audit --prefer-offline

# Initialize nx after npm install completes
npx nx --version
```

### Quick Start

Checkout the [hello world](/hello-world/README.md) sample application to see an implementation of this pattern. Then explore our open source projects including Foundry Tracing Foundation and X-Reason!

### NX Run
```
# In VS Code Run
cmd + shift + p
Then in search bar type "nx run" then select the project then the command you want to run

Run "nx generate" to see a list of generators

```
From terminal run
```
# to see the dependency graph
nx dep-graph
```
````

## File: tsconfig.base.json
````json
{
  "compileOnSave": false,
  "compilerOptions": {
    "rootDir": ".",
    "sourceMap": true,
    "declaration": false,
    "moduleResolution": "node",
    "emitDecoratorMetadata": true,
    "experimentalDecorators": true,
    "importHelpers": true,
    "target": "es2015",
    "module": "esnext",
    "lib": ["es2020", "dom"],
    "skipLibCheck": true,
    "skipDefaultLibCheck": true,
    "baseUrl": ".",
    "paths": {
      "@codestrap/developer-foundations-agents-vickie-bennie": [
        "packages/agents/vickie-bennie/src/index.ts"
      ],
      "@codestrap/developer-foundations-di": ["packages/di/src/index.ts"],
      "@codestrap/developer-foundations-services-eia": [
        "packages/services/eia/src/index.ts"
      ],
      "@codestrap/developer-foundations-services-google": [
        "packages/services/google/src/index.ts"
      ],
      "@codestrap/developer-foundations-services-palantir": [
        "packages/services/palantir/src/index.ts"
      ],
      "@codestrap/developer-foundations-services-rangr": [
        "packages/services/rangr/src/index.ts"
      ],
      "@codestrap/developer-foundations-services-slack": [
        "packages/services/slack/src/index.ts"
      ],
      "@codestrap/developer-foundations-services-weather": [
        "packages/services/weather/src/index.ts"
      ],
      "@codestrap/developer-foundations-types": ["packages/types/src/index.ts"],
      "@codestrap/developer-foundations-utils": ["packages/utils/src/index.ts"],
      "@codestrap/developer-foundations-x-reason": [
        "packages/x-reason/src/index.ts"
      ],
      "@codestrap/developer-foundations.foundry-tracing-foundations": [
        "packages/foundry-tracing-foundations/src/index.ts"
      ]
    }
  },
  "exclude": ["node_modules", "tmp"]
}
````
